Attaching to upgrade_recon_1, upgrade_dn3_1, upgrade_scm_1, upgrade_om_1, upgrade_s3g_1, upgrade_dn1_1, upgrade_dn2_1
dn1_1    | 2020-12-11 02:29:01 INFO  HddsDatanodeService:51 - STARTUP_MSG: 
dn1_1    | /************************************************************
dn1_1    | STARTUP_MSG: Starting HddsDatanodeService
dn1_1    | STARTUP_MSG:   host = 2f75b8e14cd7/10.9.0.11
dn1_1    | STARTUP_MSG:   args = []
dn1_1    | STARTUP_MSG:   version = 3.2.0
dn1_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.9.9.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta-tests.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-beta.jar
dn3_1    | 2020-12-11 02:29:05 INFO  HddsDatanodeService:51 - STARTUP_MSG: 
dn3_1    | /************************************************************
dn3_1    | STARTUP_MSG: Starting HddsDatanodeService
dn3_1    | STARTUP_MSG:   host = 1f38abbb791f/10.9.0.13
dn3_1    | STARTUP_MSG:   args = []
dn3_1    | STARTUP_MSG:   version = 3.2.0
dn3_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.9.9.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta-tests.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-beta.jar
dn3_1    | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
dn3_1    | STARTUP_MSG:   java = 11.0.3
dn3_1    | ************************************************************/
dn3_1    | 2020-12-11 02:29:05 INFO  HddsDatanodeService:51 - registered UNIX signal handlers for [TERM, HUP, INT]
dn3_1    | 2020-12-11 02:29:07 INFO  MetricRegistries:64 - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn3_1    | 2020-12-11 02:29:08 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
dn3_1    | 2020-12-11 02:29:09 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
dn3_1    | 2020-12-11 02:29:09 INFO  MetricsSystemImpl:191 - HddsDatanode metrics system started
dn3_1    | 2020-12-11 02:29:10 INFO  HddsDatanodeService:204 - HddsDatanodeService host:1f38abbb791f ip:10.9.0.13
dn3_1    | 2020-12-11 02:29:11 INFO  SaveSpaceUsageToFile:94 - Cached usage info file /data/hdds/scmUsed not found
dn3_1    | 2020-12-11 02:29:11 INFO  HddsVolume:173 - Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 14727258112
dn3_1    | 2020-12-11 02:29:11 INFO  VolumeSet:180 - Added Volume : /data/hdds/hdds to VolumeSet
dn3_1    | 2020-12-11 02:29:11 INFO  ThrottledAsyncChecker:141 - Scheduling a check for /data/hdds/hdds
dn3_1    | 2020-12-11 02:29:11 INFO  HddsVolumeChecker:199 - Scheduled health check for volume /data/hdds/hdds
dn3_1    | 2020-12-11 02:29:17 WARN  ServerUtils:237 - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn3_1    | 2020-12-11 02:29:17 INFO  RaftServerProxy:43 - raft.rpc.type = GRPC (default)
dn3_1    | 2020-12-11 02:29:18 INFO  GrpcConfigKeys$Server:43 - raft.grpc.server.port = 9858 (custom)
dn3_1    | 2020-12-11 02:29:18 INFO  GrpcService:43 - raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn3_1    | 2020-12-11 02:29:18 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2020-12-11 02:29:18 INFO  GrpcService:43 - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn3_1    | 2020-12-11 02:29:18 INFO  RaftServerConfigKeys:43 - raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2020-12-11 02:29:19 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2020-12-11 02:29:19 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
dn3_1    | 2020-12-11 02:29:19 INFO  BaseHttpServer:170 - Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn3_1    | 2020-12-11 02:29:20 INFO  log:169 - Logging initialized @20070ms to org.eclipse.jetty.util.log.Slf4jLog
dn3_1    | 2020-12-11 02:29:20 INFO  AuthenticationFilter:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn3_1    | 2020-12-11 02:29:20 INFO  HttpRequestLog:86 - Http request log for http.requests.hddsDatanode is not defined
dn3_1    | 2020-12-11 02:29:20 INFO  HttpServer2:970 - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn3_1    | 2020-12-11 02:29:20 INFO  HttpServer2:946 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn3_1    | 2020-12-11 02:29:20 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
dn3_1    | 2020-12-11 02:29:20 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
dn3_1    | 2020-12-11 02:29:20 INFO  HttpServer2:1188 - Jetty bound to port 9882
dn3_1    | 2020-12-11 02:29:20 INFO  Server:359 - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.3+7-LTS
dn3_1    | 2020-12-11 02:29:20 INFO  session:333 - DefaultSessionIdManager workerName=node0
dn3_1    | 2020-12-11 02:29:20 INFO  session:338 - No SessionScavenger set, using defaults
dn3_1    | 2020-12-11 02:29:20 INFO  session:140 - node0 Scavenging every 660000ms
dn3_1    | 2020-12-11 02:29:20 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@4e682398{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn3_1    | 2020-12-11 02:29:20 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@3f1a4795{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar!/webapps/static,AVAILABLE}
dn3_1    | 2020-12-11 02:29:21 INFO  ContextHandler:825 - Started o.e.j.w.WebAppContext@3166f664{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_5_0-beta_jar-_-any-16077012953651058640.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar!/webapps/hddsDatanode}
dn3_1    | 2020-12-11 02:29:21 INFO  AbstractConnector:330 - Started ServerConnector@77c233af{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
dn3_1    | 2020-12-11 02:29:21 INFO  Server:399 - Started @21574ms
dn3_1    | 2020-12-11 02:29:21 INFO  MetricsSinkAdapter:204 - Sink prometheus started
dn3_1    | 2020-12-11 02:29:21 INFO  MetricsSystemImpl:301 - Registered sink prometheus
dn3_1    | 2020-12-11 02:29:21 INFO  BaseHttpServer:284 - HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn3_1    | 2020-12-11 02:29:21 INFO  JvmPauseMonitor:188 - Starting JVM pause monitor
dn3_1    | 2020-12-11 02:29:22 INFO  SCMConnectionManager:142 - Adding Recon Server : recon/10.9.0.15:9891
dn3_1    | 2020-12-11 02:29:22 INFO  InitDatanodeState:147 - DatanodeDetails is persisted to /data/datanode.id
dn3_1    | 2020-12-11 02:29:24 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
dn3_1    | 2020-12-11 02:29:24 WARN  EndpointStateMachine:217 - Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn3_1    | java.net.SocketTimeoutException: Call From 1f38abbb791f/10.9.0.13 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.13:49314 remote=recon/10.9.0.15:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn3_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn3_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn3_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn3_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn3_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
dn3_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
dn3_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
dn3_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
dn3_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
dn3_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
dn3_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
dn3_1    | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
dn3_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
dn3_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
om_1     | 2020-12-11 02:29:06 INFO  OzoneManagerStarter:51 - STARTUP_MSG: 
om_1     | /************************************************************
om_1     | STARTUP_MSG: Starting OzoneManager
om_1     | STARTUP_MSG:   host = ae483b72d770/10.9.0.14
om_1     | STARTUP_MSG:   args = [--init]
om_1     | STARTUP_MSG:   version = 3.2.0
om_1     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.9.9.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-beta.jar
om_1     | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1     | STARTUP_MSG:   java = 11.0.3
om_1     | ************************************************************/
om_1     | 2020-12-11 02:29:06 INFO  OzoneManagerStarter:51 - registered UNIX signal handlers for [TERM, HUP, INT]
om_1     | 2020-12-11 02:29:11 INFO  OMHANodeDetails:104 - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1     | 2020-12-11 02:29:11 INFO  OMHANodeDetails:207 - Configuration either no ozone.om.address set. Falling back to the default OM address om/10.9.0.14:9862
om_1     | 2020-12-11 02:29:11 INFO  OMHANodeDetails:237 - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1     | 2020-12-11 02:29:12 WARN  ServerUtils:225 - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1     | 2020-12-11 02:29:12 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
om_1     | 2020-12-11 02:29:14 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-11 02:29:15 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-11 02:29:16 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-11 02:29:17 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-11 02:29:18 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-11 02:29:19 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-11 02:29:20 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-11 02:29:21 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-11 02:29:22 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-11 02:29:23 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om_1     | 2020-12-11 02:29:23 INFO  RetriableTask:62 - Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om_1     | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-d36fba17-d19d-4677-a235-d22714b3e2db
om_1     | 2020-12-11 02:29:30 INFO  OzoneManagerStarter:51 - SHUTDOWN_MSG: 
om_1     | /************************************************************
om_1     | SHUTDOWN_MSG: Shutting down OzoneManager at ae483b72d770/10.9.0.14
om_1     | ************************************************************/
om_1     | 2020-12-11 02:29:33 INFO  OzoneManagerStarter:51 - STARTUP_MSG: 
om_1     | /************************************************************
om_1     | STARTUP_MSG: Starting OzoneManager
om_1     | STARTUP_MSG:   host = ae483b72d770/10.9.0.14
om_1     | STARTUP_MSG:   args = []
om_1     | STARTUP_MSG:   version = 3.2.0
dn1_1    | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
dn1_1    | STARTUP_MSG:   java = 11.0.3
dn1_1    | ************************************************************/
dn1_1    | 2020-12-11 02:29:01 INFO  HddsDatanodeService:51 - registered UNIX signal handlers for [TERM, HUP, INT]
dn1_1    | 2020-12-11 02:29:03 INFO  MetricRegistries:64 - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn1_1    | 2020-12-11 02:29:04 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
dn1_1    | 2020-12-11 02:29:05 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
dn1_1    | 2020-12-11 02:29:05 INFO  MetricsSystemImpl:191 - HddsDatanode metrics system started
dn1_1    | 2020-12-11 02:29:06 INFO  HddsDatanodeService:204 - HddsDatanodeService host:2f75b8e14cd7 ip:10.9.0.11
dn1_1    | 2020-12-11 02:29:07 INFO  SaveSpaceUsageToFile:94 - Cached usage info file /data/hdds/scmUsed not found
dn1_1    | 2020-12-11 02:29:07 INFO  HddsVolume:173 - Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 14727258112
dn1_1    | 2020-12-11 02:29:07 INFO  VolumeSet:180 - Added Volume : /data/hdds/hdds to VolumeSet
dn1_1    | 2020-12-11 02:29:07 INFO  ThrottledAsyncChecker:141 - Scheduling a check for /data/hdds/hdds
dn1_1    | 2020-12-11 02:29:07 INFO  HddsVolumeChecker:199 - Scheduled health check for volume /data/hdds/hdds
dn1_1    | 2020-12-11 02:29:13 WARN  ServerUtils:237 - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn1_1    | 2020-12-11 02:29:13 INFO  RaftServerProxy:43 - raft.rpc.type = GRPC (default)
dn1_1    | 2020-12-11 02:29:14 INFO  GrpcConfigKeys$Server:43 - raft.grpc.server.port = 9858 (custom)
dn1_1    | 2020-12-11 02:29:14 INFO  GrpcService:43 - raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn1_1    | 2020-12-11 02:29:14 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2020-12-11 02:29:14 INFO  GrpcService:43 - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn1_1    | 2020-12-11 02:29:14 INFO  RaftServerConfigKeys:43 - raft.server.rpc.request.timeout = 60s (custom)
dn1_1    | 2020-12-11 02:29:15 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2020-12-11 02:29:16 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
dn1_1    | 2020-12-11 02:29:16 INFO  BaseHttpServer:170 - Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn1_1    | 2020-12-11 02:29:16 INFO  log:169 - Logging initialized @19860ms to org.eclipse.jetty.util.log.Slf4jLog
dn1_1    | 2020-12-11 02:29:17 INFO  AuthenticationFilter:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn1_1    | 2020-12-11 02:29:17 INFO  HttpRequestLog:86 - Http request log for http.requests.hddsDatanode is not defined
dn1_1    | 2020-12-11 02:29:17 INFO  HttpServer2:970 - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn1_1    | 2020-12-11 02:29:17 INFO  HttpServer2:946 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn1_1    | 2020-12-11 02:29:17 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
dn1_1    | 2020-12-11 02:29:17 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
dn1_1    | 2020-12-11 02:29:17 INFO  HttpServer2:1188 - Jetty bound to port 9882
dn1_1    | 2020-12-11 02:29:17 INFO  Server:359 - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.3+7-LTS
dn1_1    | 2020-12-11 02:29:17 INFO  session:333 - DefaultSessionIdManager workerName=node0
dn1_1    | 2020-12-11 02:29:17 INFO  session:338 - No SessionScavenger set, using defaults
dn1_1    | 2020-12-11 02:29:17 INFO  session:140 - node0 Scavenging every 600000ms
dn1_1    | 2020-12-11 02:29:17 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@670b3ca{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn1_1    | 2020-12-11 02:29:17 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@6a6f6c7e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar!/webapps/static,AVAILABLE}
dn1_1    | 2020-12-11 02:29:18 INFO  ContextHandler:825 - Started o.e.j.w.WebAppContext@47ac613b{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_5_0-beta_jar-_-any-5083597774517692203.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar!/webapps/hddsDatanode}
dn1_1    | 2020-12-11 02:29:18 INFO  AbstractConnector:330 - Started ServerConnector@37b56ac7{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
dn1_1    | 2020-12-11 02:29:18 INFO  Server:399 - Started @21611ms
dn1_1    | 2020-12-11 02:29:18 INFO  MetricsSinkAdapter:204 - Sink prometheus started
dn1_1    | 2020-12-11 02:29:18 INFO  MetricsSystemImpl:301 - Registered sink prometheus
dn1_1    | 2020-12-11 02:29:18 INFO  BaseHttpServer:284 - HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn1_1    | 2020-12-11 02:29:18 INFO  JvmPauseMonitor:188 - Starting JVM pause monitor
dn1_1    | 2020-12-11 02:29:19 INFO  SCMConnectionManager:142 - Adding Recon Server : recon/10.9.0.15:9891
dn1_1    | 2020-12-11 02:29:19 INFO  InitDatanodeState:147 - DatanodeDetails is persisted to /data/datanode.id
dn1_1    | 2020-12-11 02:29:21 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
dn1_1    | 2020-12-11 02:29:22 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
dn1_1    | 2020-12-11 02:29:23 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
dn1_1    | 2020-12-11 02:29:24 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
dn1_1    | 2020-12-11 02:29:25 WARN  EndpointStateMachine:217 - Unable to communicate to SCM server at scm:9861 for past 0 seconds.
dn1_1    | java.net.SocketTimeoutException: Call From 2f75b8e14cd7/10.9.0.11 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.11:56244 remote=scm/10.9.0.17:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn1_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn1_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn1_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn1_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn1_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
dn1_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
dn1_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
dn3_1    | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.13:49314 remote=recon/10.9.0.15:9891]
dn3_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn3_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn3_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn3_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn3_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
dn3_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn3_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
dn3_1    | 2020-12-11 02:29:25 WARN  EndpointStateMachine:217 - Unable to communicate to SCM server at scm:9861 for past 0 seconds.
dn3_1    | java.net.SocketTimeoutException: Call From 1f38abbb791f/10.9.0.13 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.13:46764 remote=scm/10.9.0.17:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn3_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn3_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn3_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn3_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn3_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
dn3_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
dn3_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
dn3_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
dn3_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
dn3_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
dn3_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
dn3_1    | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
dn3_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
dn3_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
dn3_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
dn3_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn3_1    | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.13:46764 remote=scm/10.9.0.17:9861]
dn3_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn3_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn3_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn3_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn3_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn3_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
dn3_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn3_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
dn3_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
dn3_1    | 2020-12-11 02:29:30 INFO  OzoneContainer:230 - Attempting to start container services.
dn3_1    | 2020-12-11 02:29:30 INFO  OzoneContainer:194 - Background container scanner has been disabled.
dn3_1    | 2020-12-11 02:29:30 INFO  XceiverServerRatis:415 - Starting XceiverServerRatis e927a432-7d30-4eab-9c57-07bc74eb3997 at port 9858
dn3_1    | 2020-12-11 02:29:30 INFO  RaftServerProxy:299 - e927a432-7d30-4eab-9c57-07bc74eb3997: start RPC server
dn3_1    | 2020-12-11 02:29:31 INFO  GrpcService:158 - e927a432-7d30-4eab-9c57-07bc74eb3997: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
dn3_1    | 2020-12-11 02:29:34 INFO  RaftServerProxy:89 - e927a432-7d30-4eab-9c57-07bc74eb3997: addNew group-E649B78A07B0:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858] returns group-E649B78A07B0:java.util.concurrent.CompletableFuture@4c86bab6[Not completed]
dn3_1    | 2020-12-11 02:29:34 INFO  RaftServerImpl:97 - e927a432-7d30-4eab-9c57-07bc74eb3997: new RaftServerImpl for group-E649B78A07B0:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858] with ContainerStateMachine:uninitialized
dn3_1    | 2020-12-11 02:29:34 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2020-12-11 02:29:34 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2020-12-11 02:29:34 INFO  RaftServerConfigKeys:43 - raft.server.rpcslowness.timeout = 300s (custom)
dn3_1    | 2020-12-11 02:29:34 INFO  RaftServerConfigKeys:43 - raft.server.sleep.deviation.threshold = 300 (default)
dn3_1    | 2020-12-11 02:29:34 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
dn1_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
dn1_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
dn1_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
dn1_1    | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
dn1_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
dn1_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
dn1_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
dn1_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn1_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
dn1_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn1_1    | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.11:56244 remote=scm/10.9.0.17:9861]
dn1_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn1_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn1_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn1_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn1_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn1_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
dn1_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn1_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
dn1_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
dn1_1    | 2020-12-11 02:29:30 INFO  OzoneContainer:230 - Attempting to start container services.
dn1_1    | 2020-12-11 02:29:30 INFO  OzoneContainer:194 - Background container scanner has been disabled.
dn1_1    | 2020-12-11 02:29:30 INFO  XceiverServerRatis:415 - Starting XceiverServerRatis f50c55c5-6776-4b64-8cb9-bd5a75d26a9a at port 9858
dn1_1    | 2020-12-11 02:29:30 INFO  RaftServerProxy:299 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: start RPC server
dn1_1    | 2020-12-11 02:29:31 INFO  GrpcService:158 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerProxy:89 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: addNew group-41EB68542FD0:[f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] returns group-41EB68542FD0:java.util.concurrent.CompletableFuture@5da65f64[Not completed]
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerImpl:97 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: new RaftServerImpl for group-41EB68542FD0:[f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] with ContainerStateMachine:uninitialized
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.rpcslowness.timeout = 300s (custom)
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.sleep.deviation.threshold = 300 (default)
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerImpl:103 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0: ConfigurationManager, init=-1: [f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858], old=null, confs=<EMPTY_MAP>
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2020-12-11 02:29:35 INFO  RaftStorageDirectory:253 - The storage directory /data/metadata/ratis/512805e8-9b7a-49ec-bd87-41eb68542fd0 does not exist. Creating ...
dn1_1    | 2020-12-11 02:29:35 INFO  RaftStorageDirectory:335 - Lock on /data/metadata/ratis/512805e8-9b7a-49ec-bd87-41eb68542fd0/in_use.lock acquired by nodename 7@2f75b8e14cd7
dn1_1    | 2020-12-11 02:29:35 INFO  RaftStorage:84 - Storage directory /data/metadata/ratis/512805e8-9b7a-49ec-bd87-41eb68542fd0 has been successfully formatted.
dn1_1    | 2020-12-11 02:29:35 INFO  ContainerStateMachine:228 - group-41EB68542FD0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.notification.no-leader.timeout = 60s (default)
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.use.memory = false (default)
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2020-12-11 02:29:35 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.log_worker.f50c55c5-6776-4b64-8cb9-bd5a75d26a9a
dn1_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  SegmentedRaftLogWorker:176 - new f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/512805e8-9b7a-49ec-bd87-41eb68542fd0
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.byte-limit = 2147483647 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2020-12-11 02:29:34 INFO  RaftServerImpl:103 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0: ConfigurationManager, init=-1: [e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858], old=null, confs=<EMPTY_MAP>
dn3_1    | 2020-12-11 02:29:34 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2020-12-11 02:29:34 INFO  RaftServerConfigKeys:43 - raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2020-12-11 02:29:34 INFO  RaftStorageDirectory:253 - The storage directory /data/metadata/ratis/7ffd4706-2840-4531-94d6-e649b78a07b0 does not exist. Creating ...
dn3_1    | 2020-12-11 02:29:34 INFO  RaftStorageDirectory:335 - Lock on /data/metadata/ratis/7ffd4706-2840-4531-94d6-e649b78a07b0/in_use.lock acquired by nodename 6@1f38abbb791f
dn3_1    | 2020-12-11 02:29:34 INFO  RaftStorage:84 - Storage directory /data/metadata/ratis/7ffd4706-2840-4531-94d6-e649b78a07b0 has been successfully formatted.
dn3_1    | 2020-12-11 02:29:34 INFO  ContainerStateMachine:228 - group-E649B78A07B0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn3_1    | 2020-12-11 02:29:34 INFO  RaftServerConfigKeys:43 - raft.server.notification.no-leader.timeout = 60s (default)
dn3_1    | 2020-12-11 02:29:34 INFO  RaftServerConfigKeys:43 - raft.server.log.use.memory = false (default)
dn3_1    | 2020-12-11 02:29:34 INFO  RaftServerConfigKeys:43 - raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2020-12-11 02:29:34 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2020-12-11 02:29:34 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2020-12-11 02:29:34 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.log_worker.e927a432-7d30-4eab-9c57-07bc74eb3997
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  SegmentedRaftLogWorker:176 - new e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/7ffd4706-2840-4531-94d6-e649b78a07b0
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.byte-limit = 2147483647 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  SegmentedRaftLogWorker:129 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.leader_election.e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0
dn3_1    | 2020-12-11 02:29:35 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.server.e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerImpl:183 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0: start as a follower, conf=-1: [e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858], old=null
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerImpl:172 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn3_1    | 2020-12-11 02:29:35 INFO  RoleInfo:143 - e927a432-7d30-4eab-9c57-07bc74eb3997: start FollowerState
dn3_1    | 2020-12-11 02:29:35 INFO  JmxRegister:44 - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E649B78A07B0,id=e927a432-7d30-4eab-9c57-07bc74eb3997
dn3_1    | 2020-12-11 02:29:35 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.state_machine.e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0
dn3_1    | 2020-12-11 02:29:35 INFO  CreatePipelineCommandHandler:109 - Created Pipeline RATIS ONE #id: "7ffd4706-2840-4531-94d6-e649b78a07b0"
dn3_1    | .
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerProxy:89 - e927a432-7d30-4eab-9c57-07bc74eb3997: addNew group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] returns group-E4B11790D590:java.util.concurrent.CompletableFuture@16fc5e0d[Not completed]
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerImpl:97 - e927a432-7d30-4eab-9c57-07bc74eb3997: new RaftServerImpl for group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] with ContainerStateMachine:uninitialized
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.max = 5200ms (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.rpcslowness.timeout = 300s (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.sleep.deviation.threshold = 300 (default)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerImpl:103 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590: ConfigurationManager, init=-1: [e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858], old=null, confs=<EMPTY_MAP>
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.corruption.policy = EXCEPTION (default)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftStorageDirectory:253 - The storage directory /data/metadata/ratis/915fef40-6db3-4e2c-8eb3-e4b11790d590 does not exist. Creating ...
dn3_1    | 2020-12-11 02:29:35 INFO  RaftStorageDirectory:335 - Lock on /data/metadata/ratis/915fef40-6db3-4e2c-8eb3-e4b11790d590/in_use.lock acquired by nodename 6@1f38abbb791f
dn3_1    | 2020-12-11 02:29:35 INFO  RaftStorage:84 - Storage directory /data/metadata/ratis/915fef40-6db3-4e2c-8eb3-e4b11790d590 has been successfully formatted.
dn3_1    | 2020-12-11 02:29:35 INFO  ContainerStateMachine:228 - group-E4B11790D590: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.notification.no-leader.timeout = 60s (default)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.use.memory = false (default)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.caching.enabled = true (custom)
om_1     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-tools-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.9.9.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-beta.jar
om_1     | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
om_1     | STARTUP_MSG:   java = 11.0.3
om_1     | ************************************************************/
om_1     | 2020-12-11 02:29:33 INFO  OzoneManagerStarter:51 - registered UNIX signal handlers for [TERM, HUP, INT]
om_1     | 2020-12-11 02:29:34 INFO  OMHANodeDetails:104 - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1     | 2020-12-11 02:29:34 INFO  OMHANodeDetails:207 - Configuration either no ozone.om.address set. Falling back to the default OM address om/10.9.0.14:9862
om_1     | 2020-12-11 02:29:34 INFO  OMHANodeDetails:237 - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1     | 2020-12-11 02:29:34 WARN  ServerUtils:225 - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1     | 2020-12-11 02:29:35 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
om_1     | 2020-12-11 02:29:35 WARN  ServerUtils:225 - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1     | 2020-12-11 02:29:37 WARN  ServerUtils:225 - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1     | 2020-12-11 02:29:38 INFO  CallQueueManager:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1     | 2020-12-11 02:29:38 INFO  Server:1074 - Starting Socket Reader #1 for port 9862
om_1     | 2020-12-11 02:29:39 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
om_1     | 2020-12-11 02:29:39 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
om_1     | 2020-12-11 02:29:39 INFO  MetricsSystemImpl:191 - OzoneManager metrics system started
om_1     | 2020-12-11 02:29:39 INFO  OzoneManager:1105 - OzoneManager RPC server is listening at om/10.9.0.14:9862
om_1     | 2020-12-11 02:29:39 INFO  Server:1314 - IPC Server Responder: starting
om_1     | 2020-12-11 02:29:39 INFO  Server:1153 - IPC Server listener on 9862: starting
om_1     | 2020-12-11 02:29:39 INFO  BaseHttpServer:170 - Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1     | 2020-12-11 02:29:39 INFO  log:169 - Logging initialized @8711ms to org.eclipse.jetty.util.log.Slf4jLog
om_1     | 2020-12-11 02:29:39 INFO  AuthenticationFilter:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om_1     | 2020-12-11 02:29:39 INFO  HttpRequestLog:86 - Http request log for http.requests.ozoneManager is not defined
om_1     | 2020-12-11 02:29:39 INFO  HttpServer2:970 - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1     | 2020-12-11 02:29:39 INFO  HttpServer2:946 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om_1     | 2020-12-11 02:29:39 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
om_1     | 2020-12-11 02:29:39 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
om_1     | 2020-12-11 02:29:39 INFO  HttpServer2:1188 - Jetty bound to port 9874
om_1     | 2020-12-11 02:29:39 INFO  Server:359 - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.3+7-LTS
om_1     | 2020-12-11 02:29:40 INFO  session:333 - DefaultSessionIdManager workerName=node0
om_1     | 2020-12-11 02:29:40 INFO  session:338 - No SessionScavenger set, using defaults
om_1     | 2020-12-11 02:29:40 INFO  session:140 - node0 Scavenging every 600000ms
om_1     | 2020-12-11 02:29:40 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@506a1372{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1     | 2020-12-11 02:29:40 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@5399f6c5{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-beta.jar!/webapps/static,AVAILABLE}
om_1     | 2020-12-11 02:29:40 INFO  ContextHandler:825 - Started o.e.j.w.WebAppContext@326e0b8e{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-0_5_0-beta_jar-_-any-5209524053144250197.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-0.5.0-beta.jar!/webapps/ozoneManager}
om_1     | 2020-12-11 02:29:40 INFO  AbstractConnector:330 - Started ServerConnector@541179e7{HTTP/1.1,[http/1.1]}{0.0.0.0:9874}
om_1     | 2020-12-11 02:29:40 INFO  Server:399 - Started @9158ms
om_1     | 2020-12-11 02:29:40 INFO  MetricsSinkAdapter:204 - Sink prometheus started
om_1     | 2020-12-11 02:29:40 INFO  MetricsSystemImpl:301 - Registered sink prometheus
om_1     | 2020-12-11 02:29:40 INFO  BaseHttpServer:284 - HTTP server of ozoneManager listening at http://0.0.0.0:9874
om_1     | 2020-12-11 02:29:48 INFO  OMVolumeCreateRequest:207 - created volume:topvol1 for user:hadoop
recon_1  | WARNING: An illegal reflective access operation has occurred
recon_1  | WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
recon_1  | WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
recon_1  | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1  | WARNING: All illegal access operations will be denied in a future release
recon_1  | 2020-12-11 02:29:04 INFO  ReconRestServletModule:75 - rest([/api/v1/*]).packages(org.apache.hadoop.ozone.recon.api)
recon_1  | 2020-12-11 02:29:06 INFO  ReconServer:73 - Initializing Recon server...
recon_1  | 2020-12-11 02:29:11 INFO  ReconServer:81 - Creating Recon Schema.
recon_1  | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
recon_1  | 2020-12-11 02:29:15 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
recon_1  | 2020-12-11 02:29:15 INFO  BaseHttpServer:170 - Starting Web-server for recon at: http://0.0.0.0:9888
recon_1  | 2020-12-11 02:29:15 INFO  log:169 - Logging initialized @17840ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1  | 2020-12-11 02:29:15 INFO  AuthenticationFilter:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
recon_1  | 2020-12-11 02:29:15 WARN  HttpRequestLog:103 - Jetty request log can only be enabled using Log4j
recon_1  | 2020-12-11 02:29:16 INFO  HttpServer2:970 - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1  | 2020-12-11 02:29:16 INFO  HttpServer2:946 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context recon
recon_1  | 2020-12-11 02:29:16 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
recon_1  | 2020-12-11 02:29:16 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
recon_1  | 2020-12-11 02:29:16 INFO  ReconTaskControllerImpl:81 - Registered task ContainerKeyMapperTask with controller.
recon_1  | 2020-12-11 02:29:19 INFO  ReconTaskControllerImpl:81 - Registered task FileSizeCountTask with controller.
recon_1  | 2020-12-11 02:29:20 WARN  ReconUtils:88 - ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2020-12-11 02:29:20 INFO  deprecation:1394 - No unit for recon.om.connection.request.timeout(5000) assuming MILLISECONDS
recon_1  | 2020-12-11 02:29:22 WARN  ReconUtils:88 - ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2020-12-11 02:29:22 INFO  NodeSchemaLoader:126 - Loading file from java.lang.CompoundEnumeration@6c8f60f3
recon_1  | 2020-12-11 02:29:22 INFO  NodeSchemaLoader:172 - Loading network topology layer schema file
recon_1  | 2020-12-11 02:29:22 INFO  SCMNodeManager:116 - Entering startup safe mode.
recon_1  | 2020-12-11 02:29:22 WARN  ReconUtils:88 - ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2020-12-11 02:29:22 INFO  ReconNodeManager:93 - Loaded 0 nodes from node DB.
recon_1  | 2020-12-11 02:29:22 INFO  CallQueueManager:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1  | 2020-12-11 02:29:22 INFO  Server:1074 - Starting Socket Reader #1 for port 9891
recon_1  | 2020-12-11 02:29:22 WARN  ReconUtils:88 - ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2020-12-11 02:29:22 INFO  SCMPipelineManager:150 - No pipeline exists in current db
recon_1  | 2020-12-11 02:29:22 WARN  ReconUtils:88 - ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2020-12-11 02:29:23 INFO  ReconScmTask:49 - Registered MissingContainerTask task 
recon_1  | 2020-12-11 02:29:23 INFO  ReconScmTask:49 - Registered PipelineSyncTask task 
recon_1  | 2020-12-11 02:29:23 INFO  ReconServer:89 - Recon server initialized successfully!
recon_1  | 2020-12-11 02:29:23 INFO  ReconServer:114 - Starting Recon server
recon_1  | 2020-12-11 02:29:23 INFO  HttpServer2:1188 - Jetty bound to port 9888
recon_1  | 2020-12-11 02:29:23 INFO  Server:359 - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.3+7-LTS
recon_1  | 2020-12-11 02:29:23 INFO  session:333 - DefaultSessionIdManager workerName=node0
recon_1  | 2020-12-11 02:29:23 INFO  session:338 - No SessionScavenger set, using defaults
recon_1  | 2020-12-11 02:29:23 INFO  session:140 - node0 Scavenging every 660000ms
recon_1  | 2020-12-11 02:29:23 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@1f44ddab{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1  | 2020-12-11 02:29:23 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@5b275174{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.5.0-beta.jar!/webapps/static,AVAILABLE}
recon_1  | 2020-12-11 02:29:25 INFO  ContextHandler:825 - Started o.e.j.w.WebAppContext@315b4202{recon,/,file:///tmp/jetty-0_0_0_0-9888-hadoop-ozone-recon-0_5_0-beta_jar-_-any-5526190220935309267.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-recon-0.5.0-beta.jar!/webapps/recon}
recon_1  | 2020-12-11 02:29:25 INFO  AbstractConnector:330 - Started ServerConnector@33d53216{HTTP/1.1,[http/1.1]}{0.0.0.0:9888}
recon_1  | 2020-12-11 02:29:25 INFO  Server:399 - Started @27779ms
recon_1  | 2020-12-11 02:29:30 INFO  BaseHttpServer:284 - HTTP server of recon listening at http://0.0.0.0:9888
recon_1  | 2020-12-11 02:29:30 INFO  OzoneManagerServiceProviderImpl:203 - Starting Ozone Manager Service Provider.
recon_1  | 2020-12-11 02:29:30 INFO  OzoneManagerServiceProviderImpl:181 - Registered OmDeltaRequest task 
recon_1  | 2020-12-11 02:29:30 INFO  OzoneManagerServiceProviderImpl:191 - Registered OmSnapshotRequest task 
recon_1  | 2020-12-11 02:29:30 INFO  ReconOmMetadataManagerImpl:64 - Starting ReconOMMetadataManagerImpl
recon_1  | 2020-12-11 02:29:30 WARN  ReconUtils:88 - ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1  | 2020-12-11 02:29:30 INFO  ReconTaskControllerImpl:230 - Starting Recon Task Controller.
recon_1  | 2020-12-11 02:29:30 INFO  ReconStorageContainerManagerFacade:179 - Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1  | 2020-12-11 02:29:31 INFO  ReconStorageContainerManagerFacade:224 - Obtained 0 pipelines from SCM.
recon_1  | 2020-12-11 02:29:31 INFO  ReconPipelineManager:88 - Recon has 0 pipelines in house.
recon_1  | 2020-12-11 02:29:31 INFO  SCMDatanodeProtocolServer:178 - RPC server for DataNodes is listening at /0.0.0.0:9891
dn1_1    | 2020-12-11 02:29:36 INFO  SegmentedRaftLogWorker:129 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.leader_election.f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0
dn1_1    | 2020-12-11 02:29:36 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.server.f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerImpl:183 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0: start as a follower, conf=-1: [f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858], old=null
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerImpl:172 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn1_1    | 2020-12-11 02:29:36 INFO  RoleInfo:143 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: start FollowerState
dn1_1    | 2020-12-11 02:29:36 INFO  JmxRegister:44 - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-41EB68542FD0,id=f50c55c5-6776-4b64-8cb9-bd5a75d26a9a
dn1_1    | 2020-12-11 02:29:36 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.state_machine.f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0
dn1_1    | 2020-12-11 02:29:36 INFO  CreatePipelineCommandHandler:109 - Created Pipeline RATIS ONE #id: "512805e8-9b7a-49ec-bd87-41eb68542fd0"
dn1_1    | .
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerProxy:89 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: addNew group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] returns group-E4B11790D590:java.util.concurrent.CompletableFuture@cef7689[Not completed]
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerImpl:97 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: new RaftServerImpl for group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] with ContainerStateMachine:uninitialized
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.min = 5s (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.max = 5200ms (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.rpcslowness.timeout = 300s (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.sleep.deviation.threshold = 300 (default)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerImpl:103 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590: ConfigurationManager, init=-1: [e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858], old=null, confs=<EMPTY_MAP>
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.corruption.policy = EXCEPTION (default)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftStorageDirectory:253 - The storage directory /data/metadata/ratis/915fef40-6db3-4e2c-8eb3-e4b11790d590 does not exist. Creating ...
dn1_1    | 2020-12-11 02:29:36 INFO  RaftStorageDirectory:335 - Lock on /data/metadata/ratis/915fef40-6db3-4e2c-8eb3-e4b11790d590/in_use.lock acquired by nodename 7@2f75b8e14cd7
dn1_1    | 2020-12-11 02:29:36 INFO  RaftStorage:84 - Storage directory /data/metadata/ratis/915fef40-6db3-4e2c-8eb3-e4b11790d590 has been successfully formatted.
dn1_1    | 2020-12-11 02:29:36 INFO  ContainerStateMachine:228 - group-E4B11790D590: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.notification.no-leader.timeout = 60s (default)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.use.memory = false (default)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.purge.gap = 1000000 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.cache.num.max = 2 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  SegmentedRaftLogWorker:176 - new f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/915fef40-6db3-4e2c-8eb3-e4b11790d590
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.byte-limit = 2147483647 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.element-limit = 1024 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.preallocated.size = 16384 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.write.buffer.size = 1048576 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.force.sync.num = 128 (default)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync = true (default)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.caching.enabled = true (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  SegmentedRaftLogWorker:129 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.enabled = true (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.retention.file.num = 5 (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.retrycache.expirytime = 600000ms (custom)
dn1_1    | 2020-12-11 02:29:36 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.leader_election.f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590
dn1_1    | 2020-12-11 02:29:36 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.server.f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerImpl:183 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590: start as a follower, conf=-1: [e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858], old=null
dn2_1    | 2020-12-11 02:29:04 INFO  HddsDatanodeService:51 - STARTUP_MSG: 
dn2_1    | /************************************************************
dn2_1    | STARTUP_MSG: Starting HddsDatanodeService
dn2_1    | STARTUP_MSG:   host = 8cbe53844264/10.9.0.12
dn2_1    | STARTUP_MSG:   args = []
dn2_1    | STARTUP_MSG:   version = 3.2.0
dn2_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.9.9.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta-tests.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-0.5.0-beta.jar
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.purge.gap = 1000000 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.cache.num.max = 2 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  SegmentedRaftLogWorker:176 - new e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/915fef40-6db3-4e2c-8eb3-e4b11790d590
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.byte-limit = 2147483647 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.element-limit = 1024 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.preallocated.size = 16384 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.write.buffer.size = 1048576 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.force.sync.num = 128 (default)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync = true (default)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.caching.enabled = true (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  SegmentedRaftLogWorker:129 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.enabled = true (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.retention.file.num = 5 (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerConfigKeys:43 - raft.server.retrycache.expirytime = 600000ms (custom)
dn3_1    | 2020-12-11 02:29:35 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.leader_election.e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590
dn3_1    | 2020-12-11 02:29:35 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.server.e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerImpl:183 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590: start as a follower, conf=-1: [e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858], old=null
dn3_1    | 2020-12-11 02:29:35 INFO  RaftServerImpl:172 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn3_1    | 2020-12-11 02:29:35 INFO  RoleInfo:143 - e927a432-7d30-4eab-9c57-07bc74eb3997: start FollowerState
dn3_1    | 2020-12-11 02:29:35 INFO  JmxRegister:44 - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E4B11790D590,id=e927a432-7d30-4eab-9c57-07bc74eb3997
dn3_1    | 2020-12-11 02:29:35 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.state_machine.e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590
dn3_1    | 2020-12-11 02:29:38 WARN  CreatePipelineCommandHandler:106 - Add group failed for 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
dn3_1    | org.apache.ratis.protocol.AlreadyExistsException: 50607d05-dbe3-476f-a8ca-cda3416766f8: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn3_1    | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
dn3_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
dn3_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
dn3_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
dn3_1    | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
dn3_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
dn3_1    | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn3_1    | 2020-12-11 02:29:39 WARN  RaftServerProxy:390 - e927a432-7d30-4eab-9c57-07bc74eb3997: Failed groupAdd* GroupManagementRequest:client-752F2B59E883->e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590, cid=1, seq=0, RW, null, Add:group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858]
dn3_1    | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: e927a432-7d30-4eab-9c57-07bc74eb3997: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn3_1    | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
dn3_1    | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
dn3_1    | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
dn1_1    | 2020-12-11 02:29:36 INFO  RaftServerImpl:172 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn1_1    | 2020-12-11 02:29:36 INFO  RoleInfo:143 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: start FollowerState
dn1_1    | 2020-12-11 02:29:36 INFO  JmxRegister:44 - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E4B11790D590,id=f50c55c5-6776-4b64-8cb9-bd5a75d26a9a
dn1_1    | 2020-12-11 02:29:36 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.state_machine.f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590
dn1_1    | 2020-12-11 02:29:38 WARN  CreatePipelineCommandHandler:106 - Add group failed for 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
dn1_1    | org.apache.ratis.protocol.AlreadyExistsException: 50607d05-dbe3-476f-a8ca-cda3416766f8: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn1_1    | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
dn1_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
dn1_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
dn1_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
dn1_1    | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
dn1_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
dn1_1    | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn1_1    | 2020-12-11 02:29:39 WARN  RaftServerProxy:390 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: Failed groupAdd* GroupManagementRequest:client-5E5E403E48AD->f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590, cid=1, seq=0, RW, null, Add:group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858]
dn1_1    | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn1_1    | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
dn1_1    | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
dn1_1    | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
dn1_1    | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
dn1_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
dn1_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
dn1_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
dn1_1    | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
dn1_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
dn1_1    | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn1_1    | Caused by: org.apache.ratis.protocol.AlreadyExistsException: f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn1_1    | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
dn1_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
dn1_1    | 	... 13 more
dn1_1    | 2020-12-11 02:29:39 WARN  CreatePipelineCommandHandler:106 - Add group failed for e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
dn1_1    | org.apache.ratis.protocol.AlreadyExistsException: e927a432-7d30-4eab-9c57-07bc74eb3997: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn1_1    | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
dn1_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
dn1_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
dn1_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
dn1_1    | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
dn1_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
dn1_1    | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
dn2_1    | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
dn2_1    | STARTUP_MSG:   java = 11.0.3
dn2_1    | ************************************************************/
dn2_1    | 2020-12-11 02:29:04 INFO  HddsDatanodeService:51 - registered UNIX signal handlers for [TERM, HUP, INT]
dn2_1    | 2020-12-11 02:29:06 INFO  MetricRegistries:64 - Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
dn2_1    | 2020-12-11 02:29:06 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
dn2_1    | 2020-12-11 02:29:08 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
dn2_1    | 2020-12-11 02:29:08 INFO  MetricsSystemImpl:191 - HddsDatanode metrics system started
dn2_1    | 2020-12-11 02:29:09 INFO  HddsDatanodeService:204 - HddsDatanodeService host:8cbe53844264 ip:10.9.0.12
dn2_1    | 2020-12-11 02:29:10 INFO  SaveSpaceUsageToFile:94 - Cached usage info file /data/hdds/scmUsed not found
dn2_1    | 2020-12-11 02:29:10 INFO  HddsVolume:173 - Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 14727258112
dn2_1    | 2020-12-11 02:29:10 INFO  VolumeSet:180 - Added Volume : /data/hdds/hdds to VolumeSet
dn2_1    | 2020-12-11 02:29:10 INFO  ThrottledAsyncChecker:141 - Scheduling a check for /data/hdds/hdds
dn2_1    | 2020-12-11 02:29:10 INFO  HddsVolumeChecker:199 - Scheduled health check for volume /data/hdds/hdds
dn2_1    | 2020-12-11 02:29:15 WARN  ServerUtils:237 - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
dn2_1    | 2020-12-11 02:29:16 INFO  RaftServerProxy:43 - raft.rpc.type = GRPC (default)
dn2_1    | 2020-12-11 02:29:17 INFO  GrpcConfigKeys$Server:43 - raft.grpc.server.port = 9858 (custom)
dn2_1    | 2020-12-11 02:29:17 INFO  GrpcService:43 - raft.grpc.message.size.max = 32MB (=33554432) (custom)
dn2_1    | 2020-12-11 02:29:17 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2020-12-11 02:29:17 INFO  GrpcService:43 - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
dn2_1    | 2020-12-11 02:29:17 INFO  RaftServerConfigKeys:43 - raft.server.rpc.request.timeout = 60s (custom)
dn2_1    | 2020-12-11 02:29:18 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2020-12-11 02:29:18 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
dn2_1    | 2020-12-11 02:29:19 INFO  BaseHttpServer:170 - Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
dn2_1    | 2020-12-11 02:29:19 INFO  log:169 - Logging initialized @20520ms to org.eclipse.jetty.util.log.Slf4jLog
dn2_1    | 2020-12-11 02:29:19 INFO  AuthenticationFilter:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
dn2_1    | 2020-12-11 02:29:19 INFO  HttpRequestLog:86 - Http request log for http.requests.hddsDatanode is not defined
dn2_1    | 2020-12-11 02:29:19 INFO  HttpServer2:970 - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
dn2_1    | 2020-12-11 02:29:19 INFO  HttpServer2:946 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
dn2_1    | 2020-12-11 02:29:19 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
dn2_1    | 2020-12-11 02:29:19 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
dn2_1    | 2020-12-11 02:29:20 INFO  HttpServer2:1188 - Jetty bound to port 9882
dn2_1    | 2020-12-11 02:29:20 INFO  Server:359 - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.3+7-LTS
dn2_1    | 2020-12-11 02:29:20 INFO  session:333 - DefaultSessionIdManager workerName=node0
dn2_1    | 2020-12-11 02:29:20 INFO  session:338 - No SessionScavenger set, using defaults
dn2_1    | 2020-12-11 02:29:20 INFO  session:140 - node0 Scavenging every 660000ms
dn2_1    | 2020-12-11 02:29:20 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@4e682398{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
dn2_1    | 2020-12-11 02:29:20 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@3f1a4795{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar!/webapps/static,AVAILABLE}
dn2_1    | 2020-12-11 02:29:20 INFO  ContextHandler:825 - Started o.e.j.w.WebAppContext@3166f664{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-0_5_0-beta_jar-_-any-10503253837434229118.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar!/webapps/hddsDatanode}
dn2_1    | 2020-12-11 02:29:21 INFO  AbstractConnector:330 - Started ServerConnector@77c233af{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
dn2_1    | 2020-12-11 02:29:21 INFO  Server:399 - Started @22315ms
dn2_1    | 2020-12-11 02:29:21 INFO  MetricsSinkAdapter:204 - Sink prometheus started
dn2_1    | 2020-12-11 02:29:21 INFO  MetricsSystemImpl:301 - Registered sink prometheus
dn2_1    | 2020-12-11 02:29:21 INFO  BaseHttpServer:284 - HTTP server of hddsDatanode listening at http://0.0.0.0:9882
dn2_1    | 2020-12-11 02:29:21 INFO  JvmPauseMonitor:188 - Starting JVM pause monitor
dn2_1    | 2020-12-11 02:29:21 INFO  SCMConnectionManager:142 - Adding Recon Server : recon/10.9.0.15:9891
dn2_1    | 2020-12-11 02:29:22 INFO  InitDatanodeState:147 - DatanodeDetails is persisted to /data/datanode.id
dn2_1    | 2020-12-11 02:29:24 INFO  Client:948 - Retrying connect to server: scm/10.9.0.17:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=2147483647, sleepTime=1000 MILLISECONDS)
dn2_1    | 2020-12-11 02:29:24 WARN  EndpointStateMachine:217 - Unable to communicate to Recon server at recon:9891 for past 0 seconds.
dn2_1    | java.net.SocketTimeoutException: Call From 8cbe53844264/10.9.0.12 to recon:9891 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.12:42286 remote=recon/10.9.0.15:9891]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn2_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn2_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
dn2_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
dn2_1    | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn1_1    | 2020-12-11 02:29:39 INFO  CreatePipelineCommandHandler:109 - Created Pipeline RATIS THREE #id: "915fef40-6db3-4e2c-8eb3-e4b11790d590"
dn1_1    | .
dn1_1    | 2020-12-11 02:29:39 WARN  RaftServerProxy:390 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: Failed groupAdd* GroupManagementRequest:client-584CF1336CA4->f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590, cid=1, seq=0, RW, null, Add:group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858]
dn1_1    | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn1_1    | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
dn1_1    | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
dn1_1    | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
dn1_1    | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
dn1_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
dn1_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
dn1_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
dn1_1    | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
dn1_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
dn1_1    | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
dn1_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn1_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn1_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn1_1    | Caused by: org.apache.ratis.protocol.AlreadyExistsException: f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn1_1    | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
dn1_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
dn1_1    | 	... 13 more
dn1_1    | 2020-12-11 02:29:40 INFO  RaftServerImpl:172 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:e927a432-7d30-4eab-9c57-07bc74eb3997
dn1_1    | 2020-12-11 02:29:40 INFO  RoleInfo:121 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: shutdown FollowerState
dn1_1    | 2020-12-11 02:29:40 INFO  FollowerState:117 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
dn1_1    | 2020-12-11 02:29:40 INFO  RoleInfo:143 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: start FollowerState
dn1_1    | 2020-12-11 02:29:40 INFO  XceiverServerRatis:744 - Leader change notification received for group: group-E4B11790D590 with new leaderId: e927a432-7d30-4eab-9c57-07bc74eb3997
dn1_1    | 2020-12-11 02:29:40 INFO  RaftServerImpl:255 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590: change Leader from null to e927a432-7d30-4eab-9c57-07bc74eb3997 at term 1 for appendEntries, leader elected after 4047ms
dn1_1    | 2020-12-11 02:29:40 INFO  RaftServerImpl:356 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590: set configuration 0: [e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858], old=null at 0
dn1_1    | 2020-12-11 02:29:40 INFO  SegmentedRaftLogWorker:391 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590-SegmentedRaftLogWorker: Starting segment from index:0
dn1_1    | 2020-12-11 02:29:40 INFO  SegmentedRaftLogWorker:583 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-E4B11790D590-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/915fef40-6db3-4e2c-8eb3-e4b11790d590/current/log_inprogress_0
dn1_1    | 2020-12-11 02:29:41 INFO  FollowerState:108 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0-FollowerState: change to CANDIDATE, lastRpcTime:5030ms, electionTimeout:5006ms
dn1_1    | 2020-12-11 02:29:41 INFO  RoleInfo:121 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: shutdown FollowerState
dn1_1    | 2020-12-11 02:29:41 INFO  RaftServerImpl:172 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn1_1    | 2020-12-11 02:29:41 INFO  RoleInfo:143 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: start LeaderElection
dn1_1    | 2020-12-11 02:29:41 INFO  LeaderElection:206 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0-LeaderElection1: begin an election at term 1 for -1: [f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858], old=null
dn1_1    | 2020-12-11 02:29:41 INFO  RoleInfo:134 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: shutdown LeaderElection
dn1_1    | 2020-12-11 02:29:41 INFO  RaftServerImpl:172 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn1_1    | 2020-12-11 02:29:41 INFO  XceiverServerRatis:744 - Leader change notification received for group: group-41EB68542FD0 with new leaderId: f50c55c5-6776-4b64-8cb9-bd5a75d26a9a
dn1_1    | 2020-12-11 02:29:41 INFO  RaftServerImpl:255 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0: change Leader from null to f50c55c5-6776-4b64-8cb9-bd5a75d26a9a at term 1 for becomeLeader, leader elected after 5655ms
dn1_1    | 2020-12-11 02:29:41 INFO  RaftServerConfigKeys:43 - raft.server.staging.catchup.gap = 1000 (default)
dn1_1    | 2020-12-11 02:29:41 INFO  RaftServerConfigKeys:43 - raft.server.rpc.sleep.time = 25ms (default)
dn1_1    | 2020-12-11 02:29:41 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.log_appender.f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0
dn1_1    | 2020-12-11 02:29:41 INFO  RaftServerConfigKeys:43 - raft.server.write.element-limit = 1024 (custom)
dn1_1    | 2020-12-11 02:29:41 INFO  RaftServerConfigKeys:43 - raft.server.write.byte-limit = 1073741824 (custom)
dn1_1    | 2020-12-11 02:29:41 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout = 180s (custom)
dn1_1    | 2020-12-11 02:29:41 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout.denomination = 1s (default)
dn1_1    | 2020-12-11 02:29:41 INFO  RaftServerConfigKeys:43 - raft.server.watch.element-limit = 65536 (default)
dn1_1    | 2020-12-11 02:29:41 INFO  RoleInfo:143 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: start LeaderState
dn1_1    | 2020-12-11 02:29:41 INFO  SegmentedRaftLogWorker:391 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0-SegmentedRaftLogWorker: Starting segment from index:0
dn1_1    | 2020-12-11 02:29:41 INFO  SegmentedRaftLogWorker:583 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/512805e8-9b7a-49ec-bd87-41eb68542fd0/current/log_inprogress_0
dn1_1    | 2020-12-11 02:29:41 INFO  RaftServerImpl:356 - f50c55c5-6776-4b64-8cb9-bd5a75d26a9a@group-41EB68542FD0: set configuration 0: [f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858], old=null at 0
dn3_1    | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
dn3_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
dn3_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
dn3_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
dn3_1    | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
dn3_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
dn3_1    | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn3_1    | Caused by: org.apache.ratis.protocol.AlreadyExistsException: e927a432-7d30-4eab-9c57-07bc74eb3997: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn3_1    | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
dn3_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
dn3_1    | 	... 13 more
dn3_1    | 2020-12-11 02:29:39 WARN  RaftServerProxy:390 - e927a432-7d30-4eab-9c57-07bc74eb3997: Failed groupAdd* GroupManagementRequest:client-932B0C6C49FC->e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590, cid=0, seq=0, RW, null, Add:group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858]
dn3_1    | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: e927a432-7d30-4eab-9c57-07bc74eb3997: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn3_1    | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
dn3_1    | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
dn3_1    | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
dn3_1    | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
dn3_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
dn3_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
dn3_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
dn3_1    | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
dn3_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
dn3_1    | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn3_1    | Caused by: org.apache.ratis.protocol.AlreadyExistsException: e927a432-7d30-4eab-9c57-07bc74eb3997: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn3_1    | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
dn3_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
dn3_1    | 	... 13 more
dn3_1    | 2020-12-11 02:29:39 WARN  CreatePipelineCommandHandler:106 - Add group failed for f50c55c5-6776-4b64-8cb9-bd5a75d26a9a{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
dn3_1    | org.apache.ratis.protocol.AlreadyExistsException: f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn3_1    | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
dn3_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
dn3_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
dn3_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
dn3_1    | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
dn3_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
dn3_1    | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
dn3_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn3_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn3_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn3_1    | 2020-12-11 02:29:39 INFO  CreatePipelineCommandHandler:109 - Created Pipeline RATIS THREE #id: "915fef40-6db3-4e2c-8eb3-e4b11790d590"
dn3_1    | .
dn3_1    | 2020-12-11 02:29:40 INFO  FollowerState:108 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0-FollowerState: change to CANDIDATE, lastRpcTime:5116ms, electionTimeout:5091ms
dn3_1    | 2020-12-11 02:29:40 INFO  RoleInfo:121 - e927a432-7d30-4eab-9c57-07bc74eb3997: shutdown FollowerState
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerImpl:172 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn3_1    | 2020-12-11 02:29:40 INFO  RoleInfo:143 - e927a432-7d30-4eab-9c57-07bc74eb3997: start LeaderElection
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn2_1    | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.12:42286 remote=recon/10.9.0.15:9891]
dn2_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn2_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn2_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
dn2_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn2_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
dn2_1    | 2020-12-11 02:29:25 WARN  EndpointStateMachine:217 - Unable to communicate to SCM server at scm:9861 for past 0 seconds.
dn2_1    | java.net.SocketTimeoutException: Call From 8cbe53844264/10.9.0.12 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.12:54818 remote=scm/10.9.0.17:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
dn2_1    | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
dn2_1    | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
dn2_1    | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
dn2_1    | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:775)
dn2_1    | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
dn2_1    | 	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
dn2_1    | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
dn2_1    | 	at com.sun.proxy.$Proxy39.submitRequest(Unknown Source)
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:116)
dn2_1    | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:132)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:71)
dn2_1    | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:42)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
dn2_1    | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn2_1    | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.9.0.12:54818 remote=scm/10.9.0.17:9861]
dn2_1    | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
dn2_1    | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
dn2_1    | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
dn2_1    | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
dn2_1    | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
dn2_1    | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
dn2_1    | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
dn2_1    | 2020-12-11 02:29:31 INFO  OzoneContainer:230 - Attempting to start container services.
dn2_1    | 2020-12-11 02:29:31 INFO  OzoneContainer:194 - Background container scanner has been disabled.
dn2_1    | 2020-12-11 02:29:31 INFO  XceiverServerRatis:415 - Starting XceiverServerRatis 50607d05-dbe3-476f-a8ca-cda3416766f8 at port 9858
dn2_1    | 2020-12-11 02:29:31 INFO  RaftServerProxy:299 - 50607d05-dbe3-476f-a8ca-cda3416766f8: start RPC server
dn2_1    | 2020-12-11 02:29:31 INFO  GrpcService:158 - 50607d05-dbe3-476f-a8ca-cda3416766f8: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerProxy:89 - 50607d05-dbe3-476f-a8ca-cda3416766f8: addNew group-4A9003E01997:[50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858] returns group-4A9003E01997:java.util.concurrent.CompletableFuture@382af2c9[Not completed]
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerImpl:97 - 50607d05-dbe3-476f-a8ca-cda3416766f8: new RaftServerImpl for group-4A9003E01997:[50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858] with ContainerStateMachine:uninitialized
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.min = 5s (custom)
dn3_1    | 2020-12-11 02:29:40 INFO  LeaderElection:206 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0-LeaderElection1: begin an election at term 1 for -1: [e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858], old=null
dn3_1    | 2020-12-11 02:29:40 INFO  RoleInfo:134 - e927a432-7d30-4eab-9c57-07bc74eb3997: shutdown LeaderElection
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerImpl:172 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn3_1    | 2020-12-11 02:29:40 INFO  XceiverServerRatis:744 - Leader change notification received for group: group-E649B78A07B0 with new leaderId: e927a432-7d30-4eab-9c57-07bc74eb3997
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerImpl:255 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0: change Leader from null to e927a432-7d30-4eab-9c57-07bc74eb3997 at term 1 for becomeLeader, leader elected after 5520ms
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.staging.catchup.gap = 1000 (default)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2020-12-11 02:29:40 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.log_appender.e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.write.byte-limit = 1073741824 (custom)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout = 180s (custom)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout.denomination = 1s (default)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.watch.element-limit = 65536 (default)
dn3_1    | 2020-12-11 02:29:40 INFO  RoleInfo:143 - e927a432-7d30-4eab-9c57-07bc74eb3997: start LeaderState
dn3_1    | 2020-12-11 02:29:40 INFO  SegmentedRaftLogWorker:391 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0-SegmentedRaftLogWorker: Starting segment from index:0
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerImpl:356 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0: set configuration 0: [e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858], old=null at 0
dn3_1    | 2020-12-11 02:29:40 INFO  FollowerState:108 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590-FollowerState: change to CANDIDATE, lastRpcTime:5057ms, electionTimeout:5056ms
dn3_1    | 2020-12-11 02:29:40 INFO  RoleInfo:121 - e927a432-7d30-4eab-9c57-07bc74eb3997: shutdown FollowerState
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerImpl:172 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn3_1    | 2020-12-11 02:29:40 INFO  RoleInfo:143 - e927a432-7d30-4eab-9c57-07bc74eb3997: start LeaderElection
dn3_1    | 2020-12-11 02:29:40 INFO  LeaderElection:206 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590-LeaderElection2: begin an election at term 1 for -1: [e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858], old=null
dn3_1    | 2020-12-11 02:29:40 INFO  SegmentedRaftLogWorker:583 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E649B78A07B0-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7ffd4706-2840-4531-94d6-e649b78a07b0/current/log_inprogress_0
dn3_1    | 2020-12-11 02:29:40 INFO  LeaderElection:61 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590-LeaderElection2: Election PASSED; received 1 response(s) [e927a432-7d30-4eab-9c57-07bc74eb3997<-50607d05-dbe3-476f-a8ca-cda3416766f8#0:OK-t1] and 0 exception(s); e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590:t1, leader=null, voted=e927a432-7d30-4eab-9c57-07bc74eb3997, raftlog=e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858], old=null
dn3_1    | 2020-12-11 02:29:40 INFO  RoleInfo:134 - e927a432-7d30-4eab-9c57-07bc74eb3997: shutdown LeaderElection
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerImpl:172 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn3_1    | 2020-12-11 02:29:40 INFO  XceiverServerRatis:744 - Leader change notification received for group: group-E4B11790D590 with new leaderId: e927a432-7d30-4eab-9c57-07bc74eb3997
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerImpl:255 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590: change Leader from null to e927a432-7d30-4eab-9c57-07bc74eb3997 at term 1 for becomeLeader, leader elected after 5231ms
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.staging.catchup.gap = 1000 (default)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.rpc.sleep.time = 25ms (default)
dn3_1    | 2020-12-11 02:29:40 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.log_appender.e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.write.element-limit = 1024 (custom)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.write.byte-limit = 1073741824 (custom)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout = 180s (custom)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout.denomination = 1s (default)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.watch.element-limit = 65536 (default)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.element-limit = 1 (custom)
dn3_1    | 2020-12-11 02:29:40 INFO  GrpcConfigKeys$Server:43 - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.element-limit = 1 (custom)
dn3_1    | 2020-12-11 02:29:40 INFO  GrpcConfigKeys$Server:43 - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.rpc.request.timeout = 60s (custom)
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
dn3_1    | 2020-12-11 02:29:40 INFO  RoleInfo:143 - e927a432-7d30-4eab-9c57-07bc74eb3997: start LeaderState
dn3_1    | 2020-12-11 02:29:40 INFO  SegmentedRaftLogWorker:391 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590-SegmentedRaftLogWorker: Starting segment from index:0
dn3_1    | 2020-12-11 02:29:40 INFO  SegmentedRaftLogWorker:583 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/915fef40-6db3-4e2c-8eb3-e4b11790d590/current/log_inprogress_0
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.rpcslowness.timeout = 300s (custom)
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.sleep.deviation.threshold = 300 (default)
s3g_1    | 2020-12-11 02:29:03 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
s3g_1    | 2020-12-11 02:29:04 INFO  BaseHttpServer:170 - Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1    | 2020-12-11 02:29:04 INFO  log:169 - Logging initialized @7153ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1    | 2020-12-11 02:29:05 INFO  AuthenticationFilter:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1    | 2020-12-11 02:29:05 INFO  HttpRequestLog:86 - Http request log for http.requests.s3gateway is not defined
s3g_1    | 2020-12-11 02:29:05 INFO  HttpServer2:970 - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1    | 2020-12-11 02:29:05 INFO  HttpServer2:946 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g_1    | 2020-12-11 02:29:05 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1    | 2020-12-11 02:29:05 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1    | 2020-12-11 02:29:06 INFO  Gateway:58 - Starting Ozone S3 gateway
s3g_1    | 2020-12-11 02:29:06 INFO  HttpServer2:1188 - Jetty bound to port 9878
s3g_1    | 2020-12-11 02:29:06 INFO  Server:359 - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.3+7-LTS
s3g_1    | 2020-12-11 02:29:06 INFO  session:333 - DefaultSessionIdManager workerName=node0
s3g_1    | 2020-12-11 02:29:06 INFO  session:338 - No SessionScavenger set, using defaults
s3g_1    | 2020-12-11 02:29:06 INFO  session:140 - node0 Scavenging every 660000ms
s3g_1    | 2020-12-11 02:29:06 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@7dfb0c0f{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1    | 2020-12-11 02:29:06 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@2d0399f4{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.5.0-beta.jar!/webapps/static,AVAILABLE}
s3g_1    | ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
s3g_1    | WARNING: An illegal reflective access operation has occurred
s3g_1    | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1    | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1    | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1    | WARNING: All illegal access operations will be denied in a future release
s3g_1    | Dec 11, 2020 2:29:23 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1    | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1    | 
s3g_1    | 2020-12-11 02:29:23 INFO  ContextHandler:825 - Started o.e.j.w.WebAppContext@48268eec{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-0_5_0-beta_jar-_-any-3573226746921113224.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-0.5.0-beta.jar!/webapps/s3gateway}
s3g_1    | 2020-12-11 02:29:23 INFO  AbstractConnector:330 - Started ServerConnector@3e62d773{HTTP/1.1,[http/1.1]}{0.0.0.0:9878}
s3g_1    | 2020-12-11 02:29:23 INFO  Server:399 - Started @26105ms
s3g_1    | 2020-12-11 02:29:28 INFO  BaseHttpServer:284 - HTTP server of s3gateway listening at http://0.0.0.0:9878
dn3_1    | 2020-12-11 02:29:40 INFO  RaftServerImpl:356 - e927a432-7d30-4eab-9c57-07bc74eb3997@group-E4B11790D590: set configuration 0: [e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858], old=null at 0
recon_1  | 2020-12-11 02:29:31 INFO  Server:1314 - IPC Server Responder: starting
recon_1  | 2020-12-11 02:29:31 INFO  Server:1153 - IPC Server listener on 9891: starting
recon_1  | 2020-12-11 02:29:31 INFO  ReconScmTask:58 - Starting MissingContainerTask Thread.
recon_1  | 2020-12-11 02:29:31 INFO  ReconScmTask:58 - Starting PipelineSyncTask Thread.
recon_1  | 2020-12-11 02:29:31 INFO  PipelineSyncTask:64 - Pipeline sync Thread took 83 milliseconds.
recon_1  | 2020-12-11 02:29:31 INFO  MissingContainerTask:72 - Missing Container task Thread took 129 milliseconds for processing 0 containers.
recon_1  | 2020-12-11 02:29:31 WARN  Server:1523 - IPC Server handler 7 on 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.12:42286: output error
recon_1  | 2020-12-11 02:29:31 WARN  Server:1523 - IPC Server handler 3 on 9891, call Call#6 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.13:49374: output error
recon_1  | 2020-12-11 02:29:31 WARN  Server:1523 - IPC Server handler 5 on 9891, call Call#4 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.12:42336: output error
recon_1  | 2020-12-11 02:29:31 WARN  Server:1523 - IPC Server handler 1 on 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.13:49346: output error
recon_1  | 2020-12-11 02:29:31 WARN  Server:1523 - IPC Server handler 0 on 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.13:49314: output error
recon_1  | 2020-12-11 02:29:31 WARN  Server:1523 - IPC Server handler 2 on 9891, call Call#4 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.13:49358: output error
recon_1  | 2020-12-11 02:29:31 WARN  Server:1523 - IPC Server handler 6 on 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.12:42324: output error
recon_1  | 2020-12-11 02:29:31 INFO  Server:2695 - IPC Server handler 6 on 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1  | 2020-12-11 02:29:31 WARN  Server:1523 - IPC Server handler 8 on 9891, call Call#6 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.12:42352: output error
recon_1  | 2020-12-11 02:29:31 INFO  Server:2695 - IPC Server handler 0 on 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1  | 2020-12-11 02:29:31 INFO  Server:2695 - IPC Server handler 1 on 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1  | 2020-12-11 02:29:31 INFO  Server:2695 - IPC Server handler 2 on 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1  | 2020-12-11 02:29:31 INFO  Server:2695 - IPC Server handler 8 on 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1  | 2020-12-11 02:29:31 INFO  Server:2695 - IPC Server handler 7 on 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1  | 2020-12-11 02:29:31 INFO  Server:2695 - IPC Server handler 3 on 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1  | 2020-12-11 02:29:31 INFO  Server:2695 - IPC Server handler 5 on 9891 caught an exception
recon_1  | java.nio.channels.AsynchronousCloseException
recon_1  | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
recon_1  | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
recon_1  | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
recon_1  | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
recon_1  | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
recon_1  | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
recon_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
recon_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
recon_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
recon_1  | 2020-12-11 02:29:33 INFO  NetworkTopology:111 - Added a new node: /default-rack/50607d05-dbe3-476f-a8ca-cda3416766f8
recon_1  | 2020-12-11 02:29:33 INFO  ReconNodeManager:109 - Adding new node 50607d05-dbe3-476f-a8ca-cda3416766f8 to Node DB.
recon_1  | 2020-12-11 02:29:33 INFO  SCMNodeManager:268 - Registered Data node : 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
recon_1  | 2020-12-11 02:29:33 INFO  ReconNodeManager:109 - Adding new node e927a432-7d30-4eab-9c57-07bc74eb3997 to Node DB.
recon_1  | 2020-12-11 02:29:33 INFO  NetworkTopology:111 - Added a new node: /default-rack/e927a432-7d30-4eab-9c57-07bc74eb3997
recon_1  | 2020-12-11 02:29:33 INFO  SCMNodeManager:268 - Registered Data node : e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
recon_1  | 2020-12-11 02:29:35 INFO  ReconPipelineReportHandler:63 - Unknown pipeline PipelineID=7ffd4706-2840-4531-94d6-e649b78a07b0. Trying to get from SCM.
recon_1  | 2020-12-11 02:29:35 INFO  ReconPipelineReportHandler:66 - Adding new pipeline Pipeline[ Id: 7ffd4706-2840-4531-94d6-e649b78a07b0, Nodes: e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:e927a432-7d30-4eab-9c57-07bc74eb3997, CreationTimestamp2020-12-11T02:29:31.824Z] to Recon pipeline metadata.
recon_1  | 2020-12-11 02:29:35 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: 7ffd4706-2840-4531-94d6-e649b78a07b0, Nodes: e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN, leaderId:e927a432-7d30-4eab-9c57-07bc74eb3997, CreationTimestamp2020-12-11T02:29:31.824Z]
recon_1  | 2020-12-11 02:29:35 INFO  ReconPipelineReportHandler:63 - Unknown pipeline PipelineID=915fef40-6db3-4e2c-8eb3-e4b11790d590. Trying to get from SCM.
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerImpl:103 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997: ConfigurationManager, init=-1: [50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858], old=null, confs=<EMPTY_MAP>
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2020-12-11 02:29:36 INFO  RaftStorageDirectory:253 - The storage directory /data/metadata/ratis/0a4e6833-e832-4109-b0ce-4a9003e01997 does not exist. Creating ...
dn2_1    | 2020-12-11 02:29:36 INFO  RaftStorageDirectory:335 - Lock on /data/metadata/ratis/0a4e6833-e832-4109-b0ce-4a9003e01997/in_use.lock acquired by nodename 6@8cbe53844264
dn2_1    | 2020-12-11 02:29:36 INFO  RaftStorage:84 - Storage directory /data/metadata/ratis/0a4e6833-e832-4109-b0ce-4a9003e01997 has been successfully formatted.
dn2_1    | 2020-12-11 02:29:36 INFO  ContainerStateMachine:228 - group-4A9003E01997: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.notification.no-leader.timeout = 60s (default)
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.use.memory = false (default)
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2020-12-11 02:29:36 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.log_worker.50607d05-dbe3-476f-a8ca-cda3416766f8
dn2_1    | 2020-12-11 02:29:36 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  SegmentedRaftLogWorker:176 - new 50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/0a4e6833-e832-4109-b0ce-4a9003e01997
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.byte-limit = 2147483647 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  SegmentedRaftLogWorker:129 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.leader_election.50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997
dn2_1    | 2020-12-11 02:29:37 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.server.50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerImpl:183 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997: start as a follower, conf=-1: [50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858], old=null
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerImpl:172 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn2_1    | 2020-12-11 02:29:37 INFO  RoleInfo:143 - 50607d05-dbe3-476f-a8ca-cda3416766f8: start FollowerState
dn2_1    | 2020-12-11 02:29:37 INFO  JmxRegister:44 - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4A9003E01997,id=50607d05-dbe3-476f-a8ca-cda3416766f8
dn2_1    | 2020-12-11 02:29:37 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.state_machine.50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997
dn2_1    | 2020-12-11 02:29:37 INFO  CreatePipelineCommandHandler:109 - Created Pipeline RATIS ONE #id: "0a4e6833-e832-4109-b0ce-4a9003e01997"
dn2_1    | .
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerProxy:89 - 50607d05-dbe3-476f-a8ca-cda3416766f8: addNew group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] returns group-E4B11790D590:java.util.concurrent.CompletableFuture@599729f6[Not completed]
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerImpl:97 - 50607d05-dbe3-476f-a8ca-cda3416766f8: new RaftServerImpl for group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] with ContainerStateMachine:uninitialized
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.min = 5s (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.rpc.timeout.max = 5200ms (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.rpcslowness.timeout = 300s (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.sleep.deviation.threshold = 300 (default)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.install.snapshot.enabled = false (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerImpl:103 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590: ConfigurationManager, init=-1: [e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858], old=null, confs=<EMPTY_MAP>
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.storage.dir = [/data/metadata/ratis] (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.corruption.policy = EXCEPTION (default)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftStorageDirectory:253 - The storage directory /data/metadata/ratis/915fef40-6db3-4e2c-8eb3-e4b11790d590 does not exist. Creating ...
dn2_1    | 2020-12-11 02:29:37 INFO  RaftStorageDirectory:335 - Lock on /data/metadata/ratis/915fef40-6db3-4e2c-8eb3-e4b11790d590/in_use.lock acquired by nodename 6@8cbe53844264
dn2_1    | 2020-12-11 02:29:37 INFO  RaftStorage:84 - Storage directory /data/metadata/ratis/915fef40-6db3-4e2c-8eb3-e4b11790d590 has been successfully formatted.
dn2_1    | 2020-12-11 02:29:37 INFO  ContainerStateMachine:228 - group-E4B11790D590: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
recon_1  | 2020-12-11 02:29:35 INFO  ReconPipelineReportHandler:66 - Adding new pipeline Pipeline[ Id: 915fef40-6db3-4e2c-8eb3-e4b11790d590, Nodes: 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}f50c55c5-6776-4b64-8cb9-bd5a75d26a9a{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-12-11T02:29:33.252Z] to Recon pipeline metadata.
recon_1  | 2020-12-11 02:29:35 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: 915fef40-6db3-4e2c-8eb3-e4b11790d590, Nodes: 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}f50c55c5-6776-4b64-8cb9-bd5a75d26a9a{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-12-11T02:29:33.252Z]
recon_1  | 2020-12-11 02:29:35 INFO  ReconPipelineReportHandler:83 - Pipeline THREE PipelineID=915fef40-6db3-4e2c-8eb3-e4b11790d590 reported by e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
recon_1  | 2020-12-11 02:29:37 INFO  ReconPipelineReportHandler:63 - Unknown pipeline PipelineID=0a4e6833-e832-4109-b0ce-4a9003e01997. Trying to get from SCM.
recon_1  | 2020-12-11 02:29:37 INFO  ReconPipelineReportHandler:66 - Adding new pipeline Pipeline[ Id: 0a4e6833-e832-4109-b0ce-4a9003e01997, Nodes: 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:50607d05-dbe3-476f-a8ca-cda3416766f8, CreationTimestamp2020-12-11T02:29:33.233Z] to Recon pipeline metadata.
recon_1  | 2020-12-11 02:29:37 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: 0a4e6833-e832-4109-b0ce-4a9003e01997, Nodes: 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:50607d05-dbe3-476f-a8ca-cda3416766f8, CreationTimestamp2020-12-11T02:29:33.233Z]
recon_1  | 2020-12-11 02:29:37 INFO  ReconPipelineReportHandler:83 - Pipeline ONE PipelineID=0a4e6833-e832-4109-b0ce-4a9003e01997 reported by 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
recon_1  | 2020-12-11 02:29:37 INFO  PipelineStateManager:131 - Pipeline Pipeline[ Id: 0a4e6833-e832-4109-b0ce-4a9003e01997, Nodes: 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:50607d05-dbe3-476f-a8ca-cda3416766f8, CreationTimestamp2020-12-11T02:29:33.233Z] moved to OPEN state
recon_1  | 2020-12-11 02:29:37 INFO  ReconPipelineReportHandler:83 - Pipeline THREE PipelineID=915fef40-6db3-4e2c-8eb3-e4b11790d590 reported by 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
recon_1  | 2020-12-11 02:29:40 INFO  ReconPipelineReportHandler:83 - Pipeline THREE PipelineID=915fef40-6db3-4e2c-8eb3-e4b11790d590 reported by e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
recon_1  | 2020-12-11 02:29:40 INFO  ReconPipelineReportHandler:83 - Pipeline THREE PipelineID=915fef40-6db3-4e2c-8eb3-e4b11790d590 reported by e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
recon_1  | 2020-12-11 02:29:42 INFO  ReconPipelineReportHandler:83 - Pipeline THREE PipelineID=915fef40-6db3-4e2c-8eb3-e4b11790d590 reported by 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.notification.no-leader.timeout = 60s (default)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.use.memory = false (default)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.purge.gap = 1000000 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.cache.num.max = 2 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  SegmentedRaftLogWorker:176 - new 50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/915fef40-6db3-4e2c-8eb3-e4b11790d590
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.byte-limit = 2147483647 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.queue.element-limit = 1024 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.segment.size.max = 1048576 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.preallocated.size = 16384 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.write.buffer.size = 1048576 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.force.sync.num = 128 (default)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync = true (default)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout = 10s (default)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.log.statemachine.data.caching.enabled = true (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  SegmentedRaftLogWorker:129 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.enabled = true (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.snapshot.retention.file.num = 5 (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerConfigKeys:43 - raft.server.retrycache.expirytime = 600000ms (custom)
dn2_1    | 2020-12-11 02:29:37 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.leader_election.50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590
dn2_1    | 2020-12-11 02:29:37 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.server.50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerImpl:183 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590: start as a follower, conf=-1: [e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858], old=null
dn2_1    | 2020-12-11 02:29:37 INFO  RaftServerImpl:172 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590: changes role from      null to FOLLOWER at term 0 for startAsFollower
dn2_1    | 2020-12-11 02:29:37 INFO  RoleInfo:143 - 50607d05-dbe3-476f-a8ca-cda3416766f8: start FollowerState
dn2_1    | 2020-12-11 02:29:37 INFO  JmxRegister:44 - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E4B11790D590,id=50607d05-dbe3-476f-a8ca-cda3416766f8
dn2_1    | 2020-12-11 02:29:37 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.state_machine.50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590
dn2_1    | 2020-12-11 02:29:38 WARN  RaftServerProxy:390 - 50607d05-dbe3-476f-a8ca-cda3416766f8: Failed groupAdd* GroupManagementRequest:client-E8B321511DDF->50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590, cid=0, seq=0, RW, null, Add:group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858]
dn2_1    | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 50607d05-dbe3-476f-a8ca-cda3416766f8: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn2_1    | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
dn2_1    | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
dn2_1    | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
dn2_1    | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
dn2_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
dn2_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
dn2_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
dn2_1    | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
dn2_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
dn2_1    | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn2_1    | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 50607d05-dbe3-476f-a8ca-cda3416766f8: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn2_1    | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
dn2_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
dn2_1    | 	... 13 more
dn2_1    | 2020-12-11 02:29:38 WARN  RaftServerProxy:390 - 50607d05-dbe3-476f-a8ca-cda3416766f8: Failed groupAdd* GroupManagementRequest:client-3835B272E74B->50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590, cid=0, seq=0, RW, null, Add:group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858]
scm_1    | 2020-12-11 02:29:01 INFO  StorageContainerManagerStarter:51 - STARTUP_MSG: 
scm_1    | /************************************************************
scm_1    | STARTUP_MSG: Starting StorageContainerManager
scm_1    | STARTUP_MSG:   host = 67d0b0e26ec1/10.9.0.17
scm_1    | STARTUP_MSG:   args = [--init]
scm_1    | STARTUP_MSG:   version = 3.2.0
scm_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.9.9.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta-tests.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-beta.jar
scm_1    | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1    | STARTUP_MSG:   java = 11.0.3
scm_1    | ************************************************************/
scm_1    | 2020-12-11 02:29:02 INFO  StorageContainerManagerStarter:51 - registered UNIX signal handlers for [TERM, HUP, INT]
scm_1    | 2020-12-11 02:29:02 WARN  ServerUtils:148 - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2020-12-11 02:29:03 INFO  StorageContainerManager:635 - SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-d36fba17-d19d-4677-a235-d22714b3e2db
scm_1    | 2020-12-11 02:29:03 INFO  StorageContainerManagerStarter:51 - SHUTDOWN_MSG: 
scm_1    | /************************************************************
scm_1    | SHUTDOWN_MSG: Shutting down StorageContainerManager at 67d0b0e26ec1/10.9.0.17
scm_1    | ************************************************************/
scm_1    | 2020-12-11 02:29:18 INFO  StorageContainerManagerStarter:51 - STARTUP_MSG: 
scm_1    | /************************************************************
scm_1    | STARTUP_MSG: Starting StorageContainerManager
scm_1    | STARTUP_MSG:   host = 67d0b0e26ec1/10.9.0.17
scm_1    | STARTUP_MSG:   args = []
scm_1    | STARTUP_MSG:   version = 3.2.0
scm_1    | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-0.5.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-0.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/ratis-proto-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.0.jar:/opt/hadoop/share/ozone/lib/jline-0.9.94.jar:/opt/hadoop/share/ozone/lib/ratis-server-0.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.31.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.12.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/zookeeper-3.4.13.jar:/opt/hadoop/share/ozone/lib/avro-1.7.7.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-docs-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jaeger-client-0.34.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.9.9.jar:/opt/hadoop/share/ozone/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.31.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-0.34.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/curator-client-2.12.0.jar:/opt/hadoop/share/ozone/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.5.jar:/opt/hadoop/share/ozone/lib/paranamer-2.3.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-0.5.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-1.13.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.9.9.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.9.9.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-0.34.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-0.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.9.9.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-0.34.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-3.9.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-0.5.0-beta-tests.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.31.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-0.5.0-beta.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-beta.jar
scm_1    | STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r e97acb3bd8f3befd27418996fa5d4b50bf2e17bf; compiled by 'sunilg' on 2019-01-15T17:34Z
scm_1    | STARTUP_MSG:   java = 11.0.3
scm_1    | ************************************************************/
scm_1    | 2020-12-11 02:29:18 INFO  StorageContainerManagerStarter:51 - registered UNIX signal handlers for [TERM, HUP, INT]
scm_1    | 2020-12-11 02:29:19 WARN  ServerUtils:148 - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2020-12-11 02:29:19 WARN  ServerUtils:148 - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2020-12-11 02:29:20 INFO  NodeSchemaLoader:126 - Loading file from java.lang.CompoundEnumeration@2dc9b0f5
scm_1    | 2020-12-11 02:29:20 INFO  NodeSchemaLoader:172 - Loading network topology layer schema file
scm_1    | 2020-12-11 02:29:20 INFO  SCMNodeManager:116 - Entering startup safe mode.
scm_1    | 2020-12-11 02:29:21 INFO  ContainerPlacementPolicyFactory:59 - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1    | 2020-12-11 02:29:21 WARN  ServerUtils:148 - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2020-12-11 02:29:21 INFO  SCMPipelineManager:150 - No pipeline exists in current db
scm_1    | 2020-12-11 02:29:21 WARN  ServerUtils:148 - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1    | 2020-12-11 02:29:21 INFO  HealthyPipelineSafeModeRule:88 - Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1    | 2020-12-11 02:29:21 INFO  OneReplicaPipelineSafeModeRule:79 - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1    | 2020-12-11 02:29:21 WARN  PipelinePlacementPolicy:151 - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1    | 2020-12-11 02:29:22 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
scm_1    | 2020-12-11 02:29:23 INFO  CallQueueManager:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2020-12-11 02:29:24 INFO  Server:1074 - Starting Socket Reader #1 for port 9861
scm_1    | 2020-12-11 02:29:24 INFO  CallQueueManager:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2020-12-11 02:29:24 INFO  Server:1074 - Starting Socket Reader #1 for port 9863
scm_1    | 2020-12-11 02:29:24 INFO  CallQueueManager:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1    | 2020-12-11 02:29:24 INFO  Server:1074 - Starting Socket Reader #1 for port 9860
scm_1    | 2020-12-11 02:29:29 INFO  BaseHttpServer:170 - Starting Web-server for scm at: http://0.0.0.0:9876
scm_1    | 2020-12-11 02:29:29 INFO  log:169 - Logging initialized @24527ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1    | 2020-12-11 02:29:29 INFO  AuthenticationFilter:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1    | 2020-12-11 02:29:29 INFO  HttpRequestLog:86 - Http request log for http.requests.scm is not defined
scm_1    | 2020-12-11 02:29:29 INFO  HttpServer2:970 - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1    | 2020-12-11 02:29:29 INFO  HttpServer2:946 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1    | 2020-12-11 02:29:29 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context static
scm_1    | 2020-12-11 02:29:29 INFO  HttpServer2:954 - Added filter static_user_filter (class=org.apache.hadoop.hdds.server.http.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1    | 2020-12-11 02:29:29 INFO  StorageContainerManager:773 - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1    | 2020-12-11 02:29:29 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
scm_1    | 2020-12-11 02:29:29 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
scm_1    | 2020-12-11 02:29:29 INFO  MetricsSystemImpl:191 - StorageContainerManager metrics system started
scm_1    | 2020-12-11 02:29:30 INFO  SCMClientProtocolServer:160 - RPC server for Client  is listening at /0.0.0.0:9860
scm_1    | 2020-12-11 02:29:30 INFO  Server:1314 - IPC Server Responder: starting
scm_1    | 2020-12-11 02:29:30 INFO  Server:1153 - IPC Server listener on 9860: starting
scm_1    | 2020-12-11 02:29:30 INFO  StorageContainerManager:785 - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1    | 2020-12-11 02:29:30 INFO  SCMBlockProtocolServer:147 - RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1    | 2020-12-11 02:29:30 INFO  Server:1314 - IPC Server Responder: starting
scm_1    | 2020-12-11 02:29:30 INFO  Server:1153 - IPC Server listener on 9863: starting
scm_1    | 2020-12-11 02:29:30 INFO  StorageContainerManager:791 - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1    | 2020-12-11 02:29:30 INFO  SCMDatanodeProtocolServer:178 - RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1    | 2020-12-11 02:29:30 INFO  Server:1314 - IPC Server Responder: starting
scm_1    | 2020-12-11 02:29:30 INFO  Server:1153 - IPC Server listener on 9861: starting
scm_1    | 2020-12-11 02:29:30 INFO  HttpServer2:1188 - Jetty bound to port 9876
scm_1    | 2020-12-11 02:29:30 INFO  Server:359 - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.3+7-LTS
scm_1    | 2020-12-11 02:29:30 INFO  session:333 - DefaultSessionIdManager workerName=node0
scm_1    | 2020-12-11 02:29:30 INFO  session:338 - No SessionScavenger set, using defaults
scm_1    | 2020-12-11 02:29:30 INFO  session:140 - node0 Scavenging every 660000ms
scm_1    | 2020-12-11 02:29:30 WARN  Server:1523 - IPC Server handler 0 on 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.12:54818: output error
dn2_1    | java.util.concurrent.CompletionException: org.apache.ratis.protocol.AlreadyExistsException: 50607d05-dbe3-476f-a8ca-cda3416766f8: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn2_1    | 	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
dn2_1    | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyNow(CompletableFuture.java:670)
dn2_1    | 	at java.base/java.util.concurrent.CompletableFuture.uniApplyStage(CompletableFuture.java:658)
dn2_1    | 	at java.base/java.util.concurrent.CompletableFuture.thenApplyAsync(CompletableFuture.java:2104)
dn2_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:379)
dn2_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
dn2_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
dn2_1    | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
dn2_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
dn2_1    | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn2_1    | Caused by: org.apache.ratis.protocol.AlreadyExistsException: 50607d05-dbe3-476f-a8ca-cda3416766f8: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn2_1    | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
dn2_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
dn2_1    | 	... 13 more
dn2_1    | 2020-12-11 02:29:39 WARN  CreatePipelineCommandHandler:106 - Add group failed for e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
dn2_1    | org.apache.ratis.protocol.AlreadyExistsException: e927a432-7d30-4eab-9c57-07bc74eb3997: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn2_1    | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
dn2_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
dn2_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
dn2_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
dn2_1    | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
dn2_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
dn2_1    | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn2_1    | 2020-12-11 02:29:39 WARN  CreatePipelineCommandHandler:106 - Add group failed for f50c55c5-6776-4b64-8cb9-bd5a75d26a9a{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
dn2_1    | org.apache.ratis.protocol.AlreadyExistsException: f50c55c5-6776-4b64-8cb9-bd5a75d26a9a: Failed to add group-E4B11790D590:[e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858] since the group already exists in the map.
dn2_1    | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.addNew(RaftServerProxy.java:83)
dn2_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupAddAsync(RaftServerProxy.java:378)
dn2_1    | 	at org.apache.ratis.server.impl.RaftServerProxy.groupManagementAsync(RaftServerProxy.java:363)
dn2_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.lambda$groupManagement$0(GrpcAdminProtocolService.java:42)
dn2_1    | 	at org.apache.ratis.grpc.GrpcUtil.asyncCall(GrpcUtil.java:160)
dn2_1    | 	at org.apache.ratis.grpc.server.GrpcAdminProtocolService.groupManagement(GrpcAdminProtocolService.java:42)
dn2_1    | 	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$MethodHandlers.invoke(AdminProtocolServiceGrpc.java:358)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:814)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
dn2_1    | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
dn2_1    | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
dn2_1    | 	at java.base/java.lang.Thread.run(Thread.java:834)
dn2_1    | 2020-12-11 02:29:39 INFO  CreatePipelineCommandHandler:109 - Created Pipeline RATIS THREE #id: "915fef40-6db3-4e2c-8eb3-e4b11790d590"
dn2_1    | .
dn2_1    | 2020-12-11 02:29:40 INFO  RaftServerImpl:172 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:e927a432-7d30-4eab-9c57-07bc74eb3997
dn2_1    | 2020-12-11 02:29:40 INFO  RoleInfo:121 - 50607d05-dbe3-476f-a8ca-cda3416766f8: shutdown FollowerState
dn2_1    | 2020-12-11 02:29:40 INFO  RoleInfo:143 - 50607d05-dbe3-476f-a8ca-cda3416766f8: start FollowerState
scm_1    | 2020-12-11 02:29:30 WARN  Server:1523 - IPC Server handler 1 on 9861, call Call#3 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.11:56274: output error
scm_1    | 2020-12-11 02:29:30 WARN  Server:1523 - IPC Server handler 5 on 9861, call Call#3 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.12:54844: output error
dn2_1    | 2020-12-11 02:29:40 INFO  FollowerState:117 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590-FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
dn2_1    | 2020-12-11 02:29:40 INFO  XceiverServerRatis:744 - Leader change notification received for group: group-E4B11790D590 with new leaderId: e927a432-7d30-4eab-9c57-07bc74eb3997
dn2_1    | 2020-12-11 02:29:40 INFO  RaftServerImpl:255 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590: change Leader from null to e927a432-7d30-4eab-9c57-07bc74eb3997 at term 1 for appendEntries, leader elected after 3070ms
dn2_1    | 2020-12-11 02:29:40 INFO  RaftServerImpl:356 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590: set configuration 0: [e927a432-7d30-4eab-9c57-07bc74eb3997:10.9.0.13:9858, 50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858, f50c55c5-6776-4b64-8cb9-bd5a75d26a9a:10.9.0.11:9858], old=null at 0
dn2_1    | 2020-12-11 02:29:40 INFO  SegmentedRaftLogWorker:391 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590-SegmentedRaftLogWorker: Starting segment from index:0
dn2_1    | 2020-12-11 02:29:40 INFO  SegmentedRaftLogWorker:583 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-E4B11790D590-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/915fef40-6db3-4e2c-8eb3-e4b11790d590/current/log_inprogress_0
dn2_1    | 2020-12-11 02:29:42 INFO  FollowerState:108 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997-FollowerState: change to CANDIDATE, lastRpcTime:5052ms, electionTimeout:5046ms
dn2_1    | 2020-12-11 02:29:42 INFO  RoleInfo:121 - 50607d05-dbe3-476f-a8ca-cda3416766f8: shutdown FollowerState
dn2_1    | 2020-12-11 02:29:42 INFO  RaftServerImpl:172 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
dn2_1    | 2020-12-11 02:29:42 INFO  RoleInfo:143 - 50607d05-dbe3-476f-a8ca-cda3416766f8: start LeaderElection
dn2_1    | 2020-12-11 02:29:42 INFO  LeaderElection:206 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997-LeaderElection1: begin an election at term 1 for -1: [50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858], old=null
dn2_1    | 2020-12-11 02:29:42 INFO  RoleInfo:134 - 50607d05-dbe3-476f-a8ca-cda3416766f8: shutdown LeaderElection
dn2_1    | 2020-12-11 02:29:42 INFO  RaftServerImpl:172 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
dn2_1    | 2020-12-11 02:29:42 INFO  XceiverServerRatis:744 - Leader change notification received for group: group-4A9003E01997 with new leaderId: 50607d05-dbe3-476f-a8ca-cda3416766f8
dn2_1    | 2020-12-11 02:29:42 INFO  RaftServerImpl:255 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997: change Leader from null to 50607d05-dbe3-476f-a8ca-cda3416766f8 at term 1 for becomeLeader, leader elected after 5843ms
dn2_1    | 2020-12-11 02:29:42 INFO  RaftServerConfigKeys:43 - raft.server.staging.catchup.gap = 1000 (default)
dn2_1    | 2020-12-11 02:29:42 INFO  RaftServerConfigKeys:43 - raft.server.rpc.sleep.time = 25ms (default)
dn2_1    | 2020-12-11 02:29:42 INFO  RatisMetrics:39 - Creating Metrics Registry : ratis.log_appender.50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997
dn2_1    | 2020-12-11 02:29:42 INFO  RaftServerConfigKeys:43 - raft.server.write.element-limit = 1024 (custom)
dn2_1    | 2020-12-11 02:29:42 INFO  RaftServerConfigKeys:43 - raft.server.write.byte-limit = 1073741824 (custom)
dn2_1    | 2020-12-11 02:29:42 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout = 180s (custom)
dn2_1    | 2020-12-11 02:29:42 INFO  RaftServerConfigKeys:43 - raft.server.watch.timeout.denomination = 1s (default)
dn2_1    | 2020-12-11 02:29:42 INFO  RaftServerConfigKeys:43 - raft.server.watch.element-limit = 65536 (default)
dn2_1    | 2020-12-11 02:29:42 INFO  RoleInfo:143 - 50607d05-dbe3-476f-a8ca-cda3416766f8: start LeaderState
dn2_1    | 2020-12-11 02:29:42 INFO  SegmentedRaftLogWorker:391 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997-SegmentedRaftLogWorker: Starting segment from index:0
dn2_1    | 2020-12-11 02:29:42 INFO  SegmentedRaftLogWorker:583 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/0a4e6833-e832-4109-b0ce-4a9003e01997/current/log_inprogress_0
dn2_1    | 2020-12-11 02:29:42 INFO  RaftServerImpl:356 - 50607d05-dbe3-476f-a8ca-cda3416766f8@group-4A9003E01997: set configuration 0: [50607d05-dbe3-476f-a8ca-cda3416766f8:10.9.0.12:9858], old=null at 0
scm_1    | 2020-12-11 02:29:30 WARN  Server:1523 - IPC Server handler 7 on 9861, call Call#7 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.12:54868: output error
scm_1    | 2020-12-11 02:29:30 WARN  Server:1523 - IPC Server handler 6 on 9861, call Call#4 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.11:56284: output error
scm_1    | 2020-12-11 02:29:30 WARN  Server:1523 - IPC Server handler 2 on 9861, call Call#5 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.12:54856: output error
scm_1    | 2020-12-11 02:29:30 INFO  Server:869 - IPC Server handler 9 on 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.11:56244
scm_1    | 2020-12-11 02:29:30 INFO  Server:869 - IPC Server handler 9 on 9861: skipped Call#2 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.11:56270
scm_1    | 2020-12-11 02:29:30 INFO  Server:869 - IPC Server handler 9 on 9861: skipped Call#3 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.13:46790
scm_1    | 2020-12-11 02:29:30 WARN  Server:1523 - IPC Server handler 8 on 9861, call Call#5 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.13:46798: output error
scm_1    | 2020-12-11 02:29:30 WARN  Server:1523 - IPC Server handler 4 on 9861, call Call#5 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.11:56288: output error
scm_1    | 2020-12-11 02:29:30 WARN  Server:1523 - IPC Server handler 3 on 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 10.9.0.13:46764: output error
scm_1    | 2020-12-11 02:29:30 INFO  Server:2695 - IPC Server handler 0 on 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1    | 2020-12-11 02:29:30 INFO  Server:2695 - IPC Server handler 2 on 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1    | 2020-12-11 02:29:30 INFO  Server:2695 - IPC Server handler 8 on 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1    | 2020-12-11 02:29:30 INFO  Server:2695 - IPC Server handler 4 on 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1    | 2020-12-11 02:29:30 INFO  Server:2695 - IPC Server handler 1 on 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1    | 2020-12-11 02:29:30 INFO  Server:2695 - IPC Server handler 5 on 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1    | 2020-12-11 02:29:30 INFO  Server:2695 - IPC Server handler 7 on 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1    | 2020-12-11 02:29:30 INFO  Server:2695 - IPC Server handler 6 on 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1    | 2020-12-11 02:29:30 INFO  Server:2695 - IPC Server handler 3 on 9861 caught an exception
scm_1    | java.nio.channels.AsynchronousCloseException
scm_1    | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1    | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3250)
scm_1    | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:137)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1473)
scm_1    | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1543)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2593)
scm_1    | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1615)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:940)
scm_1    | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:774)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:885)
scm_1    | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822)
scm_1    | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1    | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1    | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
scm_1    | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)
scm_1    | 2020-12-11 02:29:30 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@365553de{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1    | 2020-12-11 02:29:30 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@67e28be3{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-beta.jar!/webapps/static,AVAILABLE}
scm_1    | 2020-12-11 02:29:31 INFO  ContextHandler:825 - Started o.e.j.w.WebAppContext@53e800f9{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-0_5_0-beta_jar-_-any-4810792573840460827.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-0.5.0-beta.jar!/webapps/scm}
scm_1    | 2020-12-11 02:29:31 INFO  AbstractConnector:330 - Started ServerConnector@14f3c6fc{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
scm_1    | 2020-12-11 02:29:31 INFO  Server:399 - Started @26272ms
scm_1    | 2020-12-11 02:29:31 INFO  MetricsSinkAdapter:204 - Sink prometheus started
scm_1    | 2020-12-11 02:29:31 INFO  MetricsSystemImpl:301 - Registered sink prometheus
scm_1    | 2020-12-11 02:29:31 INFO  BaseHttpServer:284 - HTTP server of scm listening at http://0.0.0.0:9876
scm_1    | 2020-12-11 02:29:31 INFO  JvmPauseMonitor:188 - Starting JVM pause monitor
scm_1    | 2020-12-11 02:29:31 INFO  NetworkTopology:111 - Added a new node: /default-rack/e927a432-7d30-4eab-9c57-07bc74eb3997
scm_1    | 2020-12-11 02:29:31 INFO  RatisPipelineProvider:187 - Sending CreatePipelineCommand for pipeline:PipelineID=7ffd4706-2840-4531-94d6-e649b78a07b0 to datanode:e927a432-7d30-4eab-9c57-07bc74eb3997
scm_1    | 2020-12-11 02:29:31 INFO  SCMNodeManager:268 - Registered Data node : e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
scm_1    | 2020-12-11 02:29:31 INFO  SCMSafeModeManager:71 - SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1    | 2020-12-11 02:29:31 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: 7ffd4706-2840-4531-94d6-e649b78a07b0, Nodes: e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-12-11T02:29:31.824386Z]
scm_1    | 2020-12-11 02:29:31 WARN  PipelinePlacementPolicy:151 - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
scm_1    | 2020-12-11 02:29:31 INFO  SCMSafeModeManager:175 - ContainerSafeModeRule rule is successfully validated
scm_1    | 2020-12-11 02:29:32 INFO  NetworkTopology:111 - Added a new node: /default-rack/f50c55c5-6776-4b64-8cb9-bd5a75d26a9a
scm_1    | 2020-12-11 02:29:32 INFO  SCMNodeManager:268 - Registered Data node : f50c55c5-6776-4b64-8cb9-bd5a75d26a9a{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
scm_1    | 2020-12-11 02:29:32 INFO  SCMSafeModeManager:71 - SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1    | 2020-12-11 02:29:32 INFO  SCMSafeModeManager:175 - ContainerSafeModeRule rule is successfully validated
scm_1    | 2020-12-11 02:29:32 INFO  RatisPipelineProvider:187 - Sending CreatePipelineCommand for pipeline:PipelineID=512805e8-9b7a-49ec-bd87-41eb68542fd0 to datanode:f50c55c5-6776-4b64-8cb9-bd5a75d26a9a
scm_1    | 2020-12-11 02:29:32 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: 512805e8-9b7a-49ec-bd87-41eb68542fd0, Nodes: f50c55c5-6776-4b64-8cb9-bd5a75d26a9a{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-12-11T02:29:32.631114Z]
scm_1    | 2020-12-11 02:29:32 WARN  PipelinePlacementPolicy:151 - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
scm_1    | 2020-12-11 02:29:33 INFO  NetworkTopology:111 - Added a new node: /default-rack/50607d05-dbe3-476f-a8ca-cda3416766f8
scm_1    | 2020-12-11 02:29:33 INFO  SCMNodeManager:268 - Registered Data node : 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
scm_1    | 2020-12-11 02:29:33 INFO  RatisPipelineProvider:187 - Sending CreatePipelineCommand for pipeline:PipelineID=0a4e6833-e832-4109-b0ce-4a9003e01997 to datanode:50607d05-dbe3-476f-a8ca-cda3416766f8
scm_1    | 2020-12-11 02:29:33 INFO  SCMSafeModeManager:175 - ContainerSafeModeRule rule is successfully validated
scm_1    | 2020-12-11 02:29:33 INFO  SCMSafeModeManager:71 - SCM in safe mode. 3 DataNodes registered, 3 required.
scm_1    | 2020-12-11 02:29:33 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: 0a4e6833-e832-4109-b0ce-4a9003e01997, Nodes: 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-12-11T02:29:33.233657Z]
scm_1    | 2020-12-11 02:29:33 INFO  SCMSafeModeManager:175 - DataNodeSafeModeRule rule is successfully validated
scm_1    | 2020-12-11 02:29:33 INFO  RatisPipelineProvider:187 - Sending CreatePipelineCommand for pipeline:PipelineID=915fef40-6db3-4e2c-8eb3-e4b11790d590 to datanode:50607d05-dbe3-476f-a8ca-cda3416766f8
scm_1    | 2020-12-11 02:29:33 INFO  RatisPipelineProvider:187 - Sending CreatePipelineCommand for pipeline:PipelineID=915fef40-6db3-4e2c-8eb3-e4b11790d590 to datanode:e927a432-7d30-4eab-9c57-07bc74eb3997
scm_1    | 2020-12-11 02:29:33 INFO  RatisPipelineProvider:187 - Sending CreatePipelineCommand for pipeline:PipelineID=915fef40-6db3-4e2c-8eb3-e4b11790d590 to datanode:f50c55c5-6776-4b64-8cb9-bd5a75d26a9a
scm_1    | 2020-12-11 02:29:33 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: 915fef40-6db3-4e2c-8eb3-e4b11790d590, Nodes: 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}f50c55c5-6776-4b64-8cb9-bd5a75d26a9a{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:null, CreationTimestamp2020-12-11T02:29:33.252307Z]
scm_1    | 2020-12-11 02:29:35 INFO  PipelineReportHandler:117 - Pipeline ONE PipelineID=7ffd4706-2840-4531-94d6-e649b78a07b0 reported by e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
scm_1    | 2020-12-11 02:29:35 INFO  PipelineStateManager:131 - Pipeline Pipeline[ Id: 7ffd4706-2840-4531-94d6-e649b78a07b0, Nodes: e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:e927a432-7d30-4eab-9c57-07bc74eb3997, CreationTimestamp2020-12-11T02:29:31.824386Z] moved to OPEN state
scm_1    | 2020-12-11 02:29:35 INFO  SCMSafeModeManager:131 - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2020-12-11 02:29:35 INFO  SCMSafeModeManager:175 - AtleastOneDatanodeReportedRule rule is successfully validated
scm_1    | 2020-12-11 02:29:35 INFO  PipelineReportHandler:117 - Pipeline THREE PipelineID=915fef40-6db3-4e2c-8eb3-e4b11790d590 reported by e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
scm_1    | 2020-12-11 02:29:36 INFO  PipelineReportHandler:117 - Pipeline ONE PipelineID=512805e8-9b7a-49ec-bd87-41eb68542fd0 reported by f50c55c5-6776-4b64-8cb9-bd5a75d26a9a{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
scm_1    | 2020-12-11 02:29:36 INFO  PipelineStateManager:131 - Pipeline Pipeline[ Id: 512805e8-9b7a-49ec-bd87-41eb68542fd0, Nodes: f50c55c5-6776-4b64-8cb9-bd5a75d26a9a{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:f50c55c5-6776-4b64-8cb9-bd5a75d26a9a, CreationTimestamp2020-12-11T02:29:32.631114Z] moved to OPEN state
scm_1    | 2020-12-11 02:29:36 INFO  SCMSafeModeManager:131 - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2020-12-11 02:29:36 INFO  SCMSafeModeManager:175 - AtleastOneDatanodeReportedRule rule is successfully validated
scm_1    | 2020-12-11 02:29:36 INFO  PipelineReportHandler:117 - Pipeline THREE PipelineID=915fef40-6db3-4e2c-8eb3-e4b11790d590 reported by f50c55c5-6776-4b64-8cb9-bd5a75d26a9a{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
scm_1    | 2020-12-11 02:29:37 INFO  PipelineReportHandler:117 - Pipeline ONE PipelineID=0a4e6833-e832-4109-b0ce-4a9003e01997 reported by 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
scm_1    | 2020-12-11 02:29:37 INFO  PipelineStateManager:131 - Pipeline Pipeline[ Id: 0a4e6833-e832-4109-b0ce-4a9003e01997, Nodes: 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:50607d05-dbe3-476f-a8ca-cda3416766f8, CreationTimestamp2020-12-11T02:29:33.233657Z] moved to OPEN state
scm_1    | 2020-12-11 02:29:37 INFO  SCMSafeModeManager:131 - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1    | 2020-12-11 02:29:37 INFO  SCMSafeModeManager:175 - AtleastOneDatanodeReportedRule rule is successfully validated
scm_1    | 2020-12-11 02:29:37 INFO  PipelineReportHandler:117 - Pipeline THREE PipelineID=915fef40-6db3-4e2c-8eb3-e4b11790d590 reported by 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
scm_1    | 2020-12-11 02:29:40 INFO  PipelineReportHandler:117 - Pipeline THREE PipelineID=915fef40-6db3-4e2c-8eb3-e4b11790d590 reported by e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
scm_1    | 2020-12-11 02:29:40 INFO  PipelineReportHandler:117 - Pipeline THREE PipelineID=915fef40-6db3-4e2c-8eb3-e4b11790d590 reported by e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}
scm_1    | 2020-12-11 02:29:40 INFO  PipelineStateManager:131 - Pipeline Pipeline[ Id: 915fef40-6db3-4e2c-8eb3-e4b11790d590, Nodes: 50607d05-dbe3-476f-a8ca-cda3416766f8{ip: 10.9.0.12, host: upgrade_dn2_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}e927a432-7d30-4eab-9c57-07bc74eb3997{ip: 10.9.0.13, host: upgrade_dn3_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}f50c55c5-6776-4b64-8cb9-bd5a75d26a9a{ip: 10.9.0.11, host: upgrade_dn1_1.upgrade_net, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:e927a432-7d30-4eab-9c57-07bc74eb3997, CreationTimestamp2020-12-11T02:29:33.252307Z] moved to OPEN state
scm_1    | 2020-12-11 02:29:40 INFO  SCMSafeModeManager:131 - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1    | 2020-12-11 02:29:40 INFO  SCMSafeModeManager:175 - AtleastOneDatanodeReportedRule rule is successfully validated
scm_1    | 2020-12-11 02:29:40 INFO  SCMSafeModeManager:175 - HealthyPipelineSafeModeRule rule is successfully validated
scm_1    | 2020-12-11 02:29:40 INFO  SCMSafeModeManager:184 - ScmSafeModeManager, all rules are successfully validated
scm_1    | 2020-12-11 02:29:40 INFO  SCMSafeModeManager:200 - SCM exiting safe mode.
