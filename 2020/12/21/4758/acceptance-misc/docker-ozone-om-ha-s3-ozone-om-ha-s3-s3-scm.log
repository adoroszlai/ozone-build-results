Attaching to ozone-om-ha-s3_datanode_1, ozone-om-ha-s3_datanode_3, ozone-om-ha-s3_datanode_2, ozone-om-ha-s3_s3g_1, ozone-om-ha-s3_scm_1, ozone-om-ha-s3_om2_1, ozone-om-ha-s3_om3_1, ozone-om-ha-s3_om1_1
datanode_2  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2020-12-21 16:35:21,701 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = 0c1ed6ebf729/172.23.0.4
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/ozone/c958bfb4070aab1068d7e455792957fc116a31fc ; compiled by 'runner' on 2020-12-21T16:02Z
datanode_2  | STARTUP_MSG:   java = 11.0.7
datanode_2  | ************************************************************/
datanode_2  | 2020-12-21 16:35:21,747 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2020-12-21 16:35:23,610 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2020-12-21 16:35:24,526 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2020-12-21 16:35:25,868 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2020-12-21 16:35:25,872 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2020-12-21 16:35:26,525 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:0c1ed6ebf729 ip:172.23.0.4
datanode_2  | 2020-12-21 16:35:28,533 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2  | 2020-12-21 16:35:28,556 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2  | 2020-12-21 16:35:28,627 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2020-12-21 16:35:28,646 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2  | 2020-12-21 16:35:28,952 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2020-12-21 16:35:29,187 [Thread-6] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_2  | 2020-12-21 16:35:29,200 [Thread-6] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_2  | 2020-12-21 16:35:29,204 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_2  | 2020-12-21 16:35:38,695 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-12-21 16:35:39,072 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2020-12-21 16:35:39,728 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2  | 2020-12-21 16:35:39,729 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2  | 2020-12-21 16:35:39,729 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-12-21 16:35:39,736 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2  | 2020-12-21 16:35:39,737 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-12-21 16:35:41,333 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_2  | 2020-12-21 16:35:41,398 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-12-21 16:35:41,419 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-12-21 16:35:42,238 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 2020-12-21 16:35:42,300 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2  | 2020-12-21 16:35:42,574 [main] INFO util.log: Logging initialized @28619ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | 2020-12-21 16:35:43,307 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2020-12-21 16:35:43,343 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2020-12-21 16:35:43,444 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2020-12-21 16:35:43,446 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2  | 2020-12-21 16:35:43,454 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2  | 2020-12-21 16:35:43,455 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2  | 2020-12-21 16:35:43,653 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2  | 2020-12-21 16:35:43,674 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2020-12-21 16:35:43,687 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
datanode_2  | 2020-12-21 16:35:43,850 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2020-12-21 16:35:43,850 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2020-12-21 16:35:43,852 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2  | 2020-12-21 16:35:43,937 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@aee05f4{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2020-12-21 16:35:43,946 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2b2b7e3c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2020-12-21 16:35:44,388 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@77f4038c{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-16638369863613459300/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 2020-12-21 16:35:44,430 [main] INFO server.AbstractConnector: Started ServerConnector@4a453f8d{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_2  | 2020-12-21 16:35:44,430 [main] INFO server.Server: Started @30475ms
datanode_2  | 2020-12-21 16:35:44,453 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2020-12-21 16:35:44,453 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2020-12-21 16:35:44,483 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2020-12-21 16:35:44,571 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@61ef66e8] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2020-12-21 16:35:45,637 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2  | 2020-12-21 16:35:47,957 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-12-21 16:35:48,957 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-12-21 16:35:49,958 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-12-21 16:35:50,959 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-12-21 16:35:53,211 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2020-12-21 16:35:53,228 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2  | 2020-12-21 16:35:53,228 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis ec956fef-022a-4e11-a406-1dfa86e0929f at port 9858
datanode_2  | 2020-12-21 16:35:53,312 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO impl.RaftServerProxy: ec956fef-022a-4e11-a406-1dfa86e0929f: start RPC server
datanode_2  | 2020-12-21 16:35:53,977 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO server.GrpcService: ec956fef-022a-4e11-a406-1dfa86e0929f: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2  | 2020-12-21 16:35:54,041 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2020-12-21 16:35:54,051 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2  | 2020-12-21 16:35:54,102 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] INFO server.JvmPauseMonitor: Starting Ratis JVM pause monitor
datanode_2  | 2020-12-21 16:35:57,174 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_2  | No GCs detected
datanode_2  | 2020-12-21 16:35:57,707 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 15ms
datanode_2  | No GCs detected
datanode_2  | 2020-12-21 16:35:57,803 [Command processor thread] INFO impl.RaftServerProxy: ec956fef-022a-4e11-a406-1dfa86e0929f: addNew group-A46A69316625:[f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858] returns group-A46A69316625:java.util.concurrent.CompletableFuture@1d882ac2[Not completed]
datanode_2  | 2020-12-21 16:35:57,936 [pool-19-thread-1] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f: new RaftServerImpl for group-A46A69316625:[f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-12-21 16:35:57,939 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-12-21 16:35:57,940 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-12-21 16:35:57,940 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2  | 2020-12-21 16:35:57,940 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2020-12-21 16:35:57,944 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-12-21 16:35:57,944 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-12-21 16:35:57,989 [pool-19-thread-1] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625: ConfigurationManager, init=-1: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-12-21 16:35:57,990 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-12-21 16:35:58,014 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-12-21 16:35:58,028 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/1f541f4e-a162-4978-bdd3-a46a69316625 does not exist. Creating ...
datanode_2  | 2020-12-21 16:35:58,062 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/1f541f4e-a162-4978-bdd3-a46a69316625/in_use.lock acquired by nodename 6@0c1ed6ebf729
datanode_2  | 2020-12-21 16:35:58,077 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/1f541f4e-a162-4978-bdd3-a46a69316625 has been successfully formatted.
datanode_2  | 2020-12-21 16:35:58,116 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-A46A69316625: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-12-21 16:35:58,123 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2020-12-21 16:35:58,202 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-12-21 16:35:58,220 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_2  | GC pool 'ParNew' had collection(s): count=1 time=55ms
datanode_2  | 2020-12-21 16:35:58,236 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-12-21 16:35:58,260 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625
datanode_2  | 2020-12-21 16:35:58,330 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-12-21 16:35:58,334 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-12-21 16:35:58,379 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-12-21 16:35:58,405 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/1f541f4e-a162-4978-bdd3-a46a69316625
datanode_2  | 2020-12-21 16:35:58,412 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-12-21 16:35:58,412 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-12-21 16:35:58,413 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-12-21 16:35:58,416 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-12-21 16:35:58,432 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-12-21 16:35:58,435 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-12-21 16:35:58,439 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-12-21 16:35:58,439 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-12-21 16:35:58,440 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-12-21 16:35:58,488 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-12-21 16:35:58,500 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2020-12-21 16:35:22,334 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = 73cd1ddef382/172.23.0.5
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_2  | 2020-12-21 16:35:58,506 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-12-21 16:35:58,528 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-12-21 16:35:58,529 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-12-21 16:35:58,529 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-12-21 16:35:58,530 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-12-21 16:35:58,530 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-12-21 16:35:58,612 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625
datanode_2  | 2020-12-21 16:35:58,631 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625
datanode_2  | 2020-12-21 16:35:58,648 [pool-19-thread-1] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625: start as a follower, conf=-1: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858], old=null
datanode_2  | 2020-12-21 16:35:58,652 [pool-19-thread-1] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-12-21 16:35:58,654 [pool-19-thread-1] INFO impl.RoleInfo: ec956fef-022a-4e11-a406-1dfa86e0929f: start ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-FollowerState
datanode_2  | 2020-12-21 16:35:58,680 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A46A69316625,id=ec956fef-022a-4e11-a406-1dfa86e0929f
datanode_2  | 2020-12-21 16:35:58,681 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625
datanode_2  | 2020-12-21 16:35:58,726 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=1 time=55ms
datanode_2  | 2020-12-21 16:35:58,954 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-8F5171FDC7A5->d59b5746-4c38-43fa-95c4-93039b647722
datanode_2  | 2020-12-21 16:35:59,826 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 94ms
datanode_2  | GC pool 'ParNew' had collection(s): count=2 time=152ms
datanode_2  | 2020-12-21 16:36:00,856 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 16ms
datanode_2  | GC pool 'ParNew' had collection(s): count=2 time=152ms
datanode_2  | 2020-12-21 16:36:02,834 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-920007E7CAF1->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2
datanode_2  | 2020-12-21 16:36:02,866 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=2 time=152ms
datanode_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2020-12-21 16:35:22,090 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = b57317203960/172.23.0.7
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/c958bfb4070aab1068d7e455792957fc116a31fc ; compiled by 'runner' on 2020-12-21T16:02Z
datanode_1  | STARTUP_MSG:   java = 11.0.7
datanode_1  | ************************************************************/
datanode_1  | 2020-12-21 16:35:22,156 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2020-12-21 16:35:24,000 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2020-12-21 16:35:24,987 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2020-12-21 16:35:26,000 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2020-12-21 16:35:26,000 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2020-12-21 16:35:26,753 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:b57317203960 ip:172.23.0.7
datanode_1  | 2020-12-21 16:35:28,887 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2020-12-21 16:35:28,924 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1  | 2020-12-21 16:35:28,995 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2020-12-21 16:35:29,110 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2020-12-21 16:35:29,556 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2020-12-21 16:35:29,869 [Thread-6] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_1  | 2020-12-21 16:35:29,871 [Thread-6] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_1  | 2020-12-21 16:35:29,872 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_1  | 2020-12-21 16:35:39,324 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2020-12-21 16:35:39,657 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1  | 2020-12-21 16:35:40,126 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1  | 2020-12-21 16:35:40,127 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  | 2020-12-21 16:35:40,129 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-12-21 16:35:40,129 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1  | 2020-12-21 16:35:40,130 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2020-12-21 16:35:42,055 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_1  | 2020-12-21 16:35:42,158 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-12-21 16:35:42,189 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2020-12-21 16:35:43,016 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2020-12-21 16:35:43,143 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1  | 2020-12-21 16:35:43,356 [main] INFO util.log: Logging initialized @28204ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2020-12-21 16:35:44,014 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2020-12-21 16:35:44,042 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2020-12-21 16:35:44,120 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2020-12-21 16:35:44,132 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1  | 2020-12-21 16:35:44,136 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1  | 2020-12-21 16:35:44,136 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1  | 2020-12-21 16:35:44,362 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1  | 2020-12-21 16:35:44,431 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2020-12-21 16:35:44,437 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
datanode_1  | 2020-12-21 16:35:44,646 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  | 2020-12-21 16:35:44,674 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2020-12-21 16:35:44,677 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1  | 2020-12-21 16:35:44,752 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@a55e82a{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2020-12-21 16:35:44,784 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@16b7e04a{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2020-12-21 16:35:45,499 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@43b4ec0c{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-3232320529628171673/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1  | 2020-12-21 16:35:45,579 [main] INFO server.AbstractConnector: Started ServerConnector@1be3f8f8{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_1  | 2020-12-21 16:35:45,579 [main] INFO server.Server: Started @30427ms
datanode_1  | 2020-12-21 16:35:45,652 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2020-12-21 16:35:45,652 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2020-12-21 16:35:45,660 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1  | 2020-12-21 16:35:45,840 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@19611238] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2020-12-21 16:35:47,063 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1  | 2020-12-21 16:35:49,003 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-12-21 16:35:50,004 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-12-21 16:35:51,004 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om1_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om1_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1       | 2020-12-21 16:35:20,250 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1       | /************************************************************
om1_1       | STARTUP_MSG: Starting OzoneManager
om1_1       | STARTUP_MSG:   host = 45a6689dd7c9/172.23.0.2
om1_1       | STARTUP_MSG:   args = [--init]
om1_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om1_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/ozone/c958bfb4070aab1068d7e455792957fc116a31fc ; compiled by 'runner' on 2020-12-21T16:02Z
datanode_3  | STARTUP_MSG:   java = 11.0.7
datanode_3  | ************************************************************/
datanode_3  | 2020-12-21 16:35:22,424 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2020-12-21 16:35:24,251 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2020-12-21 16:35:25,358 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2020-12-21 16:35:26,486 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2020-12-21 16:35:26,487 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2020-12-21 16:35:27,178 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:73cd1ddef382 ip:172.23.0.5
datanode_3  | 2020-12-21 16:35:29,316 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3  | 2020-12-21 16:35:29,332 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3  | 2020-12-21 16:35:29,357 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2020-12-21 16:35:29,395 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2020-12-21 16:35:29,683 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2020-12-21 16:35:29,963 [Thread-6] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_3  | 2020-12-21 16:35:30,003 [Thread-6] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_3  | 2020-12-21 16:35:30,007 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_3  | 2020-12-21 16:35:39,570 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-12-21 16:35:39,925 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3  | 2020-12-21 16:35:40,552 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3  | 2020-12-21 16:35:40,554 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3  | 2020-12-21 16:35:40,572 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-12-21 16:35:40,574 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3  | 2020-12-21 16:35:40,584 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-12-21 16:35:42,070 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_3  | 2020-12-21 16:35:42,184 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-12-21 16:35:42,198 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-12-21 16:35:43,558 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2020-12-21 16:35:43,680 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3  | 2020-12-21 16:35:43,847 [main] INFO util.log: Logging initialized @29645ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2020-12-21 16:35:44,581 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2020-12-21 16:35:44,622 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2020-12-21 16:35:44,692 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2020-12-21 16:35:44,700 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3  | 2020-12-21 16:35:44,706 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3  | 2020-12-21 16:35:44,706 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3  | 2020-12-21 16:35:44,934 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_3  | 2020-12-21 16:35:45,025 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2020-12-21 16:35:45,033 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
datanode_3  | 2020-12-21 16:35:45,244 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2020-12-21 16:35:45,244 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 2020-12-21 16:35:45,248 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_3  | 2020-12-21 16:35:45,287 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2bcb1414{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2020-12-21 16:35:45,288 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2fa879ed{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2020-12-21 16:35:45,985 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@27a90ce5{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-6972179486595857336/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2020-12-21 16:35:46,084 [main] INFO server.AbstractConnector: Started ServerConnector@2efcc0b3{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_3  | 2020-12-21 16:35:46,087 [main] INFO server.Server: Started @31896ms
datanode_3  | 2020-12-21 16:35:46,104 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2020-12-21 16:35:46,104 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2020-12-21 16:35:46,112 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3  | 2020-12-21 16:35:46,240 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d20eac8] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2020-12-21 16:35:47,233 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3  | 2020-12-21 16:35:49,404 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-12-21 16:35:50,409 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-12-21 16:35:51,410 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-12-21 16:35:53,228 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3  | 2020-12-21 16:35:53,245 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3  | 2020-12-21 16:35:53,246 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis d59b5746-4c38-43fa-95c4-93039b647722 at port 9858
datanode_3  | 2020-12-21 16:35:53,359 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO impl.RaftServerProxy: d59b5746-4c38-43fa-95c4-93039b647722: start RPC server
datanode_3  | 2020-12-21 16:35:53,959 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO server.GrpcService: d59b5746-4c38-43fa-95c4-93039b647722: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3  | 2020-12-21 16:35:54,005 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2020-12-21 16:35:54,014 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2020-12-21 16:35:54,132 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] INFO server.JvmPauseMonitor: Starting Ratis JVM pause monitor
datanode_3  | 2020-12-21 16:35:54,678 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1 time=171ms
datanode_3  | 2020-12-21 16:35:56,704 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1 time=171ms
datanode_3  | 2020-12-21 16:35:57,711 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1 time=171ms
datanode_3  | 2020-12-21 16:36:00,216 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1 time=171ms
datanode_3  | 2020-12-21 16:36:01,217 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.d59b5746-4c38-43fa-95c4-93039b647722
datanode_3  | 2020-12-21 16:36:01,341 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 108ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2 time=281ms
datanode_3  | 2020-12-21 16:36:01,680 [grpc-default-executor-0] INFO impl.RaftServerProxy: d59b5746-4c38-43fa-95c4-93039b647722: addNew group-A46A69316625:[f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858|dataStream:, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858|dataStream:, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858|dataStream:] returns group-A46A69316625:java.util.concurrent.CompletableFuture@42416350[Not completed]
datanode_3  | 2020-12-21 16:36:01,752 [pool-19-thread-1] INFO impl.RaftServerImpl: d59b5746-4c38-43fa-95c4-93039b647722: new RaftServerImpl for group-A46A69316625:[f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858|dataStream:, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858|dataStream:, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858|dataStream:] with ContainerStateMachine:uninitialized
om1_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/c958bfb4070aab1068d7e455792957fc116a31fc ; compiled by 'runner' on 2020-12-21T16:02Z
om1_1       | STARTUP_MSG:   java = 11.0.7
om1_1       | ************************************************************/
om1_1       | 2020-12-21 16:35:20,330 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1       | 2020-12-21 16:35:29,975 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om1_1       | 2020-12-21 16:35:30,797 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1       | 2020-12-21 16:35:30,807 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om1: om1
om1_1       | 2020-12-21 16:35:30,934 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1       | 2020-12-21 16:35:34,543 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-21 16:35:35,544 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-21 16:35:36,544 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-21 16:35:37,545 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-21 16:35:38,546 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-21 16:35:39,546 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-21 16:35:40,548 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-21 16:35:41,557 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-21 16:35:42,558 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-21 16:35:43,559 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-21 16:35:43,561 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om1_1       | 2020-12-21 16:35:49,563 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-21 16:35:50,564 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-21 16:35:51,565 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-7fd6ff48-e398-43cb-8679-8634afd5c1b9;layoutVersion=0
om1_1       | 2020-12-21 16:35:52,828 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1       | /************************************************************
om1_1       | SHUTDOWN_MSG: Shutting down OzoneManager at 45a6689dd7c9/172.23.0.2
om1_1       | ************************************************************/
om1_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om1_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1       | 2020-12-21 16:35:58,768 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1       | /************************************************************
om1_1       | STARTUP_MSG: Starting OzoneManager
om1_1       | STARTUP_MSG:   host = 45a6689dd7c9/172.23.0.2
om1_1       | STARTUP_MSG:   args = []
om1_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om1_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om1_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/c958bfb4070aab1068d7e455792957fc116a31fc ; compiled by 'runner' on 2020-12-21T16:02Z
om1_1       | STARTUP_MSG:   java = 11.0.7
om1_1       | ************************************************************/
om1_1       | 2020-12-21 16:35:58,799 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1       | 2020-12-21 16:36:05,623 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om1_1       | 2020-12-21 16:36:06,162 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1       | 2020-12-21 16:36:06,162 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om1: om1
om1_1       | 2020-12-21 16:36:06,268 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1       | 2020-12-21 16:36:06,389 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1       | 2020-12-21 16:36:10,654 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1       | 2020-12-21 16:36:11,238 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1       | 2020-12-21 16:36:11,247 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1       | 2020-12-21 16:36:12,180 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
om1_1       | 2020-12-21 16:36:12,219 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1       | 2020-12-21 16:36:12,493 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1       | 2020-12-21 16:36:12,628 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om1:9872, om2:9872, om3:9872
om1_1       | 2020-12-21 16:36:12,671 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1       | 2020-12-21 16:36:12,747 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
om1_1       | 2020-12-21 16:36:12,992 [main] INFO grpc.GrpcFactory: PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
om1_1       | 	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
om1_1       | 2020-12-21 16:36:13,007 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1       | 2020-12-21 16:36:13,015 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om1_1       | 2020-12-21 16:36:13,028 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-12-21 16:36:03,796 [Thread-23] INFO impl.FollowerState: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-FollowerState: change to CANDIDATE, lastRpcTime:5142ms, electionTimeout:5116ms
datanode_2  | 2020-12-21 16:36:03,797 [Thread-23] INFO impl.RoleInfo: ec956fef-022a-4e11-a406-1dfa86e0929f: shutdown ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-FollowerState
datanode_2  | 2020-12-21 16:36:03,798 [Thread-23] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-12-21 16:36:03,820 [Thread-23] INFO impl.RoleInfo: ec956fef-022a-4e11-a406-1dfa86e0929f: start ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1
datanode_2  | 2020-12-21 16:36:03,849 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO impl.LeaderElection: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1: begin an election at term 1 for -1: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858], old=null
datanode_2  | 2020-12-21 16:36:03,872 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_2  | GC pool 'ParNew' had collection(s): count=2 time=152ms
datanode_2  | 2020-12-21 16:36:04,165 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO impl.LeaderElection: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1: Election PASSED; received 1 response(s) [ec956fef-022a-4e11-a406-1dfa86e0929f<-d59b5746-4c38-43fa-95c4-93039b647722#0:OK-t1] and 0 exception(s); ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625:t1, leader=null, voted=ec956fef-022a-4e11-a406-1dfa86e0929f, raftlog=ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858], old=null
datanode_2  | 2020-12-21 16:36:04,184 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO impl.RoleInfo: ec956fef-022a-4e11-a406-1dfa86e0929f: shutdown ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1
datanode_2  | 2020-12-21 16:36:04,197 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-12-21 16:36:04,203 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A46A69316625 with new leaderId: ec956fef-022a-4e11-a406-1dfa86e0929f
datanode_2  | 2020-12-21 16:36:04,208 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625: change Leader from null to ec956fef-022a-4e11-a406-1dfa86e0929f at term 1 for becomeLeader, leader elected after 6086ms
datanode_2  | 2020-12-21 16:36:04,221 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-12-21 16:36:04,232 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2020-12-21 16:36:04,233 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625
datanode_2  | 2020-12-21 16:36:04,253 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-12-21 16:36:01,769 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-12-21 16:36:01,773 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-12-21 16:36:01,773 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2020-12-21 16:36:01,773 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2020-12-21 16:36:01,774 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-12-21 16:36:01,786 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-12-21 16:36:01,826 [pool-19-thread-1] INFO impl.RaftServerImpl: d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625: ConfigurationManager, init=-1: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858|dataStream:, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858|dataStream:, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858|dataStream:], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-12-21 16:36:01,829 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-12-21 16:36:01,852 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-12-21 16:36:01,854 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/1f541f4e-a162-4978-bdd3-a46a69316625 does not exist. Creating ...
datanode_3  | 2020-12-21 16:36:01,893 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/1f541f4e-a162-4978-bdd3-a46a69316625/in_use.lock acquired by nodename 6@73cd1ddef382
datanode_3  | 2020-12-21 16:36:01,904 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/1f541f4e-a162-4978-bdd3-a46a69316625 has been successfully formatted.
datanode_3  | 2020-12-21 16:36:01,933 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-A46A69316625: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-12-21 16:36:01,949 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3  | 2020-12-21 16:36:01,963 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-12-21 16:36:02,078 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-12-21 16:36:02,079 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625
datanode_3  | 2020-12-21 16:36:02,106 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-12-21 16:36:02,112 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-12-21 16:36:02,135 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-12-21 16:36:02,189 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/1f541f4e-a162-4978-bdd3-a46a69316625
datanode_3  | 2020-12-21 16:36:02,193 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-12-21 16:36:02,194 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-12-21 16:36:02,194 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-12-21 16:36:02,196 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-12-21 16:35:53,133 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 2020-12-21 16:35:53,135 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1  | 2020-12-21 16:35:53,144 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 at port 9858
datanode_1  | 2020-12-21 16:35:53,169 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO impl.RaftServerProxy: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: start RPC server
datanode_1  | 2020-12-21 16:35:53,642 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO server.GrpcService: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1  | 2020-12-21 16:35:53,684 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2020-12-21 16:35:53,684 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2020-12-21 16:35:53,835 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] INFO server.JvmPauseMonitor: Starting Ratis JVM pause monitor
datanode_1  | 2020-12-21 16:36:02,907 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=1 time=109ms
datanode_1  | 2020-12-21 16:36:03,415 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
datanode_1  | GC pool 'ParNew' had collection(s): count=1 time=109ms
datanode_1  | 2020-12-21 16:36:03,708 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2
datanode_1  | 2020-12-21 16:36:04,255 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: Failed requestVote ec956fef-022a-4e11-a406-1dfa86e0929f->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2#0
datanode_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: group-A46A69316625 not found.
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:131)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:286)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:295)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:290)
datanode_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:484)
datanode_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:170)
datanode_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:325)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:172)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:331)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:818)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_2  | 2020-12-21 16:36:04,257 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-12-21 16:36:04,308 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-12-21 16:36:04,310 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-12-21 16:36:04,312 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2020-12-21 16:36:04,375 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=2 time=152ms
datanode_2  | 2020-12-21 16:36:04,380 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2  | 2020-12-21 16:36:04,381 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-12-21 16:36:04,381 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2  | 2020-12-21 16:36:04,385 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2  | 2020-12-21 16:36:04,400 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-12-21 16:36:04,402 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-12-21 16:36:04,403 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625
datanode_2  | 2020-12-21 16:36:04,426 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2  | 2020-12-21 16:36:04,437 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-12-21 16:36:04,438 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2  | 2020-12-21 16:36:04,458 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2  | 2020-12-21 16:36:04,459 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-12-21 16:36:04,464 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-12-21 16:36:04,477 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO impl.RoleInfo: ec956fef-022a-4e11-a406-1dfa86e0929f: start ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderState
datanode_2  | 2020-12-21 16:36:04,568 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-12-21 16:36:04,672 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-LeaderElection1] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625: set configuration 0: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858|dataStream:, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858|dataStream:, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858|dataStream:], old=null at 0
datanode_2  | 2020-12-21 16:36:04,884 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_2  | GC pool 'ParNew' had collection(s): count=2 time=152ms
datanode_2  | 2020-12-21 16:36:05,389 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_2  | GC pool 'ParNew' had collection(s): count=2 time=152ms
datanode_2  | 2020-12-21 16:36:05,460 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/1f541f4e-a162-4978-bdd3-a46a69316625/current/log_inprogress_0
datanode_2  | 2020-12-21 16:36:05,766 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=1f541f4e-a162-4978-bdd3-a46a69316625.
datanode_2  | 2020-12-21 16:36:05,767 [Command processor thread] INFO impl.RaftServerProxy: ec956fef-022a-4e11-a406-1dfa86e0929f: addNew group-C0245D86E4D4:[ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858] returns group-C0245D86E4D4:java.util.concurrent.CompletableFuture@3887f561[Not completed]
datanode_2  | 2020-12-21 16:36:05,769 [pool-19-thread-1] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f: new RaftServerImpl for group-C0245D86E4D4:[ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-12-21 16:36:05,769 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-12-21 16:36:05,769 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 2020-12-21 16:36:02,196 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-12-21 16:36:02,197 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-12-21 16:36:04,385 [grpc-default-executor-0] INFO impl.RaftServerProxy: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: addNew group-A46A69316625:[f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858|dataStream:, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858|dataStream:, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858|dataStream:] returns group-A46A69316625:java.util.concurrent.CompletableFuture@ca9300c[Not completed]
datanode_1  | 2020-12-21 16:36:04,588 [pool-19-thread-1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: new RaftServerImpl for group-A46A69316625:[f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858|dataStream:, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858|dataStream:, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858|dataStream:] with ContainerStateMachine:uninitialized
datanode_1  | 2020-12-21 16:36:04,593 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-12-21 16:36:04,598 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-12-21 16:36:04,598 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2020-12-21 16:36:04,598 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2020-12-21 16:36:04,599 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-12-21 16:36:04,603 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-12-21 16:36:04,635 [pool-19-thread-1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625: ConfigurationManager, init=-1: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858|dataStream:, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858|dataStream:, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858|dataStream:], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-12-21 16:36:04,648 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-12-21 16:36:04,675 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-12-21 16:36:04,677 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/1f541f4e-a162-4978-bdd3-a46a69316625 does not exist. Creating ...
datanode_1  | 2020-12-21 16:36:04,714 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/1f541f4e-a162-4978-bdd3-a46a69316625/in_use.lock acquired by nodename 6@b57317203960
datanode_1  | 2020-12-21 16:36:04,736 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/1f541f4e-a162-4978-bdd3-a46a69316625 has been successfully formatted.
datanode_1  | 2020-12-21 16:36:04,796 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-A46A69316625: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-12-21 16:36:04,801 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3  | 2020-12-21 16:36:02,202 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-12-21 16:36:02,204 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-12-21 16:36:02,207 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-12-21 16:36:02,227 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-12-21 16:36:02,275 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-12-21 16:36:02,275 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-12-21 16:36:02,297 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-12-21 16:36:02,298 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-12-21 16:36:02,300 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-12-21 16:36:02,301 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-12-21 16:36:02,303 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-12-21 16:36:02,375 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625
datanode_3  | 2020-12-21 16:36:02,436 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625
datanode_3  | 2020-12-21 16:36:02,450 [pool-19-thread-1] INFO impl.RaftServerImpl: d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625: start as a follower, conf=-1: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858|dataStream:, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858|dataStream:, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858|dataStream:], old=null
datanode_3  | 2020-12-21 16:36:02,464 [pool-19-thread-1] INFO impl.RaftServerImpl: d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-12-21 16:36:02,467 [pool-19-thread-1] INFO impl.RoleInfo: d59b5746-4c38-43fa-95c4-93039b647722: start d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625-FollowerState
datanode_3  | 2020-12-21 16:36:02,488 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A46A69316625,id=d59b5746-4c38-43fa-95c4-93039b647722
datanode_3  | 2020-12-21 16:36:02,490 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625
datanode_3  | 2020-12-21 16:36:04,016 [grpc-default-executor-0] INFO impl.RaftServerImpl: d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:ec956fef-022a-4e11-a406-1dfa86e0929f
datanode_3  | 2020-12-21 16:36:04,017 [grpc-default-executor-0] INFO impl.RoleInfo: d59b5746-4c38-43fa-95c4-93039b647722: shutdown d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625-FollowerState
datanode_3  | 2020-12-21 16:36:04,018 [grpc-default-executor-0] INFO impl.RoleInfo: d59b5746-4c38-43fa-95c4-93039b647722: start d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625-FollowerState
datanode_3  | 2020-12-21 16:36:04,019 [Thread-23] INFO impl.FollowerState: d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625-FollowerState was interrupted: {}
datanode_3  | java.lang.InterruptedException: sleep interrupted
datanode_3  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_3  | 	at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:250)
datanode_3  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:116)
datanode_3  | 2020-12-21 16:36:04,046 [grpc-default-executor-0] INFO impl.RaftServerImpl:  FOLLOWER d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625:t1, leader=null, voted=null, raftlog=d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858|dataStream:, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858|dataStream:, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858|dataStream:], old=null RUNNING priority:0 candidate:ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858|dataStream: candidatePriority:0 compare:0
datanode_3  | 2020-12-21 16:36:04,781 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A46A69316625 with new leaderId: ec956fef-022a-4e11-a406-1dfa86e0929f
datanode_3  | 2020-12-21 16:36:04,784 [grpc-default-executor-0] INFO impl.RaftServerImpl: d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625: change Leader from null to ec956fef-022a-4e11-a406-1dfa86e0929f at term 1 for appendEntries, leader elected after 2848ms
datanode_3  | 2020-12-21 16:36:04,848 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2 time=281ms
datanode_3  | 2020-12-21 16:36:04,949 [grpc-default-executor-0] INFO impl.RaftServerImpl: d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625: set configuration 0: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858|dataStream:, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858|dataStream:, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858|dataStream:], old=null at 0
datanode_3  | 2020-12-21 16:36:04,999 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-12-21 16:36:05,440 [d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d59b5746-4c38-43fa-95c4-93039b647722@group-A46A69316625-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/1f541f4e-a162-4978-bdd3-a46a69316625/current/log_inprogress_0
datanode_3  | 2020-12-21 16:36:27,253 [Command processor thread] INFO impl.RaftServerProxy: d59b5746-4c38-43fa-95c4-93039b647722: addNew group-6E26B47E7B56:[d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858] returns group-6E26B47E7B56:java.util.concurrent.CompletableFuture@607438ef[Not completed]
datanode_3  | 2020-12-21 16:36:27,255 [pool-19-thread-1] INFO impl.RaftServerImpl: d59b5746-4c38-43fa-95c4-93039b647722: new RaftServerImpl for group-6E26B47E7B56:[d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-12-21 16:36:27,256 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-12-21 16:36:27,256 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-12-21 16:36:27,256 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2020-12-21 16:36:27,256 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2020-12-21 16:36:27,256 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-12-21 16:36:27,257 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-12-21 16:36:27,257 [pool-19-thread-1] INFO impl.RaftServerImpl: d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56: ConfigurationManager, init=-1: [d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-12-21 16:36:27,257 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-12-21 16:36:27,257 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-12-21 16:36:27,257 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/6f160a74-ec34-4eec-a46f-6e26b47e7b56 does not exist. Creating ...
datanode_3  | 2020-12-21 16:36:27,259 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/6f160a74-ec34-4eec-a46f-6e26b47e7b56/in_use.lock acquired by nodename 6@73cd1ddef382
datanode_3  | 2020-12-21 16:36:27,260 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/6f160a74-ec34-4eec-a46f-6e26b47e7b56 has been successfully formatted.
datanode_3  | 2020-12-21 16:36:27,261 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-6E26B47E7B56: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
om2_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om2_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1       | 2020-12-21 16:35:23,656 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1       | /************************************************************
om2_1       | STARTUP_MSG: Starting OzoneManager
om2_1       | STARTUP_MSG:   host = 4f06b7713c77/172.23.0.9
om2_1       | STARTUP_MSG:   args = [--init]
om2_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om2_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om2_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/c958bfb4070aab1068d7e455792957fc116a31fc ; compiled by 'runner' on 2020-12-21T16:02Z
om2_1       | STARTUP_MSG:   java = 11.0.7
om2_1       | ************************************************************/
om2_1       | 2020-12-21 16:35:23,736 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1       | 2020-12-21 16:35:31,949 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om2_1       | 2020-12-21 16:35:33,202 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1       | 2020-12-21 16:35:33,202 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om2: om2
om2_1       | 2020-12-21 16:35:33,344 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1       | 2020-12-21 16:35:37,272 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-12-21 16:36:04,863 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1       | 2020-12-21 16:36:13,029 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1       | 2020-12-21 16:36:13,030 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1       | 2020-12-21 16:35:38,284 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-21 16:35:39,284 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-21 16:35:40,286 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-21 16:35:41,287 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-12-21 16:36:04,915 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-12-21 16:36:04,945 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625
om2_1       | 2020-12-21 16:35:42,288 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-21 16:35:43,288 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-21 16:35:44,289 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-21 16:35:45,290 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-12-21 16:36:04,956 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-12-21 16:36:04,967 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-12-21 16:36:05,025 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1       | 2020-12-21 16:35:46,294 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-21 16:35:46,296 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om2_1       | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-7fd6ff48-e398-43cb-8679-8634afd5c1b9;layoutVersion=0
om2_1       | 2020-12-21 16:35:52,861 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1       | /************************************************************
datanode_1  | 2020-12-21 16:36:05,076 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/1f541f4e-a162-4978-bdd3-a46a69316625
datanode_1  | 2020-12-21 16:36:05,088 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-12-21 16:36:05,092 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-12-21 16:36:05,096 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-12-21 16:36:05,112 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-12-21 16:36:05,128 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-12-21 16:36:05,132 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-12-21 16:36:05,136 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-12-21 16:36:05,138 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1       | SHUTDOWN_MSG: Shutting down OzoneManager at 4f06b7713c77/172.23.0.9
om2_1       | ************************************************************/
om2_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om2_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1       | 2020-12-21 16:35:59,040 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
datanode_2  | 2020-12-21 16:36:05,769 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2  | 2020-12-21 16:36:05,769 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2020-12-21 16:36:05,770 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-12-21 16:36:05,770 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-12-21 16:36:05,770 [pool-19-thread-1] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4: ConfigurationManager, init=-1: [ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-12-21 16:36:05,770 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-12-21 16:36:05,770 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-12-21 16:36:05,771 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/759a8eb9-11b3-4079-be1a-c0245d86e4d4 does not exist. Creating ...
datanode_2  | 2020-12-21 16:36:05,778 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/759a8eb9-11b3-4079-be1a-c0245d86e4d4/in_use.lock acquired by nodename 6@0c1ed6ebf729
datanode_2  | 2020-12-21 16:36:05,784 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/759a8eb9-11b3-4079-be1a-c0245d86e4d4 has been successfully formatted.
datanode_2  | 2020-12-21 16:36:05,784 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-C0245D86E4D4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-12-21 16:36:05,804 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2020-12-21 16:36:05,804 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-12-21 16:36:05,804 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-12-21 16:36:05,804 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4
datanode_2  | 2020-12-21 16:36:05,805 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-12-21 16:36:05,805 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-12-21 16:36:05,805 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-12-21 16:36:05,806 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/759a8eb9-11b3-4079-be1a-c0245d86e4d4
om1_1       | 2020-12-21 16:36:13,689 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1       | 2020-12-21 16:36:13,750 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1       | 2020-12-21 16:36:13,795 [main] INFO impl.RaftServerProxy: om1: addNew group-562213E44849:[om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872] returns group-562213E44849:java.util.concurrent.CompletableFuture@58a7ca42[Not completed]
om1_1       | 2020-12-21 16:36:13,796 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1       | 2020-12-21 16:36:13,796 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1       | 2020-12-21 16:36:13,797 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2020-12-21 16:36:05,144 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-12-21 16:36:05,201 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-12-21 16:36:05,260 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-12-21 16:36:05,261 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1       | /************************************************************
om2_1       | STARTUP_MSG: Starting OzoneManager
om2_1       | STARTUP_MSG:   host = 4f06b7713c77/172.23.0.9
om2_1       | STARTUP_MSG:   args = []
om2_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om1_1       | 2020-12-21 16:36:13,880 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1       | 2020-12-21 16:36:13,963 [pool-17-thread-1] INFO impl.RaftServerImpl: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872] with OzoneManagerStateMachine:uninitialized
om1_1       | 2020-12-21 16:36:13,981 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 1s (custom)
om1_1       | 2020-12-21 16:36:13,983 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 1200ms (custom)
om1_1       | 2020-12-21 16:36:13,983 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
datanode_1  | 2020-12-21 16:36:05,273 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-12-21 16:36:05,291 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-12-21 16:36:05,293 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-12-21 16:36:05,300 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-12-21 16:36:05,302 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om2_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om2_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/c958bfb4070aab1068d7e455792957fc116a31fc ; compiled by 'runner' on 2020-12-21T16:02Z
om2_1       | STARTUP_MSG:   java = 11.0.7
om2_1       | ************************************************************/
om2_1       | 2020-12-21 16:35:59,078 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1       | 2020-12-21 16:36:05,704 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
datanode_1  | 2020-12-21 16:36:05,424 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_1  | GC pool 'ParNew' had collection(s): count=2 time=222ms
datanode_1  | 2020-12-21 16:36:05,426 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625
datanode_1  | 2020-12-21 16:36:05,449 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625
om1_1       | 2020-12-21 16:36:13,988 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1       | 2020-12-21 16:36:13,989 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
om1_1       | 2020-12-21 16:36:13,995 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1       | 2020-12-21 16:36:14,025 [pool-17-thread-1] INFO impl.RaftServerImpl: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null, confs=<EMPTY_MAP>
om1_1       | 2020-12-21 16:36:14,038 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1       | 2020-12-21 16:36:06,248 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1       | 2020-12-21 16:36:06,252 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om2: om2
om2_1       | 2020-12-21 16:36:06,301 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1       | 2020-12-21 16:36:06,420 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1       | 2020-12-21 16:36:10,542 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2020-12-21 16:36:05,497 [pool-19-thread-1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625: start as a follower, conf=-1: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858|dataStream:, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858|dataStream:, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858|dataStream:], old=null
datanode_1  | 2020-12-21 16:36:05,546 [pool-19-thread-1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-12-21 16:36:05,555 [pool-19-thread-1] INFO impl.RoleInfo: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: start f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625-FollowerState
datanode_1  | 2020-12-21 16:36:05,577 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A46A69316625,id=f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2
datanode_1  | 2020-12-21 16:36:05,581 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625
om1_1       | 2020-12-21 16:36:14,066 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-12-21 16:36:05,806 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-12-21 16:36:05,806 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-12-21 16:36:05,807 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-12-21 16:36:05,812 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-12-21 16:36:05,812 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-12-21 16:36:05,812 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-12-21 16:36:05,812 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-12-21 16:36:05,812 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om3_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1       | 2020-12-21 16:35:24,550 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1       | /************************************************************
om3_1       | STARTUP_MSG: Starting OzoneManager
om3_1       | STARTUP_MSG:   host = 77f652a2647f/172.23.0.6
om3_1       | STARTUP_MSG:   args = [--init]
om2_1       | 2020-12-21 16:36:11,313 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1       | 2020-12-21 16:36:11,321 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1       | 2020-12-21 16:36:12,189 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
om2_1       | 2020-12-21 16:36:12,242 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1       | 2020-12-21 16:36:12,512 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1       | 2020-12-21 16:36:12,690 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om2:9872, om1:9872, om3:9872
om2_1       | 2020-12-21 16:36:12,750 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1       | 2020-12-21 16:36:12,865 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
om2_1       | 2020-12-21 16:36:13,080 [main] INFO grpc.GrpcFactory: PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
om2_1       | 	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
om2_1       | 2020-12-21 16:36:13,097 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1       | 2020-12-21 16:36:13,106 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1       | 2020-12-21 16:36:13,121 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1       | 2020-12-21 16:36:13,126 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1       | 2020-12-21 16:36:13,127 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1       | 2020-12-21 16:36:13,759 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1       | 2020-12-21 16:36:13,816 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1       | 2020-12-21 16:36:13,851 [main] INFO impl.RaftServerProxy: om2: addNew group-562213E44849:[om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872] returns group-562213E44849:java.util.concurrent.CompletableFuture@58a7ca42[Not completed]
om2_1       | 2020-12-21 16:36:13,851 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1       | 2020-12-21 16:36:13,851 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1       | 2020-12-21 16:36:13,852 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1       | 2020-12-21 16:36:13,854 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1       | 2020-12-21 16:36:14,093 [pool-17-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1       | 2020-12-21 16:36:14,172 [pool-17-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@45a6689dd7c9
om1_1       | 2020-12-21 16:36:14,334 [pool-17-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1       | 2020-12-21 16:36:14,341 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1       | 2020-12-21 16:36:14,388 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1       | 2020-12-21 16:36:14,453 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1       | 2020-12-21 16:36:14,490 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om1@group-562213E44849
om1_1       | 2020-12-21 16:36:14,600 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1       | 2020-12-21 16:36:14,636 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1       | 2020-12-21 16:36:14,720 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1       | 2020-12-21 16:36:14,766 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1       | 2020-12-21 16:36:14,792 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1       | 2020-12-21 16:36:14,794 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1       | 2020-12-21 16:36:14,795 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1       | 2020-12-21 16:36:14,824 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1       | 2020-12-21 16:36:14,825 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1       | 2020-12-21 16:36:14,826 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1       | 2020-12-21 16:36:14,840 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1       | 2020-12-21 16:36:14,851 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1       | 2020-12-21 16:36:14,852 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1       | 2020-12-21 16:36:14,962 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1       | 2020-12-21 16:36:14,997 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1       | 2020-12-21 16:36:14,997 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1       | 2020-12-21 16:36:15,020 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1       | 2020-12-21 16:36:15,021 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1       | 2020-12-21 16:36:15,034 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1       | 2020-12-21 16:36:15,034 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1       | 2020-12-21 16:36:15,035 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1       | 2020-12-21 16:36:15,233 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om1@group-562213E44849
om1_1       | 2020-12-21 16:36:15,279 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om1@group-562213E44849
om1_1       | 2020-12-21 16:36:15,292 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1       | 2020-12-21 16:36:15,358 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1       | 2020-12-21 16:36:16,409 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2020-12-21 16:36:27,261 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 2020-12-21 16:36:08,018 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-A46A69316625 with new leaderId: ec956fef-022a-4e11-a406-1dfa86e0929f
datanode_1  | 2020-12-21 16:36:08,020 [grpc-default-executor-1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625: change Leader from null to ec956fef-022a-4e11-a406-1dfa86e0929f at term 1 for appendEntries, leader elected after 3221ms
datanode_1  | 2020-12-21 16:36:08,024 [grpc-default-executor-1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode_1  | 2020-12-21 16:36:08,038 [grpc-default-executor-1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625: inconsistency entries. Reply:ec956fef-022a-4e11-a406-1dfa86e0929f<-f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2#3:FAIL,INCONSISTENCY,nextIndex:0,term:0,followerCommit:-1
datanode_1  | 2020-12-21 16:36:08,074 [grpc-default-executor-1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode_1  | 2020-12-21 16:36:08,075 [grpc-default-executor-1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625: inconsistency entries. Reply:ec956fef-022a-4e11-a406-1dfa86e0929f<-f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2#4:FAIL,INCONSISTENCY,nextIndex:0,term:1,followerCommit:-1
datanode_1  | 2020-12-21 16:36:08,084 [grpc-default-executor-1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625: set configuration 0: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858|dataStream:, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858|dataStream:, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858|dataStream:], old=null at 0
datanode_1  | 2020-12-21 16:36:08,105 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-12-21 16:36:08,229 [grpc-default-executor-1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625: set configuration 0: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858|dataStream:, ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858|dataStream:, d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858|dataStream:], old=null at 0
datanode_3  | 2020-12-21 16:36:27,261 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-12-21 16:36:27,261 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-12-21 16:36:27,261 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56
datanode_3  | 2020-12-21 16:36:27,262 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-12-21 16:36:27,262 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-12-21 16:36:27,264 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-12-21 16:36:27,264 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/6f160a74-ec34-4eec-a46f-6e26b47e7b56
datanode_3  | 2020-12-21 16:36:27,264 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-12-21 16:36:27,264 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-12-21 16:36:27,264 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-12-21 16:36:27,265 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-12-21 16:36:27,265 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-12-21 16:36:27,265 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-12-21 16:36:27,265 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-12-21 16:36:27,265 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om3_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om3_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/c958bfb4070aab1068d7e455792957fc116a31fc ; compiled by 'runner' on 2020-12-21T16:02Z
om3_1       | STARTUP_MSG:   java = 11.0.7
om3_1       | ************************************************************/
om3_1       | 2020-12-21 16:35:24,639 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1       | 2020-12-21 16:35:34,123 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om3_1       | 2020-12-21 16:35:34,865 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1       | 2020-12-21 16:35:34,868 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om3: om3
om3_1       | 2020-12-21 16:35:34,995 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1       | 2020-12-21 16:35:39,357 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-21 16:35:40,358 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-21 16:35:41,359 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-21 16:35:42,359 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-21 16:35:43,360 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-21 16:35:44,361 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-21 16:35:45,362 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-21 16:35:46,363 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-21 16:35:47,363 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-21 16:35:48,364 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-21 16:35:48,366 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om3_1       | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-7fd6ff48-e398-43cb-8679-8634afd5c1b9;layoutVersion=0
om3_1       | 2020-12-21 16:35:54,020 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1       | /************************************************************
om3_1       | SHUTDOWN_MSG: Shutting down OzoneManager at 77f652a2647f/172.23.0.6
om3_1       | ************************************************************/
om3_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om3_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1       | 2020-12-21 16:36:00,694 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1       | /************************************************************
om3_1       | STARTUP_MSG: Starting OzoneManager
om3_1       | STARTUP_MSG:   host = 77f652a2647f/172.23.0.6
om3_1       | STARTUP_MSG:   args = []
om3_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om3_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om3_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/c958bfb4070aab1068d7e455792957fc116a31fc ; compiled by 'runner' on 2020-12-21T16:02Z
datanode_2  | 2020-12-21 16:36:05,815 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-12-21 16:36:05,817 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-12-21 16:36:05,828 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-12-21 16:36:05,831 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-12-21 16:36:05,834 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-12-21 16:36:05,866 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-12-21 16:36:08,514 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-A46A69316625-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/1f541f4e-a162-4978-bdd3-a46a69316625/current/log_inprogress_0
datanode_1  | 2020-12-21 16:36:10,431 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ParNew' had collection(s): count=2 time=222ms
datanode_1  | 2020-12-21 16:36:26,889 [Command processor thread] INFO impl.RaftServerProxy: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: addNew group-859F1892A458:[f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858] returns group-859F1892A458:java.util.concurrent.CompletableFuture@3d281c3a[Not completed]
datanode_2  | 2020-12-21 16:36:05,888 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-12-21 16:36:05,889 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-12-21 16:36:05,889 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-12-21 16:36:05,889 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4
datanode_2  | 2020-12-21 16:36:05,889 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4
datanode_2  | 2020-12-21 16:36:05,892 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=2 time=152ms
datanode_2  | 2020-12-21 16:36:05,892 [pool-19-thread-1] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4: start as a follower, conf=-1: [ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858], old=null
datanode_2  | 2020-12-21 16:36:05,910 [pool-19-thread-1] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-12-21 16:36:05,932 [pool-19-thread-1] INFO impl.RoleInfo: ec956fef-022a-4e11-a406-1dfa86e0929f: start ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-FollowerState
datanode_2  | 2020-12-21 16:36:05,932 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C0245D86E4D4,id=ec956fef-022a-4e11-a406-1dfa86e0929f
datanode_2  | 2020-12-21 16:36:05,980 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4
datanode_2  | 2020-12-21 16:36:06,051 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=759a8eb9-11b3-4079-be1a-c0245d86e4d4.
datanode_2  | 2020-12-21 16:36:06,394 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=2 time=152ms
datanode_2  | 2020-12-21 16:36:08,063 [grpc-default-executor-1] INFO impl.FollowerInfo: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: nextIndex: updateUnconditionally 1 -> 0
datanode_2  | 2020-12-21 16:36:08,078 [grpc-default-executor-1] INFO impl.FollowerInfo: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: nextIndex: updateUnconditionally 1 -> 0
datanode_2  | 2020-12-21 16:36:11,052 [Thread-32] INFO impl.FollowerState: ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-FollowerState: change to CANDIDATE, lastRpcTime:5120ms, electionTimeout:5057ms
datanode_2  | 2020-12-21 16:36:11,052 [Thread-32] INFO impl.RoleInfo: ec956fef-022a-4e11-a406-1dfa86e0929f: shutdown ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-FollowerState
datanode_2  | 2020-12-21 16:36:11,053 [Thread-32] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-12-21 16:36:11,053 [Thread-32] INFO impl.RoleInfo: ec956fef-022a-4e11-a406-1dfa86e0929f: start ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2
datanode_1  | 2020-12-21 16:36:26,891 [pool-19-thread-1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: new RaftServerImpl for group-859F1892A458:[f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-12-21 16:36:26,891 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-12-21 16:36:26,892 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-12-21 16:36:26,892 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2020-12-21 16:36:27,265 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-12-21 16:36:27,266 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-12-21 16:36:27,270 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-12-21 16:36:27,270 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-12-21 16:36:27,278 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-12-21 16:36:27,279 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-12-21 16:36:27,279 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-12-21 16:36:27,279 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-12-21 16:36:27,279 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-12-21 16:36:27,279 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56
datanode_3  | 2020-12-21 16:36:27,280 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56
datanode_3  | 2020-12-21 16:36:27,280 [pool-19-thread-1] INFO impl.RaftServerImpl: d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56: start as a follower, conf=-1: [d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858], old=null
datanode_3  | 2020-12-21 16:36:27,281 [pool-19-thread-1] INFO impl.RaftServerImpl: d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-12-21 16:36:27,281 [pool-19-thread-1] INFO impl.RoleInfo: d59b5746-4c38-43fa-95c4-93039b647722: start d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-FollowerState
datanode_3  | 2020-12-21 16:36:27,282 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6E26B47E7B56,id=d59b5746-4c38-43fa-95c4-93039b647722
datanode_3  | 2020-12-21 16:36:27,282 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56
datanode_3  | 2020-12-21 16:36:27,284 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=6f160a74-ec34-4eec-a46f-6e26b47e7b56.
datanode_3  | 2020-12-21 16:36:32,434 [Thread-38] INFO impl.FollowerState: d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-FollowerState: change to CANDIDATE, lastRpcTime:5153ms, electionTimeout:5149ms
datanode_1  | 2020-12-21 16:36:26,892 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2020-12-21 16:36:26,892 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-12-21 16:36:26,892 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-12-21 16:36:26,892 [pool-19-thread-1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458: ConfigurationManager, init=-1: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858], old=null, confs=<EMPTY_MAP>
om2_1       | 2020-12-21 16:36:13,900 [pool-17-thread-1] INFO impl.RaftServerImpl: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872] with OzoneManagerStateMachine:uninitialized
om2_1       | 2020-12-21 16:36:13,949 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 1s (custom)
om2_1       | 2020-12-21 16:36:13,953 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 1200ms (custom)
om2_1       | 2020-12-21 16:36:13,954 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
datanode_1  | 2020-12-21 16:36:26,893 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-12-21 16:36:26,893 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-12-21 16:36:11,057 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO impl.LeaderElection: ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2: begin an election at term 1 for -1: [ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858], old=null
datanode_1  | 2020-12-21 16:36:26,893 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/23c75842-87fc-4ac0-be5f-859f1892a458 does not exist. Creating ...
datanode_1  | 2020-12-21 16:36:26,895 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/23c75842-87fc-4ac0-be5f-859f1892a458/in_use.lock acquired by nodename 6@b57317203960
datanode_1  | 2020-12-21 16:36:26,896 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/23c75842-87fc-4ac0-be5f-859f1892a458 has been successfully formatted.
datanode_1  | 2020-12-21 16:36:26,898 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-859F1892A458: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-12-21 16:36:26,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 2020-12-21 16:36:26,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-12-21 16:36:26,901 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-12-21 16:36:26,901 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458
datanode_1  | 2020-12-21 16:36:26,902 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-12-21 16:36:26,902 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-12-21 16:36:26,917 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-12-21 16:36:26,918 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/23c75842-87fc-4ac0-be5f-859f1892a458
datanode_1  | 2020-12-21 16:36:26,923 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-12-21 16:36:26,923 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-12-21 16:36:26,924 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-12-21 16:36:26,924 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-12-21 16:36:26,924 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-12-21 16:36:26,924 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-12-21 16:36:26,925 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-12-21 16:36:26,925 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1       | 2020-12-21 16:36:13,955 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1       | 2020-12-21 16:36:13,955 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
om1_1       | 2020-12-21 16:36:16,752 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1       | STARTUP_MSG:   java = 11.0.7
om3_1       | ************************************************************/
om3_1       | 2020-12-21 16:36:00,740 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1       | 2020-12-21 16:36:06,607 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om2_1       | 2020-12-21 16:36:13,956 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-12-21 16:36:26,925 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-12-21 16:36:26,926 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-12-21 16:35:25,492 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
om2_1       | 2020-12-21 16:36:13,982 [pool-17-thread-1] INFO impl.RaftServerImpl: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-12-21 16:36:32,435 [Thread-38] INFO impl.RoleInfo: d59b5746-4c38-43fa-95c4-93039b647722: shutdown d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-FollowerState
datanode_2  | 2020-12-21 16:36:11,057 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO impl.RoleInfo: ec956fef-022a-4e11-a406-1dfa86e0929f: shutdown ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2
datanode_1  | 2020-12-21 16:36:26,932 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-12-21 16:36:26,932 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-12-21 16:36:26,932 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-12-21 16:36:26,932 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
om3_1       | 2020-12-21 16:36:07,196 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1       | 2020-12-21 16:36:07,198 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om3: om3
om3_1       | 2020-12-21 16:36:07,264 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1       | 2020-12-21 16:36:07,338 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1       | 2020-12-21 16:36:11,797 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1       | 2020-12-21 16:36:14,001 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1       | 2020-12-21 16:36:14,007 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1       | 2020-12-21 16:36:16,752 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1       | 2020-12-21 16:36:17,016 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.23.0.2:9862
datanode_2  | 2020-12-21 16:36:11,058 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm_1       | /************************************************************
om2_1       | 2020-12-21 16:36:14,027 [pool-17-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1       | 2020-12-21 16:36:14,109 [pool-17-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@4f06b7713c77
om2_1       | 2020-12-21 16:36:14,192 [pool-17-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1       | 2020-12-21 16:36:14,205 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1       | 2020-12-21 16:36:14,218 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1       | 2020-12-21 16:36:14,249 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1       | 2020-12-21 16:36:14,307 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om2@group-562213E44849
om2_1       | 2020-12-21 16:36:14,438 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1       | 2020-12-21 16:36:14,443 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1       | 2020-12-21 16:36:14,548 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1       | 2020-12-21 16:36:14,615 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1       | 2020-12-21 16:36:14,620 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
datanode_2  | 2020-12-21 16:36:11,058 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C0245D86E4D4 with new leaderId: ec956fef-022a-4e11-a406-1dfa86e0929f
datanode_2  | 2020-12-21 16:36:11,059 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4: change Leader from null to ec956fef-022a-4e11-a406-1dfa86e0929f at term 1 for becomeLeader, leader elected after 5274ms
datanode_2  | 2020-12-21 16:36:11,059 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-12-21 16:36:11,059 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om2_1       | 2020-12-21 16:36:14,628 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1       | 2020-12-21 16:36:14,632 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1       | 2020-12-21 16:36:14,656 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1       | 2020-12-21 16:36:14,659 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1       | 2020-12-21 16:36:14,665 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-12-21 16:36:11,059 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4
datanode_2  | 2020-12-21 16:36:11,060 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2020-12-21 16:36:11,060 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-12-21 16:36:11,062 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-12-21 16:36:11,070 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-12-21 16:36:11,071 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om3_1       | 2020-12-21 16:36:12,499 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1       | 2020-12-21 16:36:12,509 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1       | 2020-12-21 16:36:13,363 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
om3_1       | 2020-12-21 16:36:13,393 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1       | 2020-12-21 16:36:14,667 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1       | 2020-12-21 16:36:14,680 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1       | 2020-12-21 16:36:13,542 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1       | 2020-12-21 16:36:13,674 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om3:9872, om1:9872, om2:9872
om3_1       | 2020-12-21 16:36:13,901 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1       | 2020-12-21 16:36:14,031 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2020-12-21 16:36:11,076 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO impl.RoleInfo: ec956fef-022a-4e11-a406-1dfa86e0929f: start ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderState
datanode_2  | 2020-12-21 16:36:11,076 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-12-21 16:36:11,077 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-LeaderElection2] INFO impl.RaftServerImpl: ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4: set configuration 0: [ec956fef-022a-4e11-a406-1dfa86e0929f|rpc:172.23.0.4:9858|dataStream:], old=null at 0
datanode_2  | 2020-12-21 16:36:11,097 [ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ec956fef-022a-4e11-a406-1dfa86e0929f@group-C0245D86E4D4-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/759a8eb9-11b3-4079-be1a-c0245d86e4d4/current/log_inprogress_0
datanode_2  | 2020-12-21 16:36:15,907 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
om2_1       | 2020-12-21 16:36:14,680 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1       | 2020-12-21 16:36:14,759 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1       | 2020-12-21 16:36:14,833 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1       | 2020-12-21 16:36:14,848 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1       | 2020-12-21 16:36:14,886 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1       | 2020-12-21 16:36:14,354 [main] INFO grpc.GrpcFactory: PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
om3_1       | 	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
om3_1       | 2020-12-21 16:36:14,378 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1       | 2020-12-21 16:36:14,386 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1       | 2020-12-21 16:36:14,405 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | GC pool 'ParNew' had collection(s): count=2 time=152ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=97ms
datanode_2  | 2020-12-21 16:36:41,923 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | 2020-12-21 16:36:32,435 [Thread-38] INFO impl.RaftServerImpl: d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1       | 2020-12-21 16:36:17,016 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1       | 2020-12-21 16:36:17,035 [Listener at om1/9862] INFO impl.RaftServerImpl: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om1_1       | 2020-12-21 16:36:17,038 [Listener at om1/9862] INFO impl.RaftServerImpl: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-12-21 16:36:32,439 [Thread-38] INFO impl.RoleInfo: d59b5746-4c38-43fa-95c4-93039b647722: start d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1
scm_1       | STARTUP_MSG: Starting StorageContainerManager
om1_1       | 2020-12-21 16:36:17,042 [Listener at om1/9862] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1       | 2020-12-21 16:36:17,053 [Listener at om1/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1       | 2020-12-21 16:36:17,054 [Listener at om1/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om1@group-562213E44849
om1_1       | 2020-12-21 16:36:17,077 [Listener at om1/9862] INFO impl.RaftServerProxy: om1: start RPC server
om1_1       | 2020-12-21 16:36:17,262 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 0.0.0.0/0.0.0.0:9872
om1_1       | 2020-12-21 16:36:17,288 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1       | 2020-12-21 16:36:17,300 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1       | 2020-12-21 16:36:17,419 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] INFO server.JvmPauseMonitor: Starting Ratis JVM pause monitor
om1_1       | 2020-12-21 16:36:17,499 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1       | 2020-12-21 16:36:17,504 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om1_1       | 2020-12-21 16:36:17,779 [Listener at om1/9862] INFO util.log: Logging initialized @24533ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1       | 2020-12-21 16:36:18,043 [Listener at om1/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om1_1       | 2020-12-21 16:36:18,068 [Thread-12] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcTime:1026ms, electionTimeout:1010ms
datanode_3  | 2020-12-21 16:36:32,448 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO impl.LeaderElection: d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1: begin an election at term 1 for -1: [d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858], old=null
datanode_3  | 2020-12-21 16:36:32,449 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO impl.RoleInfo: d59b5746-4c38-43fa-95c4-93039b647722: shutdown d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1
datanode_3  | 2020-12-21 16:36:32,450 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO impl.RaftServerImpl: d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-12-21 16:36:32,450 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-6E26B47E7B56 with new leaderId: d59b5746-4c38-43fa-95c4-93039b647722
datanode_3  | 2020-12-21 16:36:32,450 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO impl.RaftServerImpl: d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56: change Leader from null to d59b5746-4c38-43fa-95c4-93039b647722 at term 1 for becomeLeader, leader elected after 5188ms
datanode_3  | 2020-12-21 16:36:32,466 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-12-21 16:36:32,468 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-12-21 16:36:32,477 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56
datanode_3  | 2020-12-21 16:36:32,480 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-12-21 16:36:32,484 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-12-21 16:36:32,522 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-12-21 16:36:32,524 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-12-21 16:36:32,526 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2020-12-21 16:36:32,549 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO impl.RoleInfo: d59b5746-4c38-43fa-95c4-93039b647722: start d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderState
datanode_3  | 2020-12-21 16:36:32,563 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-12-21 16:36:32,569 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-LeaderElection1] INFO impl.RaftServerImpl: d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56: set configuration 0: [d59b5746-4c38-43fa-95c4-93039b647722|rpc:172.23.0.5:9858|dataStream:], old=null at 0
datanode_3  | 2020-12-21 16:36:32,570 [d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d59b5746-4c38-43fa-95c4-93039b647722@group-6E26B47E7B56-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/6f160a74-ec34-4eec-a46f-6e26b47e7b56/current/log_inprogress_0
datanode_3  | 2020-12-21 16:36:52,912 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 32ms
datanode_3  | GC pool 'ParNew' had collection(s): count=4 time=365ms
datanode_3  | 2020-12-21 16:36:53,416 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | 2020-12-21 16:36:18,070 [Thread-12] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1       | 2020-12-21 16:36:18,080 [Thread-12] INFO impl.RaftServerImpl: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1       | 2020-12-21 16:36:18,082 [Thread-12] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1       | 2020-12-21 16:36:18,083 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1       | 2020-12-21 16:36:18,115 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1       | 2020-12-21 16:36:14,892 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1       | 2020-12-21 16:36:14,895 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1       | 2020-12-21 16:36:14,908 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1       | 2020-12-21 16:36:14,922 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
datanode_2  | GC pool 'ParNew' had collection(s): count=2 time=152ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=97ms
datanode_2  | 2020-12-21 16:36:52,190 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.ec956fef-022a-4e11-a406-1dfa86e0929f
datanode_2  | 2020-12-21 16:36:52,936 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_2  | GC pool 'ParNew' had collection(s): count=4 time=230ms
datanode_3  | GC pool 'ParNew' had collection(s): count=4 time=365ms
scm_1       | STARTUP_MSG:   host = 574b0d77c66c/172.23.0.3
om3_1       | 2020-12-21 16:36:14,408 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1       | 2020-12-21 16:36:15,085 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om2@group-562213E44849
om2_1       | 2020-12-21 16:36:15,112 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om2@group-562213E44849
om2_1       | 2020-12-21 16:36:15,159 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1       | 2020-12-21 16:36:15,199 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1       | 2020-12-21 16:36:15,990 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1       | 2020-12-21 16:36:16,396 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1       | 2020-12-21 16:36:16,396 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1       | 2020-12-21 16:36:16,695 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.23.0.9:9862
scm_1       | STARTUP_MSG:   args = [--init]
om1_1       | 2020-12-21 16:36:18,124 [Listener at om1/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om1_1       | 2020-12-21 16:36:18,125 [Listener at om1/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3  | 2020-12-21 16:37:11,928 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=5 time=415ms
om3_1       | 2020-12-21 16:36:14,409 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1       | 2020-12-21 16:36:15,304 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1       | 2020-12-21 16:36:15,363 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1       | 2020-12-21 16:36:15,404 [main] INFO impl.RaftServerProxy: om3: addNew group-562213E44849:[om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872] returns group-562213E44849:java.util.concurrent.CompletableFuture@58a7ca42[Not completed]
om3_1       | 2020-12-21 16:36:15,416 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
datanode_1  | 2020-12-21 16:36:26,933 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-12-21 16:36:26,933 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-12-21 16:36:26,933 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-12-21 16:36:26,933 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458
datanode_1  | 2020-12-21 16:36:26,934 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20ms
datanode_3  | 2020-12-21 16:37:44,445 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | 2020-12-21 16:36:15,420 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1       | 2020-12-21 16:36:15,420 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=97ms
om1_1       | 2020-12-21 16:36:18,125 [Listener at om1/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om1_1       | 2020-12-21 16:36:18,159 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: begin an election at term 1 for -1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
datanode_3  | GC pool 'ParNew' had collection(s): count=6 time=465ms
scm_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om2_1       | 2020-12-21 16:36:16,701 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om1_1       | 2020-12-21 16:36:18,336 [Listener at om1/9862] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om1_1       | 2020-12-21 16:36:18,373 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
datanode_1  | 2020-12-21 16:36:26,934 [pool-19-thread-1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458: start as a follower, conf=-1: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858], old=null
datanode_1  | 2020-12-21 16:36:26,935 [pool-19-thread-1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458: changes role from      null to FOLLOWER at term 0 for startAsFollower
s3g_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2  | 2020-12-21 16:37:01,942 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20ms
datanode_3  | 2020-12-21 16:38:19,961 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=10 time=599ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20ms
datanode_3  | 2020-12-21 16:38:30,968 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=11 time=619ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20ms
datanode_3  | 2020-12-21 16:39:03,985 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | 2020-12-21 16:36:15,446 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
s3g_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1       | 2020-12-21 16:36:18,376 [Listener at om1/9862] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
om1_1       | 2020-12-21 16:36:18,520 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1       | 2020-12-21 16:36:18,528 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1       | 2020-12-21 16:36:18,530 [Listener at om1/9862] INFO server.session: node0 Scavenging every 600000ms
om1_1       | 2020-12-21 16:36:18,712 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@726e29d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1       | 2020-12-21 16:36:16,716 [Listener at om2/9862] INFO impl.RaftServerImpl: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om2_1       | 2020-12-21 16:36:16,727 [Listener at om2/9862] INFO impl.RaftServerImpl: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1       | 2020-12-21 16:36:16,728 [Listener at om2/9862] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1       | 2020-12-21 16:36:16,754 [Listener at om2/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
datanode_1  | 2020-12-21 16:36:26,935 [pool-19-thread-1] INFO impl.RoleInfo: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: start f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-FollowerState
datanode_1  | 2020-12-21 16:36:26,935 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-859F1892A458,id=f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2
datanode_1  | 2020-12-21 16:36:26,935 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458
datanode_1  | 2020-12-21 16:36:26,939 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=23c75842-87fc-4ac0-be5f-859f1892a458.
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/c958bfb4070aab1068d7e455792957fc116a31fc ; compiled by 'runner' on 2020-12-21T16:02Z
scm_1       | STARTUP_MSG:   java = 11.0.7
scm_1       | ************************************************************/
scm_1       | 2020-12-21 16:35:25,653 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-12-21 16:35:26,927 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-12-21 16:35:27,580 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-7fd6ff48-e398-43cb-8679-8634afd5c1b9;layoutVersion=0
scm_1       | 2020-12-21 16:35:27,642 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1       | /************************************************************
datanode_2  | GC pool 'ParNew' had collection(s): count=5 time=243ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=97ms
datanode_2  | 2020-12-21 16:37:08,079 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=7,entriesCount=1,lastEntry=(t:1, i:0)
datanode_2  | 2020-12-21 16:37:31,960 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om3_1       | 2020-12-21 16:36:15,542 [pool-17-thread-1] INFO impl.RaftServerImpl: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872] with OzoneManagerStateMachine:uninitialized
om3_1       | 2020-12-21 16:36:15,598 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 1s (custom)
om3_1       | 2020-12-21 16:36:15,601 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 1200ms (custom)
om3_1       | 2020-12-21 16:36:15,602 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1       | 2020-12-21 16:36:15,605 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1       | 2020-12-21 16:36:16,756 [Listener at om2/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om2@group-562213E44849
om1_1       | 2020-12-21 16:36:18,713 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7fb1820d{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1       | 2020-12-21 16:36:18,961 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
om1_1       | GC pool 'ParNew' had collection(s): count=1 time=38ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=76ms
datanode_2  | GC pool 'ParNew' had collection(s): count=6 time=258ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=97ms
datanode_2  | 2020-12-21 16:37:52,455 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=271,entriesCount=1,lastEntry=(t:1, i:1)
datanode_2  | 2020-12-21 16:37:52,499 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=272,entriesCount=1,lastEntry=(t:1, i:2)
datanode_1  | 2020-12-21 16:36:31,944 [Thread-36] INFO impl.FollowerState: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-FollowerState: change to CANDIDATE, lastRpcTime:5008ms, electionTimeout:5005ms
datanode_1  | 2020-12-21 16:36:31,945 [Thread-36] INFO impl.RoleInfo: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: shutdown f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-FollowerState
datanode_1  | 2020-12-21 16:36:31,945 [Thread-36] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2020-12-21 16:36:31,947 [Thread-36] INFO impl.RoleInfo: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: start f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1
om2_1       | 2020-12-21 16:36:16,790 [Listener at om2/9862] INFO impl.RaftServerProxy: om2: start RPC server
om2_1       | 2020-12-21 16:36:17,102 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 0.0.0.0/0.0.0.0:9872
om2_1       | 2020-12-21 16:36:17,108 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1       | 2020-12-21 16:36:17,112 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1       | 2020-12-21 16:36:17,137 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] INFO server.JvmPauseMonitor: Starting Ratis JVM pause monitor
om2_1       | 2020-12-21 16:36:17,213 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1       | 2020-12-21 16:36:17,219 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om2_1       | 2020-12-21 16:36:17,501 [Listener at om2/9862] INFO util.log: Logging initialized @24042ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1       | 2020-12-21 16:36:17,670 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om3_1       | 2020-12-21 16:36:15,606 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
om3_1       | 2020-12-21 16:36:15,610 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1       | 2020-12-21 16:36:15,676 [pool-17-thread-1] INFO impl.RaftServerImpl: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null, confs=<EMPTY_MAP>
om3_1       | 2020-12-21 16:36:15,677 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | GC pool 'ParNew' had collection(s): count=12 time=641ms
s3g_1       | 2020-12-21 16:35:23,710 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
om1_1       | 2020-12-21 16:36:19,353 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om1_1       | 2020-12-21 16:36:19,359 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: begin an election at term 2 for -1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om1_1       | 2020-12-21 16:36:19,406 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@22a8c837{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-1_1_0-SNAPSHOT_jar-_-any-10396270931752598670/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/ozoneManager}
datanode_2  | 2020-12-21 16:37:53,656 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=273,entriesCount=1,lastEntry=(t:1, i:3)
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at 574b0d77c66c/172.23.0.3
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
s3g_1       | 2020-12-21 16:35:23,716 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om1_1       | 2020-12-21 16:36:19,433 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@6802c10e{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
datanode_1  | 2020-12-21 16:36:31,968 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO impl.LeaderElection: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1: begin an election at term 1 for -1: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858], old=null
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om2_1       | 2020-12-21 16:36:17,842 [Thread-12] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcTime:1114ms, electionTimeout:1091ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20ms
om3_1       | 2020-12-21 16:36:15,733 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1       | 2020-12-21 16:36:19,433 [Listener at om1/9862] INFO server.Server: Started @26187ms
datanode_1  | 2020-12-21 16:36:31,969 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO impl.RoleInfo: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: shutdown f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1
datanode_1  | 2020-12-21 16:36:31,970 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-12-21 16:37:53,693 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=278,entriesCount=1,lastEntry=(t:1, i:4)
datanode_3  | 2020-12-21 16:39:42,002 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=12 time=641ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20ms
datanode_3  | 2020-12-21 16:42:27,567 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=13 time=644ms
datanode_2  | 2020-12-21 16:37:57,129 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=525,entriesCount=1,lastEntry=(t:1, i:5)
datanode_2  | 2020-12-21 16:37:57,130 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=526,entriesCount=1,lastEntry=(t:1, i:6)
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-12-21 16:35:44,299 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = 574b0d77c66c/172.23.0.3
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_2  | 2020-12-21 16:37:57,152 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=527,entriesCount=1,lastEntry=(t:1, i:7)
datanode_2  | 2020-12-21 16:37:57,169 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=529,entriesCount=1,lastEntry=(t:1, i:8)
datanode_2  | 2020-12-21 16:38:16,003 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11ms
datanode_2  | GC pool 'ParNew' had collection(s): count=9 time=315ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=97ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20ms
datanode_3  | 2020-12-21 16:43:43,092 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=13 time=644ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20ms
datanode_3  | 2020-12-21 16:43:48,595 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 2020-12-21 16:35:24,238 [main] INFO util.log: Logging initialized @10228ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1       | 2020-12-21 16:35:25,180 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 2020-12-21 16:35:25,464 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1       | 2020-12-21 16:35:25,562 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1       | 2020-12-21 16:35:25,567 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context s3gateway
om3_1       | 2020-12-21 16:36:15,753 [pool-17-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1       | 2020-12-21 16:36:15,964 [pool-17-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@77f652a2647f
om3_1       | 2020-12-21 16:36:16,106 [pool-17-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1       | 2020-12-21 16:36:16,109 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1       | 2020-12-21 16:36:16,114 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1       | 2020-12-21 16:36:19,435 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1       | 2020-12-21 16:36:19,435 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om1_1       | 2020-12-21 16:36:19,445 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1       | 2020-12-21 16:36:19,447 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_1  | 2020-12-21 16:36:31,970 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-859F1892A458 with new leaderId: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2
datanode_1  | 2020-12-21 16:36:31,972 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458: change Leader from null to f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 at term 1 for becomeLeader, leader elected after 5072ms
datanode_1  | 2020-12-21 16:36:31,978 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2020-12-21 16:36:31,979 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2020-12-21 16:36:31,981 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458
datanode_1  | 2020-12-21 16:36:31,984 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
om2_1       | 2020-12-21 16:36:17,847 [Thread-12] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1       | 2020-12-21 16:36:17,858 [Thread-12] INFO impl.RaftServerImpl: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1       | 2020-12-21 16:36:17,861 [Thread-12] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1       | 2020-12-21 16:36:17,908 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: begin an election at term 1 for -1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/c958bfb4070aab1068d7e455792957fc116a31fc ; compiled by 'runner' on 2020-12-21T16:02Z
scm_1       | STARTUP_MSG:   java = 11.0.7
scm_1       | ************************************************************/
scm_1       | 2020-12-21 16:35:44,426 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2020-12-21 16:38:20,513 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_3  | GC pool 'ParNew' had collection(s): count=13 time=644ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20ms
datanode_3  | 2020-12-21 16:48:03,677 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | 2020-12-21 16:36:19,465 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=2 time=71ms
s3g_1       | 2020-12-21 16:35:25,568 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1       | 2020-12-21 16:35:25,569 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om2_1       | 2020-12-21 16:36:18,042 [Listener at om2/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om2_1       | 2020-12-21 16:36:18,068 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1       | 2020-12-21 16:36:18,117 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1       | 2020-12-21 16:36:18,122 [Listener at om2/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om2_1       | 2020-12-21 16:36:18,129 [Listener at om2/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om3_1       | 2020-12-21 16:36:16,142 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1       | 2020-12-21 16:36:16,202 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om3@group-562213E44849
om3_1       | 2020-12-21 16:36:16,291 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1       | 2020-12-21 16:36:16,293 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
datanode_2  | GC pool 'ParNew' had collection(s): count=10 time=364ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=97ms
datanode_2  | 2020-12-21 16:38:23,543 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=789,entriesCount=1,lastEntry=(t:1, i:9)
datanode_3  | GC pool 'ParNew' had collection(s): count=15 time=649ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20ms
datanode_3  | 2020-12-21 16:50:24,720 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=15 time=649ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20ms
datanode_3  | 2020-12-21 16:51:39,244 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=16 time=651ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20ms
datanode_3  | 2020-12-21 16:52:10,757 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | GC pool 'ParNew' had collection(s): count=16 time=651ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20ms
datanode_3  | 2020-12-21 16:58:21,360 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | 2020-12-21 16:36:31,984 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1  | 2020-12-21 16:36:31,991 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2020-12-21 16:36:31,991 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2020-12-21 16:36:31,992 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2020-12-21 16:36:31,999 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO impl.RoleInfo: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2: start f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderState
s3g_1       | 2020-12-21 16:35:26,126 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
s3g_1       | 2020-12-21 16:35:26,245 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1       | /************************************************************
s3g_1       | STARTUP_MSG: Starting Gateway
s3g_1       | STARTUP_MSG:   host = 4f4e5fc7468d/172.23.0.8
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=76ms
om1_1       | 2020-12-21 16:36:19,518 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1       | 2020-12-21 16:36:19,704 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om1_1       | 2020-12-21 16:36:19,739 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@38318d67] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2020-12-21 16:35:46,066 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2  | 2020-12-21 16:38:23,553 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=790,entriesCount=1,lastEntry=(t:1, i:10)
scm_1       | 2020-12-21 16:35:47,547 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1       | 2020-12-21 16:36:18,131 [Listener at om2/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om2_1       | 2020-12-21 16:36:18,364 [Listener at om2/9862] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om3_1       | 2020-12-21 16:36:16,361 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1       | 2020-12-21 16:36:16,437 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1       | 2020-12-21 16:36:16,444 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1       | 2020-12-21 16:36:16,444 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1       | 2020-12-21 16:36:16,453 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm_1       | 2020-12-21 16:35:47,843 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@4d157787
scm_1       | 2020-12-21 16:35:47,854 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
datanode_3  | GC pool 'ParNew' had collection(s): count=17 time=660ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20ms
datanode_3  | 2020-12-21 16:59:04,874 [org.apache.ratis.server.JvmPauseMonitor@5646251d-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | 2020-12-21 16:36:19,746 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om1
om1_1       | 2020-12-21 16:36:19,969 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | 2020-12-21 16:36:16,453 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
datanode_2  | 2020-12-21 16:38:23,584 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=791,entriesCount=1,lastEntry=(t:1, i:11)
om2_1       | 2020-12-21 16:36:18,386 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1       | 2020-12-21 16:36:18,412 [Listener at om2/9862] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
om2_1       | 2020-12-21 16:36:18,567 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1       | STARTUP_MSG:   args = []
s3g_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om1_1       | GC pool 'ParNew' had collection(s): count=2 time=71ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=76ms
om3_1       | 2020-12-21 16:36:16,458 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1       | 2020-12-21 16:36:16,462 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1       | 2020-12-21 16:36:16,472 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-12-21 16:36:32,004 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-12-21 16:36:32,006 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-LeaderElection1] INFO impl.RaftServerImpl: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458: set configuration 0: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2|rpc:172.23.0.7:9858|dataStream:], old=null at 0
datanode_1  | 2020-12-21 16:36:32,205 [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2@group-859F1892A458-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/23c75842-87fc-4ac0-be5f-859f1892a458/current/log_inprogress_0
datanode_2  | 2020-12-21 16:38:23,775 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=792,entriesCount=1,lastEntry=(t:1, i:12)
datanode_2  | 2020-12-21 16:38:23,785 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=794,entriesCount=1,lastEntry=(t:1, i:13)
datanode_2  | 2020-12-21 16:38:23,809 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=798,entriesCount=1,lastEntry=(t:1, i:14)
scm_1       | 2020-12-21 16:35:48,315 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1       | 2020-12-21 16:35:48,636 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       | 2020-12-21 16:35:48,759 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.DefaultLeaderChoosePolicy
datanode_1  | 2020-12-21 16:36:47,956 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | 2020-12-21 16:38:27,681 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1050,entriesCount=1,lastEntry=(t:1, i:15)
datanode_2  | 2020-12-21 16:38:27,723 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1051,entriesCount=1,lastEntry=(t:1, i:16)
datanode_2  | 2020-12-21 16:38:27,725 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1052,entriesCount=1,lastEntry=(t:1, i:17)
datanode_2  | 2020-12-21 16:38:27,875 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1053,entriesCount=1,lastEntry=(t:1, i:18)
datanode_2  | 2020-12-21 16:38:27,897 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1056,entriesCount=1,lastEntry=(t:1, i:19)
om2_1       | 2020-12-21 16:36:18,574 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1       | 2020-12-21 16:36:18,579 [Listener at om2/9862] INFO server.session: node0 Scavenging every 600000ms
om1_1       | 2020-12-21 16:36:20,207 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: Election REJECTED; received 2 response(s) [om1<-om3#0:FAIL-t2, om1<-om2#0:FAIL-t2] and 0 exception(s); om1@group-562213E44849:t2, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
datanode_2  | 2020-12-21 16:38:27,899 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1057,entriesCount=1,lastEntry=(t:1, i:20)
datanode_2  | 2020-12-21 16:38:31,947 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1310,entriesCount=1,lastEntry=(t:1, i:21)
s3g_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.27.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.10.3.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar
scm_1       | 2020-12-21 16:35:48,764 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1       | 2020-12-21 16:35:48,853 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
datanode_1  | GC pool 'ParNew' had collection(s): count=3 time=264ms
datanode_1  | 2020-12-21 16:36:52,979 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 19ms
datanode_3  | GC pool 'ParNew' had collection(s): count=18 time=663ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=20ms
datanode_2  | 2020-12-21 16:38:31,963 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1311,entriesCount=1,lastEntry=(t:1, i:22)
om2_1       | 2020-12-21 16:36:18,681 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@726e29d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/c958bfb4070aab1068d7e455792957fc116a31fc ; compiled by 'runner' on 2020-12-21T16:02Z
s3g_1       | STARTUP_MSG:   java = 11.0.7
s3g_1       | ************************************************************/
datanode_1  | GC pool 'ParNew' had collection(s): count=4 time=318ms
scm_1       | 2020-12-21 16:35:48,960 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2020-12-21 16:35:48,965 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
datanode_2  | 2020-12-21 16:38:32,006 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1312,entriesCount=1,lastEntry=(t:1, i:23)
datanode_2  | 2020-12-21 16:38:32,085 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1313,entriesCount=1,lastEntry=(t:1, i:24)
datanode_2  | 2020-12-21 16:38:32,100 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1315,entriesCount=1,lastEntry=(t:1, i:25)
datanode_2  | 2020-12-21 16:38:32,108 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1316,entriesCount=1,lastEntry=(t:1, i:26)
om2_1       | 2020-12-21 16:36:18,714 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7fb1820d{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1       | 2020-12-21 16:36:19,175 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om3_1       | 2020-12-21 16:36:16,478 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1       | 2020-12-21 16:35:50,457 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-12-21 16:35:50,491 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2020-12-21 16:35:50,589 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1       | 2020-12-21 16:36:20,208 [om1@group-562213E44849-LeaderElection1] INFO impl.RaftServerImpl: om1@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 2 for DISCOVERED_A_NEW_TERM
s3g_1       | 2020-12-21 16:35:26,324 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | 2020-12-21 16:35:26,678 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1       | 2020-12-21 16:35:26,740 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1       | 2020-12-21 16:35:26,741 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
om3_1       | 2020-12-21 16:36:16,484 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1       | 2020-12-21 16:35:50,603 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1       | 2020-12-21 16:35:50,648 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1       | 2020-12-21 16:36:20,208 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1       | 2020-12-21 16:36:20,210 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1       | 2020-12-21 16:36:20,262 [grpc-default-executor-0] INFO impl.RaftServerImpl: om1@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 3 for recognizeCandidate:om2
om1_1       | 2020-12-21 16:36:20,262 [grpc-default-executor-0] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1       | 2020-12-21 16:36:20,262 [grpc-default-executor-0] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
s3g_1       | 2020-12-21 16:35:27,028 [main] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1       | 2020-12-21 16:36:16,558 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm_1       | 2020-12-21 16:35:50,650 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1       | 2020-12-21 16:35:50,681 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
om2_1       | GC pool 'ParNew' had collection(s): count=1 time=38ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om2_1       | 2020-12-21 16:36:19,192 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om2_1       | 2020-12-21 16:36:19,195 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: begin an election at term 2 for -1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om2_1       | 2020-12-21 16:36:19,195 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@22a8c837{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-1_1_0-SNAPSHOT_jar-_-any-5878390600158038592/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1       | 2020-12-21 16:36:19,223 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@6802c10e{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1       | 2020-12-21 16:36:19,227 [Listener at om2/9862] INFO server.Server: Started @25769ms
om2_1       | 2020-12-21 16:36:19,242 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1       | 2020-12-21 16:36:19,242 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1       | 2020-12-21 16:36:19,267 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om2_1       | 2020-12-21 16:36:19,272 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1       | 2020-12-21 16:36:19,276 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
s3g_1       | 2020-12-21 16:35:27,039 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1       | 2020-12-21 16:35:27,042 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1       | 2020-12-21 16:35:27,269 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@256f8274{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2020-12-21 16:38:35,024 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ParNew' had collection(s): count=12 time=390ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=97ms
datanode_2  | 2020-12-21 16:38:35,388 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1569,entriesCount=1,lastEntry=(t:1, i:27)
scm_1       | 2020-12-21 16:35:50,682 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1       | 2020-12-21 16:35:50,763 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @21416ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       | 2020-12-21 16:35:51,115 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 2020-12-21 16:35:27,276 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7ac2e39b{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | WARNING: An illegal reflective access operation has occurred
om3_1       | 2020-12-21 16:36:16,592 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1       | 2020-12-21 16:35:51,154 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1       | 2020-12-21 16:35:51,186 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1       | 2020-12-21 16:36:19,564 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
datanode_2  | 2020-12-21 16:38:35,388 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1570,entriesCount=1,lastEntry=(t:1, i:28)
datanode_2  | 2020-12-21 16:38:35,399 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1571,entriesCount=1,lastEntry=(t:1, i:29)
datanode_2  | 2020-12-21 16:38:35,408 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1572,entriesCount=1,lastEntry=(t:1, i:30)
datanode_2  | 2020-12-21 16:38:41,317 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1822,entriesCount=1,lastEntry=(t:1, i:31)
datanode_2  | 2020-12-21 16:38:41,329 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1823,entriesCount=1,lastEntry=(t:1, i:32)
datanode_2  | 2020-12-21 16:38:41,330 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1824,entriesCount=1,lastEntry=(t:1, i:33)
datanode_2  | 2020-12-21 16:38:44,487 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2073,entriesCount=1,lastEntry=(t:1, i:34)
s3g_1       | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1       | WARNING: All illegal access operations will be denied in a future release
s3g_1       | Dec 21, 2020 4:35:46 PM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1       | 
om2_1       | 2020-12-21 16:36:19,629 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@38318d67] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1       | 2020-12-21 16:36:19,885 [grpc-default-executor-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om2
scm_1       | 2020-12-21 16:35:51,188 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1       | 2020-12-21 16:35:51,191 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om1_1       | 2020-12-21 16:36:20,263 [grpc-default-executor-0] INFO impl.RaftServerImpl:  FOLLOWER om1@group-562213E44849:t3, leader=null, voted=null, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null RUNNING priority:0 candidate:om2|rpc:om2:9872 candidatePriority:0 compare:0
datanode_1  | 2020-12-21 16:36:53,988 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om2_1       | 2020-12-21 16:36:20,235 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: Election TIMEOUT; received 1 response(s) [om2<-om1#0:FAIL-t2] and 0 exception(s); om2@group-562213E44849:t2, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om3_1       | 2020-12-21 16:36:16,593 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1       | 2020-12-21 16:36:16,608 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
s3g_1       | 2020-12-21 16:35:46,992 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@852ef8d{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-1_1_0-SNAPSHOT_jar-_-any-10530692870365061808/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar!/webapps/s3gateway}
om1_1       | 2020-12-21 16:36:20,273 [Thread-131] INFO impl.FollowerState: om1@group-562213E44849-FollowerState was interrupted: {}
om1_1       | java.lang.InterruptedException: sleep interrupted
om1_1       | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_2  | 2020-12-21 16:38:44,494 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2074,entriesCount=1,lastEntry=(t:1, i:35)
datanode_2  | 2020-12-21 16:38:44,499 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2075,entriesCount=1,lastEntry=(t:1, i:36)
datanode_2  | 2020-12-21 16:38:44,508 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2076,entriesCount=1,lastEntry=(t:1, i:37)
datanode_2  | 2020-12-21 16:38:50,103 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2328,entriesCount=1,lastEntry=(t:1, i:38)
datanode_2  | 2020-12-21 16:38:50,122 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2329,entriesCount=1,lastEntry=(t:1, i:39)
scm_1       | 2020-12-21 16:35:51,192 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1       | 2020-12-21 16:35:47,043 [main] INFO server.AbstractConnector: Started ServerConnector@3e7634b9{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1       | 2020-12-21 16:35:47,056 [main] INFO server.Server: Started @33046ms
om2_1       | 2020-12-21 16:36:20,240 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: begin an election at term 3 for -1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om2_1       | 2020-12-21 16:36:20,288 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: Election PASSED; received 1 response(s) [om2<-om1#0:OK-t3] and 0 exception(s); om2@group-562213E44849:t3, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om2_1       | 2020-12-21 16:36:20,291 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1       | 2020-12-21 16:36:20,292 [om2@group-562213E44849-LeaderElection1] INFO impl.RaftServerImpl: om2@group-562213E44849: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
om2_1       | 2020-12-21 16:36:20,293 [om2@group-562213E44849-LeaderElection1] INFO impl.RaftServerImpl: om2@group-562213E44849: change Leader from null to om2 at term 3 for becomeLeader, leader elected after 6087ms
scm_1       | 2020-12-21 16:35:51,233 [Listener at 0.0.0.0/9860] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
scm_1       | 2020-12-21 16:35:51,242 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1       | 2020-12-21 16:35:51,433 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | 2020-12-21 16:35:51,518 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1       | 2020-12-21 16:35:51,519 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1       | 2020-12-21 16:35:51,926 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
s3g_1       | 2020-12-21 16:35:47,065 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1       | 2020-12-21 16:36:44,599 [qtp1260634890-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-46039, with Versioning false and Storage Type set to DISK and Encryption set to false 
om1_1       | 	at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:250)
om1_1       | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:116)
om2_1       | 2020-12-21 16:36:20,298 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om2_1       | 2020-12-21 16:36:20,299 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | GC pool 'ParNew' had collection(s): count=4 time=318ms
s3g_1       | 2020-12-21 16:36:45,025 [qtp1260634890-21] INFO endpoint.BucketEndpoint: Location is /bucket-46039
om1_1       | 2020-12-21 16:36:20,516 [grpc-default-executor-0] INFO impl.RaftServerImpl: om1@group-562213E44849: change Leader from null to om2 at term 3 for appendEntries, leader elected after 6174ms
om1_1       | 2020-12-21 16:36:20,557 [grpc-default-executor-0] INFO impl.RaftServerImpl: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|dataStream:, om3|rpc:om3:9872|dataStream:, om2|rpc:om2:9872|dataStream:], old=null at 0
datanode_2  | 2020-12-21 16:38:50,127 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2330,entriesCount=1,lastEntry=(t:1, i:40)
scm_1       | 2020-12-21 16:35:51,928 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-12-21 16:35:51,940 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=67ms
datanode_1  | 2020-12-21 16:37:32,008 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=6 time=414ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=67ms
datanode_2  | 2020-12-21 16:38:50,240 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2331,entriesCount=1,lastEntry=(t:1, i:41)
om2_1       | 2020-12-21 16:36:20,303 [om2@group-562213E44849-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.om2@group-562213E44849
om2_1       | 2020-12-21 16:36:20,308 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om2_1       | 2020-12-21 16:36:20,311 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om3_1       | 2020-12-21 16:36:16,613 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
datanode_1  | 2020-12-21 16:38:20,034 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | 2020-12-21 16:36:20,586 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1       | 2020-12-21 16:36:20,795 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
datanode_2  | 2020-12-21 16:38:50,249 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2332,entriesCount=1,lastEntry=(t:1, i:42)
om2_1       | 2020-12-21 16:36:20,328 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om2_1       | 2020-12-21 16:36:20,329 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om3_1       | 2020-12-21 16:36:16,620 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1       | 2020-12-21 16:36:16,621 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1       | 2020-12-21 16:36:16,621 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
s3g_1       | 2020-12-21 16:36:48,636 [qtp1260634890-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-92889, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-21 16:36:48,660 [qtp1260634890-17] INFO endpoint.BucketEndpoint: Location is /bucket-92889
s3g_1       | 2020-12-21 16:36:51,365 [qtp1260634890-24] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1       | 2020-12-21 16:36:51,408 [qtp1260634890-24] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1       | 2020-12-21 16:36:51,408 [qtp1260634890-24] INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
s3g_1       | 2020-12-21 16:36:51,415 [qtp1260634890-24] WARN impl.MetricsSystemImpl: Sink prometheus already exists!
om2_1       | 2020-12-21 16:36:20,332 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
s3g_1       | 2020-12-21 16:36:51,795 [qtp1260634890-24] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1       | 2020-12-21 16:36:51,795 [qtp1260634890-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-DF8A4A807E3B->ec956fef-022a-4e11-a406-1dfa86e0929f
datanode_1  | GC pool 'ParNew' had collection(s): count=9 time=562ms
om1_1       | 2020-12-21 16:36:21,474 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | 2020-12-21 16:38:50,249 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2333,entriesCount=1,lastEntry=(t:1, i:43)
datanode_2  | 2020-12-21 16:38:53,593 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2583,entriesCount=1,lastEntry=(t:1, i:44)
datanode_2  | 2020-12-21 16:38:53,594 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2584,entriesCount=1,lastEntry=(t:1, i:45)
datanode_2  | 2020-12-21 16:38:53,603 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2585,entriesCount=1,lastEntry=(t:1, i:46)
om2_1       | 2020-12-21 16:36:20,353 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm_1       | 2020-12-21 16:35:51,999 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om1_1       | GC pool 'ParNew' had collection(s): count=2 time=71ms
datanode_1  | 2020-12-21 16:38:30,046 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om3_1       | 2020-12-21 16:36:16,741 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om3@group-562213E44849
om3_1       | 2020-12-21 16:36:16,772 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om3@group-562213E44849
om3_1       | 2020-12-21 16:36:16,805 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1       | 2020-12-21 16:36:16,846 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
datanode_1  | GC pool 'ParNew' had collection(s): count=10 time=572ms
scm_1       | 2020-12-21 16:35:52,004 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1       | 2020-12-21 16:35:52,005 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-12-21 16:35:52,025 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1       | 2020-12-21 16:35:52,031 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1       | 2020-12-21 16:35:52,031 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1       | 2020-12-21 16:35:52,032 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-12-21 16:35:52,032 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm_1       | 2020-12-21 16:35:52,219 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1       | 2020-12-21 16:35:52,225 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=76ms
om1_1       | 2020-12-21 16:36:42,995 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
s3g_1       | 2020-12-21 16:36:51,796 [qtp1260634890-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:36:57,087 [qtp1260634890-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-7532DA01E19D->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:36:57,095 [qtp1260634890-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
datanode_2  | 2020-12-21 16:38:53,668 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2586,entriesCount=1,lastEntry=(t:1, i:47)
datanode_2  | 2020-12-21 16:38:53,689 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2588,entriesCount=1,lastEntry=(t:1, i:48)
datanode_2  | 2020-12-21 16:38:53,694 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2589,entriesCount=1,lastEntry=(t:1, i:49)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:38:33,549 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=11 time=591ms
s3g_1       | 2020-12-21 16:37:04,004 [qtp1260634890-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-40714, with Versioning false and Storage Type set to DISK and Encryption set to false 
om2_1       | 2020-12-21 16:36:20,353 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1       | 2020-12-21 16:36:20,354 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
datanode_2  | 2020-12-21 16:38:56,918 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2841,entriesCount=1,lastEntry=(t:1, i:50)
om3_1       | 2020-12-21 16:36:17,372 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1       | 2020-12-21 16:36:17,564 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1       | GC pool 'ParNew' had collection(s): count=3 time=124ms
om2_1       | 2020-12-21 16:36:20,363 [om2@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om2_1       | 2020-12-21 16:36:20,364 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_2  | 2020-12-21 16:38:56,919 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2842,entriesCount=1,lastEntry=(t:1, i:51)
scm_1       | 2020-12-21 16:35:52,369 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1       | 2020-12-21 16:35:52,371 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
om3_1       | 2020-12-21 16:36:17,564 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
s3g_1       | 2020-12-21 16:37:04,027 [qtp1260634890-24] INFO endpoint.BucketEndpoint: Location is /bucket-40714
s3g_1       | 2020-12-21 16:37:04,632 [qtp1260634890-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-98904, with Versioning false and Storage Type set to DISK and Encryption set to false 
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:38:46,560 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
om2_1       | 2020-12-21 16:36:20,364 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 2020-12-21 16:35:52,377 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm_1       | 2020-12-21 16:35:52,490 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6734ff92{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1       | 2020-12-21 16:35:52,490 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@74500e4f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | 2020-12-21 16:35:53,635 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3568ea59{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-1_1_0-SNAPSHOT_jar-_-any-18228877465875089064/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar!/webapps/scm}
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=79ms
datanode_2  | 2020-12-21 16:38:56,929 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2843,entriesCount=1,lastEntry=(t:1, i:52)
datanode_2  | 2020-12-21 16:38:56,938 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2844,entriesCount=1,lastEntry=(t:1, i:53)
datanode_2  | 2020-12-21 16:39:06,041 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3096,entriesCount=1,lastEntry=(t:1, i:54)
datanode_2  | 2020-12-21 16:39:06,070 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3097,entriesCount=1,lastEntry=(t:1, i:55)
om3_1       | 2020-12-21 16:36:17,926 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.23.0.6:9862
om3_1       | 2020-12-21 16:36:17,928 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
s3g_1       | 2020-12-21 16:37:04,654 [qtp1260634890-24] INFO endpoint.BucketEndpoint: Location is /bucket-98904
om1_1       | 2020-12-21 16:36:43,506 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10ms
om2_1       | 2020-12-21 16:36:20,365 [om2@group-562213E44849-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.om2@group-562213E44849
om2_1       | 2020-12-21 16:36:20,374 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om2_1       | 2020-12-21 16:36:20,378 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1       | 2020-12-21 16:36:20,378 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
s3g_1       | 2020-12-21 16:37:05,285 [qtp1260634890-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-40714, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-21 16:37:05,307 [qtp1260634890-23] INFO endpoint.BucketEndpoint: Location is /bucket-40714
s3g_1       | 2020-12-21 16:37:05,911 [qtp1260634890-24] ERROR endpoint.BucketEndpoint: Error in Create Bucket Request for bucket: bucket_1
s3g_1       | INVALID_BUCKET_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Bucket or Volume name has an unsupported character : _
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.verifyBucketName(RpcClient.java:448)
om1_1       | GC pool 'ParNew' had collection(s): count=5 time=157ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=113ms
om1_1       | 2020-12-21 16:36:43,518 [IPC Server handler 0 on default port 9862] INFO ipc.Server: IPC Server handler 0 on default port 9862, call Call#0 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:38866
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
scm_1       | 2020-12-21 16:35:53,777 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@4cb24e2{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm_1       | 2020-12-21 16:35:53,778 [Listener at 0.0.0.0/9860] INFO server.Server: Started @24430ms
scm_1       | 2020-12-21 16:35:53,814 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1       | 2020-12-21 16:36:17,945 [Listener at om3/9862] INFO impl.RaftServerImpl: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om3_1       | 2020-12-21 16:36:17,957 [Listener at om3/9862] INFO impl.RaftServerImpl: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1       | 2020-12-21 16:36:17,958 [Listener at om3/9862] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
datanode_1  | GC pool 'ParNew' had collection(s): count=12 time=602ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:39:11,074 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | 2020-12-21 16:36:20,378 [om2@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2  | 2020-12-21 16:39:06,071 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3098,entriesCount=1,lastEntry=(t:1, i:56)
datanode_2  | 2020-12-21 16:39:06,134 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3099,entriesCount=1,lastEntry=(t:1, i:57)
datanode_2  | 2020-12-21 16:39:06,141 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3100,entriesCount=1,lastEntry=(t:1, i:58)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
scm_1       | 2020-12-21 16:35:53,814 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:392)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:383)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneVolume.createBucket(OzoneVolume.java:330)
s3g_1       | 	at org.apache.hadoop.ozone.client.ObjectStore.createS3Bucket(ObjectStore.java:118)
om3_1       | 2020-12-21 16:36:17,964 [Listener at om3/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1       | 2020-12-21 16:36:17,971 [Listener at om3/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om3@group-562213E44849
om3_1       | 2020-12-21 16:36:18,013 [Listener at om3/9862] INFO impl.RaftServerProxy: om3: start RPC server
om3_1       | 2020-12-21 16:36:18,289 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 0.0.0.0/0.0.0.0:9872
om3_1       | 2020-12-21 16:36:18,306 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1       | 2020-12-21 16:36:20,378 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1       | 2020-12-21 16:36:20,379 [om2@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1       | 2020-12-21 16:36:20,387 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderState
om2_1       | 2020-12-21 16:36:20,414 [om2@group-562213E44849-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1       | 2020-12-21 16:36:20,459 [om2@group-562213E44849-LeaderElection1] INFO impl.RaftServerImpl: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|dataStream:, om3|rpc:om3:9872|dataStream:, om2|rpc:om2:9872|dataStream:], old=null at 0
datanode_2  | 2020-12-21 16:39:06,150 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3101,entriesCount=1,lastEntry=(t:1, i:59)
datanode_2  | 2020-12-21 16:39:09,398 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3353,entriesCount=1,lastEntry=(t:1, i:60)
datanode_2  | 2020-12-21 16:39:09,398 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3354,entriesCount=1,lastEntry=(t:1, i:61)
datanode_2  | 2020-12-21 16:39:09,407 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3355,entriesCount=1,lastEntry=(t:1, i:62)
datanode_2  | 2020-12-21 16:39:09,416 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3356,entriesCount=1,lastEntry=(t:1, i:63)
scm_1       | 2020-12-21 16:35:53,835 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1       | 2020-12-21 16:35:53,916 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1530d0f2] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2020-12-21 16:35:54,466 [IPC Server handler 94 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2
scm_1       | 2020-12-21 16:35:54,490 [IPC Server handler 94 on default port 9861] INFO node.SCMNodeManager: Registered Data node : f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2020-12-21 16:35:54,532 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
datanode_1  | GC pool 'ParNew' had collection(s): count=12 time=602ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:39:11,578 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_1  | GC pool 'ParNew' had collection(s): count=13 time=606ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.createS3Bucket(EndpointBase.java:98)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:217)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om2_1       | 2020-12-21 16:36:20,678 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=2 time=60ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om2_1       | 2020-12-21 16:36:20,749 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1       | 2020-12-21 16:36:49,700 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | 2020-12-21 16:36:18,306 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1       | 2020-12-21 16:36:18,323 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] INFO server.JvmPauseMonitor: Starting Ratis JVM pause monitor
om3_1       | 2020-12-21 16:36:18,579 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1       | 2020-12-21 16:36:18,584 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_2  | 2020-12-21 16:39:10,541 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=13 time=449ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=128ms
datanode_2  | 2020-12-21 16:39:15,709 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3607,entriesCount=1,lastEntry=(t:1, i:64)
datanode_1  | 2020-12-21 16:39:12,583 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | 2020-12-21 16:39:15,726 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3608,entriesCount=1,lastEntry=(t:1, i:65)
scm_1       | 2020-12-21 16:35:54,562 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-12-21 16:35:54,615 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-12-21 16:35:54,664 [IPC Server handler 93 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/d59b5746-4c38-43fa-95c4-93039b647722
scm_1       | 2020-12-21 16:35:54,708 [IPC Server handler 93 on default port 9861] INFO node.SCMNodeManager: Registered Data node : d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
om3_1       | 2020-12-21 16:36:18,702 [Listener at om3/9862] INFO util.log: Logging initialized @23895ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1       | 2020-12-21 16:36:19,047 [Thread-12] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcTime:1089ms, electionTimeout:1064ms
datanode_1  | GC pool 'ParNew' had collection(s): count=13 time=606ms
datanode_2  | 2020-12-21 16:39:15,730 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3609,entriesCount=1,lastEntry=(t:1, i:66)
datanode_2  | 2020-12-21 16:39:15,791 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3610,entriesCount=1,lastEntry=(t:1, i:67)
om2_1       | GC pool 'ParNew' had collection(s): count=7 time=123ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
scm_1       | 2020-12-21 16:35:54,722 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1       | 2020-12-21 16:35:54,722 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-12-21 16:35:54,722 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
om3_1       | 2020-12-21 16:36:19,052 [Thread-12] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1       | 2020-12-21 16:36:19,084 [Thread-12] INFO impl.RaftServerImpl: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1       | 2020-12-21 16:37:05,301 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-40714 in volume:s3v
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
scm_1       | 2020-12-21 16:35:54,868 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=23c75842-87fc-4ac0-be5f-859f1892a458 to datanode:f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2
om3_1       | 2020-12-21 16:36:19,091 [Thread-12] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om2_1       | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1       | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
datanode_2  | 2020-12-21 16:39:15,812 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3612,entriesCount=1,lastEntry=(t:1, i:68)
datanode_2  | 2020-12-21 16:39:15,936 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3625,entriesCount=1,lastEntry=(t:1, i:69)
datanode_2  | 2020-12-21 16:39:16,033 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3629,entriesCount=1,lastEntry=(t:1, i:70)
datanode_2  | 2020-12-21 16:39:16,034 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3630,entriesCount=1,lastEntry=(t:1, i:71)
datanode_2  | 2020-12-21 16:39:16,139 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3638,entriesCount=1,lastEntry=(t:1, i:72)
datanode_1  | 2020-12-21 16:39:19,593 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
om3_1       | 2020-12-21 16:36:19,146 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: begin an election at term 1 for -1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om3_1       | 2020-12-21 16:36:19,409 [Listener at om3/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om3_1       | 2020-12-21 16:36:19,498 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       | 2020-12-21 16:35:54,980 [IPC Server handler 92 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ec956fef-022a-4e11-a406-1dfa86e0929f
scm_1       | 2020-12-21 16:35:54,980 [IPC Server handler 92 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2020-12-21 16:35:54,996 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
datanode_1  | GC pool 'ParNew' had collection(s): count=19 time=664ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:39:21,102 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_1  | GC pool 'ParNew' had collection(s): count=23 time=675ms
scm_1       | 2020-12-21 16:35:54,996 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
om3_1       | 2020-12-21 16:36:19,530 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1       | 2020-12-21 16:36:19,544 [Listener at om3/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om3_1       | 2020-12-21 16:36:19,544 [Listener at om3/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om3_1       | 2020-12-21 16:36:19,544 [Listener at om3/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:36:45,510 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=6 time=175ms
datanode_2  | 2020-12-21 16:39:16,162 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3642,entriesCount=1,lastEntry=(t:1, i:73)
datanode_2  | 2020-12-21 16:39:16,245 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3650,entriesCount=1,lastEntry=(t:1, i:74)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
scm_1       | 2020-12-21 16:35:54,997 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2020-12-21 16:35:54,997 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=113ms
datanode_2  | 2020-12-21 16:39:16,250 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3651,entriesCount=1,lastEntry=(t:1, i:75)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:39:29,107 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=98 time=875ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
scm_1       | 2020-12-21 16:35:54,997 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
om3_1       | 2020-12-21 16:36:19,848 [Listener at om3/9862] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om3_1       | 2020-12-21 16:36:19,976 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1       | 2020-12-21 16:36:19,977 [Listener at om3/9862] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
datanode_2  | 2020-12-21 16:39:16,298 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3652,entriesCount=1,lastEntry=(t:1, i:76)
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-12-21 16:39:16,298 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3653,entriesCount=1,lastEntry=(t:1, i:77)
datanode_2  | 2020-12-21 16:39:16,313 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3655,entriesCount=1,lastEntry=(t:1, i:78)
datanode_2  | 2020-12-21 16:39:16,378 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3667,entriesCount=1,lastEntry=(t:1, i:79)
datanode_2  | 2020-12-21 16:39:16,405 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3670,entriesCount=1,lastEntry=(t:1, i:80)
datanode_2  | 2020-12-21 16:39:22,123 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3918,entriesCount=1,lastEntry=(t:1, i:81)
scm_1       | 2020-12-21 16:35:55,150 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 23c75842-87fc-4ac0-be5f-859f1892a458, Nodes: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-12-21T16:35:54.766817Z]
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
om2_1       | 2020-12-21 16:37:10,717 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
scm_1       | 2020-12-21 16:35:55,312 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=1f541f4e-a162-4978-bdd3-a46a69316625 to datanode:ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
datanode_1  | 2020-12-21 16:39:32,113 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om1_1       | 2020-12-21 16:36:46,037 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26ms
om3_1       | 2020-12-21 16:36:20,047 [grpc-default-executor-2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om3
om3_1       | 2020-12-21 16:36:20,048 [grpc-default-executor-3] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om3
datanode_2  | 2020-12-21 16:39:22,130 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3919,entriesCount=1,lastEntry=(t:1, i:82)
om2_1       | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2020-12-21 16:35:55,322 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=1f541f4e-a162-4978-bdd3-a46a69316625 to datanode:d59b5746-4c38-43fa-95c4-93039b647722
scm_1       | 2020-12-21 16:35:55,324 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=1f541f4e-a162-4978-bdd3-a46a69316625 to datanode:f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2
scm_1       | 2020-12-21 16:35:55,330 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-12-21T16:35:55.312811Z]
scm_1       | 2020-12-21 16:35:55,349 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=759a8eb9-11b3-4079-be1a-c0245d86e4d4 to datanode:ec956fef-022a-4e11-a406-1dfa86e0929f
om1_1       | GC pool 'ParNew' had collection(s): count=7 time=229ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=113ms
om1_1       | 2020-12-21 16:36:46,543 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_1  | GC pool 'ParNew' had collection(s): count=131 time=960ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:39:39,128 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11ms
datanode_1  | GC pool 'ParNew' had collection(s): count=205 time=1183ms
om3_1       | 2020-12-21 16:36:20,048 [grpc-default-executor-4] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om3
om3_1       | 2020-12-21 16:36:20,085 [grpc-default-executor-4] INFO impl.RaftServerImpl: om3@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 2 for recognizeCandidate:om1
om3_1       | 2020-12-21 16:36:20,085 [grpc-default-executor-4] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
om2_1       | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:119)
om1_1       | GC pool 'ParNew' had collection(s): count=7 time=229ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=113ms
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
scm_1       | 2020-12-21 16:35:55,361 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 759a8eb9-11b3-4079-be1a-c0245d86e4d4, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-12-21T16:35:55.349843Z]
om3_1       | 2020-12-21 16:36:20,086 [grpc-default-executor-4] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
datanode_2  | 2020-12-21 16:39:22,141 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3920,entriesCount=1,lastEntry=(t:1, i:83)
datanode_2  | 2020-12-21 16:39:22,219 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3921,entriesCount=1,lastEntry=(t:1, i:84)
datanode_2  | 2020-12-21 16:39:22,231 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3923,entriesCount=1,lastEntry=(t:1, i:85)
datanode_2  | 2020-12-21 16:39:22,233 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3924,entriesCount=1,lastEntry=(t:1, i:86)
datanode_2  | 2020-12-21 16:39:26,152 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4176,entriesCount=1,lastEntry=(t:1, i:87)
datanode_1  | 2020-12-21 16:39:39,630 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=210 time=1208ms
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
om3_1       | 2020-12-21 16:36:20,103 [grpc-default-executor-5] INFO impl.RaftServerImpl: om3@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:om2
datanode_2  | 2020-12-21 16:39:26,166 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4177,entriesCount=1,lastEntry=(t:1, i:88)
datanode_2  | 2020-12-21 16:39:26,166 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4178,entriesCount=1,lastEntry=(t:1, i:89)
om1_1       | 2020-12-21 16:36:48,613 [IPC Server handler 43 on default port 9862] INFO ipc.Server: IPC Server handler 43 on default port 9862, call Call#3 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:38882
scm_1       | 2020-12-21 16:35:55,366 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=6f160a74-ec34-4eec-a46f-6e26b47e7b56 to datanode:d59b5746-4c38-43fa-95c4-93039b647722
scm_1       | 2020-12-21 16:35:55,377 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 6f160a74-ec34-4eec-a46f-6e26b47e7b56, Nodes: d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-12-21T16:35:55.366641Z]
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om3_1       | 2020-12-21 16:36:20,103 [grpc-default-executor-5] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
scm_1       | 2020-12-21 16:35:58,280 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-12-21 16:36:02,055 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
datanode_1  | 2020-12-21 16:39:58,645 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
scm_1       | 2020-12-21 16:36:04,222 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1       | 2020-12-21 16:37:31,723 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | 2020-12-21 16:36:20,103 [grpc-default-executor-5] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
datanode_2  | 2020-12-21 16:39:26,216 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4179,entriesCount=1,lastEntry=(t:1, i:90)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
datanode_2  | 2020-12-21 16:39:26,233 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4181,entriesCount=1,lastEntry=(t:1, i:91)
om3_1       | 2020-12-21 16:36:20,109 [grpc-default-executor-5] INFO impl.RaftServerImpl:  FOLLOWER om3@group-562213E44849:t2, leader=null, voted=null, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null RUNNING priority:0 candidate:om2|rpc:om2:9872 candidatePriority:0 compare:0
om3_1       | 2020-12-21 16:36:20,115 [Thread-19] INFO impl.FollowerState: om3@group-562213E44849-FollowerState was interrupted: {}
datanode_1  | GC pool 'ParNew' had collection(s): count=390 time=1699ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:40:15,654 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
om2_1       | GC pool 'ParNew' had collection(s): count=8 time=146ms
scm_1       | 2020-12-21 16:36:04,963 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-12-21 16:36:04,963 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312811Z] moved to OPEN state
scm_1       | 2020-12-21 16:36:04,982 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
datanode_2  | 2020-12-21 16:39:26,251 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4183,entriesCount=1,lastEntry=(t:1, i:92)
datanode_2  | 2020-12-21 16:39:30,811 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4433,entriesCount=1,lastEntry=(t:1, i:93)
datanode_1  | GC pool 'ParNew' had collection(s): count=569 time=2191ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:40:57,676 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
scm_1       | 2020-12-21 16:36:04,982 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1       | 2020-12-21 16:36:04,982 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
om3_1       | java.lang.InterruptedException: sleep interrupted
om3_1       | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_1  | GC pool 'ParNew' had collection(s): count=992 time=3504ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:41:12,704 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 19ms
datanode_2  | 2020-12-21 16:39:30,903 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4434,entriesCount=1,lastEntry=(t:1, i:94)
om2_1       | 2020-12-21 16:37:47,643 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-00598/25914/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om2_1       | 2020-12-21 16:37:47,647 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 25914/multipartKey2 in Volume/Bucket s3v/bucket-00598
datanode_2  | 2020-12-21 16:39:30,928 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4435,entriesCount=1,lastEntry=(t:1, i:95)
scm_1       | 2020-12-21 16:36:05,010 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om3_1       | 	at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:250)
om3_1       | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:116)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om2_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 25914/multipartKey2. Entity too small.
datanode_2  | 2020-12-21 16:39:30,933 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4436,entriesCount=1,lastEntry=(t:1, i:96)
datanode_2  | 2020-12-21 16:39:30,941 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4437,entriesCount=1,lastEntry=(t:1, i:97)
datanode_2  | 2020-12-21 16:39:30,998 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4442,entriesCount=1,lastEntry=(t:1, i:98)
scm_1       | 2020-12-21 16:36:05,814 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 759a8eb9-11b3-4079-be1a-c0245d86e4d4, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.349843Z] moved to OPEN state
scm_1       | 2020-12-21 16:36:26,910 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 23c75842-87fc-4ac0-be5f-859f1892a458, Nodes: f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2, CreationTimestamp2020-12-21T16:35:54.766817Z] moved to OPEN state
scm_1       | 2020-12-21 16:36:27,303 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 6f160a74-ec34-4eec-a46f-6e26b47e7b56, Nodes: d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:d59b5746-4c38-43fa-95c4-93039b647722, CreationTimestamp2020-12-21T16:35:55.366641Z] moved to OPEN state
datanode_1  | GC pool 'ParNew' had collection(s): count=1120 time=3929ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:41:15,207 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om3_1       | 2020-12-21 16:36:20,277 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: Election DISCOVERED_A_NEW_TERM; received 1 response(s) [om3<-om2#0:FAIL-t2] and 0 exception(s); om3@group-562213E44849:t2, leader=null, voted=om2, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om3_1       | 2020-12-21 16:36:20,287 [grpc-default-executor-2] INFO impl.RaftServerImpl: om3@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 3 for recognizeCandidate:om2
scm_1       | 2020-12-21 16:41:05,026 [EventQueue-Delayed safe mode statusForReplicationManager] INFO container.ReplicationManager: Starting Replication Monitor Thread.
scm_1       | 2020-12-21 16:41:05,033 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 5 milliseconds for processing 1 containers.
scm_1       | 2020-12-21 16:46:05,045 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om2_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:227)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
datanode_2  | 2020-12-21 16:39:31,037 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4447,entriesCount=1,lastEntry=(t:1, i:99)
om3_1       | 2020-12-21 16:36:20,287 [grpc-default-executor-2] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1       | 2020-12-21 16:36:20,287 [grpc-default-executor-2] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_2  | 2020-12-21 16:39:31,042 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4448,entriesCount=1,lastEntry=(t:1, i:100)
datanode_1  | GC pool 'ParNew' had collection(s): count=1147 time=3987ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
scm_1       | 2020-12-21 16:51:05,045 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
datanode_1  | 2020-12-21 16:41:22,712 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
datanode_2  | 2020-12-21 16:39:34,920 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4700,entriesCount=1,lastEntry=(t:1, i:101)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | GC pool 'ParNew' had collection(s): count=1229 time=4224ms
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
datanode_2  | 2020-12-21 16:39:34,957 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4701,entriesCount=1,lastEntry=(t:1, i:102)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 2020-12-21 16:36:20,287 [Thread-20] INFO impl.FollowerState: om3@group-562213E44849-FollowerState was interrupted: {}
datanode_2  | 2020-12-21 16:39:35,085 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4713,entriesCount=1,lastEntry=(t:1, i:103)
datanode_2  | 2020-12-21 16:39:35,231 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4720,entriesCount=1,lastEntry=(t:1, i:104)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1       | java.lang.InterruptedException: sleep interrupted
om3_1       | 	at java.base/java.lang.Thread.sleep(Native Method)
scm_1       | 2020-12-21 16:56:05,045 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
datanode_2  | 2020-12-21 16:39:35,231 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4721,entriesCount=1,lastEntry=(t:1, i:105)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:41:34,221 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om3_1       | 	at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:250)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om3_1       | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:116)
datanode_2  | 2020-12-21 16:39:35,268 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4725,entriesCount=1,lastEntry=(t:1, i:106)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:36:49,300 [IPC Server handler 1 on default port 9862] INFO ipc.Server: IPC Server handler 1 on default port 9862, call Call#6 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:38888
datanode_1  | GC pool 'ParNew' had collection(s): count=1360 time=4549ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:41:38,728 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | 2020-12-21 16:39:35,272 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4726,entriesCount=1,lastEntry=(t:1, i:107)
datanode_2  | 2020-12-21 16:39:35,293 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4729,entriesCount=1,lastEntry=(t:1, i:108)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
datanode_1  | GC pool 'ParNew' had collection(s): count=1411 time=4671ms
datanode_2  | 2020-12-21 16:39:38,514 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4979,entriesCount=1,lastEntry=(t:1, i:109)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om3_1       | 2020-12-21 16:36:20,293 [grpc-default-executor-2] INFO impl.RaftServerImpl:  FOLLOWER om3@group-562213E44849:t3, leader=null, voted=null, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null RUNNING priority:0 candidate:om2|rpc:om2:9872 candidatePriority:0 compare:0
om3_1       | 2020-12-21 16:36:20,304 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-12-21 16:41:45,738 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
datanode_2  | 2020-12-21 16:39:38,522 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4980,entriesCount=1,lastEntry=(t:1, i:110)
om2_1       | 2020-12-21 16:37:48,786 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-00598/26385/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om2_1       | partName: "etag1"
om2_1       | , partNumber: 2
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om3_1       | 2020-12-21 16:36:20,304 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1       | 2020-12-21 16:36:20,306 [Listener at om3/9862] INFO server.session: node0 Scavenging every 600000ms
datanode_2  | 2020-12-21 16:39:38,530 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4981,entriesCount=1,lastEntry=(t:1, i:111)
datanode_2  | 2020-12-21 16:39:38,536 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4983,entriesCount=1,lastEntry=(t:1, i:112)
datanode_2  | 2020-12-21 16:39:42,053 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
datanode_1  | GC pool 'ParNew' had collection(s): count=1496 time=4900ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om3_1       | 2020-12-21 16:36:20,338 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@726e29d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1       | 2020-12-21 16:36:20,344 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7fb1820d{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om2_1       | partName: "etag2"
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
datanode_1  | 2020-12-21 16:42:00,246 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=1671 time=5317ms
om2_1       | ]
om2_1       | 2020-12-21 16:37:48,787 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 26385/multipartKey3 in Volume/Bucket s3v/bucket-00598
datanode_2  | GC pool 'ParNew' had collection(s): count=27 time=688ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=144ms
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
om3_1       | 2020-12-21 16:36:20,598 [grpc-default-executor-2] INFO impl.RaftServerImpl: om3@group-562213E44849: change Leader from null to om2 at term 3 for appendEntries, leader elected after 4489ms
om3_1       | 2020-12-21 16:36:20,669 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@22a8c837{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-1_1_0-SNAPSHOT_jar-_-any-10888592954731340827/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om3_1       | 2020-12-21 16:36:20,679 [grpc-default-executor-2] INFO impl.RaftServerImpl: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|dataStream:, om3|rpc:om3:9872|dataStream:, om2|rpc:om2:9872|dataStream:], old=null at 0
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om2_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3
om2_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:167)
datanode_2  | 2020-12-21 16:39:47,868 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5231,entriesCount=1,lastEntry=(t:1, i:113)
datanode_2  | 2020-12-21 16:39:47,869 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5232,entriesCount=1,lastEntry=(t:1, i:114)
datanode_1  | 2020-12-21 16:42:18,256 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om3_1       | 2020-12-21 16:36:20,717 [grpc-default-executor-2] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om3_1       | 2020-12-21 16:36:20,724 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@6802c10e{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
datanode_1  | GC pool 'ParNew' had collection(s): count=1884 time=5861ms
datanode_2  | 2020-12-21 16:39:47,888 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5233,entriesCount=1,lastEntry=(t:1, i:115)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om3_1       | 2020-12-21 16:36:20,724 [Listener at om3/9862] INFO server.Server: Started @25918ms
om3_1       | 2020-12-21 16:36:20,744 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2020-12-21 16:42:18,760 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=1890 time=5879ms
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
datanode_2  | 2020-12-21 16:39:48,559 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ParNew' had collection(s): count=32 time=813ms
om3_1       | 2020-12-21 16:36:20,760 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1       | 2020-12-21 16:36:20,766 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om3_1       | 2020-12-21 16:36:20,769 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=144ms
datanode_2  | 2020-12-21 16:39:49,062 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-12-21 16:42:57,278 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | 2020-12-21 16:36:20,777 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om3_1       | 2020-12-21 16:36:20,910 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om3_1       | 2020-12-21 16:36:20,917 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@38318d67] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | GC pool 'ParNew' had collection(s): count=32 time=813ms
om2_1       | 2020-12-21 16:37:49,333 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-00598/26385/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1       | partName: "etag1"
om2_1       | , partNumber: 1
om2_1       | partName: "etag2"
datanode_1  | GC pool 'ParNew' had collection(s): count=2352 time=6988ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:42:57,781 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=2358 time=7002ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=144ms
datanode_2  | 2020-12-21 16:39:50,095 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 32ms
datanode_2  | GC pool 'ParNew' had collection(s): count=33 time=856ms
om3_1       | 2020-12-21 16:36:20,951 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:36:50,051 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
om1_1       | GC pool 'ParNew' had collection(s): count=7 time=229ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=113ms
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
om3_1       | 2020-12-21 16:36:45,359 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om3_1       | GC pool 'ParNew' had collection(s): count=3 time=195ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=45ms
datanode_1  | 2020-12-21 16:42:58,783 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | ]
om2_1       | 2020-12-21 16:37:49,334 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 26385/multipartKey3 in Volume/Bucket s3v/bucket-00598
om2_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=144ms
datanode_2  | 2020-12-21 16:39:51,588 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5482,entriesCount=1,lastEntry=(t:1, i:116)
datanode_2  | 2020-12-21 16:39:51,592 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5483,entriesCount=1,lastEntry=(t:1, i:117)
datanode_2  | 2020-12-21 16:39:51,657 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5484,entriesCount=1,lastEntry=(t:1, i:118)
om1_1       | 2020-12-21 16:36:54,058 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=7 time=229ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=113ms
om1_1       | 2020-12-21 16:36:57,019 [IPC Server handler 1 on default port 9862] INFO ipc.Server: IPC Server handler 1 on default port 9862, call Call#11 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:38912
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
om3_1       | 2020-12-21 16:36:45,876 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om3_1       | GC pool 'ParNew' had collection(s): count=4 time=222ms
om2_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:167)
datanode_1  | GC pool 'ParNew' had collection(s): count=2370 time=7032ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_2  | 2020-12-21 16:39:51,657 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5485,entriesCount=1,lastEntry=(t:1, i:119)
datanode_2  | 2020-12-21 16:39:55,685 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5731,entriesCount=1,lastEntry=(t:1, i:120)
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=45ms
om3_1       | 2020-12-21 16:37:05,328 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-40714 in volume:s3v
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
datanode_1  | 2020-12-21 16:43:05,788 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=2459 time=7228ms
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_2  | 2020-12-21 16:39:55,685 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5732,entriesCount=1,lastEntry=(t:1, i:121)
datanode_2  | 2020-12-21 16:39:55,717 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5733,entriesCount=1,lastEntry=(t:1, i:122)
datanode_2  | 2020-12-21 16:40:03,642 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 41ms
om3_1       | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1       | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
datanode_2  | GC pool 'ParNew' had collection(s): count=40 time=1113ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=4 time=175ms
datanode_2  | 2020-12-21 16:40:03,961 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5983,entriesCount=1,lastEntry=(t:1, i:123)
s3g_1       | 2020-12-21 16:37:06,173 [qtp1260634890-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
datanode_1  | 2020-12-21 16:43:21,295 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=2638 time=7692ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
s3g_1       |   <Code>InvalidBucketName</Code>
om2_1       | 2020-12-21 16:38:00,142 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 26385/multipartKey3 in Volume/Bucket s3v/bucket-00598
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 2020-12-21 16:40:03,973 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5984,entriesCount=1,lastEntry=(t:1, i:124)
datanode_2  | 2020-12-21 16:40:03,981 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5985,entriesCount=1,lastEntry=(t:1, i:125)
datanode_1  | 2020-12-21 16:43:24,798 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1       |   <Message>The specified bucket is not valid.</Message>
s3g_1       |   <Resource>bucket_1</Resource>
om2_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-00598/26385/multipartKey3105419156353777677
om2_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-12-21 16:40:03,985 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5986,entriesCount=1,lastEntry=(t:1, i:126)
datanode_1  | GC pool 'ParNew' had collection(s): count=2678 time=7788ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:43:26,802 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
s3g_1       |   <RequestId/>
s3g_1       | </Error>
om3_1       | 2020-12-21 16:37:10,715 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om3_1       | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om3_1       | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:119)
datanode_2  | 2020-12-21 16:40:05,645 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=41 time=1156ms
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 
s3g_1       | 2020-12-21 16:37:08,711 [qtp1260634890-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-25902, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-21 16:37:08,737 [qtp1260634890-23] INFO endpoint.BucketEndpoint: Location is /bucket-25902
s3g_1       | 2020-12-21 16:37:09,348 [qtp1260634890-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-07088, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-21 16:37:09,363 [qtp1260634890-23] INFO endpoint.BucketEndpoint: Location is /bucket-07088
s3g_1       | 2020-12-21 16:37:10,724 [qtp1260634890-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchBucket</Code>
s3g_1       |   <Message>The specified bucket does not exist</Message>
s3g_1       |   <Resource>nosuchbucket</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
datanode_1  | GC pool 'ParNew' had collection(s): count=2702 time=7847ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:43:27,804 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=2714 time=7875ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:44:01,824 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ParNew' had collection(s): count=3124 time=8975ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=4 time=175ms
datanode_2  | 2020-12-21 16:40:10,339 [java.util.concurrent.ThreadPoolExecutor$Worker@db81803[State = -1, empty queue]] WARN server.GrpcLogAppender: ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625->f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6237,entriesCount=1,lastEntry=(t:1, i:127)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:00,436 [IPC Server handler 4 on default port 9862] INFO ipc.Server: IPC Server handler 4 on default port 9862, call Call#16 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:38928
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 2020-12-21 16:40:11,652 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_2  | GC pool 'ParNew' had collection(s): count=44 time=1277ms
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=4 time=175ms
datanode_2  | 2020-12-21 16:40:15,171 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 17ms
datanode_2  | GC pool 'ParNew' had collection(s): count=47 time=1338ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=4 time=178ms
datanode_2  | 2020-12-21 16:40:21,192 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 18ms
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1       | 2020-12-21 16:37:20,968 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 71ms
om3_1       | GC pool 'ParNew' had collection(s): count=8 time=399ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=45ms
om3_1       | 2020-12-21 16:37:23,472 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:44:32,839 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=3500 time=9886ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:44:59,850 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1       | 2020-12-21 16:38:00,670 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 26385/multipartKey3 in Volume/Bucket s3v/bucket-00598
om2_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-00598/26385/multipartKey3105419156583481358
s3g_1       | 
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
datanode_2  | GC pool 'ParNew' had collection(s): count=50 time=1465ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=5 time=197ms
datanode_2  | 2020-12-21 16:40:39,200 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
s3g_1       | 2020-12-21 16:37:13,234 [qtp1260634890-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-09803, with Versioning false and Storage Type set to DISK and Encryption set to false 
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
datanode_1  | GC pool 'ParNew' had collection(s): count=3814 time=10779ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:45:21,864 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_1  | GC pool 'ParNew' had collection(s): count=4049 time=11386ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:45:22,866 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=4061 time=11416ms
om2_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om3_1       | GC pool 'ParNew' had collection(s): count=8 time=399ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=48ms
om3_1       | 2020-12-21 16:37:45,985 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | GC pool 'ParNew' had collection(s): count=9 time=421ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=112ms
om3_1       | 2020-12-21 16:37:47,652 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-00598/25914/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
datanode_2  | GC pool 'ParNew' had collection(s): count=60 time=1720ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=5 time=197ms
s3g_1       | 2020-12-21 16:37:13,252 [qtp1260634890-24] INFO endpoint.BucketEndpoint: Location is /bucket-09803
s3g_1       | 2020-12-21 16:37:14,479 [qtp1260634890-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchBucket</Code>
s3g_1       |   <Message>The specified bucket does not exist</Message>
s3g_1       |   <Resource>ozonenosuchbucketqqweqwe</Resource>
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1       | 2020-12-21 16:38:01,179 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-00598/26385/multipartKey3
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_2  | 2020-12-21 16:40:51,739 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_2  | GC pool 'ParNew' had collection(s): count=68 time=2008ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:45:23,868 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | 2020-12-21 16:37:47,653 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 25914/multipartKey2 in Volume/Bucket s3v/bucket-00598
om3_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 25914/multipartKey2. Entity too small.
om3_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:227)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=220ms
datanode_2  | 2020-12-21 16:41:03,751 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
datanode_2  | GC pool 'ParNew' had collection(s): count=74 time=2158ms
datanode_1  | GC pool 'ParNew' had collection(s): count=4072 time=11456ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:46:26,403 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ParNew' had collection(s): count=4816 time=13481ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om2_1       | 2020-12-21 16:38:01,180 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 26385/multipartKey3 in Volume/Bucket s3v/bucket-00598
om2_1       | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3 because parts are in Invalid order.
om2_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-21 16:37:14,479 [qtp1260634890-23] ERROR endpoint.BucketEndpoint: Exception occurred in headBucket
s3g_1       | org.apache.hadoop.ozone.s3.exception.OS3Exception
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:121)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:00,986 [IPC Server handler 1 on default port 9862] INFO ipc.Server: IPC Server handler 1 on default port 9862, call Call#21 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:38934
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=220ms
datanode_2  | 2020-12-21 16:41:10,274 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 20ms
datanode_2  | GC pool 'ParNew' had collection(s): count=78 time=2272ms
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
datanode_1  | 2020-12-21 16:46:27,906 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=4828 time=13558ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=222ms
datanode_2  | 2020-12-21 16:41:13,780 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_2  | GC pool 'ParNew' had collection(s): count=79 time=2288ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=7 time=248ms
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:72)
datanode_1  | 2020-12-21 16:46:30,908 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode_1  | GC pool 'ParNew' had collection(s): count=4864 time=13663ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:46:42,914 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=5010 time=14071ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:46:54,920 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | 2020-12-21 16:41:21,790 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_2  | GC pool 'ParNew' had collection(s): count=85 time=2448ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=7 time=248ms
datanode_2  | 2020-12-21 16:41:43,340 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 42ms
datanode_2  | GC pool 'ParNew' had collection(s): count=99 time=2838ms
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:273)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=8 time=275ms
datanode_2  | 2020-12-21 16:41:47,861 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 19ms
om2_1       | 2020-12-21 16:38:01,746 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | GC pool 'ParNew' had collection(s): count=5148 time=14442ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om2_1       | GC pool 'ParNew' had collection(s): count=10 time=211ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_2  | GC pool 'ParNew' had collection(s): count=102 time=2926ms
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=8 time=275ms
datanode_2  | 2020-12-21 16:41:59,388 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 23ms
datanode_2  | GC pool 'ParNew' had collection(s): count=110 time=3120ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=8 time=275ms
om3_1       | 2020-12-21 16:37:48,793 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-00598/26385/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om3_1       | partName: "etag1"
datanode_1  | 2020-12-21 16:47:10,444 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 16ms
datanode_1  | GC pool 'ParNew' had collection(s): count=5338 time=14918ms
datanode_2  | 2020-12-21 16:42:10,461 [Thread-180] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-42A15712002E->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=118, seq=0, Watch-ALL_COMMITTED(128), Message:<EMPTY>, reply=RaftClientReply:client-42A15712002E->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=118, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 118 and log index 128 is not yet replicated to ALL_COMMITTED, logIndex=128, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c138, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c138]
om1_1       | 2020-12-21 16:37:01,498 [IPC Server handler 6 on default port 9862] INFO ipc.Server: IPC Server handler 6 on default port 9862, call Call#26 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:38940
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
om2_1       | 2020-12-21 16:38:02,248 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
om2_1       | GC pool 'ParNew' had collection(s): count=10 time=211ms
datanode_2  | 2020-12-21 16:42:34,468 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 17ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:47:18,960 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10ms
datanode_1  | GC pool 'ParNew' had collection(s): count=5442 time=15179ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:47:21,462 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=5467 time=15265ms
om3_1       | , partNumber: 2
om3_1       | partName: "etag2"
om3_1       | ]
om3_1       | 2020-12-21 16:37:48,794 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 26385/multipartKey3 in Volume/Bucket s3v/bucket-00598
om3_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om2_1       | 2020-12-21 16:38:04,206 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 07532/multipartKey5 in VolumeName/Bucket s3v/bucket-00598
om2_1       | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-00598key: 07532/multipartKey5
om2_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:131)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
datanode_2  | GC pool 'ParNew' had collection(s): count=134 time=3771ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=338ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:47:44,974 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
datanode_2  | 2020-12-21 16:42:44,995 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22ms
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
datanode_2  | GC pool 'ParNew' had collection(s): count=141 time=4021ms
datanode_1  | GC pool 'ParNew' had collection(s): count=5721 time=15892ms
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=338ms
om3_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:167)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
datanode_2  | 2020-12-21 16:43:06,003 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=155 time=4381ms
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1       | 2020-12-21 16:38:04,726 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-00598, Key36596/multipartKey. Exception:{}
datanode_1  | 2020-12-21 16:47:48,980 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ParNew' had collection(s): count=5766 time=16025ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:47:51,985 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1       | 2020-12-21 16:37:49,341 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-00598/26385/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1       | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:399)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=11 time=355ms
datanode_2  | 2020-12-21 16:43:11,458 [Thread-188] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-F2497CC5F13F->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=122, seq=0, Watch-ALL_COMMITTED(132), Message:<EMPTY>, reply=RaftClientReply:client-F2497CC5F13F->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=122, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 122 and log index 132 is not yet replicated to ALL_COMMITTED, logIndex=132, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c142, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c142]
datanode_1  | GC pool 'ParNew' had collection(s): count=5800 time=16128ms
om3_1       | partName: "etag1"
om1_1       | 2020-12-21 16:37:03,989 [IPC Server handler 4 on default port 9862] INFO ipc.Server: IPC Server handler 4 on default port 9862, call Call#31 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:38954
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om2_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:340)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om3_1       | , partNumber: 1
om3_1       | partName: "etag2"
om3_1       | ]
om3_1       | 2020-12-21 16:37:49,341 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 26385/multipartKey3 in Volume/Bucket s3v/bucket-00598
datanode_2  | 2020-12-21 16:43:27,011 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=169 time=4748ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=12 time=378ms
datanode_2  | 2020-12-21 16:43:39,049 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:47:57,990 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=177 time=4965ms
om2_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:272)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
datanode_1  | GC pool 'ParNew' had collection(s): count=5870 time=16286ms
om3_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:49:15,540 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_1  | GC pool 'ParNew' had collection(s): count=6771 time=18644ms
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om3_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:167)
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:49:35,572 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22ms
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | GC pool 'ParNew' had collection(s): count=7019 time=19257ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=12 time=378ms
datanode_2  | 2020-12-21 16:43:58,581 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 25ms
datanode_2  | GC pool 'ParNew' had collection(s): count=191 time=5357ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=13 time=404ms
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1       | 2020-12-21 16:37:49,992 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om2_1       | 2020-12-21 16:38:24,764 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
om2_1       | GC pool 'ParNew' had collection(s): count=11 time=241ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om2_1       | 2020-12-21 16:38:28,768 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | 2020-12-21 16:50:04,585 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=7360 time=20189ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om3_1       | GC pool 'ParNew' had collection(s): count=9 time=421ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=112ms
datanode_2  | 2020-12-21 16:44:08,586 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
om1_1       | 2020-12-21 16:37:04,622 [IPC Server handler 48 on default port 9862] INFO ipc.Server: IPC Server handler 48 on default port 9862, call Call#34 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:38960
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
datanode_1  | 2020-12-21 16:50:07,588 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=7395 time=20306ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om2_1       | GC pool 'ParNew' had collection(s): count=11 time=241ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om2_1       | 2020-12-21 16:38:34,773 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | 2020-12-21 16:38:00,152 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 26385/multipartKey3 in Volume/Bucket s3v/bucket-00598
om3_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-00598/26385/multipartKey3105419156353777677
om3_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
datanode_2  | GC pool 'ParNew' had collection(s): count=197 time=5502ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=13 time=406ms
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
datanode_1  | 2020-12-21 16:50:16,594 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | GC pool 'ParNew' had collection(s): count=11 time=241ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
datanode_2  | 2020-12-21 16:44:12,458 [Thread-199] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-DFD8958AAED3->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=126, seq=0, Watch-ALL_COMMITTED(136), Message:<EMPTY>, reply=RaftClientReply:client-DFD8958AAED3->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=126, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 126 and log index 136 is not yet replicated to ALL_COMMITTED, logIndex=136, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c150, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c148]
datanode_2  | 2020-12-21 16:44:19,138 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 49ms
datanode_1  | GC pool 'ParNew' had collection(s): count=7506 time=20585ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:50:17,103 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9ms
datanode_1  | GC pool 'ParNew' had collection(s): count=7512 time=20607ms
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
datanode_2  | GC pool 'ParNew' had collection(s): count=205 time=5779ms
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om2_1       | 2020-12-21 16:38:59,283 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=11 time=241ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=14 time=426ms
datanode_2  | 2020-12-21 16:44:57,670 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 18ms
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om2_1       | 2020-12-21 16:39:01,788 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om2_1       | GC pool 'ParNew' had collection(s): count=11 time=241ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_2  | GC pool 'ParNew' had collection(s): count=231 time=6485ms
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
datanode_1  | 2020-12-21 16:50:30,609 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=7680 time=21020ms
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=452ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:51:00,122 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=8027 time=21924ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om3_1       | 2020-12-21 16:38:00,675 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 26385/multipartKey3 in Volume/Bucket s3v/bucket-00598
om3_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-00598/26385/multipartKey3105419156583481358
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om2_1       | 2020-12-21 16:39:19,799 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | GC pool 'ParNew' had collection(s): count=11 time=241ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_2  | 2020-12-21 16:45:15,678 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=241 time=6735ms
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=473ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
om2_1       | 2020-12-21 16:39:24,807 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | GC pool 'ParNew' had collection(s): count=11 time=241ms
datanode_1  | 2020-12-21 16:51:12,128 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=8176 time=22279ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
om3_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om2_1       | 2020-12-21 16:39:28,310 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:05,253 [IPC Server handler 2 on default port 9862] INFO ipc.Server: IPC Server handler 2 on default port 9862, call Call#37 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:38966
datanode_2  | 2020-12-21 16:45:16,458 [Thread-206] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-88D2A0CCDBA5->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=131, seq=0, Watch-ALL_COMMITTED(140), Message:<EMPTY>, reply=RaftClientReply:client-88D2A0CCDBA5->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=131, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 131 and log index 140 is not yet replicated to ALL_COMMITTED, logIndex=140, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c153, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c153]
datanode_2  | 2020-12-21 16:45:19,184 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:51:23,135 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1       | GC pool 'ParNew' had collection(s): count=11 time=241ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
datanode_1  | GC pool 'ParNew' had collection(s): count=8314 time=22612ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om2_1       | 2020-12-21 16:41:41,859 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=12 time=257ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
datanode_1  | 2020-12-21 16:51:23,644 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
datanode_1  | GC pool 'ParNew' had collection(s): count=8320 time=22632ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om3_1       | 2020-12-21 16:38:01,185 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-00598/26385/multipartKey3
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
datanode_2  | GC pool 'ParNew' had collection(s): count=244 time=6794ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=473ms
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om3_1       | 2020-12-21 16:38:01,186 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 26385/multipartKey3 in Volume/Bucket s3v/bucket-00598
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
datanode_1  | 2020-12-21 16:51:38,150 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3 because parts are in Invalid order.
om3_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
datanode_1  | GC pool 'ParNew' had collection(s): count=8500 time=23091ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
datanode_1  | 2020-12-21 16:51:46,156 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | 2020-12-21 16:45:22,188 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ParNew' had collection(s): count=8601 time=23348ms
om2_1       | 2020-12-21 16:44:17,912 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=13 time=284ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om2_1       | 2020-12-21 16:44:24,916 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=13 time=284ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om2_1       | 2020-12-21 16:44:28,421 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 2020-12-21 16:52:04,164 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=8814 time=23899ms
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
datanode_2  | GC pool 'ParNew' had collection(s): count=246 time=6838ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=473ms
datanode_2  | 2020-12-21 16:45:23,190 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=246 time=6838ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=473ms
datanode_2  | 2020-12-21 16:45:23,693 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:52:23,172 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
datanode_2  | GC pool 'ParNew' had collection(s): count=247 time=6868ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=473ms
datanode_2  | 2020-12-21 16:45:29,704 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9ms
om2_1       | GC pool 'ParNew' had collection(s): count=13 time=284ms
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
om3_1       | 2020-12-21 16:38:02,536 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=10 time=456ms
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om2_1       | 2020-12-21 16:47:10,475 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-12-21 16:37:17,052 [qtp1260634890-24] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-65640, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-21 16:37:17,073 [qtp1260634890-24] INFO endpoint.BucketEndpoint: Location is /bucket-65640
s3g_1       | 2020-12-21 16:37:20,191 [qtp1260634890-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-00598, with Versioning false and Storage Type set to DISK and Encryption set to false 
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=126ms
om3_1       | 2020-12-21 16:38:04,208 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 07532/multipartKey5 in VolumeName/Bucket s3v/bucket-00598
om3_1       | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-00598key: 07532/multipartKey5
om3_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:131)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om2_1       | GC pool 'ParNew' had collection(s): count=14 time=304ms
datanode_2  | GC pool 'ParNew' had collection(s): count=251 time=6967ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=475ms
datanode_2  | 2020-12-21 16:45:35,717 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10ms
datanode_2  | GC pool 'ParNew' had collection(s): count=255 time=7055ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=17 time=497ms
datanode_1  | GC pool 'ParNew' had collection(s): count=9045 time=24466ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:52:24,177 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_1  | GC pool 'ParNew' had collection(s): count=9056 time=24492ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:52:41,186 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=9259 time=25021ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:52:51,192 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=9379 time=25314ms
datanode_2  | 2020-12-21 16:45:41,736 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 16ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om2_1       | 2020-12-21 16:47:25,984 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ParNew' had collection(s): count=259 time=7128ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=17 time=497ms
om2_1       | GC pool 'ParNew' had collection(s): count=14 time=304ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 2020-12-21 16:37:20,209 [qtp1260634890-23] INFO endpoint.BucketEndpoint: Location is /bucket-00598
s3g_1       | 2020-12-21 16:37:23,298 [qtp1260634890-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-AC22B1778BA4->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:37:23,298 [qtp1260634890-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
datanode_2  | 2020-12-21 16:45:43,240 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=260 time=7171ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=17 time=497ms
datanode_2  | 2020-12-21 16:46:00,751 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_2  | GC pool 'ParNew' had collection(s): count=272 time=7515ms
om1_1       | 2020-12-21 16:37:05,316 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-40714 in volume:s3v
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 2020-12-21 16:52:09,072 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:52:59,198 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ParNew' had collection(s): count=9475 time=25540ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:53:21,207 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=9742 time=26274ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:53:30,716 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_1  | GC pool 'ParNew' had collection(s): count=9858 time=26568ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:53:56,726 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=10167 time=27373ms
om2_1       | GC pool 'ParNew' had collection(s): count=16 time=345ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om1_1       | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1       | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 2020-12-21 16:53:44,101 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=16 time=345ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=87ms
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:54:06,232 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=10284 time=27659ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:54:19,238 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 2020-12-21 16:37:27,482 [qtp1260634890-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-EF26E9632728->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:37:27,483 [qtp1260634890-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:37:31,818 [qtp1260634890-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-198B1C778440->ec956fef-022a-4e11-a406-1dfa86e0929f
datanode_1  | GC pool 'ParNew' had collection(s): count=10430 time=28094ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:54:58,759 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 2020-12-21 16:37:31,819 [qtp1260634890-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:37:35,357 [qtp1260634890-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-4F19902B4C2E->ec956fef-022a-4e11-a406-1dfa86e0929f
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=18 time=522ms
datanode_2  | 2020-12-21 16:46:19,800 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 16ms
datanode_2  | GC pool 'ParNew' had collection(s): count=285 time=7798ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=18 time=522ms
s3g_1       | 2020-12-21 16:37:35,357 [qtp1260634890-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:37:41,294 [qtp1260634890-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-6A0DFA664FBE->ec956fef-022a-4e11-a406-1dfa86e0929f
datanode_2  | 2020-12-21 16:46:20,459 [Thread-213] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-2DD7D732AEF1->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=136, seq=0, Watch-ALL_COMMITTED(144), Message:<EMPTY>, reply=RaftClientReply:client-2DD7D732AEF1->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=136, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 136 and log index 144 is not yet replicated to ALL_COMMITTED, logIndex=144, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c157, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c157]
datanode_2  | 2020-12-21 16:46:28,312 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9ms
datanode_2  | GC pool 'ParNew' had collection(s): count=290 time=7893ms
datanode_1  | GC pool 'ParNew' had collection(s): count=10899 time=29379ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:55:28,770 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=18 time=558ms
datanode_2  | 2020-12-21 16:46:46,320 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 2020-12-21 16:37:05,897 [IPC Server handler 1 on default port 9862] INFO ipc.Server: IPC Server handler 1 on default port 9862, call Call#40 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:38972
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
datanode_1  | GC pool 'ParNew' had collection(s): count=11255 time=30343ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_2  | GC pool 'ParNew' had collection(s): count=302 time=8208ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=19 time=558ms
datanode_2  | 2020-12-21 16:47:08,852 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26ms
datanode_2  | GC pool 'ParNew' had collection(s): count=318 time=8660ms
datanode_1  | 2020-12-21 16:55:29,272 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=20 time=584ms
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1       | 2020-12-21 16:38:04,731 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-00598, Key36596/multipartKey. Exception:{}
om3_1       | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
datanode_1  | GC pool 'ParNew' had collection(s): count=11261 time=30356ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om3_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:399)
om3_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:340)
datanode_2  | 2020-12-21 16:47:10,459 [Thread-217] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-33C5BFEEFE28->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=140, seq=0, Watch-ALL_COMMITTED(148), Message:<EMPTY>, reply=RaftClientReply:client-33C5BFEEFE28->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=140, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 140 and log index 148 is not yet replicated to ALL_COMMITTED, logIndex=148, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c157, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c157]
datanode_2  | 2020-12-21 16:47:15,856 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 2020-12-21 16:37:41,294 [qtp1260634890-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:37:44,459 [qtp1260634890-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-837FE27C0F99->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:37:44,460 [qtp1260634890-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
datanode_1  | 2020-12-21 16:55:32,779 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_1  | GC pool 'ParNew' had collection(s): count=11302 time=30446ms
om3_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:272)
datanode_2  | GC pool 'ParNew' had collection(s): count=322 time=8730ms
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=20 time=584ms
datanode_2  | 2020-12-21 16:47:18,861 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_2  | GC pool 'ParNew' had collection(s): count=325 time=8787ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=20 time=586ms
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
datanode_1  | 2020-12-21 16:55:37,783 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=11364 time=30593ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
s3g_1       | 2020-12-21 16:37:47,653 [qtp1260634890-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-00598, , key: 25914/multipartKey2
s3g_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 25914/multipartKey2. Entity too small.
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:602)
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:947)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:955)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:635)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:521)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-12-21 16:47:31,883 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 17ms
datanode_2  | GC pool 'ParNew' had collection(s): count=332 time=8923ms
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
datanode_1  | 2020-12-21 16:55:42,286 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=21 time=608ms
datanode_2  | 2020-12-21 16:48:11,496 [Thread-224] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-0F8C35282A1F->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=145, seq=0, Watch-ALL_COMMITTED(152), Message:<EMPTY>, reply=RaftClientReply:client-0F8C35282A1F->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=145, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 145 and log index 152 is not yet replicated to ALL_COMMITTED, logIndex=152, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c161, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c161]
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
om3_1       | 2020-12-21 16:38:12,541 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=10 time=456ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=126ms
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
datanode_1  | GC pool 'ParNew' had collection(s): count=11420 time=30709ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
datanode_1  | 2020-12-21 16:55:50,792 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=11518 time=31012ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:56:08,803 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=11742 time=31528ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:56:27,811 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=11965 time=32118ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:57:01,332 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ParNew' had collection(s): count=12378 time=33170ms
datanode_2  | 2020-12-21 16:48:18,407 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10ms
datanode_2  | GC pool 'ParNew' had collection(s): count=363 time=9736ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=22 time=664ms
om3_1       | 2020-12-21 16:38:22,547 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=10 time=456ms
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=126ms
om3_1       | 2020-12-21 16:38:54,563 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=11 time=482ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=126ms
om3_1       | 2020-12-21 16:38:56,066 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | GC pool 'ParNew' had collection(s): count=12 time=522ms
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=138ms
om3_1       | 2020-12-21 16:39:11,073 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=13 time=532ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=4 time=186ms
om3_1       | 2020-12-21 16:39:27,586 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
om3_1       | GC pool 'ParNew' had collection(s): count=13 time=532ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=4 time=186ms
om3_1       | 2020-12-21 16:41:17,630 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=15 time=593ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=230ms
om3_1       | 2020-12-21 16:41:31,637 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | GC pool 'ParNew' had collection(s): count=15 time=593ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=230ms
om3_1       | 2020-12-21 16:42:15,653 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=16 time=621ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=7 time=246ms
om3_1       | 2020-12-21 16:44:15,701 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om3_1       | GC pool 'ParNew' had collection(s): count=18 time=688ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=9 time=293ms
om3_1       | 2020-12-21 16:45:21,242 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 18ms
om3_1       | GC pool 'ParNew' had collection(s): count=20 time=744ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=312ms
om3_1       | 2020-12-21 16:54:29,918 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | GC pool 'ParNew' had collection(s): count=30 time=1041ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=21 time=615ms
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
datanode_2  | 2020-12-21 16:48:31,935 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 23ms
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_2  | GC pool 'ParNew' had collection(s): count=373 time=9918ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=23 time=664ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:57:39,348 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
datanode_2  | 2020-12-21 16:49:09,974 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=399 time=10566ms
datanode_1  | GC pool 'ParNew' had collection(s): count=12841 time=34354ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=24 time=694ms
datanode_2  | 2020-12-21 16:49:12,458 [Thread-231] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-5D16EA935D05->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=150, seq=0, Watch-ALL_COMMITTED(155), Message:<EMPTY>, reply=RaftClientReply:client-5D16EA935D05->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=150, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 150 and log index 155 is not yet replicated to ALL_COMMITTED, logIndex=155, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c165, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c165]
datanode_1  | 2020-12-21 16:57:40,850 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_2  | 2020-12-21 16:49:42,490 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
datanode_2  | GC pool 'ParNew' had collection(s): count=420 time=11108ms
datanode_1  | GC pool 'ParNew' had collection(s): count=12860 time=34394ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:57:55,361 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=26 time=754ms
datanode_2  | 2020-12-21 16:50:16,458 [Thread-241] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-44CD1D613A44->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=156, seq=0, Watch-ALL_COMMITTED(159), Message:<EMPTY>, reply=RaftClientReply:client-44CD1D613A44->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=156, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 156 and log index 159 is not yet replicated to ALL_COMMITTED, logIndex=159, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c173, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c172]
datanode_1  | GC pool 'ParNew' had collection(s): count=13037 time=34831ms
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:08,690 [IPC Server handler 75 on default port 9862] INFO ipc.Server: IPC Server handler 75 on default port 9862, call Call#42 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:38978
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
datanode_2  | 2020-12-21 16:50:33,533 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:09,334 [IPC Server handler 3 on default port 9862] INFO ipc.Server: IPC Server handler 3 on default port 9862, call Call#45 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:38984
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
datanode_2  | GC pool 'ParNew' had collection(s): count=455 time=11846ms
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
datanode_1  | 2020-12-21 16:57:56,871 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9ms
datanode_1  | GC pool 'ParNew' had collection(s): count=13052 time=34904ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=28 time=794ms
datanode_1  | 2020-12-21 16:58:07,380 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
datanode_2  | 2020-12-21 16:51:04,053 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11ms
datanode_2  | GC pool 'ParNew' had collection(s): count=476 time=12360ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=29 time=822ms
datanode_2  | 2020-12-21 16:51:11,062 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_2  | GC pool 'ParNew' had collection(s): count=481 time=12494ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=29 time=822ms
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
datanode_1  | GC pool 'ParNew' had collection(s): count=13181 time=35270ms
datanode_2  | 2020-12-21 16:51:22,458 [Thread-248] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-6ED22C92C1E6->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=161, seq=0, Watch-ALL_COMMITTED(164), Message:<EMPTY>, reply=RaftClientReply:client-6ED22C92C1E6->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=161, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 161 and log index 164 is not yet replicated to ALL_COMMITTED, logIndex=164, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c177, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c177]
datanode_2  | 2020-12-21 16:52:08,098 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 19ms
datanode_2  | GC pool 'ParNew' had collection(s): count=521 time=13439ms
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
datanode_1  | 2020-12-21 16:58:27,388 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:09,945 [IPC Server handler 4 on default port 9862] INFO ipc.Server: IPC Server handler 4 on default port 9862, call Call#48 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:38998
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=31 time=864ms
datanode_2  | 2020-12-21 16:52:13,604 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ParNew' had collection(s): count=524 time=13507ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=31 time=886ms
datanode_2  | 2020-12-21 16:52:14,458 [Thread-252] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-ED8EE6345E1A->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=166, seq=0, Watch-ALL_COMMITTED(168), Message:<EMPTY>, reply=RaftClientReply:client-ED8EE6345E1A->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=166, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 166 and log index 168 is not yet replicated to ALL_COMMITTED, logIndex=168, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c177, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c177]
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
datanode_1  | GC pool 'ParNew' had collection(s): count=13415 time=35916ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_2  | 2020-12-21 16:52:17,131 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 24ms
datanode_1  | 2020-12-21 16:58:38,393 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=527 time=13574ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=32 time=886ms
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
datanode_1  | GC pool 'ParNew' had collection(s): count=13553 time=36242ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:58:42,398 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ParNew' had collection(s): count=13601 time=36375ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:58:52,403 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=13688 time=36608ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:59:16,413 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=13976 time=37290ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:59:17,297 [grpc-default-executor-10] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 191 .Container 1 bcsId is 124. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 191 .Container 1 bcsId is 124.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:196)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:483)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:189)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:163)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:309)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.lambda$dispatch$0(HddsDispatcher.java:171)
datanode_1  | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:170)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:783)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-12-21 16:59:17,899 [grpc-default-executor-10] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 191 .Container 1 bcsId is 124. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 191 .Container 1 bcsId is 124.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:196)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:483)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:189)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:163)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:309)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.lambda$dispatch$0(HddsDispatcher.java:171)
datanode_1  | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:170)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_2  | 2020-12-21 16:52:37,148 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12ms
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-12-21 16:37:47,660 [qtp1260634890-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>EntityTooSmall</Code>
datanode_2  | GC pool 'ParNew' had collection(s): count=541 time=13945ms
s3g_1       |   <Message>Your proposed upload is smaller than the minimum allowed object size. Each part must be at least 5 MB in size, except the last part.</Message>
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=32 time=886ms
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:10,628 [IPC Server handler 51 on default port 9862] INFO ipc.Server: IPC Server handler 51 on default port 9862, call Call#51 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39004
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
datanode_2  | 2020-12-21 16:53:15,458 [Thread-259] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-4C5AD094988F->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=170, seq=0, Watch-ALL_COMMITTED(172), Message:<EMPTY>, reply=RaftClientReply:client-4C5AD094988F->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=170, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 170 and log index 172 is not yet replicated to ALL_COMMITTED, logIndex=172, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c180, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c180]
s3g_1       |   <Resource>25914/multipartKey2</Resource>
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:783)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-12-21 16:59:17,917 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ParNew' had collection(s): count=13988 time=37340ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_2  | 2020-12-21 16:53:41,197 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_1  | 2020-12-21 16:59:18,650 [grpc-default-executor-9] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 191 .Container 1 bcsId is 124. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-21 16:37:48,791 [qtp1260634890-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-00598, , key: 26385/multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode_2  | GC pool 'ParNew' had collection(s): count=585 time=14931ms
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:602)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=35 time=972ms
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 191 .Container 1 bcsId is 124.
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:947)
datanode_2  | 2020-12-21 16:54:10,221 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 15ms
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:955)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:635)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:521)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:10,714 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om1_1       | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:196)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:483)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:189)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:163)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:309)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.lambda$dispatch$0(HddsDispatcher.java:171)
datanode_2  | GC pool 'ParNew' had collection(s): count=605 time=15411ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=36 time=998ms
datanode_2  | 2020-12-21 16:54:16,458 [Thread-266] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-08F3F1B8245B->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=175, seq=0, Watch-ALL_COMMITTED(175), Message:<EMPTY>, reply=RaftClientReply:client-08F3F1B8245B->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=175, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 175 and log index 175 is not yet replicated to ALL_COMMITTED, logIndex=175, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c184, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c184]
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
datanode_1  | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode_2  | 2020-12-21 16:55:17,458 [Thread-275] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-73902BF185B8->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=181, seq=0, Watch-ALL_COMMITTED(179), Message:<EMPTY>, reply=RaftClientReply:client-73902BF185B8->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=181, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 181 and log index 179 is not yet replicated to ALL_COMMITTED, logIndex=179, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c189, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c188]
datanode_2  | 2020-12-21 16:55:45,292 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:170)
om1_1       | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:119)
datanode_2  | GC pool 'ParNew' had collection(s): count=669 time=17067ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=39 time=1072ms
datanode_2  | 2020-12-21 16:56:22,458 [Thread-283] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-D15112C60807->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=186, seq=0, Watch-ALL_COMMITTED(182), Message:<EMPTY>, reply=RaftClientReply:client-D15112C60807->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=186, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 186 and log index 182 is not yet replicated to ALL_COMMITTED, logIndex=182, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c196, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c196]
datanode_2  | 2020-12-21 16:56:37,845 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 17ms
datanode_2  | GC pool 'ParNew' had collection(s): count=706 time=17933ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=41 time=1115ms
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
datanode_2  | 2020-12-21 16:56:40,349 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ParNew' had collection(s): count=707 time=17956ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=41 time=1138ms
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-21 16:37:13,214 [IPC Server handler 2 on default port 9862] INFO ipc.Server: IPC Server handler 2 on default port 9862, call Call#54 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39010
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:13,866 [IPC Server handler 1 on default port 9862] INFO ipc.Server: IPC Server handler 1 on default port 9862, call Call#57 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39016
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:783)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-12-21 16:59:19,808 [grpc-default-executor-10] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 195 .Container 1 bcsId is 124. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 195 .Container 1 bcsId is 124.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:196)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
datanode_2  | 2020-12-21 16:57:02,360 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_2  | GC pool 'ParNew' had collection(s): count=723 time=18304ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=42 time=1138ms
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:483)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:189)
datanode_2  | 2020-12-21 16:57:06,897 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 35ms
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:14,458 [IPC Server handler 6 on default port 9862] INFO ipc.Server: IPC Server handler 6 on default port 9862, call Call#60 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39022
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:163)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:309)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.lambda$dispatch$0(HddsDispatcher.java:171)
datanode_1  | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:170)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_2  | GC pool 'ParNew' had collection(s): count=726 time=18393ms
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=43 time=1156ms
datanode_2  | 2020-12-21 16:57:15,410 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10ms
datanode_2  | GC pool 'ParNew' had collection(s): count=732 time=18524ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=43 time=1156ms
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:783)
datanode_2  | 2020-12-21 16:57:17,458 [Thread-287] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-A692380149DC->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=191, seq=0, Watch-ALL_COMMITTED(187), Message:<EMPTY>, reply=RaftClientReply:client-A692380149DC->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=191, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 191 and log index 187 is not yet replicated to ALL_COMMITTED, logIndex=187, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c196, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c196]
datanode_2  | 2020-12-21 16:57:23,931 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 18ms
datanode_2  | GC pool 'ParNew' had collection(s): count=738 time=18657ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=43 time=1156ms
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-12-21 16:59:20,417 [grpc-default-executor-10] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 195 .Container 1 bcsId is 124. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 195 .Container 1 bcsId is 124.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:196)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:483)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:189)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:163)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:309)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.lambda$dispatch$0(HddsDispatcher.java:171)
datanode_1  | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:170)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
datanode_2  | 2020-12-21 16:58:18,458 [Thread-294] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-DBC973DD955D->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=196, seq=0, Watch-ALL_COMMITTED(191), Message:<EMPTY>, reply=RaftClientReply:client-DBC973DD955D->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=196, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 196 and log index 191 is not yet replicated to ALL_COMMITTED, logIndex=191, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c200, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c200]
datanode_2  | 2020-12-21 16:58:37,957 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_2  | GC pool 'ParNew' had collection(s): count=789 time=19894ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=46 time=1224ms
datanode_2  | 2020-12-21 16:59:10,468 [org.apache.ratis.server.JvmPauseMonitor@54aa804c-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode_2  | GC pool 'ParNew' had collection(s): count=809 time=20451ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=47 time=1248ms
datanode_2  | 2020-12-21 16:59:19,458 [Thread-301] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-97263838EA24->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=200, seq=0, Watch-ALL_COMMITTED(195), Message:<EMPTY>, reply=RaftClientReply:client-97263838EA24->ec956fef-022a-4e11-a406-1dfa86e0929f@group-A46A69316625, cid=200, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 200 and log index 195 is not yet replicated to ALL_COMMITTED, logIndex=195, commits[ec956fef-022a-4e11-a406-1dfa86e0929f:c204, f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2:c127, d59b5746-4c38-43fa-95c4-93039b647722:c204]
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:783)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-12-21 16:37:48,794 [qtp1260634890-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | <Error>
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       |   <Code>InvalidPart</Code>
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:17,025 [IPC Server handler 2 on default port 9862] INFO ipc.Server: IPC Server handler 2 on default port 9862, call Call#63 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39036
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
datanode_1  | 2020-12-21 16:59:23,339 [grpc-default-executor-10] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 195 .Container 1 bcsId is 124. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 195 .Container 1 bcsId is 124.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1       |   <Resource>26385/multipartKey3</Resource>
s3g_1       |   <RequestId/>
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:196)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:483)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | </Error>
s3g_1       | 
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:17,672 [IPC Server handler 56 on default port 9862] INFO ipc.Server: IPC Server handler 56 on default port 9862, call Call#66 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39042
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:189)
s3g_1       | 2020-12-21 16:37:49,344 [qtp1260634890-23] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-00598, , key: 26385/multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:163)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:309)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.lambda$dispatch$0(HddsDispatcher.java:171)
datanode_1  | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:602)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:170)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:947)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:955)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:635)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:521)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:783)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-12-21 16:59:24,440 [grpc-default-executor-10] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 195 .Container 1 bcsId is 124. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_1  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 195 .Container 1 bcsId is 124.
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:196)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
om1_1       | 2020-12-21 16:37:20,171 [IPC Server handler 3 on default port 9862] INFO ipc.Server: IPC Server handler 3 on default port 9862, call Call#70 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39048
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:483)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:189)
datanode_1  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:163)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:309)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.lambda$dispatch$0(HddsDispatcher.java:171)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
datanode_1  | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:170)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:20,802 [IPC Server handler 1 on default port 9862] INFO ipc.Server: IPC Server handler 1 on default port 9862, call Call#73 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39054
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_1  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:783)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | 2020-12-21 16:59:27,921 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=14038 time=37597ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:59:29,423 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=14050 time=37669ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
datanode_1  | 2020-12-21 16:59:29,928 [org.apache.ratis.server.JvmPauseMonitor@451ddfc0-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ParNew' had collection(s): count=14053 time=37715ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=101ms
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-12-21 16:37:49,346 [qtp1260634890-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidPart</Code>
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1       |   <Resource>26385/multipartKey3</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-21 16:37:50,053 [qtp1260634890-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-131F1198448A->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:37:50,053 [qtp1260634890-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:37:53,521 [qtp1260634890-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0BE888DF76D9->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:37:53,521 [qtp1260634890-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:21,076 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | GC pool 'ParNew' had collection(s): count=8 time=240ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=113ms
om1_1       | 2020-12-21 16:37:22,083 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
om1_1       | GC pool 'ParNew' had collection(s): count=8 time=240ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=113ms
om1_1       | 2020-12-21 16:37:22,308 [IPC Server handler 6 on default port 9862] INFO ipc.Server: IPC Server handler 6 on default port 9862, call Call#77 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39068
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:22,997 [IPC Server handler 2 on default port 9862] INFO ipc.Server: IPC Server handler 2 on default port 9862, call Call#81 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39074
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:27,345 [IPC Server handler 19 on default port 9862] INFO ipc.Server: IPC Server handler 19 on default port 9862, call Call#87 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39100
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 2020-12-21 16:37:56,892 [qtp1260634890-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-F625EECC145C->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:37:56,892 [qtp1260634890-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:38:00,144 [qtp1260634890-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-00598, , key: 26385/multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-00598/26385/multipartKey3105419156353777677
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:602)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:947)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:955)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:635)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:521)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:31,048 [IPC Server handler 3 on default port 9862] INFO ipc.Server: IPC Server handler 3 on default port 9862, call Call#93 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39116
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:31,095 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
om1_1       | GC pool 'ParNew' had collection(s): count=9 time=282ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=114ms
om1_1       | 2020-12-21 16:37:31,699 [IPC Server handler 75 on default port 9862] INFO ipc.Server: IPC Server handler 75 on default port 9862, call Call#97 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39122
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:35,279 [IPC Server handler 6 on default port 9862] INFO ipc.Server: IPC Server handler 6 on default port 9862, call Call#103 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39138
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:38,552 [IPC Server handler 27 on default port 9862] INFO ipc.Server: IPC Server handler 27 on default port 9862, call Call#109 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39146
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-12-21 16:38:00,145 [qtp1260634890-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidPart</Code>
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1       |   <Resource>26385/multipartKey3</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-21 16:38:00,690 [qtp1260634890-24] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-00598, , key: 26385/multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-00598/26385/multipartKey3105419156583481358
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:602)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:947)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:955)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:635)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:521)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-12-21 16:38:00,692 [qtp1260634890-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidPart</Code>
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1       |   <Resource>26385/multipartKey3</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-21 16:38:01,183 [qtp1260634890-23] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-00598, , key: 26385/multipartKey3
s3g_1       | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3 because parts are in Invalid order.
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:602)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:947)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:955)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:635)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:521)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:39,259 [IPC Server handler 6 on default port 9862] INFO ipc.Server: IPC Server handler 6 on default port 9862, call Call#113 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39152
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:40,660 [IPC Server handler 56 on default port 9862] INFO ipc.Server: IPC Server handler 56 on default port 9862, call Call#118 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39172
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:41,236 [IPC Server handler 6 on default port 9862] INFO ipc.Server: IPC Server handler 6 on default port 9862, call Call#122 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39178
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:44,413 [IPC Server handler 16 on default port 9862] INFO ipc.Server: IPC Server handler 16 on default port 9862, call Call#128 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39186
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-12-21 16:38:01,189 [qtp1260634890-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidPartOrder</Code>
s3g_1       |   <Message>The list of parts was not in ascending order. The parts list must be specified in order by part number.</Message>
s3g_1       |   <Resource>26385/multipartKey3</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-21 16:38:04,215 [qtp1260634890-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchUpload</Code>
s3g_1       |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1       |   <Resource>random</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-21 16:38:04,732 [qtp1260634890-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchUpload</Code>
s3g_1       |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1       |   <Resource>random</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-21 16:38:05,970 [qtp1260634890-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-7F265452F718->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:38:05,971 [qtp1260634890-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:38:09,381 [qtp1260634890-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-C5B919CC31D6->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:38:09,381 [qtp1260634890-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:38:15,545 [qtp1260634890-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-FDA02FE60C0A->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:38:15,545 [qtp1260634890-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | Dec 21, 2020 4:38:15 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=55, target=172.23.0.5:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:47,617 [IPC Server handler 41 on default port 9862] INFO ipc.Server: IPC Server handler 41 on default port 9862, call Call#134 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39204
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:47,651 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-00598/25914/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om1_1       | 2020-12-21 16:37:47,651 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 25914/multipartKey2 in Volume/Bucket s3v/bucket-00598
om1_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 25914/multipartKey2. Entity too small.
om1_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:227)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-21 16:37:48,169 [IPC Server handler 6 on default port 9862] INFO ipc.Server: IPC Server handler 6 on default port 9862, call Call#138 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39210
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:48,761 [IPC Server handler 77 on default port 9862] INFO ipc.Server: IPC Server handler 77 on default port 9862, call Call#142 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39216
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:543)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.checkOpen(XceiverClientGrpc.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:462)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:371)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.lambda$sendCommandWithTraceIDAndRetry$0(XceiverClientGrpc.java:311)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInSpan(TracingUtil.java:174)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:148)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:305)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:286)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:106)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:206)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Dec 21, 2020 4:38:15 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=53, target=172.23.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:142)
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:48,806 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-00598/26385/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om1_1       | partName: "etag1"
om1_1       | , partNumber: 2
om1_1       | partName: "etag2"
om1_1       | ]
om1_1       | 2020-12-21 16:37:48,807 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 26385/multipartKey3 in Volume/Bucket s3v/bucket-00598
om1_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3
om1_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:167)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-21 16:37:49,301 [IPC Server handler 19 on default port 9862] INFO ipc.Server: IPC Server handler 19 on default port 9862, call Call#146 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39222
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:49,356 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-00598/26385/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1       | partName: "etag1"
om1_1       | , partNumber: 1
om1_1       | partName: "etag2"
om1_1       | ]
om1_1       | 2020-12-21 16:37:49,370 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 26385/multipartKey3 in Volume/Bucket s3v/bucket-00598
om1_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:240)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4876)
s3g_1       | 	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
s3g_1       | 	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4871)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:170)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:159)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.acquireClient(BlockInputStream.java:220)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:194)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
om1_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:167)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-21 16:37:49,938 [IPC Server handler 4 on default port 9862] INFO ipc.Server: IPC Server handler 4 on default port 9862, call Call#150 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39228
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:53,439 [IPC Server handler 7 on default port 9862] INFO ipc.Server: IPC Server handler 7 on default port 9862, call Call#156 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39246
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:37:56,852 [IPC Server handler 4 on default port 9862] INFO ipc.Server: IPC Server handler 4 on default port 9862, call Call#162 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39258
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:00,118 [IPC Server handler 6 on default port 9862] INFO ipc.Server: IPC Server handler 6 on default port 9862, call Call#168 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39274
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | 2020-12-21 16:38:15,678 [qtp1260634890-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-93522E65A15B->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:38:15,678 [qtp1260634890-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:38:15,707 [qtp1260634890-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0E728572D72F->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:38:15,717 [qtp1260634890-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:38:22,074 [qtp1260634890-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-34BC8DDF3CE4->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:38:22,074 [qtp1260634890-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:38:26,085 [qtp1260634890-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-F53D0BA25078->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:38:26,086 [qtp1260634890-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:38:30,746 [qtp1260634890-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-15354D3808BB->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:38:30,746 [qtp1260634890-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | Dec 21, 2020 4:38:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=109, target=172.23.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:142)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:240)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4876)
s3g_1       | 	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
s3g_1       | 	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4871)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:170)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:159)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.acquireClient(BlockInputStream.java:220)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:194)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Dec 21, 2020 4:38:30 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=101, target=172.23.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:142)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:240)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4876)
s3g_1       | 	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
s3g_1       | 	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4871)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:00,164 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 26385/multipartKey3 in Volume/Bucket s3v/bucket-00598
om1_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-00598/26385/multipartKey3105419156353777677
om1_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-21 16:38:00,645 [IPC Server handler 53 on default port 9862] INFO ipc.Server: IPC Server handler 53 on default port 9862, call Call#172 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39280
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:00,682 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 26385/multipartKey3 in Volume/Bucket s3v/bucket-00598
om1_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-00598/26385/multipartKey3105419156583481358
om1_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-21 16:38:01,158 [IPC Server handler 19 on default port 9862] INFO ipc.Server: IPC Server handler 19 on default port 9862, call Call#176 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39286
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:01,183 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-00598/26385/multipartKey3
om1_1       | 2020-12-21 16:38:01,187 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 26385/multipartKey3 in Volume/Bucket s3v/bucket-00598
om1_1       | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-00598 key: 26385/multipartKey3 because parts are in Invalid order.
om1_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-21 16:38:01,686 [IPC Server handler 75 on default port 9862] INFO ipc.Server: IPC Server handler 75 on default port 9862, call Call#180 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39292
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:02,296 [IPC Server handler 16 on default port 9862] INFO ipc.Server: IPC Server handler 16 on default port 9862, call Call#184 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39298
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:03,017 [IPC Server handler 3 on default port 9862] INFO ipc.Server: IPC Server handler 3 on default port 9862, call Call#189 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39310
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:170)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:159)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.acquireClient(BlockInputStream.java:220)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:03,577 [IPC Server handler 31 on default port 9862] INFO ipc.Server: IPC Server handler 31 on default port 9862, call Call#193 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39316
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:194)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:606)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:156)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:04,182 [IPC Server handler 16 on default port 9862] INFO ipc.Server: IPC Server handler 16 on default port 9862, call Call#197 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39330
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:04,209 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 07532/multipartKey5 in VolumeName/Bucket s3v/bucket-00598
om1_1       | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-00598key: 07532/multipartKey5
om1_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:131)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-21 16:38:04,704 [IPC Server handler 91 on default port 9862] INFO ipc.Server: IPC Server handler 91 on default port 9862, call Call#201 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39336
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:04,729 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-00598, Key36596/multipartKey. Exception:{}
om1_1       | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om1_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:399)
om1_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:340)
om1_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:272)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-21 16:38:05,228 [IPC Server handler 7 on default port 9862] INFO ipc.Server: IPC Server handler 7 on default port 9862, call Call#205 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39342
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:05,868 [IPC Server handler 2 on default port 9862] INFO ipc.Server: IPC Server handler 2 on default port 9862, call Call#209 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39348
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:09,324 [IPC Server handler 11 on default port 9862] INFO ipc.Server: IPC Server handler 11 on default port 9862, call Call#215 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39356
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:12,552 [IPC Server handler 27 on default port 9862] INFO ipc.Server: IPC Server handler 27 on default port 9862, call Call#221 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39372
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | 2020-12-21 16:38:34,849 [qtp1260634890-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-92AD63C9358E->ec956fef-022a-4e11-a406-1dfa86e0929f
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:12,622 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=10 time=318ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=135ms
om1_1       | 2020-12-21 16:38:13,225 [IPC Server handler 7 on default port 9862] INFO ipc.Server: IPC Server handler 7 on default port 9862, call Call#225 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39378
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:13,820 [IPC Server handler 4 on default port 9862] INFO ipc.Server: IPC Server handler 4 on default port 9862, call Call#229 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39384
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:14,356 [IPC Server handler 13 on default port 9862] INFO ipc.Server: IPC Server handler 13 on default port 9862, call Call#233 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39390
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1       | 2020-12-21 16:38:34,849 [qtp1260634890-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:38:38,494 [qtp1260634890-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-F8D18BE8FD44->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:38:38,494 [qtp1260634890-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:38:46,565 [qtp1260634890-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-21295, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-21 16:38:46,583 [qtp1260634890-21] INFO endpoint.BucketEndpoint: Location is /bucket-21295
s3g_1       | 2020-12-21 16:38:47,185 [qtp1260634890-21] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-32919, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-21 16:38:47,195 [qtp1260634890-21] INFO endpoint.BucketEndpoint: Location is /destbucket-32919
s3g_1       | 2020-12-21 16:38:47,830 [qtp1260634890-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-5286C87019E9->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:38:47,830 [qtp1260634890-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | Dec 21, 2020 4:38:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=125, target=172.23.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:142)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:240)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4876)
s3g_1       | 	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
s3g_1       | 	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4871)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:170)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:159)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.acquireClient(BlockInputStream.java:220)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:194)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:15,198 [IPC Server handler 7 on default port 9862] INFO ipc.Server: IPC Server handler 7 on default port 9862, call Call#237 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39396
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:602)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:156)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om1_1       | 2020-12-21 16:38:15,329 [IPC Server handler 13 on default port 9862] INFO ipc.Server: IPC Server handler 13 on default port 9862, call Call#241 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39404
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:15,330 [IPC Server handler 12 on default port 9862] INFO ipc.Server: IPC Server handler 12 on default port 9862, call Call#242 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39406
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:15,345 [IPC Server handler 5 on default port 9862] INFO ipc.Server: IPC Server handler 5 on default port 9862, call Call#243 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39408
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:19,152 [IPC Server handler 19 on default port 9862] INFO ipc.Server: IPC Server handler 19 on default port 9862, call Call#259 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39430
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Dec 21, 2020 4:38:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=135, target=172.23.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:543)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.checkOpen(XceiverClientGrpc.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:462)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:371)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.lambda$sendCommandWithTraceIDAndRetry$0(XceiverClientGrpc.java:311)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInSpan(TracingUtil.java:174)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:148)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:305)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:286)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:106)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:206)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:19,694 [IPC Server handler 91 on default port 9862] INFO ipc.Server: IPC Server handler 91 on default port 9862, call Call#263 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39436
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:19,854 [IPC Server handler 2 on default port 9862] INFO ipc.Server: IPC Server handler 2 on default port 9862, call Call#267 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39448
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:19,857 [IPC Server handler 3 on default port 9862] INFO ipc.Server: IPC Server handler 3 on default port 9862, call Call#268 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39450
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:19,885 [IPC Server handler 6 on default port 9862] INFO ipc.Server: IPC Server handler 6 on default port 9862, call Call#269 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39454
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:21,030 [IPC Server handler 19 on default port 9862] INFO ipc.Server: IPC Server handler 19 on default port 9862, call Call#282 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39468
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Dec 21, 2020 4:38:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=133, target=172.23.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:142)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:240)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4876)
s3g_1       | 	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
om1_1       | 2020-12-21 16:38:21,972 [IPC Server handler 19 on default port 9862] INFO ipc.Server: IPC Server handler 19 on default port 9862, call Call#287 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39474
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4871)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:170)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:159)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.acquireClient(BlockInputStream.java:220)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:194)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:278)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:25,351 [IPC Server handler 9 on default port 9862] INFO ipc.Server: IPC Server handler 9 on default port 9862, call Call#292 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39512
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:25,891 [IPC Server handler 19 on default port 9862] INFO ipc.Server: IPC Server handler 19 on default port 9862, call Call#296 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39518
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:29,327 [IPC Server handler 11 on default port 9862] INFO ipc.Server: IPC Server handler 11 on default port 9862, call Call#305 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39536
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:29,836 [IPC Server handler 3 on default port 9862] INFO ipc.Server: IPC Server handler 3 on default port 9862, call Call#309 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39542
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:30,664 [IPC Server handler 49 on default port 9862] INFO ipc.Server: IPC Server handler 49 on default port 9862, call Call#314 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39550
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:34,139 [IPC Server handler 16 on default port 9862] INFO ipc.Server: IPC Server handler 16 on default port 9862, call Call#319 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39558
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:34,684 [IPC Server handler 75 on default port 9862] INFO ipc.Server: IPC Server handler 75 on default port 9862, call Call#323 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39572
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:38,379 [IPC Server handler 15 on default port 9862] INFO ipc.Server: IPC Server handler 15 on default port 9862, call Call#332 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39582
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:41,592 [IPC Server handler 30 on default port 9862] INFO ipc.Server: IPC Server handler 30 on default port 9862, call Call#341 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39600
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:42,097 [IPC Server handler 16 on default port 9862] INFO ipc.Server: IPC Server handler 16 on default port 9862, call Call#345 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39606
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:42,895 [IPC Server handler 16 on default port 9862] INFO ipc.Server: IPC Server handler 16 on default port 9862, call Call#350 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39616
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | 2020-12-21 16:38:51,571 [qtp1260634890-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-30382CF9E3D9->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:38:51,571 [qtp1260634890-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:38:55,641 [qtp1260634890-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-1A97D33A4636->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:38:55,648 [qtp1260634890-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:38:59,280 [qtp1260634890-21] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchBucket</Code>
s3g_1       |   <Message>The specified bucket does not exist</Message>
s3g_1       |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-21 16:38:59,771 [qtp1260634890-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchBucket</Code>
s3g_1       |   <Message>The specified bucket does not exist</Message>
s3g_1       |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-21 16:39:00,743 [qtp1260634890-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchKey</Code>
s3g_1       |   <Message>The specified key does not exist</Message>
s3g_1       |   <Resource>nonnonexistentkey</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-21 16:39:03,306 [qtp1260634890-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-89015, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-21 16:39:03,321 [qtp1260634890-21] INFO endpoint.BucketEndpoint: Location is /bucket-89015
s3g_1       | 2020-12-21 16:39:03,939 [qtp1260634890-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-BEBAAD04A965->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:39:03,939 [qtp1260634890-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:39:10,286 [qtp1260634890-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-42A15712002E->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:39:10,287 [qtp1260634890-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:40:11,333 [qtp1260634890-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-F2497CC5F13F->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:40:11,333 [qtp1260634890-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:41:12,199 [qtp1260634890-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-DFD8958AAED3->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:41:12,200 [qtp1260634890-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:43,457 [IPC Server handler 10 on default port 9862] INFO ipc.Server: IPC Server handler 10 on default port 9862, call Call#354 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39622
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:44,016 [IPC Server handler 7 on default port 9862] INFO ipc.Server: IPC Server handler 7 on default port 9862, call Call#358 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39628
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:46,551 [IPC Server handler 27 on default port 9862] INFO ipc.Server: IPC Server handler 27 on default port 9862, call Call#362 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39640
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:47,172 [IPC Server handler 11 on default port 9862] INFO ipc.Server: IPC Server handler 11 on default port 9862, call Call#365 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39650
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:47,789 [IPC Server handler 4 on default port 9862] INFO ipc.Server: IPC Server handler 4 on default port 9862, call Call#368 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39656
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:50,987 [IPC Server handler 7 on default port 9862] INFO ipc.Server: IPC Server handler 7 on default port 9862, call Call#373 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39664
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:51,474 [IPC Server handler 8 on default port 9862] INFO ipc.Server: IPC Server handler 8 on default port 9862, call Call#378 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39670
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:55,040 [IPC Server handler 11 on default port 9862] INFO ipc.Server: IPC Server handler 11 on default port 9862, call Call#388 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39694
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:55,530 [IPC Server handler 17 on default port 9862] INFO ipc.Server: IPC Server handler 17 on default port 9862, call Call#393 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39700
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:58,761 [IPC Server handler 88 on default port 9862] INFO ipc.Server: IPC Server handler 88 on default port 9862, call Call#403 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39722
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:59,266 [IPC Server handler 13 on default port 9862] INFO ipc.Server: IPC Server handler 13 on default port 9862, call Call#408 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39728
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
s3g_1       | 2020-12-21 16:42:10,381 [qtp1260634890-23] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #118 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #118 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:42:10,388 [qtp1260634890-23] INFO scm.XceiverClientRatis: Could not commit index 128 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:42:10,389 [qtp1260634890-23] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419161617891353 bcsId: 128 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:42:15,601 [qtp1260634890-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-88D2A0CCDBA5->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:42:15,601 [qtp1260634890-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:43:11,414 [qtp1260634890-22] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #122 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:38:59,763 [IPC Server handler 81 on default port 9862] INFO ipc.Server: IPC Server handler 81 on default port 9862, call Call#413 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39734
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:39:00,246 [IPC Server handler 13 on default port 9862] INFO ipc.Server: IPC Server handler 13 on default port 9862, call Call#416 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39740
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:39:00,727 [IPC Server handler 88 on default port 9862] INFO ipc.Server: IPC Server handler 88 on default port 9862, call Call#417 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39746
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:39:03,300 [IPC Server handler 12 on default port 9862] INFO ipc.Server: IPC Server handler 12 on default port 9862, call Call#423 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39752
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:39:03,907 [IPC Server handler 7 on default port 9862] INFO ipc.Server: IPC Server handler 7 on default port 9862, call Call#426 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39758
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:39:07,103 [IPC Server handler 13 on default port 9862] INFO ipc.Server: IPC Server handler 13 on default port 9862, call Call#431 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39774
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:39:07,615 [IPC Server handler 34 on default port 9862] INFO ipc.Server: IPC Server handler 34 on default port 9862, call Call#436 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39780
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:39:08,213 [IPC Server handler 12 on default port 9862] INFO ipc.Server: IPC Server handler 12 on default port 9862, call Call#441 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39786
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:39:08,709 [IPC Server handler 88 on default port 9862] INFO ipc.Server: IPC Server handler 88 on default port 9862, call Call#445 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39792
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:39:09,197 [IPC Server handler 12 on default port 9862] INFO ipc.Server: IPC Server handler 12 on default port 9862, call Call#449 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39798
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:39:09,765 [IPC Server handler 81 on default port 9862] INFO ipc.Server: IPC Server handler 81 on default port 9862, call Call#453 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39804
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:39:10,265 [IPC Server handler 5 on default port 9862] INFO ipc.Server: IPC Server handler 5 on default port 9862, call Call#457 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39810
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:40:11,265 [IPC Server handler 5 on default port 9862] INFO ipc.Server: IPC Server handler 5 on default port 9862, call Call#461 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:39922
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:40:17,677 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=467ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=228ms
om1_1       | 2020-12-21 16:40:18,179 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=467ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=228ms
om1_1       | 2020-12-21 16:40:38,189 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=467ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=228ms
om1_1       | 2020-12-21 16:40:49,695 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=467ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=228ms
om1_1       | 2020-12-21 16:41:11,254 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 51ms
om1_1       | GC pool 'ParNew' had collection(s): count=16 time=525ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=228ms
om1_1       | 2020-12-21 16:41:12,114 [IPC Server handler 13 on default port 9862] INFO ipc.Server: IPC Server handler 13 on default port 9862, call Call#465 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:40044
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:41:18,759 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | GC pool 'ParNew' had collection(s): count=16 time=525ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=7 time=264ms
om1_1       | 2020-12-21 16:42:15,535 [IPC Server handler 17 on default port 9862] INFO ipc.Server: IPC Server handler 17 on default port 9862, call Call#470 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:40160
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:43:19,558 [IPC Server handler 27 on default port 9862] INFO ipc.Server: IPC Server handler 27 on default port 9862, call Call#475 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:40290
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:44:10,335 [IPC Server handler 9 on default port 9862] INFO ipc.Server: IPC Server handler 9 on default port 9862, call Call#479 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:40404
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:45:10,559 [IPC Server handler 27 on default port 9862] INFO ipc.Server: IPC Server handler 27 on default port 9862, call Call#484 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:40522
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #122 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:43:11,425 [qtp1260634890-22] INFO scm.XceiverClientRatis: Could not commit index 132 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:43:11,425 [qtp1260634890-22] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419165617946650 bcsId: 132 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:43:19,635 [qtp1260634890-301] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-2DD7D732AEF1->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:43:19,635 [qtp1260634890-301] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:44:10,383 [qtp1260634890-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-33C5BFEEFE28->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:44:10,385 [qtp1260634890-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:46:12,335 [IPC Server handler 9 on default port 9862] INFO ipc.Server: IPC Server handler 9 on default port 9862, call Call#489 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:40638
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:47:15,825 [IPC Server handler 77 on default port 9862] INFO ipc.Server: IPC Server handler 77 on default port 9862, call Call#495 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:40764
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:47:15,877 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=22 time=701ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=13 time=418ms
om1_1       | 2020-12-21 16:48:16,901 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om1_1       | GC pool 'ParNew' had collection(s): count=24 time=791ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=14 time=444ms
om1_1       | 2020-12-21 16:48:21,424 [IPC Server handler 15 on default port 9862] INFO ipc.Server: IPC Server handler 15 on default port 9862, call Call#500 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:40886
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
s3g_1       | 2020-12-21 16:44:12,292 [qtp1260634890-19] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #126 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:48:52,413 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=24 time=791ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=461ms
om1_1       | 2020-12-21 16:49:10,425 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
om1_1       | GC pool 'ParNew' had collection(s): count=25 time=845ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=464ms
om1_1       | 2020-12-21 16:49:10,588 [IPC Server handler 21 on default port 9862] INFO ipc.Server: IPC Server handler 21 on default port 9862, call Call#504 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:41006
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:49:13,308 [IPC Server handler 12 on default port 9862] INFO ipc.Server: IPC Server handler 12 on default port 9862, call Call#508 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:41014
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:49:13,800 [IPC Server handler 88 on default port 9862] INFO ipc.Server: IPC Server handler 88 on default port 9862, call Call#511 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:41020
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:49:15,428 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=25 time=845ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=499ms
om1_1       | 2020-12-21 16:50:14,384 [IPC Server handler 15 on default port 9862] INFO ipc.Server: IPC Server handler 15 on default port 9862, call Call#515 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:41134
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:51:16,232 [IPC Server handler 12 on default port 9862] INFO ipc.Server: IPC Server handler 12 on default port 9862, call Call#520 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:41250
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:52:16,786 [IPC Server handler 88 on default port 9862] INFO ipc.Server: IPC Server handler 88 on default port 9862, call Call#526 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:41368
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:53:21,793 [IPC Server handler 91 on default port 9862] INFO ipc.Server: IPC Server handler 91 on default port 9862, call Call#531 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:41498
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:54:15,954 [IPC Server handler 2 on default port 9862] INFO ipc.Server: IPC Server handler 2 on default port 9862, call Call#535 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:41618
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:54:16,560 [IPC Server handler 8 on default port 9862] INFO ipc.Server: IPC Server handler 8 on default port 9862, call Call#539 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:41626
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:55:17,390 [IPC Server handler 15 on default port 9862] INFO ipc.Server: IPC Server handler 15 on default port 9862, call Call#544 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:41742
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #126 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:44:12,302 [qtp1260634890-19] INFO scm.XceiverClientRatis: Could not commit index 136 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:44:12,302 [qtp1260634890-19] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419169604698139 bcsId: 136 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:45:10,622 [qtp1260634890-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0F8C35282A1F->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:45:10,627 [qtp1260634890-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | Dec 21, 2020 4:45:10 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=145, target=172.23.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:142)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:240)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4876)
s3g_1       | 	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
s3g_1       | 	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4871)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:170)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:159)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.acquireClient(BlockInputStream.java:220)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:194)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:56:09,054 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=32 time=1046ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=23 time=667ms
om1_1       | 2020-12-21 16:56:18,700 [IPC Server handler 39 on default port 9862] INFO ipc.Server: IPC Server handler 39 on default port 9862, call Call#548 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:41856
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:57:20,640 [IPC Server handler 25 on default port 9862] INFO ipc.Server: IPC Server handler 25 on default port 9862, call Call#554 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:41974
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:58:21,868 [IPC Server handler 77 on default port 9862] INFO ipc.Server: IPC Server handler 77 on default port 9862, call Call#559 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42104
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:59:05,108 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=36 time=1167ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=27 time=755ms
om1_1       | 2020-12-21 16:59:16,116 [org.apache.ratis.server.JvmPauseMonitor@1b881f1f-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om1_1       | GC pool 'ParNew' had collection(s): count=36 time=1167ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=27 time=755ms
om1_1       | 2020-12-21 16:59:16,545 [IPC Server handler 10 on default port 9862] INFO ipc.Server: IPC Server handler 10 on default port 9862, call Call#563 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42224
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.copyObject(ObjectEndpoint.java:762)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:178)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Dec 21, 2020 4:45:10 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:59:17,244 [IPC Server handler 13 on default port 9862] INFO ipc.Server: IPC Server handler 13 on default port 9862, call Call#568 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42234
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:59:17,863 [IPC Server handler 77 on default port 9862] INFO ipc.Server: IPC Server handler 77 on default port 9862, call Call#573 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42244
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:59:18,620 [IPC Server handler 25 on default port 9862] INFO ipc.Server: IPC Server handler 25 on default port 9862, call Call#578 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42254
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=147, target=172.23.0.7:9859} was not shutdown properly!!! ~*~*~*
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
om1_1       | 2020-12-21 16:59:19,274 [IPC Server handler 12 on default port 9862] INFO ipc.Server: IPC Server handler 12 on default port 9862, call Call#584 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42266
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:543)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.checkOpen(XceiverClientGrpc.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:462)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:371)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.lambda$sendCommandWithTraceIDAndRetry$0(XceiverClientGrpc.java:311)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInSpan(TracingUtil.java:174)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:148)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:305)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:286)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:106)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:206)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:59:19,783 [IPC Server handler 56 on default port 9862] INFO ipc.Server: IPC Server handler 56 on default port 9862, call Call#588 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42272
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.copyObject(ObjectEndpoint.java:762)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:178)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:59:20,378 [IPC Server handler 5 on default port 9862] INFO ipc.Server: IPC Server handler 5 on default port 9862, call Call#593 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42282
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:59:21,021 [IPC Server handler 16 on default port 9862] INFO ipc.Server: IPC Server handler 16 on default port 9862, call Call#598 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42292
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:59:21,666 [IPC Server handler 17 on default port 9862] INFO ipc.Server: IPC Server handler 17 on default port 9862, call Call#603 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42300
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:59:22,600 [IPC Server handler 25 on default port 9862] INFO ipc.Server: IPC Server handler 25 on default port 9862, call Call#608 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42316
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:59:23,301 [IPC Server handler 5 on default port 9862] INFO ipc.Server: IPC Server handler 5 on default port 9862, call Call#613 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42326
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:59:23,876 [IPC Server handler 75 on default port 9862] INFO ipc.Server: IPC Server handler 75 on default port 9862, call Call#618 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42340
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Dec 21, 2020 4:45:10 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=155, target=172.23.0.4:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:142)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:240)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4876)
s3g_1       | 	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
s3g_1       | 	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4871)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:170)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:159)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.acquireClient(BlockInputStream.java:220)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:194)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.copyObject(ObjectEndpoint.java:762)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:178)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:59:24,406 [IPC Server handler 9 on default port 9862] INFO ipc.Server: IPC Server handler 9 on default port 9862, call Call#623 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42348
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:59:25,002 [IPC Server handler 16 on default port 9862] INFO ipc.Server: IPC Server handler 16 on default port 9862, call Call#628 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42358
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
om1_1       | 2020-12-21 16:59:28,242 [IPC Server handler 13 on default port 9862] INFO ipc.Server: IPC Server handler 13 on default port 9862, call Call#632 Retry#0 org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol.submitRequest from 172.23.0.8:42382
om1_1       | org.apache.hadoop.ozone.om.exceptions.OMNotLeaderException: OM:om1 is not the leader. Could not determine the leader node.
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createNotLeaderException(OzoneManagerProtocolServerSideTranslatorPB.java:202)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.createLeaderErrorException(OzoneManagerProtocolServerSideTranslatorPB.java:215)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitReadRequestToOM(OzoneManagerProtocolServerSideTranslatorPB.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.processRequest(OzoneManagerProtocolServerSideTranslatorPB.java:132)
om1_1       | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:122)
om1_1       | 	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java)
om1_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
om1_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
om1_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om1_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om1_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om1_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om1_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Dec 21, 2020 4:45:10 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=157, target=172.23.0.7:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:543)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.checkOpen(XceiverClientGrpc.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:462)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:371)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.lambda$sendCommandWithTraceIDAndRetry$0(XceiverClientGrpc.java:311)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInSpan(TracingUtil.java:174)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:148)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:305)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:286)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:106)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:206)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.copyObject(ObjectEndpoint.java:762)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:178)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | 2020-12-21 16:45:15,645 [qtp1260634890-21] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #131 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #131 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:45:15,663 [qtp1260634890-21] INFO scm.XceiverClientRatis: Could not commit index 140 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:45:15,663 [qtp1260634890-21] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419173760925724 bcsId: 140 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:46:12,393 [qtp1260634890-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-5D16EA935D05->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:46:12,395 [qtp1260634890-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:46:19,686 [qtp1260634890-301] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #136 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #136 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:46:19,701 [qtp1260634890-301] INFO scm.XceiverClientRatis: Could not commit index 144 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:46:19,701 [qtp1260634890-301] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419177956933661 bcsId: 144 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:47:10,426 [qtp1260634890-23] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #140 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #140 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:47:10,431 [qtp1260634890-23] INFO scm.XceiverClientRatis: Could not commit index 148 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:47:10,431 [qtp1260634890-23] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419181284851742 bcsId: 148 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:47:15,896 [qtp1260634890-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-44CD1D613A44->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:47:15,898 [qtp1260634890-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:48:10,695 [qtp1260634890-22] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #145 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #145 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:48:10,699 [qtp1260634890-22] INFO scm.XceiverClientRatis: Could not commit index 152 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:48:10,699 [qtp1260634890-22] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419185231429663 bcsId: 152 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:48:21,491 [qtp1260634890-301] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-6ED22C92C1E6->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:48:21,492 [qtp1260634890-301] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:49:10,597 [qtp1260634890-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchBucket</Code>
s3g_1       |   <Message>The specified bucket does not exist</Message>
s3g_1       |   <Resource>bucket-89015-nosuchbucket</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-21 16:49:12,431 [qtp1260634890-24] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #150 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #150 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:49:12,436 [qtp1260634890-24] INFO scm.XceiverClientRatis: Could not commit index 155 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:49:12,436 [qtp1260634890-24] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419189280047136 bcsId: 155 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:49:13,321 [qtp1260634890-17] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-62330, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-21 16:49:13,338 [qtp1260634890-17] INFO endpoint.BucketEndpoint: Location is /bucket-62330
s3g_1       | 2020-12-21 16:49:13,846 [qtp1260634890-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-ED8EE6345E1A->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:49:13,850 [qtp1260634890-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:50:14,446 [qtp1260634890-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-4C5AD094988F->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:50:14,447 [qtp1260634890-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:50:15,955 [qtp1260634890-21] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #156 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #156 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:50:15,971 [qtp1260634890-21] INFO scm.XceiverClientRatis: Could not commit index 159 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:50:15,971 [qtp1260634890-21] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419193440534561 bcsId: 159 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:51:16,289 [qtp1260634890-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-08F3F1B8245B->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:51:16,297 [qtp1260634890-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:51:21,538 [qtp1260634890-301] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #161 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #161 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:51:21,546 [qtp1260634890-301] INFO scm.XceiverClientRatis: Could not commit index 164 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:51:21,547 [qtp1260634890-301] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419197739892770 bcsId: 164 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:52:13,891 [qtp1260634890-23] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #166 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #166 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:52:13,897 [qtp1260634890-23] INFO scm.XceiverClientRatis: Could not commit index 168 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:52:13,897 [qtp1260634890-23] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419201172471843 bcsId: 168 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:52:16,850 [qtp1260634890-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-73902BF185B8->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:52:16,851 [qtp1260634890-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:53:14,497 [qtp1260634890-24] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #170 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #170 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:53:14,511 [qtp1260634890-24] INFO scm.XceiverClientRatis: Could not commit index 172 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:53:14,511 [qtp1260634890-24] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419205143298084 bcsId: 172 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:53:21,857 [qtp1260634890-301] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-D15112C60807->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:53:21,858 [qtp1260634890-301] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:54:15,972 [qtp1260634890-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-71854, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-21 16:54:15,979 [qtp1260634890-23] INFO endpoint.BucketEndpoint: Location is /bucket-71854
s3g_1       | 2020-12-21 16:54:16,345 [qtp1260634890-17] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #175 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #175 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:54:16,351 [qtp1260634890-17] INFO scm.XceiverClientRatis: Could not commit index 175 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:54:16,351 [qtp1260634890-17] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419209196961829 bcsId: 175 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:54:16,602 [qtp1260634890-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-A692380149DC->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:54:16,603 [qtp1260634890-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:55:16,898 [qtp1260634890-21] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #181 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #181 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:55:16,905 [qtp1260634890-21] INFO scm.XceiverClientRatis: Could not commit index 179 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:55:16,906 [qtp1260634890-21] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419213164511270 bcsId: 179 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:55:17,426 [qtp1260634890-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-DBC973DD955D->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:55:17,432 [qtp1260634890-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:56:18,793 [qtp1260634890-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-97263838EA24->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:56:18,795 [qtp1260634890-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:56:21,910 [qtp1260634890-301] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #186 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #186 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:56:21,916 [qtp1260634890-301] INFO scm.XceiverClientRatis: Could not commit index 182 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:56:21,916 [qtp1260634890-301] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419217424613415 bcsId: 182 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:57:16,672 [qtp1260634890-19] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #191 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #191 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:57:16,675 [qtp1260634890-19] INFO scm.XceiverClientRatis: Could not commit index 187 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:57:16,676 [qtp1260634890-19] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419221013823528 bcsId: 187 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:57:20,716 [qtp1260634890-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-836F486E185C->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:57:20,716 [qtp1260634890-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:58:17,476 [qtp1260634890-22] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #196 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #196 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:58:17,480 [qtp1260634890-22] INFO scm.XceiverClientRatis: Could not commit index 191 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:58:17,480 [qtp1260634890-22] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419225000378409 bcsId: 191 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:58:21,944 [qtp1260634890-301] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0F93FE9F46D8->ec956fef-022a-4e11-a406-1dfa86e0929f
s3g_1       | 2020-12-21 16:58:21,944 [qtp1260634890-301] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-21 16:59:18,851 [qtp1260634890-24] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #200 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:220)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor23.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #200 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-21 16:59:18,855 [qtp1260634890-24] INFO scm.XceiverClientRatis: Could not commit index 195 on pipeline Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z] to all the nodes. Server f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2 has failed. Committed by majority.
s3g_1       | 2020-12-21 16:59:18,855 [qtp1260634890-24] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105419229018980394 bcsId: 195 on Pipeline[ Id: 1f541f4e-a162-4978-bdd3-a46a69316625, Nodes: ec956fef-022a-4e11-a406-1dfa86e0929f{ip: 172.23.0.4, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}d59b5746-4c38-43fa-95c4-93039b647722{ip: 172.23.0.5, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:ec956fef-022a-4e11-a406-1dfa86e0929f, CreationTimestamp2020-12-21T16:35:55.312Z]. Failed nodes: [f51f9b24-50fc-42fe-a5a3-4a6169b8a6f2{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-21 16:59:19,287 [qtp1260634890-22] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidRange</Code>
s3g_1       |   <Message>The requested range is not satisfiable</Message>
s3g_1       |   <Resource>bytes=10000-10000</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-21 16:59:25,009 [qtp1260634890-19] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchKey</Code>
s3g_1       |   <Message>The specified key does not exist</Message>
s3g_1       |   <Resource>67349/putobject/zerobyte</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-21 16:59:28,259 [qtp1260634890-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-43602, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-21 16:59:28,270 [qtp1260634890-22] INFO endpoint.BucketEndpoint: Location is /bucket-43602
