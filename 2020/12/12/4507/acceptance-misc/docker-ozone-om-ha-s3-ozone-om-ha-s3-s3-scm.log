Attaching to ozone-om-ha-s3_datanode_2, ozone-om-ha-s3_datanode_1, ozone-om-ha-s3_datanode_3, ozone-om-ha-s3_om3_1, ozone-om-ha-s3_om2_1, ozone-om-ha-s3_scm_1, ozone-om-ha-s3_s3g_1, ozone-om-ha-s3_om1_1
datanode_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2020-12-12 01:55:15,690 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = 5c447d6ea915/172.23.0.9
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/6677200a7be75370c0ddcdd93197dda3227c6cdb ; compiled by 'runner' on 2020-12-12T01:23Z
datanode_1  | STARTUP_MSG:   java = 11.0.7
datanode_1  | ************************************************************/
datanode_1  | 2020-12-12 01:55:15,737 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2020-12-12 01:55:17,451 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2020-12-12 01:55:18,240 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2020-12-12 01:55:19,213 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2020-12-12 01:55:19,222 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2020-12-12 01:55:19,909 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:5c447d6ea915 ip:172.23.0.9
datanode_1  | 2020-12-12 01:55:20,983 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2020-12-12 01:55:21,018 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_1  | 2020-12-12 01:55:21,042 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_1  | 2020-12-12 01:55:21,085 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2020-12-12 01:55:21,388 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_1  | 2020-12-12 01:55:21,878 [Thread-6] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_1  | 2020-12-12 01:55:21,881 [Thread-6] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_1  | 2020-12-12 01:55:21,882 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_1  | 2020-12-12 01:55:31,264 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2020-12-12 01:55:31,682 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_1  | 2020-12-12 01:55:32,622 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_1  | 2020-12-12 01:55:32,626 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  | 2020-12-12 01:55:32,627 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-12-12 01:55:32,632 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_1  | 2020-12-12 01:55:32,650 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2020-12-12 01:55:33,805 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_1  | 2020-12-12 01:55:33,962 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-12-12 01:55:33,995 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_1  | 2020-12-12 01:55:34,852 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2020-12-12 01:55:34,983 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_1  | 2020-12-12 01:55:35,181 [main] INFO util.log: Logging initialized @27039ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2020-12-12 01:55:36,470 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_1  | 2020-12-12 01:55:36,502 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2020-12-12 01:55:36,551 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2020-12-12 01:55:36,558 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_1  | 2020-12-12 01:55:36,563 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_1  | 2020-12-12 01:55:36,563 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_1  | 2020-12-12 01:55:36,801 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_1  | 2020-12-12 01:55:36,858 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2020-12-12 01:55:36,859 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
datanode_1  | 2020-12-12 01:55:37,147 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  | 2020-12-12 01:55:37,159 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2020-12-12 01:55:37,161 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1  | 2020-12-12 01:55:37,231 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@31b6b0c7{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2020-12-12 01:55:37,242 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5613247e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2020-12-12 01:55:37,894 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@431babe6{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-15024055877220830301/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1  | 2020-12-12 01:55:37,923 [main] INFO server.AbstractConnector: Started ServerConnector@126a9a3d{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_1  | 2020-12-12 01:55:37,925 [main] INFO server.Server: Started @29784ms
datanode_1  | 2020-12-12 01:55:37,948 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2020-12-12 01:55:37,948 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2020-12-12 01:55:37,953 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_1  | 2020-12-12 01:55:38,081 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b7fa592] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_1  | 2020-12-12 01:55:39,541 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_1  | 2020-12-12 01:55:41,644 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-12-12 01:55:42,645 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-12-12 01:55:43,646 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-12-12 01:55:44,679 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_1  | java.net.SocketTimeoutException: Call From 5c447d6ea915/172.23.0.9 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.9:45466 remote=scm/172.23.0.3:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_1  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_1  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.9:45466 remote=scm/172.23.0.3:9861]
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_1  | 2020-12-12 01:55:46,050 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 2020-12-12 01:55:46,066 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_1  | 2020-12-12 01:55:46,076 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 2cbe4a56-f48d-46d2-9e37-17202fd9dde9 at port 9858
datanode_1  | 2020-12-12 01:55:46,233 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO impl.RaftServerProxy: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9: start RPC server
datanode_1  | 2020-12-12 01:55:46,641 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO server.GrpcService: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_1  | 2020-12-12 01:55:46,651 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2020-12-12 01:55:46,666 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2020-12-12 01:55:46,793 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] INFO server.JvmPauseMonitor: Starting Ratis JVM pause monitor
datanode_1  | 2020-12-12 01:55:47,835 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9ms
datanode_1  | No GCs detected
datanode_1  | 2020-12-12 01:55:51,414 [Command processor thread] INFO impl.RaftServerProxy: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9: addNew group-CAD798557E75:[2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858] returns group-CAD798557E75:java.util.concurrent.CompletableFuture@7abbdd4a[Not completed]
datanode_1  | 2020-12-12 01:55:51,569 [pool-19-thread-1] INFO impl.RaftServerImpl: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9: new RaftServerImpl for group-CAD798557E75:[2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-12-12 01:55:51,608 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-12-12 01:55:51,608 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-12-12 01:55:51,608 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2020-12-12 01:55:51,608 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2020-12-12 01:55:51,609 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-12-12 01:55:51,618 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-12-12 01:55:51,662 [pool-19-thread-1] INFO impl.RaftServerImpl: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75: ConfigurationManager, init=-1: [2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-12-12 01:55:51,664 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-12-12 01:55:51,668 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-12-12 01:55:51,677 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a4d8e493-e756-437a-8c68-cad798557e75 does not exist. Creating ...
datanode_1  | 2020-12-12 01:55:51,718 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a4d8e493-e756-437a-8c68-cad798557e75/in_use.lock acquired by nodename 6@5c447d6ea915
datanode_2  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2020-12-12 01:55:17,719 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = fd43cd1e3f43/172.23.0.8
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/ozone/6677200a7be75370c0ddcdd93197dda3227c6cdb ; compiled by 'runner' on 2020-12-12T01:23Z
datanode_2  | STARTUP_MSG:   java = 11.0.7
datanode_2  | ************************************************************/
datanode_2  | 2020-12-12 01:55:17,802 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2020-12-12 01:55:19,611 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2020-12-12 01:55:20,529 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2020-12-12 01:55:21,460 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2020-12-12 01:55:21,460 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2020-12-12 01:55:22,119 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:fd43cd1e3f43 ip:172.23.0.8
datanode_2  | 2020-12-12 01:55:23,155 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2  | 2020-12-12 01:55:23,171 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_2  | 2020-12-12 01:55:23,266 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_2  | 2020-12-12 01:55:23,316 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2  | 2020-12-12 01:55:23,690 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2020-12-12 01:55:24,134 [Thread-6] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_2  | 2020-12-12 01:55:24,180 [Thread-6] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_2  | 2020-12-12 01:55:24,185 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_2  | 2020-12-12 01:55:32,254 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-12-12 01:55:32,717 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_2  | 2020-12-12 01:55:33,246 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_2  | 2020-12-12 01:55:33,260 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_2  | 2020-12-12 01:55:33,260 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-12-12 01:55:33,266 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_2  | 2020-12-12 01:55:33,274 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-12-12 01:55:34,279 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_2  | 2020-12-12 01:55:34,350 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-12-12 01:55:34,378 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2020-12-12 01:55:35,980 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 2020-12-12 01:55:36,192 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_2  | 2020-12-12 01:55:36,469 [main] INFO util.log: Logging initialized @26795ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | 2020-12-12 01:55:37,459 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_2  | 2020-12-12 01:55:37,516 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2020-12-12 01:55:37,556 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2020-12-12 01:55:37,606 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_2  | 2020-12-12 01:55:37,606 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2  | 2020-12-12 01:55:37,606 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_2  | 2020-12-12 01:55:37,795 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_2  | 2020-12-12 01:55:37,858 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_2  | 2020-12-12 01:55:37,878 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
datanode_2  | 2020-12-12 01:55:38,218 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2020-12-12 01:55:38,220 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2020-12-12 01:55:38,222 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2  | 2020-12-12 01:55:38,309 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@61e14b53{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2020-12-12 01:55:38,335 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77ba583{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2020-12-12 01:55:38,992 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@43445fc6{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-3847867349855551504/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 2020-12-12 01:55:39,096 [main] INFO server.AbstractConnector: Started ServerConnector@336e3be2{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_2  | 2020-12-12 01:55:39,097 [main] INFO server.Server: Started @29423ms
datanode_2  | 2020-12-12 01:55:39,137 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2020-12-12 01:55:39,138 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2020-12-12 01:55:39,166 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2020-12-12 01:55:39,618 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@601ec7d1] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2020-12-12 01:55:40,771 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2  | 2020-12-12 01:55:42,731 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-12-12 01:55:43,732 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2020-12-12 01:55:44,784 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_2  | java.net.SocketTimeoutException: Call From fd43cd1e3f43/172.23.0.8 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.8:60656 remote=scm/172.23.0.3:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_2  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_2  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.8:60656 remote=scm/172.23.0.3:9861]
datanode_2  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_2  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_2  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_2  | 2020-12-12 01:55:46,106 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2020-12-12 01:55:46,120 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_2  | 2020-12-12 01:55:46,121 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b at port 9858
datanode_2  | 2020-12-12 01:55:46,247 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO impl.RaftServerProxy: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: start RPC server
datanode_2  | 2020-12-12 01:55:46,635 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO server.GrpcService: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_2  | 2020-12-12 01:55:46,650 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2020-12-12 01:55:46,693 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2  | 2020-12-12 01:55:46,754 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] INFO server.JvmPauseMonitor: Starting Ratis JVM pause monitor
datanode_2  | 2020-12-12 01:55:49,822 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 16ms
datanode_2  | No GCs detected
datanode_2  | 2020-12-12 01:55:50,325 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=1 time=74ms
datanode_2  | 2020-12-12 01:55:50,687 [Command processor thread] INFO impl.RaftServerProxy: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: addNew group-7808F3E1A69A:[2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858] returns group-7808F3E1A69A:java.util.concurrent.CompletableFuture@b2b14ad[Not completed]
datanode_2  | 2020-12-12 01:55:50,814 [pool-19-thread-1] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: new RaftServerImpl for group-7808F3E1A69A:[2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-12-12 01:55:50,815 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-12-12 01:55:50,817 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-12-12 01:55:51,741 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a4d8e493-e756-437a-8c68-cad798557e75 has been successfully formatted.
datanode_1  | 2020-12-12 01:55:51,757 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-CAD798557E75: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-12-12 01:55:51,787 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 2020-12-12 01:55:51,812 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-12-12 01:55:51,860 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 20ms
datanode_1  | GC pool 'ParNew' had collection(s): count=1 time=41ms
datanode_1  | 2020-12-12 01:55:51,861 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-12-12 01:55:51,872 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75
datanode_1  | 2020-12-12 01:55:51,935 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-12-12 01:55:51,987 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-12-12 01:55:52,089 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-12-12 01:55:52,145 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/a4d8e493-e756-437a-8c68-cad798557e75
datanode_1  | 2020-12-12 01:55:52,195 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-12-12 01:55:52,201 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-12-12 01:55:52,227 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-12-12 01:55:52,228 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-12-12 01:55:52,245 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-12-12 01:55:52,252 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-12-12 01:55:52,284 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-12-12 01:55:52,287 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-12-12 01:55:52,288 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-12-12 01:55:52,424 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-12-12 01:55:52,517 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-12-12 01:55:52,517 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-12-12 01:55:52,769 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-12-12 01:55:52,787 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-12-12 01:55:52,815 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-12-12 01:55:52,819 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-12-12 01:55:52,826 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-12-12 01:55:52,868 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
datanode_1  | GC pool 'ParNew' had collection(s): count=2 time=141ms
datanode_1  | 2020-12-12 01:55:53,046 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75
datanode_1  | 2020-12-12 01:55:53,049 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75
datanode_1  | 2020-12-12 01:55:53,081 [pool-19-thread-1] INFO impl.RaftServerImpl: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75: start as a follower, conf=-1: [2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858], old=null
datanode_1  | 2020-12-12 01:55:53,085 [pool-19-thread-1] INFO impl.RaftServerImpl: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-12-12 01:55:53,089 [pool-19-thread-1] INFO impl.RoleInfo: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9: start 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-FollowerState
datanode_1  | 2020-12-12 01:55:53,130 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CAD798557E75,id=2cbe4a56-f48d-46d2-9e37-17202fd9dde9
datanode_1  | 2020-12-12 01:55:53,134 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75
datanode_1  | 2020-12-12 01:55:53,234 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=a4d8e493-e756-437a-8c68-cad798557e75.
datanode_1  | 2020-12-12 01:55:53,237 [Command processor thread] INFO impl.RaftServerProxy: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9: addNew group-45C2E0698F41:[c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858] returns group-45C2E0698F41:java.util.concurrent.CompletableFuture@6bf112ea[Not completed]
datanode_1  | 2020-12-12 01:55:53,253 [pool-19-thread-1] INFO impl.RaftServerImpl: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9: new RaftServerImpl for group-45C2E0698F41:[c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858] with ContainerStateMachine:uninitialized
datanode_1  | 2020-12-12 01:55:53,253 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2020-12-12 01:55:53,259 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2020-12-12 01:55:53,268 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2020-12-12 01:55:53,269 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2020-12-12 01:55:53,269 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_1  | 2020-12-12 01:55:53,269 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2020-12-12 01:55:53,269 [pool-19-thread-1] INFO impl.RaftServerImpl: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41: ConfigurationManager, init=-1: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_1  | 2020-12-12 01:55:53,270 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2020-12-12 01:55:53,270 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2020-12-12 01:55:53,277 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/250da368-dbcb-48e6-92cc-45c2e0698f41 does not exist. Creating ...
datanode_1  | 2020-12-12 01:55:53,288 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/250da368-dbcb-48e6-92cc-45c2e0698f41/in_use.lock acquired by nodename 6@5c447d6ea915
datanode_1  | 2020-12-12 01:55:53,291 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/250da368-dbcb-48e6-92cc-45c2e0698f41 has been successfully formatted.
datanode_1  | 2020-12-12 01:55:53,297 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-45C2E0698F41: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2020-12-12 01:55:53,300 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 2020-12-12 01:55:53,303 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2020-12-12 01:55:53,303 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2020-12-12 01:55:53,303 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41
datanode_1  | 2020-12-12 01:55:53,303 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2020-12-12 01:55:53,303 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-12-12 01:55:53,304 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2020-12-12 01:55:53,304 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/250da368-dbcb-48e6-92cc-45c2e0698f41
datanode_1  | 2020-12-12 01:55:53,304 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_1  | 2020-12-12 01:55:53,304 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2020-12-12 01:55:53,305 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2020-12-12 01:55:53,305 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_1  | 2020-12-12 01:55:53,306 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2020-12-12 01:55:53,306 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2020-12-12 01:55:53,306 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2020-12-12 01:55:53,306 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2020-12-12 01:55:53,306 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2020-12-12 01:55:53,310 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_1  | 2020-12-12 01:55:53,312 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-12-12 01:55:53,313 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_1  | 2020-12-12 01:55:53,329 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  | 2020-12-12 01:55:53,333 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2020-12-12 01:55:53,333 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_1  | 2020-12-12 01:55:53,333 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2020-12-12 01:55:53,337 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2020-12-12 01:55:53,338 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41
datanode_1  | 2020-12-12 01:55:53,338 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41
datanode_1  | 2020-12-12 01:55:53,339 [pool-19-thread-1] INFO impl.RaftServerImpl: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41: start as a follower, conf=-1: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858], old=null
datanode_1  | 2020-12-12 01:55:53,342 [pool-19-thread-1] INFO impl.RaftServerImpl: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_1  | 2020-12-12 01:55:53,342 [pool-19-thread-1] INFO impl.RoleInfo: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9: start 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41-FollowerState
datanode_1  | 2020-12-12 01:55:53,372 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-45C2E0698F41,id=2cbe4a56-f48d-46d2-9e37-17202fd9dde9
datanode_3  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | 2020-12-12 01:55:17,547 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = 0c42ed186718/172.23.0.7
datanode_3  | STARTUP_MSG:   args = []
datanode_3  | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om1_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om1_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1       | 2020-12-12 01:55:12,931 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1       | /************************************************************
om1_1       | STARTUP_MSG: Starting OzoneManager
om1_1       | STARTUP_MSG:   host = 83d73767c09c/172.23.0.2
om1_1       | STARTUP_MSG:   args = [--init]
om1_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om1_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om1_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/6677200a7be75370c0ddcdd93197dda3227c6cdb ; compiled by 'runner' on 2020-12-12T01:24Z
om1_1       | STARTUP_MSG:   java = 11.0.7
om1_1       | ************************************************************/
om1_1       | 2020-12-12 01:55:13,020 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1       | 2020-12-12 01:55:22,241 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om1_1       | 2020-12-12 01:55:22,822 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1       | 2020-12-12 01:55:22,823 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om1: om1
om1_1       | 2020-12-12 01:55:22,874 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1       | 2020-12-12 01:55:26,556 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-12 01:55:27,557 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-12 01:55:28,558 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-12 01:55:29,559 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-12 01:55:30,562 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-12 01:55:31,562 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-12 01:55:32,569 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-12 01:55:33,570 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-12 01:55:34,571 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-12 01:55:35,572 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-12 01:55:35,577 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om1_1       | 2020-12-12 01:55:41,589 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-12 01:55:42,590 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | 2020-12-12 01:55:43,590 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om1_1       | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-16ca7467-b1f6-4a00-b411-db2381979a3b;layoutVersion=0
om1_1       | 2020-12-12 01:55:45,968 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1       | /************************************************************
om1_1       | SHUTDOWN_MSG: Shutting down OzoneManager at 83d73767c09c/172.23.0.2
om1_1       | ************************************************************/
om1_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om1_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1       | 2020-12-12 01:55:53,061 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1       | /************************************************************
om1_1       | STARTUP_MSG: Starting OzoneManager
om1_1       | STARTUP_MSG:   host = 83d73767c09c/172.23.0.2
om1_1       | STARTUP_MSG:   args = []
om1_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om1_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om1_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/6677200a7be75370c0ddcdd93197dda3227c6cdb ; compiled by 'runner' on 2020-12-12T01:24Z
om1_1       | STARTUP_MSG:   java = 11.0.7
om1_1       | ************************************************************/
om1_1       | 2020-12-12 01:55:53,116 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1       | 2020-12-12 01:55:59,960 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om1_1       | 2020-12-12 01:56:00,259 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1       | 2020-12-12 01:56:00,259 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om1: om1
om1_1       | 2020-12-12 01:56:00,307 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-datanode-1.1.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/ozone/6677200a7be75370c0ddcdd93197dda3227c6cdb ; compiled by 'runner' on 2020-12-12T01:23Z
datanode_3  | STARTUP_MSG:   java = 11.0.7
datanode_3  | ************************************************************/
datanode_3  | 2020-12-12 01:55:17,625 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2020-12-12 01:55:19,567 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2020-12-12 01:55:20,479 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2020-12-12 01:55:22,034 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 2020-12-12 01:55:22,034 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2020-12-12 01:55:22,726 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:0c42ed186718 ip:172.23.0.7
datanode_3  | 2020-12-12 01:55:23,937 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_3  | 2020-12-12 01:55:23,979 [main] INFO volume.HddsVolume: Creating Volume: /data/hdds/hdds of storage type : DISK and capacity : 89311358976
datanode_3  | 2020-12-12 01:55:24,014 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2020-12-12 01:55:24,067 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2020-12-12 01:55:24,443 [main] INFO volume.HddsVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2020-12-12 01:55:24,939 [Thread-6] INFO ozoneimpl.ContainerReader: Start to verify containers on volume /data/hdds/hdds
datanode_3  | 2020-12-12 01:55:24,944 [Thread-6] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_3  | 2020-12-12 01:55:24,944 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_3  | 2020-12-12 01:55:32,986 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-12-12 01:55:33,309 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
datanode_3  | 2020-12-12 01:55:33,803 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9858 (custom)
datanode_3  | 2020-12-12 01:55:33,806 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_3  | 2020-12-12 01:55:33,818 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-12-12 01:55:33,820 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode_3  | 2020-12-12 01:55:33,823 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2020-12-12 01:55:34,840 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode_3  | 2020-12-12 01:55:34,951 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-12-12 01:55:34,999 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2020-12-12 01:55:36,366 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2020-12-12 01:55:36,505 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
datanode_3  | 2020-12-12 01:55:36,698 [main] INFO util.log: Logging initialized @27072ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2020-12-12 01:55:37,317 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode_3  | 2020-12-12 01:55:37,326 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_3  | 2020-12-12 01:55:37,332 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2020-12-12 01:55:37,333 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
datanode_3  | 2020-12-12 01:55:37,333 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_3  | 2020-12-12 01:55:37,334 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode_3  | 2020-12-12 01:55:37,622 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
datanode_3  | 2020-12-12 01:55:37,671 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2020-12-12 01:55:37,681 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
datanode_3  | 2020-12-12 01:55:37,787 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2020-12-12 01:55:37,787 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 2020-12-12 01:55:37,789 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_3  | 2020-12-12 01:55:37,844 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@61e14b53{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2020-12-12 01:55:37,863 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77ba583{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 2020-12-12 01:55:38,480 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@43445fc6{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hadoop-hdds-container-service-1_1_0-SNAPSHOT_jar-_-any-17041416149578589827/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2020-12-12 01:55:38,568 [main] INFO server.AbstractConnector: Started ServerConnector@336e3be2{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_3  | 2020-12-12 01:55:38,569 [main] INFO server.Server: Started @28943ms
datanode_3  | 2020-12-12 01:55:38,576 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2020-12-12 01:55:38,576 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2020-12-12 01:55:38,582 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3  | 2020-12-12 01:55:38,798 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ab7f8cb] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2020-12-12 01:55:39,799 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3  | 2020-12-12 01:55:42,030 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-12-12 01:55:43,031 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2020-12-12 01:55:53,375 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41
datanode_1  | 2020-12-12 01:55:53,373 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_1  | GC pool 'ParNew' had collection(s): count=2 time=141ms
datanode_1  | 2020-12-12 01:55:53,671 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-A85D7C61CBA5->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
datanode_1  | 2020-12-12 01:55:53,899 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13ms
datanode_1  | GC pool 'ParNew' had collection(s): count=2 time=141ms
datanode_1  | 2020-12-12 01:55:54,910 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
datanode_1  | GC pool 'ParNew' had collection(s): count=3 time=208ms
datanode_1  | 2020-12-12 01:55:55,162 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.2cbe4a56-f48d-46d2-9e37-17202fd9dde9
datanode_1  | 2020-12-12 01:55:55,415 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_1  | GC pool 'ParNew' had collection(s): count=3 time=208ms
datanode_1  | 2020-12-12 01:55:55,839 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-73656971A762->c825d659-cfaa-4cfc-8134-552ad3e9db61
datanode_1  | 2020-12-12 01:55:57,641 [grpc-default-executor-0] INFO impl.RaftServerImpl: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41: changes role from  FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
datanode_1  | 2020-12-12 01:55:57,642 [grpc-default-executor-0] INFO impl.RoleInfo: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9: shutdown 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41-FollowerState
datanode_1  | 2020-12-12 01:55:57,642 [Thread-26] INFO impl.FollowerState: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41-FollowerState was interrupted: {}
datanode_1  | java.lang.InterruptedException: sleep interrupted
datanode_1  | 	at java.base/java.lang.Thread.sleep(Native Method)
datanode_1  | 	at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:250)
datanode_1  | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:116)
datanode_1  | 2020-12-12 01:55:57,642 [grpc-default-executor-0] INFO impl.RoleInfo: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9: start 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41-FollowerState
datanode_1  | 2020-12-12 01:55:57,644 [grpc-default-executor-0] INFO impl.RaftServerImpl:  FOLLOWER 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41:t1, leader=null, voted=null, raftlog=2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858], old=null RUNNING priority:0 candidate:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858 candidatePriority:0 compare:0
datanode_1  | 2020-12-12 01:55:57,928 [grpc-default-executor-0] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-45C2E0698F41 with new leaderId: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
datanode_1  | 2020-12-12 01:55:57,929 [grpc-default-executor-0] INFO impl.RaftServerImpl: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41: change Leader from null to 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b at term 1 for appendEntries, leader elected after 4628ms
datanode_1  | 2020-12-12 01:55:58,024 [grpc-default-executor-0] INFO impl.RaftServerImpl: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41: set configuration 0: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858|dataStream:, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858|dataStream:, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858|dataStream:], old=null at 0
datanode_1  | 2020-12-12 01:55:58,061 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-12-12 01:55:58,207 [Thread-24] INFO impl.FollowerState: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-FollowerState: change to CANDIDATE, lastRpcTime:5118ms, electionTimeout:5079ms
datanode_1  | 2020-12-12 01:55:58,213 [Thread-24] INFO impl.RoleInfo: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9: shutdown 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-FollowerState
datanode_1  | 2020-12-12 01:55:58,213 [Thread-24] INFO impl.RaftServerImpl: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2020-12-12 01:55:58,238 [Thread-24] INFO impl.RoleInfo: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9: start 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1
datanode_1  | 2020-12-12 01:55:58,264 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO impl.LeaderElection: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1: begin an election at term 1 for -1: [2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858], old=null
datanode_1  | 2020-12-12 01:55:58,272 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO impl.RoleInfo: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9: shutdown 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1
datanode_1  | 2020-12-12 01:55:58,276 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO impl.RaftServerImpl: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2020-12-12 01:55:58,276 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CAD798557E75 with new leaderId: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9
datanode_1  | 2020-12-12 01:55:58,280 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO impl.RaftServerImpl: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75: change Leader from null to 2cbe4a56-f48d-46d2-9e37-17202fd9dde9 at term 1 for becomeLeader, leader elected after 6489ms
datanode_1  | 2020-12-12 01:55:58,287 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2020-12-12 01:55:58,290 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2020-12-12 01:55:58,296 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75
datanode_1  | 2020-12-12 01:55:58,315 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2020-12-12 01:55:58,322 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_1  | 2020-12-12 01:55:58,364 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2020-12-12 01:55:58,370 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2020-12-12 01:55:58,376 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2020-12-12 01:55:58,407 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO impl.RoleInfo: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9: start 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderState
datanode_1  | 2020-12-12 01:55:58,428 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10ms
datanode_1  | GC pool 'ParNew' had collection(s): count=3 time=208ms
datanode_1  | 2020-12-12 01:55:58,441 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2020-12-12 01:55:58,471 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-LeaderElection1] INFO impl.RaftServerImpl: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75: set configuration 0: [2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858|dataStream:], old=null at 0
datanode_2  | 2020-12-12 01:55:50,818 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2  | 2020-12-12 01:55:50,818 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2020-12-12 01:55:50,819 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-12-12 01:55:50,824 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-12-12 01:55:50,840 [pool-19-thread-1] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A: ConfigurationManager, init=-1: [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-12-12 01:55:50,841 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-12-12 01:55:50,852 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-12-12 01:55:50,863 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/a21a1ece-c09c-4265-8c25-7808f3e1a69a does not exist. Creating ...
datanode_2  | 2020-12-12 01:55:50,893 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/a21a1ece-c09c-4265-8c25-7808f3e1a69a/in_use.lock acquired by nodename 6@fd43cd1e3f43
datanode_2  | 2020-12-12 01:55:50,908 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/a21a1ece-c09c-4265-8c25-7808f3e1a69a has been successfully formatted.
datanode_2  | 2020-12-12 01:55:50,929 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-7808F3E1A69A: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-12-12 01:55:50,930 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2020-12-12 01:55:50,935 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-12-12 01:55:50,953 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-12-12 01:55:50,975 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A
datanode_2  | 2020-12-12 01:55:51,033 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-12-12 01:55:51,057 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-12-12 01:55:51,104 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-12-12 01:55:51,154 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/a21a1ece-c09c-4265-8c25-7808f3e1a69a
datanode_2  | 2020-12-12 01:55:51,166 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-12-12 01:55:51,166 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-12-12 01:55:51,167 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-12-12 01:55:51,168 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-12-12 01:55:51,182 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-12-12 01:55:51,183 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-12-12 01:55:51,186 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-12-12 01:55:51,197 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-12-12 01:55:51,199 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-12-12 01:55:51,245 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-12-12 01:55:51,299 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-12-12 01:55:51,309 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-12-12 01:55:51,330 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ParNew' had collection(s): count=1 time=74ms
datanode_2  | 2020-12-12 01:55:51,340 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-12-12 01:55:51,341 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-12-12 01:55:51,365 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-12-12 01:55:51,390 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-12-12 01:55:51,392 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-12-12 01:55:51,572 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A
datanode_2  | 2020-12-12 01:55:51,600 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A
datanode_2  | 2020-12-12 01:55:51,665 [pool-19-thread-1] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A: start as a follower, conf=-1: [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858], old=null
datanode_2  | 2020-12-12 01:55:51,669 [pool-19-thread-1] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-12-12 01:55:51,676 [pool-19-thread-1] INFO impl.RoleInfo: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: start 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-FollowerState
datanode_2  | 2020-12-12 01:55:51,763 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7808F3E1A69A,id=2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
datanode_2  | 2020-12-12 01:55:51,764 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A
datanode_2  | 2020-12-12 01:55:51,846 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_2  | GC pool 'ParNew' had collection(s): count=1 time=74ms
datanode_2  | 2020-12-12 01:55:52,058 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=a21a1ece-c09c-4265-8c25-7808f3e1a69a.
datanode_2  | 2020-12-12 01:55:52,072 [Command processor thread] INFO impl.RaftServerProxy: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: addNew group-45C2E0698F41:[c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858] returns group-45C2E0698F41:java.util.concurrent.CompletableFuture@22aee92b[Not completed]
datanode_2  | 2020-12-12 01:55:52,114 [pool-19-thread-1] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: new RaftServerImpl for group-45C2E0698F41:[c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858] with ContainerStateMachine:uninitialized
datanode_2  | 2020-12-12 01:55:52,122 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2020-12-12 01:55:52,125 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2020-12-12 01:55:52,126 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2  | 2020-12-12 01:55:52,126 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2020-12-12 01:55:52,128 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_2  | 2020-12-12 01:55:52,128 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1       | 2020-12-12 01:56:00,389 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1       | 2020-12-12 01:56:04,290 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1       | 2020-12-12 01:56:04,887 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1       | 2020-12-12 01:56:04,890 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om1_1       | 2020-12-12 01:56:05,574 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
om1_1       | 2020-12-12 01:56:05,616 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om1_1       | 2020-12-12 01:56:05,753 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1       | 2020-12-12 01:56:05,965 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om1:9872, om2:9872, om3:9872
om1_1       | 2020-12-12 01:56:06,006 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om1_1       | 2020-12-12 01:56:06,110 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
om1_1       | 2020-12-12 01:56:06,334 [main] INFO grpc.GrpcFactory: PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
om1_1       | 	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
om1_1       | 2020-12-12 01:56:06,350 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om1_1       | 2020-12-12 01:56:06,354 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
datanode_2  | 2020-12-12 01:55:52,128 [pool-19-thread-1] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41: ConfigurationManager, init=-1: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858], old=null, confs=<EMPTY_MAP>
datanode_2  | 2020-12-12 01:55:52,128 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2020-12-12 01:55:52,129 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2020-12-12 01:55:52,156 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/250da368-dbcb-48e6-92cc-45c2e0698f41 does not exist. Creating ...
datanode_2  | 2020-12-12 01:55:52,167 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/250da368-dbcb-48e6-92cc-45c2e0698f41/in_use.lock acquired by nodename 6@fd43cd1e3f43
datanode_2  | 2020-12-12 01:55:52,195 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/250da368-dbcb-48e6-92cc-45c2e0698f41 has been successfully formatted.
datanode_2  | 2020-12-12 01:55:52,205 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-45C2E0698F41: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2020-12-12 01:55:52,206 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2020-12-12 01:55:52,210 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2020-12-12 01:55:52,219 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2020-12-12 01:55:52,219 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41
datanode_2  | 2020-12-12 01:55:52,219 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-12-12 01:55:52,221 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-12-12 01:55:52,225 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2020-12-12 01:55:52,227 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/250da368-dbcb-48e6-92cc-45c2e0698f41
datanode_2  | 2020-12-12 01:55:52,234 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_2  | 2020-12-12 01:55:52,247 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2020-12-12 01:55:52,249 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2020-12-12 01:55:52,249 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2020-12-12 01:55:52,249 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-12-12 01:55:52,250 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2020-12-12 01:55:52,250 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2020-12-12 01:55:52,250 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2020-12-12 01:55:52,250 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2020-12-12 01:55:52,252 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2020-12-12 01:55:52,260 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-12-12 01:55:52,261 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2020-12-12 01:55:52,274 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2020-12-12 01:55:52,277 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2020-12-12 01:55:52,277 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2020-12-12 01:55:52,277 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2020-12-12 01:55:52,278 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2020-12-12 01:55:52,297 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41
datanode_2  | 2020-12-12 01:55:52,302 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41
datanode_2  | 2020-12-12 01:55:52,310 [pool-19-thread-1] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41: start as a follower, conf=-1: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858], old=null
datanode_2  | 2020-12-12 01:55:52,318 [pool-19-thread-1] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2020-12-12 01:55:52,322 [pool-19-thread-1] INFO impl.RoleInfo: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: start 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-FollowerState
datanode_2  | 2020-12-12 01:55:52,330 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-45C2E0698F41,id=2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
datanode_2  | 2020-12-12 01:55:52,333 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41
datanode_2  | 2020-12-12 01:55:52,350 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ParNew' had collection(s): count=2 time=243ms
datanode_2  | 2020-12-12 01:55:52,798 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-D8F1E1E8560D->2cbe4a56-f48d-46d2-9e37-17202fd9dde9
datanode_2  | 2020-12-12 01:55:52,854 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ParNew' had collection(s): count=2 time=243ms
datanode_2  | 2020-12-12 01:55:53,362 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ParNew' had collection(s): count=2 time=243ms
datanode_2  | 2020-12-12 01:55:55,240 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
datanode_2  | 2020-12-12 01:55:55,400 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 37ms
datanode_2  | GC pool 'ParNew' had collection(s): count=3 time=337ms
datanode_2  | 2020-12-12 01:55:55,786 [Command processor thread] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-90A0021EF671->c825d659-cfaa-4cfc-8134-552ad3e9db61
datanode_2  | 2020-12-12 01:55:56,825 [Thread-24] INFO impl.FollowerState: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-FollowerState: change to CANDIDATE, lastRpcTime:5149ms, electionTimeout:5104ms
datanode_2  | 2020-12-12 01:55:56,825 [Thread-24] INFO impl.RoleInfo: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: shutdown 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-FollowerState
datanode_2  | 2020-12-12 01:55:56,826 [Thread-24] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-12-12 01:55:56,828 [Thread-24] INFO impl.RoleInfo: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: start 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1
datanode_2  | 2020-12-12 01:55:56,856 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO impl.LeaderElection: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1: begin an election at term 1 for -1: [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858], old=null
datanode_2  | 2020-12-12 01:55:56,857 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO impl.RoleInfo: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: shutdown 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1
datanode_2  | 2020-12-12 01:55:56,859 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-12-12 01:55:56,859 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-7808F3E1A69A with new leaderId: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
datanode_2  | 2020-12-12 01:55:56,862 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A: change Leader from null to 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b at term 1 for becomeLeader, leader elected after 5929ms
datanode_2  | 2020-12-12 01:55:56,864 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-12-12 01:55:56,865 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2020-12-12 01:55:56,867 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A
datanode_2  | 2020-12-12 01:55:56,880 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2020-12-12 01:55:56,894 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-12-12 01:55:56,930 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 28ms
datanode_2  | GC pool 'ParNew' had collection(s): count=3 time=337ms
datanode_2  | 2020-12-12 01:55:56,931 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-12-12 01:55:56,937 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-12-12 01:55:56,938 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2020-12-12 01:55:57,008 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO impl.RoleInfo: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: start 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderState
datanode_2  | 2020-12-12 01:55:57,096 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-12-12 01:55:57,200 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-LeaderElection1] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A: set configuration 0: [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858|dataStream:], old=null at 0
datanode_2  | 2020-12-12 01:55:57,254 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=250da368-dbcb-48e6-92cc-45c2e0698f41.
datanode_2  | 2020-12-12 01:55:57,430 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-7808F3E1A69A-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a21a1ece-c09c-4265-8c25-7808f3e1a69a/current/log_inprogress_0
om1_1       | 2020-12-12 01:56:06,357 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1       | 2020-12-12 01:56:06,362 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om1_1       | 2020-12-12 01:56:06,365 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1       | 2020-12-12 01:56:06,937 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om1_1       | 2020-12-12 01:56:06,959 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1       | 2020-12-12 01:56:07,004 [main] INFO impl.RaftServerProxy: om1: addNew group-562213E44849:[om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872] returns group-562213E44849:java.util.concurrent.CompletableFuture@58b5d5fc[Not completed]
om1_1       | 2020-12-12 01:56:07,005 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om1_1       | 2020-12-12 01:56:07,005 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1       | 2020-12-12 01:56:07,005 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om1_1       | 2020-12-12 01:56:07,007 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om1_1       | 2020-12-12 01:56:07,110 [pool-17-thread-1] INFO impl.RaftServerImpl: om1: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872] with OzoneManagerStateMachine:uninitialized
om1_1       | 2020-12-12 01:56:07,128 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 1s (custom)
om1_1       | 2020-12-12 01:56:07,145 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 1200ms (custom)
om1_1       | 2020-12-12 01:56:07,157 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1       | 2020-12-12 01:56:07,157 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1       | 2020-12-12 01:56:07,158 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
om1_1       | 2020-12-12 01:56:07,158 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1       | 2020-12-12 01:56:07,238 [pool-17-thread-1] INFO impl.RaftServerImpl: om1@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null, confs=<EMPTY_MAP>
om1_1       | 2020-12-12 01:56:07,244 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om1_1       | 2020-12-12 01:56:07,296 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om1_1       | 2020-12-12 01:56:07,309 [pool-17-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om1_1       | 2020-12-12 01:56:07,442 [pool-17-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 7@83d73767c09c
om1_1       | 2020-12-12 01:56:07,584 [pool-17-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om1_1       | 2020-12-12 01:56:07,592 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om1_1       | 2020-12-12 01:56:07,622 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om1_1       | 2020-12-12 01:56:07,672 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om1_1       | 2020-12-12 01:56:07,736 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om1@group-562213E44849
om1_1       | 2020-12-12 01:56:07,850 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1       | 2020-12-12 01:56:07,852 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1       | 2020-12-12 01:56:07,958 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om1_1       | 2020-12-12 01:56:07,972 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: new om1@group-562213E44849-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om1_1       | 2020-12-12 01:56:07,972 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om1_1       | 2020-12-12 01:56:07,988 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om1_1       | 2020-12-12 01:56:07,991 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om1_1       | 2020-12-12 01:56:07,993 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om1_1       | 2020-12-12 01:56:07,993 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om1_1       | 2020-12-12 01:56:08,003 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1       | 2020-12-12 01:56:08,014 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om1_1       | 2020-12-12 01:56:08,019 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om1_1       | 2020-12-12 01:56:08,023 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om1_1       | 2020-12-12 01:56:08,087 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om1_1       | 2020-12-12 01:56:08,097 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om1_1       | 2020-12-12 01:56:08,097 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om1_1       | 2020-12-12 01:56:08,142 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om1_1       | 2020-12-12 01:56:08,142 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om1_1       | 2020-12-12 01:56:08,149 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om1_1       | 2020-12-12 01:56:08,150 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om1_1       | 2020-12-12 01:56:08,151 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om1_1       | 2020-12-12 01:56:08,305 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om1@group-562213E44849
om1_1       | 2020-12-12 01:56:08,356 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om1@group-562213E44849
om1_1       | 2020-12-12 01:56:08,465 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om1_1       | 2020-12-12 01:56:08,520 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om1_1       | 2020-12-12 01:56:09,105 [Listener at om1/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om1_1       | 2020-12-12 01:56:09,499 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om1_1       | 2020-12-12 01:56:09,500 [Listener at om1/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om1_1       | 2020-12-12 01:56:09,731 [Listener at om1/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om1/172.23.0.2:9862
om1_1       | 2020-12-12 01:56:09,732 [Listener at om1/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om1_1       | 2020-12-12 01:56:09,748 [Listener at om1/9862] INFO impl.RaftServerImpl: om1@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om1_1       | 2020-12-12 01:56:09,749 [Listener at om1/9862] INFO impl.RaftServerImpl: om1@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om1_1       | 2020-12-12 01:56:09,756 [Listener at om1/9862] INFO impl.RoleInfo: om1: start om1@group-562213E44849-FollowerState
om1_1       | 2020-12-12 01:56:09,796 [Listener at om1/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om1
om1_1       | 2020-12-12 01:56:09,804 [Listener at om1/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om1@group-562213E44849
om1_1       | 2020-12-12 01:56:09,815 [Listener at om1/9862] INFO impl.RaftServerProxy: om1: start RPC server
om1_1       | 2020-12-12 01:56:10,088 [Listener at om1/9862] INFO server.GrpcService: om1: GrpcService started, listening on 0.0.0.0/0.0.0.0:9872
om1_1       | 2020-12-12 01:56:10,097 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om1_1       | 2020-12-12 01:56:10,101 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om1_1       | 2020-12-12 01:56:10,161 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] INFO server.JvmPauseMonitor: Starting Ratis JVM pause monitor
om1_1       | 2020-12-12 01:56:10,233 [Listener at om1/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om1_1       | 2020-12-12 01:56:10,237 [Listener at om1/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om1_1       | 2020-12-12 01:56:10,401 [Listener at om1/9862] INFO util.log: Logging initialized @23591ms to org.eclipse.jetty.util.log.Slf4jLog
om1_1       | 2020-12-12 01:56:10,829 [Thread-12] INFO impl.FollowerState: om1@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcTime:1073ms, electionTimeout:1016ms
om1_1       | 2020-12-12 01:56:10,833 [Thread-12] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-FollowerState
om1_1       | 2020-12-12 01:56:10,848 [Thread-12] INFO impl.RaftServerImpl: om1@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om1_1       | 2020-12-12 01:56:10,850 [Thread-12] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderElection1
om1_1       | 2020-12-12 01:56:10,911 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: begin an election at term 1 for -1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om1_1       | 2020-12-12 01:56:10,972 [Listener at om1/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om1_1       | 2020-12-12 01:56:11,000 [Listener at om1/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om1_1       | 2020-12-12 01:56:11,050 [Listener at om1/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om1_1       | 2020-12-12 01:56:11,055 [Listener at om1/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om1_1       | 2020-12-12 01:56:11,069 [Listener at om1/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om1_1       | 2020-12-12 01:56:11,072 [Listener at om1/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om1_1       | 2020-12-12 01:56:11,210 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om1_1       | No GCs detected
om1_1       | 2020-12-12 01:56:11,473 [Listener at om1/9862] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om1_1       | 2020-12-12 01:56:11,515 [Listener at om1/9862] INFO http.HttpServer2: Jetty bound to port 9874
om1_1       | 2020-12-12 01:56:11,543 [Listener at om1/9862] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
om1_1       | 2020-12-12 01:56:11,717 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | GC pool 'ParNew' had collection(s): count=1 time=86ms
om1_1       | 2020-12-12 01:56:11,811 [Listener at om1/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om1_1       | 2020-12-12 01:56:11,821 [Listener at om1/9862] INFO server.session: No SessionScavenger set, using defaults
om1_1       | 2020-12-12 01:56:11,827 [Listener at om1/9862] INFO server.session: node0 Scavenging every 660000ms
om1_1       | 2020-12-12 01:56:11,914 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@64cec4d0{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om1_1       | 2020-12-12 01:56:11,920 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68dc2f53{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om1_1       | 2020-12-12 01:56:12,171 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); om1@group-562213E44849:t1, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om1_1       | 2020-12-12 01:56:12,176 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: begin an election at term 2 for -1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om1_1       | 2020-12-12 01:56:12,581 [Listener at om1/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@62158618{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-1_1_0-SNAPSHOT_jar-_-any-3804585122454424269/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/ozoneManager}
om1_1       | 2020-12-12 01:56:12,606 [Listener at om1/9862] INFO server.AbstractConnector: Started ServerConnector@763ddfc3{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om1_1       | 2020-12-12 01:56:12,607 [Listener at om1/9862] INFO server.Server: Started @25796ms
om1_1       | 2020-12-12 01:56:12,614 [Listener at om1/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om1_1       | 2020-12-12 01:56:12,614 [Listener at om1/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2020-12-12 01:55:57,432 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=3 time=337ms
datanode_2  | 2020-12-12 01:55:57,489 [Thread-26] INFO impl.FollowerState: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-FollowerState: change to CANDIDATE, lastRpcTime:5167ms, electionTimeout:5146ms
datanode_2  | 2020-12-12 01:55:57,494 [Thread-26] INFO impl.RoleInfo: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: shutdown 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-FollowerState
datanode_2  | 2020-12-12 01:55:57,494 [Thread-26] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2020-12-12 01:55:57,494 [Thread-26] INFO impl.RoleInfo: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: start 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2
datanode_2  | 2020-12-12 01:55:57,505 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO impl.LeaderElection: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2: begin an election at term 1 for -1: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858], old=null
datanode_2  | 2020-12-12 01:55:57,721 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO impl.LeaderElection: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2: Election PASSED; received 1 response(s) [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b<-2cbe4a56-f48d-46d2-9e37-17202fd9dde9#0:OK-t1] and 0 exception(s); 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41:t1, leader=null, voted=2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, raftlog=2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858], old=null
datanode_1  | 2020-12-12 01:55:58,586 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-CAD798557E75-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/a4d8e493-e756-437a-8c68-cad798557e75/current/log_inprogress_0
datanode_1  | 2020-12-12 01:55:58,605 [2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9@group-45C2E0698F41-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/250da368-dbcb-48e6-92cc-45c2e0698f41/current/log_inprogress_0
datanode_1  | 2020-12-12 01:55:58,818 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=250da368-dbcb-48e6-92cc-45c2e0698f41.
datanode_1  | 2020-12-12 01:56:23,446 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ParNew' had collection(s): count=3 time=208ms
datanode_1  | 2020-12-12 01:56:26,450 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=3 time=208ms
datanode_1  | 2020-12-12 01:56:39,463 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
datanode_1  | GC pool 'ParNew' had collection(s): count=4 time=231ms
datanode_1  | 2020-12-12 01:56:39,968 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_1  | GC pool 'ParNew' had collection(s): count=4 time=231ms
datanode_1  | 2020-12-12 01:56:40,507 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 38ms
datanode_1  | GC pool 'ParNew' had collection(s): count=5 time=286ms
datanode_1  | 2020-12-12 01:56:41,018 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10ms
datanode_1  | GC pool 'ParNew' had collection(s): count=5 time=286ms
datanode_1  | 2020-12-12 01:58:01,062 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_1  | GC pool 'ParNew' had collection(s): count=8 time=385ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=30ms
datanode_1  | 2020-12-12 01:58:16,643 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 70ms
datanode_1  | GC pool 'ParNew' had collection(s): count=11 time=637ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 01:59:09,170 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=13 time=648ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 01:59:16,676 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=13 time=648ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 01:59:34,187 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_1  | GC pool 'ParNew' had collection(s): count=13 time=648ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 01:59:47,199 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_1  | GC pool 'ParNew' had collection(s): count=13 time=648ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 01:59:55,204 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=13 time=648ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:00:00,709 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=14 time=653ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:00:13,215 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=14 time=653ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:00:19,222 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_1  | GC pool 'ParNew' had collection(s): count=14 time=653ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:00:29,734 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
datanode_1  | GC pool 'ParNew' had collection(s): count=14 time=653ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:01:27,756 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=14 time=653ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:01:37,763 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=14 time=653ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:02:31,788 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=14 time=653ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:02:32,290 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=14 time=653ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:02:58,807 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_1  | GC pool 'ParNew' had collection(s): count=14 time=653ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_3  | 2020-12-12 01:55:44,032 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9861. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2020-12-12 01:55:45,060 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to SCM server at scm:9861 for past 0 seconds.
datanode_3  | java.net.SocketTimeoutException: Call From 0c42ed186718/172.23.0.7 to scm:9861 failed on socket timeout exception: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.7:43548 remote=scm/172.23.0.3:9861]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:777)
datanode_3  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
datanode_3  | 	at com.sun.proxy.$Proxy38.submitRequest(Unknown Source)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:70)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:41)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | Caused by: java.net.SocketTimeoutException: 1000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.23.0.7:43548 remote=scm/172.23.0.3:9861]
datanode_3  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:567)
datanode_3  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
datanode_3  | 2020-12-12 01:55:45,950 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3  | 2020-12-12 01:55:45,953 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Background container scanner has been disabled.
datanode_3  | 2020-12-12 01:55:45,968 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis c825d659-cfaa-4cfc-8134-552ad3e9db61 at port 9858
datanode_3  | 2020-12-12 01:55:46,118 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO impl.RaftServerProxy: c825d659-cfaa-4cfc-8134-552ad3e9db61: start RPC server
datanode_3  | 2020-12-12 01:55:46,478 [EndpointStateMachine task thread for scm/172.23.0.3:9861 - 0 ] INFO server.GrpcService: c825d659-cfaa-4cfc-8134-552ad3e9db61: GrpcService started, listening on 0.0.0.0/0.0.0.0:9858
datanode_3  | 2020-12-12 01:55:46,510 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2020-12-12 01:55:46,518 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2020-12-12 01:55:46,584 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] INFO server.JvmPauseMonitor: Starting Ratis JVM pause monitor
datanode_3  | 2020-12-12 01:55:47,187 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 29ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1 time=138ms
datanode_3  | 2020-12-12 01:55:49,694 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1 time=138ms
datanode_3  | 2020-12-12 01:55:52,198 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1 time=138ms
datanode_3  | 2020-12-12 01:55:56,654 [grpc-default-executor-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.c825d659-cfaa-4cfc-8134-552ad3e9db61
datanode_3  | 2020-12-12 01:55:56,661 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.c825d659-cfaa-4cfc-8134-552ad3e9db61
datanode_3  | 2020-12-12 01:55:56,702 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1 time=138ms
om3_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om3_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1       | 2020-12-12 01:55:18,341 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1       | /************************************************************
om3_1       | STARTUP_MSG: Starting OzoneManager
om3_1       | STARTUP_MSG:   host = de3cb7ba8a1d/172.23.0.6
om3_1       | STARTUP_MSG:   args = [--init]
om3_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om3_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om3_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/6677200a7be75370c0ddcdd93197dda3227c6cdb ; compiled by 'runner' on 2020-12-12T01:24Z
om3_1       | STARTUP_MSG:   java = 11.0.7
om3_1       | ************************************************************/
om3_1       | 2020-12-12 01:55:18,430 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1       | 2020-12-12 01:55:26,696 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om3_1       | 2020-12-12 01:55:27,535 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1       | 2020-12-12 01:55:27,535 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om3: om3
om3_1       | 2020-12-12 01:55:27,643 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1       | 2020-12-12 01:55:31,252 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-12 01:55:32,252 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-12 01:55:33,253 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-12 01:55:34,254 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-12 01:55:35,277 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-12 01:55:36,285 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-12 01:55:37,294 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-12 01:55:38,313 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-12 01:55:39,317 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-12 01:55:40,336 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om3_1       | 2020-12-12 01:55:40,338 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om3_1       | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-16ca7467-b1f6-4a00-b411-db2381979a3b;layoutVersion=0
om3_1       | 2020-12-12 01:55:46,114 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1       | /************************************************************
om3_1       | SHUTDOWN_MSG: Shutting down OzoneManager at de3cb7ba8a1d/172.23.0.6
om3_1       | ************************************************************/
om3_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om3_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1       | 2020-12-12 01:55:53,567 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1       | /************************************************************
om3_1       | STARTUP_MSG: Starting OzoneManager
om3_1       | STARTUP_MSG:   host = de3cb7ba8a1d/172.23.0.6
om3_1       | STARTUP_MSG:   args = []
om3_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om3_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om3_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/6677200a7be75370c0ddcdd93197dda3227c6cdb ; compiled by 'runner' on 2020-12-12T01:24Z
om3_1       | STARTUP_MSG:   java = 11.0.7
om3_1       | ************************************************************/
om3_1       | 2020-12-12 01:55:53,637 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1       | 2020-12-12 01:55:59,856 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om3_1       | 2020-12-12 01:56:00,360 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1       | 2020-12-12 01:56:00,363 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om3: om3
om3_1       | 2020-12-12 01:56:00,422 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1       | 2020-12-12 01:56:00,523 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1       | 2020-12-12 01:56:04,608 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1       | 2020-12-12 01:56:05,279 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om3_1       | 2020-12-12 01:56:05,283 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1       | 2020-12-12 01:56:06,123 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
om3_1       | 2020-12-12 01:56:06,176 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om3_1       | 2020-12-12 01:56:06,309 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1       | 2020-12-12 01:56:06,494 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om3:9872, om1:9872, om2:9872
om3_1       | 2020-12-12 01:56:06,682 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om3_1       | 2020-12-12 01:56:06,775 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
om3_1       | 2020-12-12 01:56:07,034 [main] INFO grpc.GrpcFactory: PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
om3_1       | 	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
om3_1       | 2020-12-12 01:56:07,042 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om3_1       | 2020-12-12 01:56:07,043 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om3_1       | 2020-12-12 01:56:07,050 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1       | 2020-12-12 01:56:07,050 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om3_1       | 2020-12-12 01:56:07,051 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om3_1       | 2020-12-12 01:56:07,892 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om3_1       | 2020-12-12 01:56:07,951 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1       | 2020-12-12 01:56:08,018 [main] INFO impl.RaftServerProxy: om3: addNew group-562213E44849:[om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872] returns group-562213E44849:java.util.concurrent.CompletableFuture@58b5d5fc[Not completed]
datanode_2  | 2020-12-12 01:55:57,723 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO impl.RoleInfo: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: shutdown 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2
datanode_2  | 2020-12-12 01:55:57,723 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_2  | 2020-12-12 01:55:57,723 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-45C2E0698F41 with new leaderId: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
datanode_2  | 2020-12-12 01:55:57,724 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41: change Leader from null to 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b at term 1 for becomeLeader, leader elected after 5517ms
datanode_2  | 2020-12-12 01:55:57,724 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2020-12-12 01:55:57,724 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2020-12-12 01:55:57,724 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41
datanode_2  | 2020-12-12 01:55:57,724 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2020-12-12 01:55:57,724 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_2  | 2020-12-12 01:55:57,724 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_2  | 2020-12-12 01:55:57,724 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_2  | 2020-12-12 01:55:57,725 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_2  | 2020-12-12 01:55:57,741 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2  | 2020-12-12 01:55:57,748 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-12-12 01:55:57,750 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2  | 2020-12-12 01:55:57,753 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2  | 2020-12-12 01:55:57,770 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-12-12 01:55:57,770 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-12-12 01:55:57,771 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41
datanode_2  | 2020-12-12 01:55:57,789 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_2  | 2020-12-12 01:55:57,799 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2020-12-12 01:55:57,809 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_2  | 2020-12-12 01:55:57,810 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_2  | 2020-12-12 01:55:57,810 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2020-12-12 01:55:57,810 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2020-12-12 01:55:57,818 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO impl.RoleInfo: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b: start 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderState
datanode_2  | 2020-12-12 01:55:57,820 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2020-12-12 01:55:57,826 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/250da368-dbcb-48e6-92cc-45c2e0698f41/current/log_inprogress_0
datanode_2  | 2020-12-12 01:55:57,855 [2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41-LeaderElection2] INFO impl.RaftServerImpl: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41: set configuration 0: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858|dataStream:, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858|dataStream:, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858|dataStream:], old=null at 0
datanode_2  | 2020-12-12 01:55:57,937 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_2  | GC pool 'ParNew' had collection(s): count=3 time=337ms
datanode_2  | 2020-12-12 01:55:58,759 [grpc-default-executor-0] INFO impl.FollowerInfo: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61: nextIndex: updateUnconditionally 1 -> 0
datanode_2  | 2020-12-12 01:56:39,467 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_2  | GC pool 'ParNew' had collection(s): count=4 time=366ms
datanode_2  | 2020-12-12 01:56:39,969 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=4 time=366ms
datanode_2  | 2020-12-12 01:56:41,474 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=5 time=420ms
datanode_2  | 2020-12-12 01:56:43,979 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ParNew' had collection(s): count=5 time=420ms
datanode_1  | 2020-12-12 02:03:01,811 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=14 time=653ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:03:21,319 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=14 time=653ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:04:02,840 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ParNew' had collection(s): count=15 time=655ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:04:13,347 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ParNew' had collection(s): count=15 time=655ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:04:22,855 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_1  | GC pool 'ParNew' had collection(s): count=15 time=655ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:04:28,359 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=15 time=655ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:04:37,367 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om1_1       | 2020-12-12 01:56:12,622 [Listener at om1/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om1_1       | 2020-12-12 01:56:12,630 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1       | 2020-12-12 01:56:12,661 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om1_1       | 2020-12-12 01:56:12,858 [Listener at om1/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om1_1       | 2020-12-12 01:56:12,873 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73c1dda3] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om1_1       | 2020-12-12 01:56:13,252 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); om1@group-562213E44849:t2, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om1_1       | 2020-12-12 01:56:13,305 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: begin an election at term 3 for -1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om1_1       | 2020-12-12 01:56:13,393 [grpc-default-executor-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om1
om1_1       | 2020-12-12 01:56:13,546 [om1@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om1@group-562213E44849-LeaderElection1: Election PASSED; received 1 response(s) [om1<-om2#0:OK-t3] and 0 exception(s); om1@group-562213E44849:t3, leader=null, voted=om1, raftlog=om1@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om1_1       | 2020-12-12 01:56:13,546 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-562213E44849-LeaderElection1
om1_1       | 2020-12-12 01:56:13,547 [om1@group-562213E44849-LeaderElection1] INFO impl.RaftServerImpl: om1@group-562213E44849: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
om1_1       | 2020-12-12 01:56:13,547 [om1@group-562213E44849-LeaderElection1] INFO impl.RaftServerImpl: om1@group-562213E44849: change Leader from null to om1 at term 3 for becomeLeader, leader elected after 5955ms
om1_1       | 2020-12-12 01:56:13,552 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om1_1       | 2020-12-12 01:56:13,553 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om1_1       | 2020-12-12 01:56:13,554 [om1@group-562213E44849-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.om1@group-562213E44849
om1_1       | 2020-12-12 01:56:13,556 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om1_1       | 2020-12-12 01:56:13,562 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om1_1       | 2020-12-12 01:56:13,604 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om1_1       | 2020-12-12 01:56:13,605 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om1_1       | 2020-12-12 01:56:13,608 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om1_1       | 2020-12-12 01:56:13,632 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1       | 2020-12-12 01:56:13,632 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1       | 2020-12-12 01:56:13,633 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1       | 2020-12-12 01:56:13,639 [om1@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1       | 2020-12-12 01:56:13,639 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1       | 2020-12-12 01:56:13,639 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1       | 2020-12-12 01:56:13,640 [om1@group-562213E44849-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis_grpc.log_appender.om1@group-562213E44849
om1_1       | 2020-12-12 01:56:13,647 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
om1_1       | 2020-12-12 01:56:13,650 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om1_1       | 2020-12-12 01:56:13,652 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
om1_1       | 2020-12-12 01:56:13,652 [om1@group-562213E44849-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
om1_1       | 2020-12-12 01:56:13,652 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om1_1       | 2020-12-12 01:56:13,652 [om1@group-562213E44849-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om1_1       | 2020-12-12 01:56:13,660 [om1@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-562213E44849-LeaderState
om1_1       | 2020-12-12 01:56:13,675 [om1@group-562213E44849-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om1_1       | 2020-12-12 01:56:13,718 [om1@group-562213E44849-LeaderElection1] INFO impl.RaftServerImpl: om1@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|dataStream:, om3|rpc:om3:9872|dataStream:, om2|rpc:om2:9872|dataStream:], old=null at 0
om1_1       | 2020-12-12 01:56:13,730 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8ms
om1_1       | GC pool 'ParNew' had collection(s): count=2 time=138ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 01:56:14,115 [om1@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om1_1       | 2020-12-12 01:56:19,241 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
om1_1       | GC pool 'ParNew' had collection(s): count=2 time=138ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 01:56:30,254 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om1_1       | GC pool 'ParNew' had collection(s): count=5 time=220ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 01:56:31,258 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om2_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om2_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1       | 2020-12-12 01:55:17,911 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1       | /************************************************************
om2_1       | STARTUP_MSG: Starting OzoneManager
om2_1       | STARTUP_MSG:   host = 4174d1978fe9/172.23.0.5
om2_1       | STARTUP_MSG:   args = [--init]
om2_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om2_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om2_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/6677200a7be75370c0ddcdd93197dda3227c6cdb ; compiled by 'runner' on 2020-12-12T01:24Z
om2_1       | STARTUP_MSG:   java = 11.0.7
om2_1       | ************************************************************/
om2_1       | 2020-12-12 01:55:18,000 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1       | 2020-12-12 01:55:26,893 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om2_1       | 2020-12-12 01:55:27,598 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1       | 2020-12-12 01:55:27,604 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om2: om2
om2_1       | 2020-12-12 01:55:27,770 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1       | 2020-12-12 01:55:31,404 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-12 01:55:32,413 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-12 01:55:33,414 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-12 01:55:34,415 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-12 01:55:35,416 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-12 01:55:36,417 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-12 01:55:37,421 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-12 01:55:38,425 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-12 01:55:39,426 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-12 01:55:40,444 [main] INFO ipc.Client: Retrying connect to server: scm/172.23.0.3:9863. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
om2_1       | 2020-12-12 01:55:40,446 [main] INFO utils.RetriableTask: Execution of task OM#getScmInfo failed, will be retried in 5000 ms
om2_1       | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-16ca7467-b1f6-4a00-b411-db2381979a3b;layoutVersion=0
om2_1       | 2020-12-12 01:55:46,028 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1       | /************************************************************
om2_1       | SHUTDOWN_MSG: Shutting down OzoneManager at 4174d1978fe9/172.23.0.5
om2_1       | ************************************************************/
om2_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
om2_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1       | 2020-12-12 01:55:53,611 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1       | /************************************************************
om2_1       | STARTUP_MSG: Starting OzoneManager
om2_1       | STARTUP_MSG:   host = 4174d1978fe9/172.23.0.5
om2_1       | STARTUP_MSG:   args = []
om2_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
om2_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-storage-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar
om2_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/6677200a7be75370c0ddcdd93197dda3227c6cdb ; compiled by 'runner' on 2020-12-12T01:24Z
om2_1       | STARTUP_MSG:   java = 11.0.7
om2_1       | ************************************************************/
om2_1       | 2020-12-12 01:55:53,644 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1       | 2020-12-12 01:55:59,467 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om2_1       | 2020-12-12 01:56:00,098 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1       | 2020-12-12 01:56:00,098 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.om2: om2
om2_1       | 2020-12-12 01:56:00,144 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1       | 2020-12-12 01:56:00,234 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1       | 2020-12-12 01:56:04,191 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1       | 2020-12-12 01:56:04,892 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1       | 2020-12-12 01:56:04,901 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om2_1       | 2020-12-12 01:56:05,615 [main] INFO om.OzoneManager: Created Volume s3v With Owner hadoop required for S3Gateway operations.
om2_1       | 2020-12-12 01:56:05,656 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om2_1       | 2020-12-12 01:56:05,777 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1       | 2020-12-12 01:56:05,923 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with GroupID: id1 and Raft Peers: om2:9872, om1:9872, om3:9872
om2_1       | 2020-12-12 01:56:06,049 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om2_1       | 2020-12-12 01:56:06,189 [main] INFO impl.RaftServerProxy: raft.rpc.type = GRPC (default)
om2_1       | 2020-12-12 01:56:06,429 [main] INFO grpc.GrpcFactory: PERFORMANCE WARNING: useCacheForAllThreads is true that may cause Netty to create a lot garbage objects and, as a result, trigger GC.
om2_1       | 	It is recommended to disable useCacheForAllThreads by setting -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false in command line.
om2_1       | 2020-12-12 01:56:06,447 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om2_1       | 2020-12-12 01:56:06,447 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om2_1       | 2020-12-12 01:56:06,457 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1       | 2020-12-12 01:56:06,463 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om2_1       | 2020-12-12 01:56:06,466 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om2_1       | 2020-12-12 01:56:07,161 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
om2_1       | 2020-12-12 01:56:07,224 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1       | 2020-12-12 01:56:07,291 [main] INFO impl.RaftServerProxy: om2: addNew group-562213E44849:[om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872] returns group-562213E44849:java.util.concurrent.CompletableFuture@58b5d5fc[Not completed]
om2_1       | 2020-12-12 01:56:07,291 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om2_1       | 2020-12-12 01:56:07,292 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1       | 2020-12-12 01:56:07,292 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om2_1       | 2020-12-12 01:56:07,331 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om2_1       | 2020-12-12 01:56:07,423 [pool-17-thread-1] INFO impl.RaftServerImpl: om2: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872] with OzoneManagerStateMachine:uninitialized
om2_1       | 2020-12-12 01:56:07,443 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 1s (custom)
om2_1       | 2020-12-12 01:56:07,453 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 1200ms (custom)
om2_1       | 2020-12-12 01:56:07,453 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1       | 2020-12-12 01:56:07,453 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1       | 2020-12-12 01:56:07,454 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
om2_1       | 2020-12-12 01:56:07,456 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om2_1       | 2020-12-12 01:56:07,522 [pool-17-thread-1] INFO impl.RaftServerImpl: om2@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null, confs=<EMPTY_MAP>
om2_1       | 2020-12-12 01:56:07,526 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om2_1       | 2020-12-12 01:56:07,566 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om2_1       | 2020-12-12 01:56:07,569 [pool-17-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om2_1       | 2020-12-12 01:56:07,695 [pool-17-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@4174d1978fe9
om2_1       | 2020-12-12 01:56:07,887 [pool-17-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om2_1       | 2020-12-12 01:56:07,905 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om2_1       | 2020-12-12 01:56:07,921 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om2_1       | 2020-12-12 01:56:07,975 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om2_1       | 2020-12-12 01:56:08,051 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om2@group-562213E44849
datanode_1  | GC pool 'ParNew' had collection(s): count=15 time=655ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:04:52,875 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=15 time=655ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:05:18,391 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_1  | GC pool 'ParNew' had collection(s): count=15 time=655ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:05:32,899 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=15 time=655ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:05:34,405 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_1  | GC pool 'ParNew' had collection(s): count=15 time=655ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:05:56,416 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=15 time=655ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:06:04,926 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_1  | GC pool 'ParNew' had collection(s): count=15 time=655ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:06:08,433 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_1  | GC pool 'ParNew' had collection(s): count=15 time=655ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:06:49,950 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=15 time=655ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:07:10,960 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ParNew' had collection(s): count=15 time=655ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:09:12,504 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=16 time=657ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:09:26,015 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_1  | GC pool 'ParNew' had collection(s): count=16 time=657ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:09:35,026 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8ms
datanode_1  | GC pool 'ParNew' had collection(s): count=16 time=657ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:10:20,042 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=16 time=657ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:11:25,570 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_1  | GC pool 'ParNew' had collection(s): count=17 time=666ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:12:17,594 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_1  | GC pool 'ParNew' had collection(s): count=17 time=666ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:12:18,096 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=17 time=666ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:12:27,601 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_1  | GC pool 'ParNew' had collection(s): count=17 time=666ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:12:36,109 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_1  | GC pool 'ParNew' had collection(s): count=17 time=666ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_1  | 2020-12-12 02:13:28,628 [org.apache.ratis.server.JvmPauseMonitor@17ad2b1e-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_1  | GC pool 'ParNew' had collection(s): count=17 time=666ms
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=94ms
datanode_3  | 2020-12-12 01:55:56,966 [grpc-default-executor-0] INFO impl.RaftServerProxy: c825d659-cfaa-4cfc-8134-552ad3e9db61: addNew group-45C2E0698F41:[c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858|dataStream:, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858|dataStream:, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858|dataStream:] returns group-45C2E0698F41:java.util.concurrent.CompletableFuture@1f37ee69[Not completed]
datanode_3  | 2020-12-12 01:55:57,149 [pool-19-thread-1] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61: new RaftServerImpl for group-45C2E0698F41:[c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858|dataStream:, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858|dataStream:, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858|dataStream:] with ContainerStateMachine:uninitialized
datanode_3  | 2020-12-12 01:55:57,155 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-12-12 01:55:57,158 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-12-12 01:55:57,158 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2020-12-12 01:55:57,158 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2020-12-12 01:55:57,160 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-12-12 01:55:57,164 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-12-12 01:55:57,226 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 24ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2 time=206ms
datanode_3  | 2020-12-12 01:55:57,242 [pool-19-thread-1] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41: ConfigurationManager, init=-1: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858|dataStream:, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858|dataStream:, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858|dataStream:], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-12-12 01:55:57,243 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-12-12 01:55:57,284 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-12-12 01:55:57,295 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/250da368-dbcb-48e6-92cc-45c2e0698f41 does not exist. Creating ...
datanode_3  | 2020-12-12 01:55:57,347 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/250da368-dbcb-48e6-92cc-45c2e0698f41/in_use.lock acquired by nodename 6@0c42ed186718
datanode_3  | 2020-12-12 01:55:57,359 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/250da368-dbcb-48e6-92cc-45c2e0698f41 has been successfully formatted.
datanode_3  | 2020-12-12 01:55:57,405 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-45C2E0698F41: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-12-12 01:55:57,414 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3  | 2020-12-12 01:55:57,438 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-12-12 01:55:57,451 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-12-12 01:55:57,472 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41
datanode_3  | 2020-12-12 01:55:57,482 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-12-12 01:55:57,499 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-12-12 01:55:57,592 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-12-12 01:55:57,652 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/250da368-dbcb-48e6-92cc-45c2e0698f41
datanode_3  | 2020-12-12 01:55:57,678 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-12-12 01:55:57,678 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-12-12 01:55:57,691 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-12-12 01:55:57,696 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-12-12 01:55:57,696 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2020-12-12 01:55:57,700 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-12-12 01:55:57,711 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-12-12 01:55:57,721 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-12-12 01:55:57,722 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-12-12 01:55:57,798 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-12-12 01:55:57,854 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-12-12 01:55:57,867 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-12-12 01:55:57,930 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-12-12 01:55:57,942 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-12-12 01:55:57,943 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-12-12 01:55:57,953 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-12-12 01:55:57,958 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-12-12 01:55:58,246 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41
datanode_3  | 2020-12-12 01:55:58,267 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41
datanode_3  | 2020-12-12 01:55:58,398 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: c825d659-cfaa-4cfc-8134-552ad3e9db61: Failed requestVote 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b->c825d659-cfaa-4cfc-8134-552ad3e9db61#0: org.apache.ratis.protocol.exceptions.ServerNotReadyException: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41 is not in [RUNNING]: current state is NEW
datanode_3  | 2020-12-12 01:55:58,409 [pool-19-thread-1] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41: start as a follower, conf=-1: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858|dataStream:, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858|dataStream:, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858|dataStream:], old=null
datanode_3  | 2020-12-12 01:55:58,414 [pool-19-thread-1] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-12-12 01:55:58,446 [pool-19-thread-1] INFO impl.RoleInfo: c825d659-cfaa-4cfc-8134-552ad3e9db61: start c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41-FollowerState
datanode_2  | 2020-12-12 01:56:44,487 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8ms
datanode_2  | GC pool 'ParNew' had collection(s): count=5 time=420ms
datanode_2  | 2020-12-12 01:56:58,760 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3,entriesCount=1,lastEntry=(t:1, i:0)
datanode_2  | 2020-12-12 01:57:14,506 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ParNew' had collection(s): count=6 time=443ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=29ms
datanode_2  | 2020-12-12 01:57:19,009 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=7 time=463ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=29ms
datanode_2  | 2020-12-12 01:57:39,351 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=266,entriesCount=1,lastEntry=(t:1, i:1)
datanode_2  | 2020-12-12 01:57:39,410 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=267,entriesCount=1,lastEntry=(t:1, i:2)
datanode_2  | 2020-12-12 01:57:40,998 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=268,entriesCount=1,lastEntry=(t:1, i:3)
datanode_2  | 2020-12-12 01:57:41,045 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=273,entriesCount=1,lastEntry=(t:1, i:4)
datanode_2  | 2020-12-12 01:57:44,539 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=516,entriesCount=1,lastEntry=(t:1, i:5)
datanode_2  | 2020-12-12 01:57:44,539 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=517,entriesCount=1,lastEntry=(t:1, i:6)
datanode_2  | 2020-12-12 01:57:44,570 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=518,entriesCount=1,lastEntry=(t:1, i:7)
datanode_2  | 2020-12-12 01:57:44,572 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=519,entriesCount=1,lastEntry=(t:1, i:8)
datanode_2  | 2020-12-12 01:57:55,031 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ParNew' had collection(s): count=8 time=500ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=29ms
datanode_2  | 2020-12-12 01:58:05,545 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_2  | GC pool 'ParNew' had collection(s): count=10 time=557ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=30ms
datanode_2  | 2020-12-12 01:58:06,553 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
datanode_2  | GC pool 'ParNew' had collection(s): count=10 time=557ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=30ms
datanode_2  | 2020-12-12 01:58:09,056 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=10 time=557ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=30ms
datanode_2  | 2020-12-12 01:58:10,334 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=773,entriesCount=1,lastEntry=(t:1, i:9)
datanode_2  | 2020-12-12 01:58:10,335 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=774,entriesCount=1,lastEntry=(t:1, i:10)
datanode_2  | 2020-12-12 01:58:10,343 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=775,entriesCount=1,lastEntry=(t:1, i:11)
datanode_2  | 2020-12-12 01:58:10,676 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=776,entriesCount=1,lastEntry=(t:1, i:12)
datanode_2  | 2020-12-12 01:58:10,703 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=779,entriesCount=1,lastEntry=(t:1, i:13)
datanode_2  | 2020-12-12 01:58:10,704 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=780,entriesCount=1,lastEntry=(t:1, i:14)
datanode_2  | 2020-12-12 01:58:12,060 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=11 time=601ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=50ms
datanode_3  | 2020-12-12 01:55:58,497 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-45C2E0698F41,id=c825d659-cfaa-4cfc-8134-552ad3e9db61
datanode_3  | 2020-12-12 01:55:58,499 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41
datanode_3  | 2020-12-12 01:55:58,664 [grpc-default-executor-1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-45C2E0698F41 with new leaderId: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
datanode_3  | 2020-12-12 01:55:58,674 [grpc-default-executor-1] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41: change Leader from null to 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b at term 1 for appendEntries, leader elected after 1249ms
datanode_3  | 2020-12-12 01:55:58,702 [grpc-default-executor-1] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
datanode_3  | 2020-12-12 01:55:58,723 [grpc-default-executor-1] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41: inconsistency entries. Reply:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b<-c825d659-cfaa-4cfc-8134-552ad3e9db61#2:FAIL,INCONSISTENCY,nextIndex:0,term:0,followerCommit:-1
datanode_3  | 2020-12-12 01:55:58,733 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2 time=206ms
datanode_3  | 2020-12-12 01:55:58,820 [grpc-default-executor-0] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41: set configuration 0: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858|dataStream:, 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b|rpc:172.23.0.8:9858|dataStream:, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9|rpc:172.23.0.9:9858|dataStream:], old=null at 0
datanode_3  | 2020-12-12 01:55:58,841 [grpc-default-executor-0] INFO segmented.SegmentedRaftLogWorker: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-12-12 01:55:59,144 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-45C2E0698F41-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/250da368-dbcb-48e6-92cc-45c2e0698f41/current/log_inprogress_0
datanode_3  | 2020-12-12 01:55:59,251 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 16ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2 time=206ms
datanode_3  | 2020-12-12 01:56:07,259 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2 time=206ms
datanode_3  | 2020-12-12 01:56:07,765 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2 time=206ms
datanode_3  | 2020-12-12 01:56:19,885 [Command processor thread] INFO impl.RaftServerProxy: c825d659-cfaa-4cfc-8134-552ad3e9db61: addNew group-FCD203891169:[c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858] returns group-FCD203891169:java.util.concurrent.CompletableFuture@5b41a3d5[Not completed]
datanode_3  | 2020-12-12 01:56:19,887 [pool-19-thread-1] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61: new RaftServerImpl for group-FCD203891169:[c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858] with ContainerStateMachine:uninitialized
datanode_3  | 2020-12-12 01:56:19,890 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_3  | 2020-12-12 01:56:19,890 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2020-12-12 01:56:19,890 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2020-12-12 01:56:19,891 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2020-12-12 01:56:19,891 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
datanode_3  | 2020-12-12 01:56:19,891 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2020-12-12 01:56:19,891 [pool-19-thread-1] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169: ConfigurationManager, init=-1: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858], old=null, confs=<EMPTY_MAP>
datanode_3  | 2020-12-12 01:56:19,891 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2020-12-12 01:56:19,892 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2020-12-12 01:56:19,892 [pool-19-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/9afcac27-3965-4d3f-919c-fcd203891169 does not exist. Creating ...
datanode_3  | 2020-12-12 01:56:19,894 [pool-19-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/9afcac27-3965-4d3f-919c-fcd203891169/in_use.lock acquired by nodename 6@0c42ed186718
datanode_3  | 2020-12-12 01:56:19,895 [pool-19-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/9afcac27-3965-4d3f-919c-fcd203891169 has been successfully formatted.
datanode_3  | 2020-12-12 01:56:19,896 [pool-19-thread-1] INFO ratis.ContainerStateMachine: group-FCD203891169: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2020-12-12 01:56:19,896 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3  | 2020-12-12 01:56:19,896 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2020-12-12 01:56:19,897 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2020-12-12 01:56:19,897 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169
datanode_3  | 2020-12-12 01:56:19,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2020-12-12 01:56:19,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-12-12 01:56:19,898 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2020-12-12 01:56:19,899 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: new c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/9afcac27-3965-4d3f-919c-fcd203891169
datanode_3  | 2020-12-12 01:56:19,899 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 2147483647 (custom)
datanode_3  | 2020-12-12 01:56:19,900 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2020-12-12 01:56:19,900 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2020-12-12 01:56:19,900 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2020-12-12 01:56:19,901 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2020-12-12 01:58:14,419 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1032,entriesCount=1,lastEntry=(t:1, i:15)
datanode_2  | 2020-12-12 01:58:14,484 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1033,entriesCount=1,lastEntry=(t:1, i:16)
datanode_2  | 2020-12-12 01:58:14,510 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1034,entriesCount=1,lastEntry=(t:1, i:17)
datanode_2  | 2020-12-12 01:58:14,575 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1035,entriesCount=1,lastEntry=(t:1, i:18)
datanode_2  | 2020-12-12 01:58:14,599 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1037,entriesCount=1,lastEntry=(t:1, i:19)
datanode_2  | 2020-12-12 01:58:14,620 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1039,entriesCount=1,lastEntry=(t:1, i:20)
datanode_2  | 2020-12-12 01:58:16,568 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_2  | GC pool 'ParNew' had collection(s): count=12 time=628ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=50ms
datanode_2  | 2020-12-12 01:58:18,689 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1288,entriesCount=1,lastEntry=(t:1, i:21)
datanode_2  | 2020-12-12 01:58:18,699 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1289,entriesCount=1,lastEntry=(t:1, i:22)
datanode_2  | 2020-12-12 01:58:18,708 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1290,entriesCount=1,lastEntry=(t:1, i:23)
datanode_2  | 2020-12-12 01:58:18,842 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1291,entriesCount=1,lastEntry=(t:1, i:24)
datanode_2  | 2020-12-12 01:58:18,851 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1292,entriesCount=1,lastEntry=(t:1, i:25)
datanode_2  | 2020-12-12 01:58:18,880 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1295,entriesCount=1,lastEntry=(t:1, i:26)
datanode_2  | 2020-12-12 01:58:21,572 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=12 time=628ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=50ms
datanode_2  | 2020-12-12 01:58:22,218 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1545,entriesCount=1,lastEntry=(t:1, i:27)
datanode_2  | 2020-12-12 01:58:22,218 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1546,entriesCount=1,lastEntry=(t:1, i:28)
datanode_2  | 2020-12-12 01:58:22,230 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1547,entriesCount=1,lastEntry=(t:1, i:29)
datanode_2  | 2020-12-12 01:58:22,237 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1548,entriesCount=1,lastEntry=(t:1, i:30)
datanode_2  | 2020-12-12 01:58:28,578 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=13 time=632ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=50ms
datanode_2  | 2020-12-12 01:58:29,061 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1799,entriesCount=1,lastEntry=(t:1, i:31)
datanode_2  | 2020-12-12 01:58:29,075 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1800,entriesCount=1,lastEntry=(t:1, i:32)
datanode_2  | 2020-12-12 01:58:29,075 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1801,entriesCount=1,lastEntry=(t:1, i:33)
datanode_2  | 2020-12-12 01:58:29,105 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=1803,entriesCount=1,lastEntry=(t:1, i:34)
datanode_2  | 2020-12-12 01:58:32,361 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2052,entriesCount=1,lastEntry=(t:1, i:35)
datanode_2  | 2020-12-12 01:58:32,373 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2053,entriesCount=1,lastEntry=(t:1, i:36)
datanode_2  | 2020-12-12 01:58:32,378 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2054,entriesCount=1,lastEntry=(t:1, i:37)
datanode_2  | 2020-12-12 01:58:32,388 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2055,entriesCount=1,lastEntry=(t:1, i:38)
datanode_2  | 2020-12-12 01:58:38,155 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2305,entriesCount=1,lastEntry=(t:1, i:39)
datanode_2  | 2020-12-12 01:58:38,177 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2306,entriesCount=1,lastEntry=(t:1, i:40)
datanode_2  | 2020-12-12 01:58:38,178 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2307,entriesCount=1,lastEntry=(t:1, i:41)
datanode_2  | 2020-12-12 01:58:38,239 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2308,entriesCount=1,lastEntry=(t:1, i:42)
datanode_2  | 2020-12-12 01:58:38,243 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2309,entriesCount=1,lastEntry=(t:1, i:43)
datanode_2  | 2020-12-12 01:58:38,244 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2310,entriesCount=1,lastEntry=(t:1, i:44)
datanode_2  | 2020-12-12 01:58:41,792 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2560,entriesCount=1,lastEntry=(t:1, i:45)
datanode_2  | 2020-12-12 01:58:41,870 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2561,entriesCount=1,lastEntry=(t:1, i:46)
datanode_2  | 2020-12-12 01:58:41,904 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2562,entriesCount=1,lastEntry=(t:1, i:47)
datanode_2  | 2020-12-12 01:58:41,959 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2563,entriesCount=1,lastEntry=(t:1, i:48)
datanode_2  | 2020-12-12 01:58:41,964 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2565,entriesCount=1,lastEntry=(t:1, i:49)
datanode_2  | 2020-12-12 01:58:41,992 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2566,entriesCount=1,lastEntry=(t:1, i:50)
datanode_2  | 2020-12-12 01:58:45,343 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2814,entriesCount=1,lastEntry=(t:1, i:51)
datanode_2  | 2020-12-12 01:58:45,344 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2815,entriesCount=1,lastEntry=(t:1, i:52)
datanode_2  | 2020-12-12 01:58:45,362 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2816,entriesCount=1,lastEntry=(t:1, i:53)
datanode_2  | 2020-12-12 01:58:45,370 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=2818,entriesCount=1,lastEntry=(t:1, i:54)
datanode_2  | 2020-12-12 01:58:54,963 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3071,entriesCount=1,lastEntry=(t:1, i:55)
datanode_2  | 2020-12-12 01:58:55,039 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3072,entriesCount=1,lastEntry=(t:1, i:56)
datanode_2  | 2020-12-12 01:58:55,054 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3073,entriesCount=1,lastEntry=(t:1, i:57)
datanode_2  | 2020-12-12 01:58:55,080 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3074,entriesCount=1,lastEntry=(t:1, i:58)
datanode_2  | 2020-12-12 01:58:55,124 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3077,entriesCount=1,lastEntry=(t:1, i:59)
datanode_2  | 2020-12-12 01:58:55,124 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3078,entriesCount=1,lastEntry=(t:1, i:60)
datanode_2  | 2020-12-12 01:58:58,442 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3327,entriesCount=1,lastEntry=(t:1, i:61)
datanode_2  | 2020-12-12 01:58:58,442 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3328,entriesCount=1,lastEntry=(t:1, i:62)
datanode_2  | 2020-12-12 01:58:58,460 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3329,entriesCount=1,lastEntry=(t:1, i:63)
datanode_2  | 2020-12-12 01:58:58,469 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3330,entriesCount=1,lastEntry=(t:1, i:64)
datanode_2  | 2020-12-12 01:59:02,594 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=14 time=636ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=50ms
om2_1       | 2020-12-12 01:56:08,146 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om2_1       | 2020-12-12 01:56:08,148 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1       | 2020-12-12 01:56:08,249 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om2_1       | 2020-12-12 01:56:08,263 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: new om2@group-562213E44849-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om2_1       | 2020-12-12 01:56:08,286 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om2_1       | 2020-12-12 01:56:08,305 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om2_1       | 2020-12-12 01:56:08,321 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om2_1       | 2020-12-12 01:56:08,341 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om2_1       | 2020-12-12 01:56:08,341 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om2_1       | 2020-12-12 01:56:08,349 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om2_1       | 2020-12-12 01:56:08,384 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om2_1       | 2020-12-12 01:56:08,384 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om2_1       | 2020-12-12 01:56:08,384 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om2_1       | 2020-12-12 01:56:08,506 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om2_1       | 2020-12-12 01:56:08,543 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om2_1       | 2020-12-12 01:56:08,561 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om2_1       | 2020-12-12 01:56:08,596 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om2_1       | 2020-12-12 01:56:08,598 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om2_1       | 2020-12-12 01:56:08,610 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om2_1       | 2020-12-12 01:56:08,615 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om2_1       | 2020-12-12 01:56:08,622 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om2_1       | 2020-12-12 01:56:08,877 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om2@group-562213E44849
om2_1       | 2020-12-12 01:56:08,884 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om2_1       | 2020-12-12 01:56:08,896 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om2@group-562213E44849
om2_1       | 2020-12-12 01:56:08,985 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om2_1       | 2020-12-12 01:56:09,508 [Listener at om2/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om2_1       | 2020-12-12 01:56:09,651 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om2_1       | 2020-12-12 01:56:09,651 [Listener at om2/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om2_1       | 2020-12-12 01:56:09,775 [Listener at om2/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om2/172.23.0.5:9862
datanode_3  | 2020-12-12 01:56:19,901 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2020-12-12 01:56:19,901 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2020-12-12 01:56:19,901 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2020-12-12 01:56:19,902 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  | 2020-12-12 01:56:19,904 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2020-12-12 01:56:19,913 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-12-12 01:56:19,914 [pool-19-thread-1] INFO segmented.SegmentedRaftLogWorker: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2020-12-12 01:56:19,918 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2020-12-12 01:56:19,918 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2020-12-12 01:56:19,919 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2020-12-12 01:56:19,919 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2020-12-12 01:56:19,919 [pool-19-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 2020-12-12 01:56:19,919 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169
datanode_3  | 2020-12-12 01:56:19,920 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169
datanode_3  | 2020-12-12 01:56:19,920 [pool-19-thread-1] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169: start as a follower, conf=-1: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858], old=null
datanode_3  | 2020-12-12 01:56:19,920 [pool-19-thread-1] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2020-12-12 01:56:19,922 [pool-19-thread-1] INFO impl.RoleInfo: c825d659-cfaa-4cfc-8134-552ad3e9db61: start c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-FollowerState
datanode_3  | 2020-12-12 01:56:19,923 [pool-19-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FCD203891169,id=c825d659-cfaa-4cfc-8134-552ad3e9db61
datanode_3  | 2020-12-12 01:56:19,923 [pool-19-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169
datanode_3  | 2020-12-12 01:56:19,928 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=9afcac27-3965-4d3f-919c-fcd203891169.
datanode_3  | 2020-12-12 01:56:23,778 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2 time=206ms
datanode_3  | 2020-12-12 01:56:25,045 [Thread-38] INFO impl.FollowerState: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-FollowerState: change to CANDIDATE, lastRpcTime:5124ms, electionTimeout:5119ms
datanode_3  | 2020-12-12 01:56:25,046 [Thread-38] INFO impl.RoleInfo: c825d659-cfaa-4cfc-8134-552ad3e9db61: shutdown c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-FollowerState
datanode_3  | 2020-12-12 01:56:25,046 [Thread-38] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2020-12-12 01:56:25,048 [Thread-38] INFO impl.RoleInfo: c825d659-cfaa-4cfc-8134-552ad3e9db61: start c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1
datanode_3  | 2020-12-12 01:56:25,055 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO impl.LeaderElection: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1: begin an election at term 1 for -1: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858], old=null
datanode_3  | 2020-12-12 01:56:25,057 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO impl.RoleInfo: c825d659-cfaa-4cfc-8134-552ad3e9db61: shutdown c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1
datanode_3  | 2020-12-12 01:56:25,058 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2020-12-12 01:56:25,058 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-FCD203891169 with new leaderId: c825d659-cfaa-4cfc-8134-552ad3e9db61
datanode_3  | 2020-12-12 01:56:25,058 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169: change Leader from null to c825d659-cfaa-4cfc-8134-552ad3e9db61 at term 1 for becomeLeader, leader elected after 5161ms
datanode_3  | 2020-12-12 01:56:25,071 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2020-12-12 01:56:25,073 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2020-12-12 01:56:25,074 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_appender.c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169
datanode_3  | 2020-12-12 01:56:25,078 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2020-12-12 01:56:25,080 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1073741824 (custom)
datanode_3  | 2020-12-12 01:56:25,092 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2020-12-12 01:56:25,094 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2020-12-12 01:56:25,097 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om2_1       | 2020-12-12 01:56:09,775 [Listener at om2/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om2 at port 9872
om2_1       | 2020-12-12 01:56:09,897 [Listener at om2/9862] INFO impl.RaftServerImpl: om2@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om2_1       | 2020-12-12 01:56:09,914 [Listener at om2/9862] INFO impl.RaftServerImpl: om2@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om2_1       | 2020-12-12 01:56:09,915 [Listener at om2/9862] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1       | 2020-12-12 01:56:09,937 [Listener at om2/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om2
om2_1       | 2020-12-12 01:56:09,939 [Listener at om2/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om2@group-562213E44849
om2_1       | 2020-12-12 01:56:09,970 [Listener at om2/9862] INFO impl.RaftServerProxy: om2: start RPC server
om2_1       | 2020-12-12 01:56:10,389 [Listener at om2/9862] INFO server.GrpcService: om2: GrpcService started, listening on 0.0.0.0/0.0.0.0:9872
om2_1       | 2020-12-12 01:56:10,406 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om2_1       | 2020-12-12 01:56:10,407 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om2_1       | 2020-12-12 01:56:10,481 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] INFO server.JvmPauseMonitor: Starting Ratis JVM pause monitor
om2_1       | 2020-12-12 01:56:10,594 [Listener at om2/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om2_1       | 2020-12-12 01:56:10,612 [Listener at om2/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om2_1       | 2020-12-12 01:56:10,761 [Listener at om2/9862] INFO util.log: Logging initialized @23958ms to org.eclipse.jetty.util.log.Slf4jLog
om2_1       | 2020-12-12 01:56:11,021 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | No GCs detected
om2_1       | 2020-12-12 01:56:11,030 [Thread-12] INFO impl.FollowerState: om2@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcTime:1115ms, electionTimeout:1069ms
om2_1       | 2020-12-12 01:56:11,050 [Thread-12] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1       | 2020-12-12 01:56:11,051 [Thread-12] INFO impl.RaftServerImpl: om2@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om2_1       | 2020-12-12 01:56:11,066 [Thread-12] INFO impl.RoleInfo: om2: start om2@group-562213E44849-LeaderElection1
om2_1       | 2020-12-12 01:56:11,261 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: begin an election at term 1 for -1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om2_1       | 2020-12-12 01:56:11,267 [Listener at om2/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om2_1       | 2020-12-12 01:56:11,322 [Listener at om2/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om2_1       | 2020-12-12 01:56:11,341 [Listener at om2/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om2_1       | 2020-12-12 01:56:11,352 [Listener at om2/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om2_1       | 2020-12-12 01:56:11,352 [Listener at om2/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
om2_1       | 2020-12-12 01:56:11,368 [Listener at om2/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om2_1       | 2020-12-12 01:56:11,526 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om2_1       | No GCs detected
om2_1       | 2020-12-12 01:56:11,670 [Listener at om2/9862] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om2_1       | 2020-12-12 01:56:11,698 [Listener at om2/9862] INFO http.HttpServer2: Jetty bound to port 9874
om2_1       | 2020-12-12 01:56:11,706 [Listener at om2/9862] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
om2_1       | 2020-12-12 01:56:12,031 [Listener at om2/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om2_1       | 2020-12-12 01:56:12,071 [Listener at om2/9862] INFO server.session: No SessionScavenger set, using defaults
om2_1       | 2020-12-12 01:56:12,079 [Listener at om2/9862] INFO server.session: node0 Scavenging every 660000ms
om2_1       | 2020-12-12 01:56:12,173 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@64cec4d0{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om2_1       | 2020-12-12 01:56:12,181 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68dc2f53{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om2_1       | 2020-12-12 01:56:12,533 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
om2_1       | GC pool 'ParNew' had collection(s): count=1 time=79ms
om2_1       | 2020-12-12 01:56:12,623 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); om2@group-562213E44849:t1, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om2_1       | 2020-12-12 01:56:12,704 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: begin an election at term 2 for -1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om2_1       | 2020-12-12 01:56:13,019 [Listener at om2/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@62158618{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-1_1_0-SNAPSHOT_jar-_-any-6826512455523229326/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/ozoneManager}
om2_1       | 2020-12-12 01:56:13,045 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
om2_1       | GC pool 'ParNew' had collection(s): count=1 time=79ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
om2_1       | 2020-12-12 01:56:13,100 [Listener at om2/9862] INFO server.AbstractConnector: Started ServerConnector@763ddfc3{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om2_1       | 2020-12-12 01:56:13,102 [Listener at om2/9862] INFO server.Server: Started @26299ms
om2_1       | 2020-12-12 01:56:13,108 [Listener at om2/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1       | 2020-12-12 01:56:13,108 [Listener at om2/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om2_1       | 2020-12-12 01:56:13,129 [Listener at om2/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
datanode_2  | 2020-12-12 01:59:05,060 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3581,entriesCount=1,lastEntry=(t:1, i:65)
datanode_2  | 2020-12-12 01:59:05,097 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3582,entriesCount=1,lastEntry=(t:1, i:66)
datanode_2  | 2020-12-12 01:59:05,123 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3583,entriesCount=1,lastEntry=(t:1, i:67)
datanode_2  | 2020-12-12 01:59:05,144 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3584,entriesCount=1,lastEntry=(t:1, i:68)
datanode_2  | 2020-12-12 01:59:05,145 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3585,entriesCount=1,lastEntry=(t:1, i:69)
datanode_2  | 2020-12-12 01:59:05,208 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3586,entriesCount=1,lastEntry=(t:1, i:70)
datanode_2  | 2020-12-12 01:59:05,221 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3587,entriesCount=1,lastEntry=(t:1, i:71)
datanode_2  | 2020-12-12 01:59:05,253 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3588,entriesCount=1,lastEntry=(t:1, i:72)
datanode_2  | 2020-12-12 01:59:05,254 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3589,entriesCount=1,lastEntry=(t:1, i:73)
datanode_2  | 2020-12-12 01:59:05,255 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3590,entriesCount=1,lastEntry=(t:1, i:74)
datanode_2  | 2020-12-12 01:59:05,431 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3606,entriesCount=1,lastEntry=(t:1, i:75)
datanode_2  | 2020-12-12 01:59:05,584 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3619,entriesCount=1,lastEntry=(t:1, i:76)
datanode_2  | 2020-12-12 01:59:05,604 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
datanode_2  | GC pool 'ParNew' had collection(s): count=14 time=636ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=50ms
datanode_2  | 2020-12-12 01:59:05,609 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3622,entriesCount=1,lastEntry=(t:1, i:77)
datanode_2  | 2020-12-12 01:59:05,620 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3623,entriesCount=1,lastEntry=(t:1, i:78)
datanode_2  | 2020-12-12 01:59:05,630 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3624,entriesCount=1,lastEntry=(t:1, i:79)
datanode_2  | 2020-12-12 01:59:05,755 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3633,entriesCount=1,lastEntry=(t:1, i:80)
datanode_2  | 2020-12-12 01:59:05,767 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3635,entriesCount=1,lastEntry=(t:1, i:81)
datanode_2  | 2020-12-12 01:59:12,063 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3895,entriesCount=1,lastEntry=(t:1, i:82)
datanode_2  | 2020-12-12 01:59:12,090 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3896,entriesCount=1,lastEntry=(t:1, i:83)
datanode_2  | 2020-12-12 01:59:12,108 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3897,entriesCount=1,lastEntry=(t:1, i:84)
datanode_2  | 2020-12-12 01:59:12,382 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3898,entriesCount=1,lastEntry=(t:1, i:85)
datanode_2  | 2020-12-12 01:59:12,427 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=3903,entriesCount=1,lastEntry=(t:1, i:86)
datanode_2  | 2020-12-12 01:59:13,108 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=16 time=672ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=50ms
datanode_2  | 2020-12-12 01:59:16,481 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4154,entriesCount=1,lastEntry=(t:1, i:87)
datanode_2  | 2020-12-12 01:59:16,548 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4155,entriesCount=1,lastEntry=(t:1, i:88)
datanode_2  | 2020-12-12 01:59:16,550 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4156,entriesCount=1,lastEntry=(t:1, i:89)
om1_1       | GC pool 'ParNew' had collection(s): count=7 time=245ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 01:56:52,716 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-71407 in volume:s3v
om1_1       | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1       | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-12 01:56:52,774 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=8 time=290ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 01:56:58,106 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om1_1       | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om1_1       | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:118)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-12 01:57:13,302 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11ms
om1_1       | GC pool 'ParNew' had collection(s): count=8 time=290ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 01:57:35,651 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-18154/36516/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om1_1       | 2020-12-12 01:57:35,652 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 36516/multipartKey2 in Volume/Bucket s3v/bucket-18154
om1_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 36516/multipartKey2. Entity too small.
om1_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:227)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-12 01:57:36,815 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-18154/83908/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om1_1       | partName: "etag1"
om1_1       | , partNumber: 2
om1_1       | partName: "etag2"
om1_1       | ]
om1_1       | 2020-12-12 01:57:36,817 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 83908/multipartKey3 in Volume/Bucket s3v/bucket-18154
om1_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3
om1_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:167)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-12 01:57:37,352 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-18154/83908/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om1_1       | partName: "etag1"
om1_1       | , partNumber: 1
om1_1       | partName: "etag2"
om1_1       | ]
om1_1       | 2020-12-12 01:57:37,353 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 83908/multipartKey3 in Volume/Bucket s3v/bucket-18154
om1_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3
om1_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:167)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
s3g_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
s3g_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1       | 2020-12-12 01:55:19,478 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1       | 2020-12-12 01:55:19,485 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
s3g_1       | 2020-12-12 01:55:20,065 [main] INFO util.log: Logging initialized @10477ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1       | 2020-12-12 01:55:20,785 [main] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
s3g_1       | 2020-12-12 01:55:21,019 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1       | 2020-12-12 01:55:21,071 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1       | 2020-12-12 01:55:21,098 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context s3gateway
s3g_1       | 2020-12-12 01:55:21,118 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
s3g_1       | 2020-12-12 01:55:21,120 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
s3g_1       | 2020-12-12 01:55:21,581 [main] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
s3g_1       | 2020-12-12 01:55:21,750 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1       | /************************************************************
s3g_1       | STARTUP_MSG: Starting Gateway
s3g_1       | STARTUP_MSG:   host = 87d3f9878f0f/172.23.0.4
s3g_1       | STARTUP_MSG:   args = []
s3g_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
s3g_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/hadoop-ozone-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.22.0-CR2.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.5.0.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/validation-api-1.1.0.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.27.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.27.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.27.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.27.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.ws.rs-api-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.10.3.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.4.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.5.0-b42.jar:/opt/hadoop/share/ozone/lib/hadoop-ozone-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.27.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.27.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.27.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar
s3g_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/6677200a7be75370c0ddcdd93197dda3227c6cdb ; compiled by 'runner' on 2020-12-12T01:24Z
s3g_1       | STARTUP_MSG:   java = 11.0.7
s3g_1       | ************************************************************/
s3g_1       | 2020-12-12 01:55:21,789 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | 2020-12-12 01:55:22,021 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1       | 2020-12-12 01:55:22,057 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1       | 2020-12-12 01:55:22,100 [main] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
s3g_1       | 2020-12-12 01:55:22,309 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1       | 2020-12-12 01:55:22,312 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1       | 2020-12-12 01:55:22,313 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1       | 2020-12-12 01:55:22,409 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@395b56bb{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 2020-12-12 01:55:22,413 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5c10f1c3{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1       | WARNING: An illegal reflective access operation has occurred
s3g_1       | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_2  | 2020-12-12 01:59:16,670 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4157,entriesCount=1,lastEntry=(t:1, i:90)
datanode_2  | 2020-12-12 01:59:16,683 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4159,entriesCount=1,lastEntry=(t:1, i:91)
datanode_2  | 2020-12-12 01:59:21,448 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4408,entriesCount=1,lastEntry=(t:1, i:92)
datanode_2  | 2020-12-12 01:59:21,535 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4409,entriesCount=1,lastEntry=(t:1, i:93)
datanode_2  | 2020-12-12 01:59:21,572 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4413,entriesCount=1,lastEntry=(t:1, i:94)
datanode_2  | 2020-12-12 01:59:21,575 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4415,entriesCount=1,lastEntry=(t:1, i:95)
datanode_2  | 2020-12-12 01:59:21,588 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4417,entriesCount=1,lastEntry=(t:1, i:96)
datanode_2  | 2020-12-12 01:59:21,656 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4424,entriesCount=1,lastEntry=(t:1, i:97)
datanode_2  | 2020-12-12 01:59:21,661 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4425,entriesCount=1,lastEntry=(t:1, i:98)
datanode_2  | 2020-12-12 01:59:21,681 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4427,entriesCount=1,lastEntry=(t:1, i:99)
om3_1       | 2020-12-12 01:56:08,030 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om3_1       | 2020-12-12 01:56:08,030 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1       | 2020-12-12 01:56:08,031 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om3_1       | 2020-12-12 01:56:08,114 [main] INFO snapshot.OzoneManagerSnapshotProvider: Initializing OM Snapshot Provider
om3_1       | 2020-12-12 01:56:08,195 [pool-17-thread-1] INFO impl.RaftServerImpl: om3: new RaftServerImpl for group-562213E44849:[om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872] with OzoneManagerStateMachine:uninitialized
om3_1       | 2020-12-12 01:56:08,211 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 1s (custom)
om3_1       | 2020-12-12 01:56:08,223 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 1200ms (custom)
om3_1       | 2020-12-12 01:56:08,224 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1       | 2020-12-12 01:56:08,224 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1       | 2020-12-12 01:56:08,225 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300 (default)
om3_1       | 2020-12-12 01:56:08,247 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om3_1       | 2020-12-12 01:56:08,326 [pool-17-thread-1] INFO impl.RaftServerImpl: om3@group-562213E44849: ConfigurationManager, init=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null, confs=<EMPTY_MAP>
om3_1       | 2020-12-12 01:56:08,326 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om3_1       | 2020-12-12 01:56:08,365 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om3_1       | 2020-12-12 01:56:08,372 [pool-17-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 does not exist. Creating ...
om3_1       | 2020-12-12 01:56:08,432 [pool-17-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/in_use.lock acquired by nodename 6@de3cb7ba8a1d
om3_1       | 2020-12-12 01:56:08,551 [pool-17-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849 has been successfully formatted.
om3_1       | 2020-12-12 01:56:08,559 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
om3_1       | 2020-12-12 01:56:08,574 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om3_1       | 2020-12-12 01:56:08,604 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om3_1       | 2020-12-12 01:56:08,693 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.log_worker.om3@group-562213E44849
om3_1       | 2020-12-12 01:56:08,806 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om3_1       | 2020-12-12 01:56:08,811 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1       | 2020-12-12 01:56:08,921 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om3_1       | 2020-12-12 01:56:08,952 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: new om3@group-562213E44849-SegmentedRaftLogWorker for RaftStorage:Storage Directory /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849
om3_1       | 2020-12-12 01:56:08,984 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om3_1       | 2020-12-12 01:56:08,985 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om3_1       | 2020-12-12 01:56:08,997 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om3_1       | 2020-12-12 01:56:08,997 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om3_1       | 2020-12-12 01:56:09,000 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om3_1       | 2020-12-12 01:56:09,003 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om3_1       | 2020-12-12 01:56:09,010 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om3_1       | 2020-12-12 01:56:09,018 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om3_1       | 2020-12-12 01:56:09,019 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om3_1       | 2020-12-12 01:56:09,094 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om3_1       | 2020-12-12 01:56:09,110 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om3_1       | 2020-12-12 01:56:09,110 [pool-17-thread-1] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om3_1       | 2020-12-12 01:56:09,124 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om3_1       | 2020-12-12 01:56:09,136 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om3_1       | 2020-12-12 01:56:09,138 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om3_1       | 2020-12-12 01:56:09,140 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om3_1       | 2020-12-12 01:56:09,142 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om3_1       | 2020-12-12 01:56:09,272 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.leader_election.om3@group-562213E44849
om3_1       | 2020-12-12 01:56:09,287 [pool-17-thread-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server.om3@group-562213E44849
om3_1       | 2020-12-12 01:56:09,498 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om3_1       | 2020-12-12 01:56:09,542 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om3_1       | 2020-12-12 01:56:10,018 [Listener at om3/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om3_1       | 2020-12-12 01:56:10,174 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om3_1       | 2020-12-12 01:56:10,174 [Listener at om3/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
om3_1       | 2020-12-12 01:56:10,448 [Listener at om3/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om3/172.23.0.6:9862
om3_1       | 2020-12-12 01:56:10,469 [Listener at om3/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om3 at port 9872
om3_1       | 2020-12-12 01:56:10,501 [Listener at om3/9862] INFO impl.RaftServerImpl: om3@group-562213E44849: start as a follower, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om3_1       | 2020-12-12 01:56:10,509 [Listener at om3/9862] INFO impl.RaftServerImpl: om3@group-562213E44849: changes role from      null to FOLLOWER at term 0 for startAsFollower
om3_1       | 2020-12-12 01:56:10,511 [Listener at om3/9862] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
om3_1       | 2020-12-12 01:56:10,520 [Listener at om3/9862] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-562213E44849,id=om3
om3_1       | 2020-12-12 01:56:10,527 [Listener at om3/9862] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.state_machine.om3@group-562213E44849
om3_1       | 2020-12-12 01:56:10,556 [Listener at om3/9862] INFO impl.RaftServerProxy: om3: start RPC server
om3_1       | 2020-12-12 01:56:10,832 [Listener at om3/9862] INFO server.GrpcService: om3: GrpcService started, listening on 0.0.0.0/0.0.0.0:9872
om3_1       | 2020-12-12 01:56:10,852 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om3_1       | 2020-12-12 01:56:10,852 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om3_1       | 2020-12-12 01:56:10,899 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] INFO server.JvmPauseMonitor: Starting Ratis JVM pause monitor
om3_1       | 2020-12-12 01:56:11,168 [Listener at om3/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om3_1       | 2020-12-12 01:56:11,168 [Listener at om3/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
om3_1       | 2020-12-12 01:56:11,309 [Listener at om3/9862] INFO util.log: Logging initialized @24462ms to org.eclipse.jetty.util.log.Slf4jLog
om3_1       | 2020-12-12 01:56:11,428 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | No GCs detected
om3_1       | 2020-12-12 01:56:11,691 [Thread-12] INFO impl.FollowerState: om3@group-562213E44849-FollowerState: change to CANDIDATE, lastRpcTime:1180ms, electionTimeout:1155ms
om3_1       | 2020-12-12 01:56:11,695 [Thread-12] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1       | 2020-12-12 01:56:11,708 [Thread-12] INFO impl.RaftServerImpl: om3@group-562213E44849: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om3_1       | 2020-12-12 01:56:11,716 [Thread-12] INFO impl.RoleInfo: om3: start om3@group-562213E44849-LeaderElection1
om3_1       | 2020-12-12 01:56:11,758 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: begin an election at term 1 for -1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om3_1       | 2020-12-12 01:56:11,867 [Listener at om3/9862] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
om3_1       | 2020-12-12 01:56:11,891 [Listener at om3/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om3_1       | 2020-12-12 01:56:11,920 [Listener at om3/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om3_1       | 2020-12-12 01:56:11,949 [Listener at om3/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
om3_1       | 2020-12-12 01:56:11,949 [Listener at om3/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode_2  | 2020-12-12 01:59:25,685 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4678,entriesCount=1,lastEntry=(t:1, i:100)
datanode_2  | 2020-12-12 01:59:25,759 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4679,entriesCount=1,lastEntry=(t:1, i:101)
datanode_2  | 2020-12-12 01:59:25,800 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4681,entriesCount=1,lastEntry=(t:1, i:102)
datanode_2  | 2020-12-12 01:59:25,862 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4686,entriesCount=1,lastEntry=(t:1, i:103)
datanode_2  | 2020-12-12 01:59:25,870 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4688,entriesCount=1,lastEntry=(t:1, i:104)
datanode_2  | 2020-12-12 01:59:25,876 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4689,entriesCount=1,lastEntry=(t:1, i:105)
datanode_2  | 2020-12-12 01:59:25,923 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4695,entriesCount=1,lastEntry=(t:1, i:106)
datanode_2  | 2020-12-12 01:59:29,153 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4946,entriesCount=1,lastEntry=(t:1, i:107)
datanode_2  | 2020-12-12 01:59:29,153 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4947,entriesCount=1,lastEntry=(t:1, i:108)
datanode_2  | 2020-12-12 01:59:29,166 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4948,entriesCount=1,lastEntry=(t:1, i:109)
datanode_2  | 2020-12-12 01:59:29,181 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=4949,entriesCount=1,lastEntry=(t:1, i:110)
datanode_2  | 2020-12-12 01:59:34,122 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_2  | GC pool 'ParNew' had collection(s): count=26 time=886ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=86ms
datanode_2  | 2020-12-12 01:59:38,744 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5199,entriesCount=1,lastEntry=(t:1, i:111)
datanode_2  | 2020-12-12 01:59:38,754 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5200,entriesCount=1,lastEntry=(t:1, i:112)
datanode_2  | 2020-12-12 01:59:38,776 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5201,entriesCount=1,lastEntry=(t:1, i:113)
datanode_2  | 2020-12-12 01:59:38,833 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5207,entriesCount=1,lastEntry=(t:1, i:114)
datanode_2  | 2020-12-12 01:59:42,603 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5456,entriesCount=1,lastEntry=(t:1, i:115)
datanode_2  | 2020-12-12 01:59:42,603 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5457,entriesCount=1,lastEntry=(t:1, i:116)
datanode_2  | 2020-12-12 01:59:42,603 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5458,entriesCount=1,lastEntry=(t:1, i:117)
datanode_2  | 2020-12-12 01:59:44,129 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=31 time=1062ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=86ms
datanode_2  | 2020-12-12 01:59:46,265 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5706,entriesCount=1,lastEntry=(t:1, i:118)
datanode_2  | 2020-12-12 01:59:46,276 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5707,entriesCount=1,lastEntry=(t:1, i:119)
om2_1       | 2020-12-12 01:56:13,143 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om2_1       | 2020-12-12 01:56:13,337 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om2_1       | 2020-12-12 01:56:13,338 [Listener at om2/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om2_1       | 2020-12-12 01:56:13,347 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73c1dda3] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om2_1       | 2020-12-12 01:56:13,386 [grpc-default-executor-0] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om2
om2_1       | 2020-12-12 01:56:13,473 [om2@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om2@group-562213E44849-LeaderElection1: Election DISCOVERED_A_NEW_TERM; received 1 response(s) [om2<-om1#0:FAIL-t3] and 0 exception(s); om2@group-562213E44849:t2, leader=null, voted=om2, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om2_1       | 2020-12-12 01:56:13,474 [om2@group-562213E44849-LeaderElection1] INFO impl.RaftServerImpl: om2@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 3 for DISCOVERED_A_NEW_TERM
om2_1       | 2020-12-12 01:56:13,474 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-LeaderElection1
om2_1       | 2020-12-12 01:56:13,475 [om2@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1       | 2020-12-12 01:56:13,528 [grpc-default-executor-0] INFO impl.RaftServerImpl: om2@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 3 for recognizeCandidate:om1
om2_1       | 2020-12-12 01:56:13,529 [grpc-default-executor-0] INFO impl.RoleInfo: om2: shutdown om2@group-562213E44849-FollowerState
om2_1       | 2020-12-12 01:56:13,529 [grpc-default-executor-0] INFO impl.RoleInfo: om2: start om2@group-562213E44849-FollowerState
om2_1       | 2020-12-12 01:56:13,529 [grpc-default-executor-0] INFO impl.RaftServerImpl:  FOLLOWER om2@group-562213E44849:t3, leader=null, voted=null, raftlog=om2@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null RUNNING priority:0 candidate:om1|rpc:om1:9872 candidatePriority:0 compare:0
om2_1       | 2020-12-12 01:56:13,532 [Thread-131] INFO impl.FollowerState: om2@group-562213E44849-FollowerState was interrupted: {}
om2_1       | java.lang.InterruptedException: sleep interrupted
om2_1       | 	at java.base/java.lang.Thread.sleep(Native Method)
om2_1       | 	at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:250)
om2_1       | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:116)
om2_1       | 2020-12-12 01:56:13,547 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=2 time=179ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
om2_1       | 2020-12-12 01:56:13,882 [grpc-default-executor-1] INFO impl.RaftServerImpl: om2@group-562213E44849: change Leader from null to om1 at term 3 for appendEntries, leader elected after 5992ms
om2_1       | 2020-12-12 01:56:13,966 [grpc-default-executor-1] INFO impl.RaftServerImpl: om2@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|dataStream:, om3|rpc:om3:9872|dataStream:, om2|rpc:om2:9872|dataStream:], old=null at 0
om2_1       | 2020-12-12 01:56:13,986 [grpc-default-executor-1] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
om2_1       | 2020-12-12 01:56:14,256 [om2@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om2@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om2_1       | 2020-12-12 01:56:32,566 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om2_1       | GC pool 'ParNew' had collection(s): count=4 time=317ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
om2_1       | 2020-12-12 01:56:33,070 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om2_1       | GC pool 'ParNew' had collection(s): count=5 time=354ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
om2_1       | 2020-12-12 01:56:37,078 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
om2_1       | GC pool 'ParNew' had collection(s): count=7 time=414ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
om2_1       | 2020-12-12 01:56:49,599 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12ms
om2_1       | GC pool 'ParNew' had collection(s): count=7 time=414ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
om2_1       | 2020-12-12 01:56:52,727 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-71407 in volume:s3v
om2_1       | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1       | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1       | 2020-12-12 01:56:58,118 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om2_1       | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1       | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:118)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | WARNING: All illegal access operations will be denied in a future release
s3g_1       | Dec 12, 2020 1:55:40 AM org.glassfish.jersey.internal.Errors logErrors
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1       | 
s3g_1       | 2020-12-12 01:55:40,822 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@721bf7ad{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-hadoop-ozone-s3gateway-1_1_0-SNAPSHOT_jar-_-any-825368347363829162/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-s3gateway-1.1.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1       | 2020-12-12 01:55:40,845 [main] INFO server.AbstractConnector: Started ServerConnector@3fa2213{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1       | 2020-12-12 01:55:40,845 [main] INFO server.Server: Started @31266ms
s3g_1       | 2020-12-12 01:55:40,850 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
s3g_1       | 2020-12-12 01:56:30,763 [qtp166454155-21] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-62113, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-12 01:56:31,369 [qtp166454155-21] INFO endpoint.BucketEndpoint: Location is /bucket-62113
s3g_1       | 2020-12-12 01:56:35,660 [qtp166454155-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-68915, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-12 01:56:35,678 [qtp166454155-20] INFO endpoint.BucketEndpoint: Location is /bucket-68915
s3g_1       | 2020-12-12 01:56:38,313 [qtp166454155-22] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1       | 2020-12-12 01:56:38,345 [qtp166454155-22] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1       | 2020-12-12 01:56:38,345 [qtp166454155-22] INFO impl.MetricsSystemImpl: XceiverClientMetrics metrics system started
s3g_1       | 2020-12-12 01:56:38,349 [qtp166454155-22] WARN impl.MetricsSystemImpl: Sink prometheus already exists!
s3g_1       | 2020-12-12 01:56:38,722 [qtp166454155-22] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
s3g_1       | 2020-12-12 01:56:38,723 [qtp166454155-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0D117D0B4CCC->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:56:38,724 [qtp166454155-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-12-12 01:55:16,088 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = 3f29fe393305/172.23.0.3
scm_1       | STARTUP_MSG:   args = [--init]
scm_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar
s3g_1       | 2020-12-12 01:56:44,502 [qtp166454155-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-6BFE4A6D99C8->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:56:44,502 [qtp166454155-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:56:51,514 [qtp166454155-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-71407, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-12 01:56:51,530 [qtp166454155-20] INFO endpoint.BucketEndpoint: Location is /bucket-71407
s3g_1       | 2020-12-12 01:56:52,151 [qtp166454155-22] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-22177, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-12 01:56:52,166 [qtp166454155-22] INFO endpoint.BucketEndpoint: Location is /bucket-22177
s3g_1       | 2020-12-12 01:56:52,703 [qtp166454155-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-71407, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-12 01:56:52,737 [qtp166454155-20] INFO endpoint.BucketEndpoint: Location is /bucket-71407
s3g_1       | 2020-12-12 01:56:53,332 [qtp166454155-22] ERROR endpoint.BucketEndpoint: Error in Create Bucket Request for bucket: bucket_1
s3g_1       | INVALID_BUCKET_NAME org.apache.hadoop.ozone.om.exceptions.OMException: Bucket or Volume name has an unsupported character : _
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.verifyBucketName(RpcClient.java:444)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:388)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.createBucket(RpcClient.java:379)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneVolume.createBucket(OzoneVolume.java:314)
s3g_1       | 	at org.apache.hadoop.ozone.client.ObjectStore.createS3Bucket(ObjectStore.java:118)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.createS3Bucket(EndpointBase.java:96)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.put(BucketEndpoint.java:210)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
datanode_3  | 2020-12-12 01:56:25,107 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO impl.RoleInfo: c825d659-cfaa-4cfc-8134-552ad3e9db61: start c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderState
datanode_3  | 2020-12-12 01:56:25,119 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2020-12-12 01:56:25,121 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/9afcac27-3965-4d3f-919c-fcd203891169/current/log_inprogress_0
datanode_3  | 2020-12-12 01:56:25,123 [c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169-LeaderElection1] INFO impl.RaftServerImpl: c825d659-cfaa-4cfc-8134-552ad3e9db61@group-FCD203891169: set configuration 0: [c825d659-cfaa-4cfc-8134-552ad3e9db61|rpc:172.23.0.7:9858|dataStream:], old=null at 0
datanode_3  | 2020-12-12 01:56:25,283 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | GC pool 'ParNew' had collection(s): count=3 time=243ms
datanode_3  | 2020-12-12 01:56:34,790 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=3 time=243ms
datanode_3  | 2020-12-12 01:57:10,310 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=5 time=354ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=24ms
datanode_3  | 2020-12-12 01:58:05,427 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 86ms
datanode_3  | GC pool 'ParNew' had collection(s): count=9 time=550ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=27ms
datanode_3  | 2020-12-12 01:58:08,933 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=9 time=550ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=27ms
datanode_3  | 2020-12-12 01:58:11,937 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=9 time=550ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 01:58:25,945 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=12 time=610ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 01:58:28,449 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=12 time=610ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 01:58:45,460 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=12 time=610ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 01:59:20,983 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_3  | GC pool 'ParNew' had collection(s): count=82 time=926ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 01:59:36,993 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=221 time=1306ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 01:59:53,503 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=363 time=1747ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 01:59:59,507 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=413 time=1906ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:00:12,519 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_3  | GC pool 'ParNew' had collection(s): count=523 time=2226ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:00:43,040 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | GC pool 'ParNew' had collection(s): count=788 time=3036ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:00:52,554 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | GC pool 'ParNew' had collection(s): count=851 time=3230ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:00:54,557 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=871 time=3278ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:01:05,071 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=963 time=3510ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:01:29,588 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1181 time=4156ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:01:30,090 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1185 time=4171ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:01:37,097 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1251 time=4359ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:01:37,604 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1255 time=4400ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:01:38,105 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1259 time=4411ms
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-12-12 01:56:53,687 [qtp166454155-22] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidBucketName</Code>
s3g_1       |   <Message>The specified bucket is not valid.</Message>
s3g_1       |   <Resource>bucket_1</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-12 01:56:56,256 [qtp166454155-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-91706, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-12 01:56:56,274 [qtp166454155-20] INFO endpoint.BucketEndpoint: Location is /bucket-91706
s3g_1       | 2020-12-12 01:56:56,804 [qtp166454155-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-83591, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-12 01:56:56,819 [qtp166454155-20] INFO endpoint.BucketEndpoint: Location is /bucket-83591
s3g_1       | 2020-12-12 01:56:58,111 [qtp166454155-22] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchBucket</Code>
s3g_1       |   <Message>The specified bucket does not exist</Message>
s3g_1       |   <Resource>nosuchbucket</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-12 01:57:00,730 [qtp166454155-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-13347, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-12 01:57:00,757 [qtp166454155-20] INFO endpoint.BucketEndpoint: Location is /bucket-13347
s3g_1       | 2020-12-12 01:57:01,887 [qtp166454155-22] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchBucket</Code>
s3g_1       |   <Message>The specified bucket does not exist</Message>
s3g_1       |   <Resource>ozonenosuchbucketqqweqwe</Resource>
s3g_1       |   <RequestId/>
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:01:41,613 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_2  | 2020-12-12 01:59:46,280 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5708,entriesCount=1,lastEntry=(t:1, i:120)
datanode_2  | 2020-12-12 01:59:46,314 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5709,entriesCount=1,lastEntry=(t:1, i:121)
datanode_2  | 2020-12-12 01:59:48,157 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26ms
datanode_2  | GC pool 'ParNew' had collection(s): count=34 time=1160ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=86ms
datanode_2  | 2020-12-12 01:59:54,997 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5959,entriesCount=1,lastEntry=(t:1, i:122)
datanode_2  | 2020-12-12 01:59:55,006 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5960,entriesCount=1,lastEntry=(t:1, i:123)
datanode_2  | 2020-12-12 01:59:55,016 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5963,entriesCount=1,lastEntry=(t:1, i:124)
scm_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/6677200a7be75370c0ddcdd93197dda3227c6cdb ; compiled by 'runner' on 2020-12-12T01:23Z
scm_1       | STARTUP_MSG:   java = 11.0.7
scm_1       | ************************************************************/
scm_1       | 2020-12-12 01:55:16,244 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-12-12 01:55:16,980 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-12-12 01:55:17,502 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-16ca7467-b1f6-4a00-b411-db2381979a3b;layoutVersion=0
scm_1       | 2020-12-12 01:55:17,588 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at 3f29fe393305/172.23.0.3
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2020-12-12 01:55:35,113 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = 3f29fe393305/172.23.0.3
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 1.1.0-SNAPSHOT
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.1.0-913f5a4-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.34.v20201102.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/6677200a7be75370c0ddcdd93197dda3227c6cdb ; compiled by 'runner' on 2020-12-12T01:23Z
scm_1       | STARTUP_MSG:   java = 11.0.7
scm_1       | ************************************************************/
scm_1       | 2020-12-12 01:55:35,192 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2020-12-12 01:55:36,671 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-12-12 01:55:39,821 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2020-12-12 01:55:41,013 [main] INFO net.NodeSchemaLoader: Loading file from java.lang.CompoundEnumeration@436390f4
scm_1       | 2020-12-12 01:55:41,023 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1       | 2020-12-12 01:55:41,353 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm_1       | 2020-12-12 01:55:41,600 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       | 2020-12-12 01:55:41,700 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.DefaultLeaderChoosePolicy
scm_1       | 2020-12-12 01:55:41,701 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
scm_1       | 2020-12-12 01:55:41,757 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm_1       | 2020-12-12 01:55:41,898 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2020-12-12 01:55:41,912 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1       | 2020-12-12 01:55:43,343 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-12-12 01:55:43,376 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2020-12-12 01:55:43,429 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-12-12 01:55:43,430 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1       | 2020-12-12 01:55:43,494 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2020-12-12 01:55:43,495 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm_1       | 2020-12-12 01:55:43,540 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm_1       | 2020-12-12 01:55:43,541 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
scm_1       | 2020-12-12 01:55:43,571 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @24037ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       | 2020-12-12 01:55:43,874 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
scm_1       | 2020-12-12 01:55:43,903 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1       | 2020-12-12 01:55:43,931 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       | 2020-12-12 01:55:43,942 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
scm_1       | 2020-12-12 01:55:43,943 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
scm_1       | 2020-12-12 01:55:43,943 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
scm_1       | 2020-12-12 01:55:44,020 [Listener at 0.0.0.0/9860] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
scm_1       | 2020-12-12 01:55:44,030 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1       | 2020-12-12 01:55:44,156 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       | 2020-12-12 01:55:44,237 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm_1       | 2020-12-12 01:55:44,237 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm_1       | 2020-12-12 01:55:44,764 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1       | 2020-12-12 01:55:44,771 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-12-12 01:55:44,777 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1       | 2020-12-12 01:55:44,846 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm_1       | 2020-12-12 01:55:44,847 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1       | 2020-12-12 01:55:44,849 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-12-12 01:55:44,849 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1       | 2020-12-12 01:55:44,910 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
scm_1       | 2020-12-12 01:55:44,910 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
scm_1       | 2020-12-12 01:55:44,915 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm_1       | 2020-12-12 01:55:44,915 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1       | 2020-12-12 01:57:07,611 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=8 time=449ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=40ms
om2_1       | 2020-12-12 01:57:35,659 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-18154/36516/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om2_1       | 2020-12-12 01:57:35,660 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 36516/multipartKey2 in Volume/Bucket s3v/bucket-18154
om2_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 36516/multipartKey2. Entity too small.
om2_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:227)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1       | 2020-12-12 01:57:36,825 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-18154/83908/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om2_1       | partName: "etag1"
om2_1       | , partNumber: 2
om2_1       | partName: "etag2"
om2_1       | ]
om2_1       | 2020-12-12 01:57:36,825 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 83908/multipartKey3 in Volume/Bucket s3v/bucket-18154
om2_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3
om2_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:167)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1       | 2020-12-12 01:57:37,354 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-18154/83908/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om2_1       | partName: "etag1"
om2_1       | , partNumber: 1
om2_1       | partName: "etag2"
om2_1       | ]
om2_1       | 2020-12-12 01:57:37,355 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 83908/multipartKey3 in Volume/Bucket s3v/bucket-18154
om2_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3
om2_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:167)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1       | 2020-12-12 01:57:48,547 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 83908/multipartKey3 in Volume/Bucket s3v/bucket-18154
om2_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-18154/83908/multipartKey3105364734474453005
om2_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1       | 2020-12-12 01:57:48,639 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | GC pool 'ParNew' had collection(s): count=9 time=487ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=57ms
om2_1       | 2020-12-12 01:57:49,124 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 83908/multipartKey3 in Volume/Bucket s3v/bucket-18154
om2_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-18154/83908/multipartKey3105364734706188302
om2_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
datanode_2  | 2020-12-12 01:59:55,027 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=5966,entriesCount=1,lastEntry=(t:1, i:125)
datanode_2  | 2020-12-12 02:00:01,551 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6217,entriesCount=1,lastEntry=(t:1, i:126)
datanode_2  | 2020-12-12 02:00:01,552 [java.util.concurrent.ThreadPoolExecutor$Worker@3359bb69[State = -1, empty queue]] WARN server.GrpcLogAppender: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41->c825d659-cfaa-4cfc-8134-552ad3e9db61-GrpcLogAppender:  appendEntries Timeout, request=AppendEntriesRequest:cid=6218,entriesCount=1,lastEntry=(t:1, i:127)
datanode_2  | 2020-12-12 02:00:04,665 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=42 time=1371ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=4 time=117ms
datanode_2  | 2020-12-12 02:00:14,173 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_2  | GC pool 'ParNew' had collection(s): count=47 time=1524ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=4 time=117ms
datanode_2  | 2020-12-12 02:00:20,178 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=50 time=1585ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=4 time=117ms
datanode_2  | 2020-12-12 02:00:23,682 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=52 time=1747ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=4 time=119ms
datanode_2  | 2020-12-12 02:01:22,216 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12ms
datanode_2  | GC pool 'ParNew' had collection(s): count=83 time=2624ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=163ms
datanode_2  | 2020-12-12 02:01:36,257 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=90 time=2791ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=7 time=191ms
datanode_2  | 2020-12-12 02:01:48,264 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=97 time=3030ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=7 time=191ms
datanode_2  | 2020-12-12 02:01:53,287 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 18ms
datanode_2  | GC pool 'ParNew' had collection(s): count=100 time=3125ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=7 time=191ms
datanode_2  | 2020-12-12 02:01:58,839 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 49ms
datanode_2  | GC pool 'ParNew' had collection(s): count=103 time=3222ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=8 time=213ms
datanode_2  | 2020-12-12 02:02:04,843 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=106 time=3312ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=8 time=213ms
datanode_2  | 2020-12-12 02:02:04,852 [Thread-184] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-B3F48DD8CFE6->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=121, seq=0, Watch-ALL_COMMITTED(131), Message:<EMPTY>, reply=RaftClientReply:client-B3F48DD8CFE6->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=121, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 121 and log index 131 is not yet replicated to ALL_COMMITTED, logIndex=131, commits[2efbbdc8-7434-4046-ac05-b8a2df4b2a7b:c140, c825d659-cfaa-4cfc-8134-552ad3e9db61:c127, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9:c140]
datanode_2  | 2020-12-12 02:02:21,856 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=114 time=3541ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=8 time=213ms
datanode_2  | 2020-12-12 02:02:33,371 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10ms
datanode_2  | GC pool 'ParNew' had collection(s): count=120 time=3672ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=9 time=272ms
datanode_2  | 2020-12-12 02:02:35,384 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12ms
datanode_2  | GC pool 'ParNew' had collection(s): count=121 time=3706ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=9 time=272ms
datanode_2  | 2020-12-12 02:02:38,889 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ParNew' had collection(s): count=122 time=3764ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=9 time=272ms
datanode_2  | 2020-12-12 02:02:49,395 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=128 time=3947ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=9 time=272ms
datanode_2  | 2020-12-12 02:02:54,407 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1291 time=4493ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:02:03,626 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1489 time=5067ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:02:08,632 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1531 time=5161ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:02:11,136 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1550 time=5218ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:02:22,644 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1628 time=5439ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:02:27,649 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1672 time=5575ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:02:32,162 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1709 time=5698ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:02:33,165 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1718 time=5721ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:02:34,171 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1726 time=5737ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:02:36,674 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1748 time=5810ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:02:45,181 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1820 time=6031ms
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-12 01:57:48,539 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 83908/multipartKey3 in Volume/Bucket s3v/bucket-18154
om1_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-18154/83908/multipartKey3105364734474453005
om1_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2020-12-12 01:55:45,004 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.23.0.9:45466
scm_1       | 2020-12-12 01:55:45,022 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm_1       | 2020-12-12 01:55:45,051 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
scm_1       | 2020-12-12 01:55:45,063 [IPC Server handler 4 on default port 9861] INFO ipc.Server: IPC Server handler 4 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.23.0.8:60656
scm_1       | 2020-12-12 01:55:45,294 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1       | 2020-12-12 01:55:45,297 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2020-12-12 01:55:45,308 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm_1       | 2020-12-12 01:55:45,382 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5fb7ab9c{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1       | 2020-12-12 01:55:45,384 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3dea226b{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | 2020-12-12 01:55:45,689 [IPC Server handler 1 on default port 9861] WARN ipc.Server: IPC Server handler 1 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.23.0.7:43548: output error
scm_1       | 2020-12-12 01:55:45,714 [IPC Server handler 1 on default port 9861] INFO ipc.Server: IPC Server handler 1 on default port 9861 caught an exception
scm_1       | java.nio.channels.AsynchronousCloseException
scm_1       | 	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
scm_1       | 	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
scm_1       | 	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
scm_1       | 	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
scm_1       | 	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
scm_1       | 	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
datanode_2  | GC pool 'ParNew' had collection(s): count=131 time=4051ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=9 time=272ms
datanode_2  | 2020-12-12 02:02:55,410 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ParNew' had collection(s): count=131 time=4051ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=9 time=272ms
datanode_2  | 2020-12-12 02:03:02,421 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
datanode_2  | GC pool 'ParNew' had collection(s): count=134 time=4126ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=290ms
datanode_2  | 2020-12-12 02:03:04,430 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8ms
datanode_2  | GC pool 'ParNew' had collection(s): count=135 time=4147ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=290ms
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-12 01:57:49,099 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 83908/multipartKey3 in Volume/Bucket s3v/bucket-18154
om1_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-18154/83908/multipartKey3105364734706188302
om1_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-12 01:57:49,715 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-18154/83908/multipartKey3
om1_1       | 2020-12-12 01:57:49,717 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 83908/multipartKey3 in Volume/Bucket s3v/bucket-18154
om1_1       | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3 because parts are in Invalid order.
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
s3g_1       | </Error>
om3_1       | 2020-12-12 01:56:11,949 [Listener at om3/9862] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
om3_1       | 2020-12-12 01:56:12,299 [Listener at om3/9862] WARN http.BaseHttpServer: /prof java profiling servlet is activated. Not safe for production!
om3_1       | 2020-12-12 01:56:12,341 [Listener at om3/9862] INFO http.HttpServer2: Jetty bound to port 9874
om3_1       | 2020-12-12 01:56:12,352 [Listener at om3/9862] INFO server.Server: jetty-9.4.34.v20201102; built: 2020-11-02T14:15:39.302Z; git: e46af88704a893fc12cb0e3bf46e2c7b48a009e7; jvm 11.0.7+10-LTS
om3_1       | 2020-12-12 01:56:12,436 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
om3_1       | GC pool 'ParNew' had collection(s): count=1 time=63ms
om3_1       | 2020-12-12 01:56:12,604 [Listener at om3/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om3_1       | 2020-12-12 01:56:12,604 [Listener at om3/9862] INFO server.session: No SessionScavenger set, using defaults
om3_1       | 2020-12-12 01:56:12,613 [Listener at om3/9862] INFO server.session: node0 Scavenging every 660000ms
s3g_1       | 
om3_1       | 2020-12-12 01:56:12,782 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@64cec4d0{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om3_1       | 2020-12-12 01:56:12,784 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@68dc2f53{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om3_1       | 2020-12-12 01:56:12,938 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=1 time=63ms
om3_1       | 2020-12-12 01:56:13,034 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: Election TIMEOUT; received 0 response(s) [] and 0 exception(s); om3@group-562213E44849:t1, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om3_1       | 2020-12-12 01:56:13,042 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: begin an election at term 2 for -1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
om3_1       | 2020-12-12 01:56:13,396 [grpc-default-executor-1] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.server_message_metrics.om3
om3_1       | 2020-12-12 01:56:13,440 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
s3g_1       | 2020-12-12 01:57:01,887 [qtp166454155-22] ERROR endpoint.BucketEndpoint: Exception occurred in headBucket
om3_1       | GC pool 'ParNew' had collection(s): count=1 time=63ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
om3_1       | 2020-12-12 01:56:13,499 [om3@group-562213E44849-LeaderElection1] INFO impl.LeaderElection: om3@group-562213E44849-LeaderElection1: Election DISCOVERED_A_NEW_TERM; received 1 response(s) [om3<-om1#0:FAIL-t3] and 0 exception(s); om3@group-562213E44849:t2, leader=null, voted=om3, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null
datanode_2  | 2020-12-12 02:03:05,846 [Thread-192] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-DD1B1BD89B99->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=125, seq=0, Watch-ALL_COMMITTED(134), Message:<EMPTY>, reply=RaftClientReply:client-DD1B1BD89B99->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=125, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 125 and log index 134 is not yet replicated to ALL_COMMITTED, logIndex=134, commits[2efbbdc8-7434-4046-ac05-b8a2df4b2a7b:c144, c825d659-cfaa-4cfc-8134-552ad3e9db61:c127, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9:c144]
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:02:45,682 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1825 time=6043ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
s3g_1       | org.apache.hadoop.ozone.s3.exception.OS3Exception
om3_1       | 2020-12-12 01:56:13,499 [om3@group-562213E44849-LeaderElection1] INFO impl.RaftServerImpl: om3@group-562213E44849: changes role from CANDIDATE to FOLLOWER at term 3 for DISCOVERED_A_NEW_TERM
om3_1       | 2020-12-12 01:56:13,500 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-LeaderElection1
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
datanode_2  | 2020-12-12 02:03:19,949 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13ms
datanode_2  | GC pool 'ParNew' had collection(s): count=142 time=4304ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=290ms
datanode_2  | 2020-12-12 02:03:29,959 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om3_1       | 2020-12-12 01:56:13,501 [om3@group-562213E44849-LeaderElection1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
s3g_1       | 	at org.apache.hadoop.ozone.s3.exception.S3ErrorTable.newError(S3ErrorTable.java:117)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.EndpointBase.getBucket(EndpointBase.java:72)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.BucketEndpoint.head(BucketEndpoint.java:258)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1       | 2020-12-12 01:57:49,168 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 28ms
om2_1       | GC pool 'ParNew' had collection(s): count=10 time=522ms
om1_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
datanode_2  | GC pool 'ParNew' had collection(s): count=147 time=4435ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=290ms
datanode_2  | 2020-12-12 02:03:35,464 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=150 time=4500ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=290ms
datanode_2  | 2020-12-12 02:03:49,471 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=57ms
om2_1       | 2020-12-12 01:57:49,718 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-18154/83908/multipartKey3
om2_1       | 2020-12-12 01:57:49,723 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 83908/multipartKey3 in Volume/Bucket s3v/bucket-18154
datanode_3  | 2020-12-12 02:02:50,186 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1862 time=6183ms
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | 2020-12-12 01:57:53,013 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 05213/multipartKey5 in VolumeName/Bucket s3v/bucket-18154
om1_1       | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-18154key: 05213/multipartKey5
om1_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:134)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
om2_1       | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3 because parts are in Invalid order.
om2_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om2_1       | 2020-12-12 01:57:53,009 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 05213/multipartKey5 in VolumeName/Bucket s3v/bucket-18154
om2_1       | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-18154key: 05213/multipartKey5
om2_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:134)
datanode_2  | GC pool 'ParNew' had collection(s): count=158 time=4710ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=11 time=319ms
datanode_2  | 2020-12-12 02:04:05,846 [Thread-200] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-437A183AD5A6->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=129, seq=0, Watch-ALL_COMMITTED(139), Message:<EMPTY>, reply=RaftClientReply:client-437A183AD5A6->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=129, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 129 and log index 139 is not yet replicated to ALL_COMMITTED, logIndex=139, commits[2efbbdc8-7434-4046-ac05-b8a2df4b2a7b:c148, c825d659-cfaa-4cfc-8134-552ad3e9db61:c127, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9:c148]
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:02:56,692 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=1918 time=6337ms
datanode_2  | 2020-12-12 02:04:13,487 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_2  | GC pool 'ParNew' had collection(s): count=171 time=5190ms
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=11 time=321ms
om1_1       | 2020-12-12 01:57:53,549 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-18154, Key65217/multipartKey. Exception:{}
om3_1       | 2020-12-12 01:56:13,538 [grpc-default-executor-1] INFO impl.RaftServerImpl: om3@group-562213E44849: changes role from  FOLLOWER to FOLLOWER at term 3 for recognizeCandidate:om1
om3_1       | 2020-12-12 01:56:13,538 [grpc-default-executor-1] INFO impl.RoleInfo: om3: shutdown om3@group-562213E44849-FollowerState
om3_1       | 2020-12-12 01:56:13,538 [grpc-default-executor-1] INFO impl.RoleInfo: om3: start om3@group-562213E44849-FollowerState
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
scm_1       | 2020-12-12 01:55:46,718 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@797f97e3{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-1_1_0-SNAPSHOT_jar-_-any-12931710057157224614/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0-SNAPSHOT.jar!/webapps/scm}
om1_1       | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om1_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:400)
scm_1       | 2020-12-12 01:55:46,833 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@2cbe455c{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm_1       | 2020-12-12 01:55:46,835 [Listener at 0.0.0.0/9860] INFO server.Server: Started @27301ms
scm_1       | 2020-12-12 01:55:46,856 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 2020-12-12 01:56:13,539 [grpc-default-executor-1] INFO impl.RaftServerImpl:  FOLLOWER om3@group-562213E44849:t3, leader=null, voted=null, raftlog=om3@group-562213E44849-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [om1|rpc:om1:9872, om3|rpc:om3:9872, om2|rpc:om2:9872], old=null RUNNING priority:0 candidate:om1|rpc:om1:9872 candidatePriority:0 compare:0
om3_1       | 2020-12-12 01:56:13,540 [Thread-29] INFO impl.FollowerState: om3@group-562213E44849-FollowerState was interrupted: {}
datanode_2  | 2020-12-12 02:05:02,566 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=195 time=5882ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=13 time=366ms
datanode_2  | 2020-12-12 02:05:09,846 [Thread-210] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-7EDD794D3A70->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=134, seq=0, Watch-ALL_COMMITTED(142), Message:<EMPTY>, reply=RaftClientReply:client-7EDD794D3A70->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=134, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 134 and log index 142 is not yet replicated to ALL_COMMITTED, logIndex=142, commits[2efbbdc8-7434-4046-ac05-b8a2df4b2a7b:c156, c825d659-cfaa-4cfc-8134-552ad3e9db61:c127, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9:c154]
om1_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:341)
om1_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:274)
om1_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om3_1       | java.lang.InterruptedException: sleep interrupted
datanode_2  | 2020-12-12 02:05:10,071 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
scm_1       | 2020-12-12 01:55:46,856 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1       | 	at java.base/java.lang.Thread.sleep(Native Method)
om3_1       | 	at org.apache.ratis.util.JavaUtils.sleep(JavaUtils.java:250)
om3_1       | 	at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:116)
scm_1       | 2020-12-12 01:55:46,864 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm_1       | 2020-12-12 01:55:46,958 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6fd7aba8] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om3_1       | 2020-12-12 01:56:13,681 [Listener at om3/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@62158618{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-hadoop-ozone-ozone-manager-1_1_0-SNAPSHOT_jar-_-any-2750000493085547579/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-ozone-ozone-manager-1.1.0-SNAPSHOT.jar!/webapps/ozoneManager}
datanode_2  | GC pool 'ParNew' had collection(s): count=199 time=6026ms
datanode_3  | 2020-12-12 02:03:21,206 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2089 time=6827ms
om1_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
scm_1       | 2020-12-12 01:55:47,506 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/c825d659-cfaa-4cfc-8134-552ad3e9db61
scm_1       | 2020-12-12 01:55:47,516 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered Data node : c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2020-12-12 01:55:47,632 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=13 time=366ms
datanode_2  | 2020-12-12 02:05:35,582 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=211 time=6400ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=14 time=391ms
om1_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 2020-12-12 01:55:47,633 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
datanode_2  | 2020-12-12 02:05:54,111 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22ms
datanode_2  | GC pool 'ParNew' had collection(s): count=222 time=6711ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=14 time=391ms
datanode_2  | 2020-12-12 02:06:06,617 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1       | 2020-12-12 01:56:13,701 [Listener at om3/9862] INFO server.AbstractConnector: Started ServerConnector@763ddfc3{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
om3_1       | 2020-12-12 01:56:13,701 [Listener at om3/9862] INFO server.Server: Started @26855ms
om3_1       | 2020-12-12 01:56:13,705 [Listener at om3/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
om3_1       | 2020-12-12 01:56:13,705 [Listener at om3/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
om3_1       | 2020-12-12 01:56:13,713 [Listener at om3/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
om3_1       | 2020-12-12 01:56:13,714 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om3_1       | 2020-12-12 01:56:13,725 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om1_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1       | 2020-12-12 01:56:13,782 [Listener at om3/9862] INFO om.OzoneManager: Trash Interval set to 0. Files deleted will not move to trash
om3_1       | 2020-12-12 01:56:13,831 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73c1dda3] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2020-12-12 01:55:47,746 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-12-12 01:55:47,916 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
scm_1       | 2020-12-12 01:55:47,946 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2020-12-12 01:55:47,946 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm_1       | 2020-12-12 01:55:47,946 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1       | 2020-12-12 01:55:47,946 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_2  | GC pool 'ParNew' had collection(s): count=228 time=6873ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=414ms
om1_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-12-12 02:06:11,132 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11ms
datanode_2  | GC pool 'ParNew' had collection(s): count=231 time=6967ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=414ms
scm_1       | 2020-12-12 01:55:48,105 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9afcac27-3965-4d3f-919c-fcd203891169 to datanode:c825d659-cfaa-4cfc-8134-552ad3e9db61
scm_1       | 2020-12-12 01:55:48,275 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 9afcac27-3965-4d3f-919c-fcd203891169, Nodes: c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-12-12T01:55:47.904499Z]
scm_1       | 2020-12-12 01:55:48,328 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a21a1ece-c09c-4265-8c25-7808f3e1a69a to datanode:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
om3_1       | 2020-12-12 01:56:13,890 [grpc-default-executor-2] INFO impl.RaftServerImpl: om3@group-562213E44849: change Leader from null to om1 at term 3 for appendEntries, leader elected after 5331ms
om3_1       | 2020-12-12 01:56:13,942 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | 2020-12-12 01:58:01,826 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=2 time=100ms
scm_1       | 2020-12-12 01:55:48,329 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: a21a1ece-c09c-4265-8c25-7808f3e1a69a, Nodes: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-12-12T01:55:48.328724Z]
scm_1       | 2020-12-12 01:55:48,570 [IPC Server handler 3 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/2cbe4a56-f48d-46d2-9e37-17202fd9dde9
scm_1       | 2020-12-12 01:55:48,570 [IPC Server handler 3 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2020-12-12 01:55:48,576 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 2020-12-12 02:06:12,135 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=231 time=6967ms
scm_1       | 2020-12-12 01:55:48,580 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-12-12 01:55:48,572 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a4d8e493-e756-437a-8c68-cad798557e75 to datanode:2cbe4a56-f48d-46d2-9e37-17202fd9dde9
om1_1       | GC pool 'ParNew' had collection(s): count=10 time=330ms
scm_1       | 2020-12-12 01:55:48,579 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 01:58:04,330 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | GC pool 'ParNew' had collection(s): count=10 time=330ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
om3_1       | 2020-12-12 01:56:13,981 [grpc-default-executor-2] INFO impl.RaftServerImpl: om3@group-562213E44849: set configuration 0: [om1|rpc:om1:9872|dataStream:, om3|rpc:om3:9872|dataStream:, om2|rpc:om2:9872|dataStream:], old=null at 0
om3_1       | 2020-12-12 01:56:14,000 [grpc-default-executor-2] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: Starting segment from index:0
scm_1       | 2020-12-12 01:55:48,581 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2020-12-12 01:55:48,581 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
om3_1       | 2020-12-12 01:56:14,255 [om3@group-562213E44849-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om3@group-562213E44849-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fafe1b60-c241-37cc-98f4-562213e44849/current/log_inprogress_0
om3_1       | 2020-12-12 01:56:25,955 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om3_1       | GC pool 'ParNew' had collection(s): count=2 time=100ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=414ms
datanode_2  | 2020-12-12 02:06:17,846 [Thread-218] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-50F8EFDB006D->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=139, seq=0, Watch-ALL_COMMITTED(147), Message:<EMPTY>, reply=RaftClientReply:client-50F8EFDB006D->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=139, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 139 and log index 147 is not yet replicated to ALL_COMMITTED, logIndex=147, commits[2efbbdc8-7434-4046-ac05-b8a2df4b2a7b:c159, c825d659-cfaa-4cfc-8134-552ad3e9db61:c127, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9:c159]
datanode_2  | 2020-12-12 02:06:27,166 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 26ms
scm_1       | 2020-12-12 01:55:48,583 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: a4d8e493-e756-437a-8c68-cad798557e75, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2020-12-12T01:55:48.572174Z]
om1_1       | 2020-12-12 01:58:10,336 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om1_1       | GC pool 'ParNew' had collection(s): count=11 time=364ms
datanode_2  | GC pool 'ParNew' had collection(s): count=240 time=7276ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=414ms
datanode_2  | 2020-12-12 02:06:28,669 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=240 time=7276ms
scm_1       | 2020-12-12 01:55:48,613 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=250da368-dbcb-48e6-92cc-45c2e0698f41 to datanode:2cbe4a56-f48d-46d2-9e37-17202fd9dde9
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 01:58:28,850 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=11 time=364ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=414ms
datanode_2  | 2020-12-12 02:06:29,175 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
scm_1       | 2020-12-12 01:55:48,614 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=250da368-dbcb-48e6-92cc-45c2e0698f41 to datanode:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
scm_1       | 2020-12-12 01:55:48,614 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=250da368-dbcb-48e6-92cc-45c2e0698f41 to datanode:c825d659-cfaa-4cfc-8134-552ad3e9db61
scm_1       | 2020-12-12 01:55:48,615 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2020-12-12T01:55:48.613906Z]
scm_1       | 2020-12-12 01:55:51,785 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
datanode_2  | GC pool 'ParNew' had collection(s): count=241 time=7299ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
om3_1       | 2020-12-12 01:56:30,462 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:03:22,210 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2097 time=6845ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om3_1       | GC pool 'ParNew' had collection(s): count=2 time=100ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
datanode_3  | 2020-12-12 02:03:36,722 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2229 time=7305ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=414ms
om3_1       | 2020-12-12 01:56:31,516 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 53ms
om1_1       | 2020-12-12 01:58:32,356 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om1_1       | GC pool 'ParNew' had collection(s): count=11 time=364ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 01:58:41,361 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=11 time=364ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 01:58:59,375 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
om1_1       | GC pool 'ParNew' had collection(s): count=11 time=364ms
scm_1       | 2020-12-12 01:55:51,790 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: a21a1ece-c09c-4265-8c25-7808f3e1a69a, Nodes: 2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.328724Z] moved to OPEN state
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om3_1       | GC pool 'ParNew' had collection(s): count=3 time=219ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
om3_1       | 2020-12-12 01:56:32,018 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=3 time=219ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
scm_1       | 2020-12-12 01:55:51,854 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om2_1       | 2020-12-12 01:57:53,551 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-18154, Key65217/multipartKey. Exception:{}
om2_1       | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
om2_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:400)
om2_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:341)
om2_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:274)
om2_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
scm_1       | 2020-12-12 01:55:52,257 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
om1_1       | 2020-12-12 01:59:02,378 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=11 time=364ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 01:59:10,384 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | GC pool 'ParNew' had collection(s): count=11 time=364ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
scm_1       | 2020-12-12 01:55:52,321 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-12-12 01:55:52,973 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: a4d8e493-e756-437a-8c68-cad798557e75, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:2cbe4a56-f48d-46d2-9e37-17202fd9dde9, CreationTimestamp2020-12-12T01:55:48.572174Z] moved to OPEN state
scm_1       | 2020-12-12 01:55:52,980 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-12-12 01:55:52,973 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_2  | 2020-12-12 02:06:30,182 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=241 time=7299ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=414ms
datanode_2  | 2020-12-12 02:06:32,708 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 24ms
datanode_2  | GC pool 'ParNew' had collection(s): count=243 time=7377ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=416ms
scm_1       | 2020-12-12 01:55:53,307 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2020-12-12 01:55:53,312 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-12-12 01:55:56,883 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
om3_1       | 2020-12-12 01:56:33,020 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | GC pool 'ParNew' had collection(s): count=5 time=299ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
om3_1       | 2020-12-12 01:56:33,527 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
om3_1       | GC pool 'ParNew' had collection(s): count=5 time=299ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
scm_1       | 2020-12-12 01:55:56,913 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-12-12 01:55:57,746 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-12-12 01:55:57,747 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:03:54,233 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
scm_1       | 2020-12-12 01:55:58,301 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_3  | GC pool 'ParNew' had collection(s): count=2383 time=7716ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:04:04,239 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2474 time=7940ms
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
om1_1       | 2020-12-12 01:59:53,410 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=12 time=383ms
datanode_2  | 2020-12-12 02:06:39,214 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om2_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:00:20,430 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
scm_1       | 2020-12-12 01:55:58,330 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2020-12-12 01:55:58,506 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:04:04,746 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2478 time=7954ms
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
datanode_2  | GC pool 'ParNew' had collection(s): count=246 time=7462ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=439ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:04:07,251 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2499 time=8066ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:04:08,256 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om1_1       | GC pool 'ParNew' had collection(s): count=12 time=383ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
datanode_2  | 2020-12-12 02:07:08,846 [Thread-221] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-2769D812F4A0->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=144, seq=0, Watch-ALL_COMMITTED(150), Message:<EMPTY>, reply=RaftClientReply:client-2769D812F4A0->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=144, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 144 and log index 150 is not yet replicated to ALL_COMMITTED, logIndex=150, commits[2efbbdc8-7434-4046-ac05-b8a2df4b2a7b:c159, c825d659-cfaa-4cfc-8134-552ad3e9db61:c127, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9:c159]
datanode_2  | 2020-12-12 02:07:17,231 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2507 time=8098ms
scm_1       | 2020-12-12 01:55:58,506 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613906Z] moved to OPEN state
scm_1       | 2020-12-12 01:55:58,511 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
om3_1       | 2020-12-12 01:56:37,030 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | 2020-12-12 02:00:30,939 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om1_1       | GC pool 'ParNew' had collection(s): count=12 time=383ms
datanode_2  | GC pool 'ParNew' had collection(s): count=266 time=7933ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=17 time=468ms
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om3_1       | GC pool 'ParNew' had collection(s): count=6 time=325ms
om2_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om2_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2020-12-12 01:55:58,517 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
datanode_2  | 2020-12-12 02:07:18,737 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_2  | GC pool 'ParNew' had collection(s): count=267 time=7955ms
scm_1       | 2020-12-12 01:55:58,517 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1       | 2020-12-12 01:55:58,517 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
om3_1       | 2020-12-12 01:56:44,536 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=7 time=385ms
om1_1       | 2020-12-12 02:00:39,944 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=12 time=383ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:00:40,948 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1       | 2020-12-12 01:58:10,179 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=12 time=383ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
om3_1       | 2020-12-12 01:56:52,748 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket-71407 in volume:s3v
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=17 time=468ms
scm_1       | 2020-12-12 01:56:19,921 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 9afcac27-3965-4d3f-919c-fcd203891169, Nodes: c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:c825d659-cfaa-4cfc-8134-552ad3e9db61, CreationTimestamp2020-12-12T01:55:47.904499Z] moved to OPEN state
om2_1       | GC pool 'ParNew' had collection(s): count=10 time=522ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=80ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om3_1       | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
scm_1       | 2020-12-12 02:00:58,555 [EventQueue-Delayed safe mode statusForReplicationManager] INFO container.ReplicationManager: Starting Replication Monitor Thread.
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:04:18,765 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | 2020-12-12 02:01:19,463 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=12 time=383ms
om3_1       | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:192)
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
datanode_2  | 2020-12-12 02:07:23,251 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13ms
datanode_2  | GC pool 'ParNew' had collection(s): count=270 time=8017ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2600 time=8407ms
om2_1       | 2020-12-12 01:58:29,189 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=11 time=537ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=4 time=105ms
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=17 time=468ms
datanode_3  | 2020-12-12 02:04:27,272 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2677 time=8645ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
datanode_2  | 2020-12-12 02:07:26,761 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_2  | GC pool 'ParNew' had collection(s): count=272 time=8059ms
datanode_3  | 2020-12-12 02:04:29,275 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | 2020-12-12 01:59:29,216 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=17 time=468ms
datanode_2  | 2020-12-12 02:08:09,846 [Thread-228] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-A10EEBFF423A->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=148, seq=0, Watch-ALL_COMMITTED(154), Message:<EMPTY>, reply=RaftClientReply:client-A10EEBFF423A->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=148, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 148 and log index 154 is not yet replicated to ALL_COMMITTED, logIndex=154, commits[2efbbdc8-7434-4046-ac05-b8a2df4b2a7b:c163, c825d659-cfaa-4cfc-8134-552ad3e9db61:c127, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9:c163]
om1_1       | 2020-12-12 02:02:48,996 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=13 time=423ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om2_1       | GC pool 'ParNew' had collection(s): count=13 time=662ms
datanode_2  | 2020-12-12 02:08:31,285 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
scm_1       | 2020-12-12 02:00:58,579 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 13 milliseconds for processing 1 containers.
datanode_3  | GC pool 'ParNew' had collection(s): count=2695 time=8686ms
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om1_1       | 2020-12-12 02:02:53,999 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
datanode_2  | GC pool 'ParNew' had collection(s): count=306 time=9097ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=19 time=526ms
datanode_2  | 2020-12-12 02:08:37,306 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 19ms
datanode_2  | GC pool 'ParNew' had collection(s): count=309 time=9184ms
om1_1       | GC pool 'ParNew' had collection(s): count=13 time=423ms
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=5 time=159ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:04:36,280 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2739 time=8800ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:04:47,286 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:03:06,510 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=19 time=557ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2807 time=9046ms
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1       | 2020-12-12 01:59:35,221 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | GC pool 'ParNew' had collection(s): count=13 time=423ms
datanode_2  | 2020-12-12 02:08:48,314 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om3_1       | 2020-12-12 01:56:58,146 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketDeleteRequest: Delete bucket failed for bucket:nosuchbucket in volume:s3v
om3_1       | BUCKET_NOT_FOUND org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om2_1       | GC pool 'ParNew' had collection(s): count=13 time=662ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=5 time=159ms
datanode_2  | GC pool 'ParNew' had collection(s): count=316 time=9390ms
datanode_3  | 2020-12-12 02:04:47,788 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketDeleteRequest.validateAndUpdateCache(OMBucketDeleteRequest.java:118)
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=20 time=557ms
datanode_2  | 2020-12-12 02:08:53,820 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
scm_1       | 2020-12-12 02:05:58,582 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2020-12-12 02:10:58,582 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_3  | GC pool 'ParNew' had collection(s): count=2812 time=9055ms
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:04:57,304 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11ms
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | GC pool 'ParNew' had collection(s): count=2897 time=9310ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om2_1       | 2020-12-12 01:59:38,732 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8ms
om2_1       | GC pool 'ParNew' had collection(s): count=13 time=662ms
datanode_2  | GC pool 'ParNew' had collection(s): count=319 time=9478ms
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
om1_1       | 2020-12-12 02:03:48,031 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
om1_1       | GC pool 'ParNew' had collection(s): count=13 time=423ms
om3_1       | 2020-12-12 01:57:03,049 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=7 time=385ms
datanode_3  | 2020-12-12 02:04:59,811 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_3  | GC pool 'ParNew' had collection(s): count=2919 time=9369ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=5 time=159ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=20 time=557ms
datanode_2  | 2020-12-12 02:08:55,322 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
om1_1       | 2020-12-12 02:04:13,044 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_2  | GC pool 'ParNew' had collection(s): count=319 time=9478ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=20 time=557ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
om3_1       | 2020-12-12 01:57:06,056 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:05:20,326 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_3  | GC pool 'ParNew' had collection(s): count=3083 time=9824ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:05:24,829 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=3122 time=9977ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:05:27,332 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=3144 time=10048ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
om1_1       | GC pool 'ParNew' had collection(s): count=13 time=423ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
om2_1       | 2020-12-12 02:00:17,749 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | GC pool 'ParNew' had collection(s): count=14 time=717ms
datanode_2  | 2020-12-12 02:09:06,838 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:04:42,559 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=13 time=423ms
om3_1       | GC pool 'ParNew' had collection(s): count=7 time=385ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
om3_1       | 2020-12-12 01:57:08,568 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:04:56,066 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=326 time=9680ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=20 time=559ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
om3_1       | GC pool 'ParNew' had collection(s): count=8 time=486ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=38ms
datanode_3  | 2020-12-12 02:05:28,834 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=3157 time=10088ms
om1_1       | GC pool 'ParNew' had collection(s): count=13 time=423ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:05:34,841 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
datanode_2  | 2020-12-12 02:09:10,846 [Thread-236] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-BAF9CE88F264->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=153, seq=0, Watch-ALL_COMMITTED(158), Message:<EMPTY>, reply=RaftClientReply:client-BAF9CE88F264->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=153, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 153 and log index 158 is not yet replicated to ALL_COMMITTED, logIndex=158, commits[2efbbdc8-7434-4046-ac05-b8a2df4b2a7b:c167, c825d659-cfaa-4cfc-8134-552ad3e9db61:c127, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9:c167]
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=188ms
om2_1       | 2020-12-12 02:00:36,760 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om2_1       | GC pool 'ParNew' had collection(s): count=14 time=717ms
datanode_3  | GC pool 'ParNew' had collection(s): count=3211 time=10221ms
om3_1       | 2020-12-12 01:57:13,072 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | 2020-12-12 02:09:13,342 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=188ms
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
om1_1       | 2020-12-12 02:04:57,068 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=8 time=486ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=76ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_2  | GC pool 'ParNew' had collection(s): count=329 time=9815ms
om2_1       | 2020-12-12 02:00:56,268 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=15 time=750ms
om1_1       | GC pool 'ParNew' had collection(s): count=13 time=423ms
om3_1       | 2020-12-12 01:57:25,606 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 27ms
datanode_3  | 2020-12-12 02:05:51,353 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=3362 time=10711ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om3_1       | GC pool 'ParNew' had collection(s): count=9 time=545ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=76ms
om3_1       | 2020-12-12 01:57:35,666 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload: /s3v/bucket-18154/36516/multipartKey2 Part number: 1 size 6  is less than minimum part size 5242880
om3_1       | 2020-12-12 01:57:35,685 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 36516/multipartKey2 in Volume/Bucket s3v/bucket-18154
om3_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 36516/multipartKey2. Entity too small.
om3_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:227)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=21 time=600ms
datanode_2  | 2020-12-12 02:09:45,861 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
datanode_2  | GC pool 'ParNew' had collection(s): count=347 time=10377ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=7 time=219ms
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
om1_1       | 2020-12-12 02:05:29,583 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om1_1       | GC pool 'ParNew' had collection(s): count=14 time=446ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
om2_1       | 2020-12-12 02:02:11,298 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=16 time=792ms
datanode_3  | 2020-12-12 02:06:00,359 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=22 time=625ms
datanode_2  | 2020-12-12 02:09:54,870 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_2  | GC pool 'ParNew' had collection(s): count=352 time=10555ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=22 time=625ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=8 time=242ms
datanode_3  | GC pool 'ParNew' had collection(s): count=3439 time=10937ms
datanode_2  | 2020-12-12 02:10:09,885 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 9ms
datanode_2  | GC pool 'ParNew' had collection(s): count=360 time=10794ms
om2_1       | 2020-12-12 02:02:21,805 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om2_1       | GC pool 'ParNew' had collection(s): count=16 time=792ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=8 time=242ms
om2_1       | 2020-12-12 02:02:51,320 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=23 time=657ms
datanode_2  | 2020-12-12 02:10:11,846 [Thread-243] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-C0BC04381E2F->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=159, seq=0, Watch-ALL_COMMITTED(162), Message:<EMPTY>, reply=RaftClientReply:client-C0BC04381E2F->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=159, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 159 and log index 162 is not yet replicated to ALL_COMMITTED, logIndex=162, commits[2efbbdc8-7434-4046-ac05-b8a2df4b2a7b:c171, c825d659-cfaa-4cfc-8134-552ad3e9db61:c127, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9:c171]
om2_1       | GC pool 'ParNew' had collection(s): count=17 time=838ms
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
datanode_3  | 2020-12-12 02:06:11,866 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
datanode_3  | GC pool 'ParNew' had collection(s): count=3539 time=11205ms
om1_1       | 2020-12-12 02:05:35,587 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=9 time=271ms
om2_1       | 2020-12-12 02:03:01,828 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_2  | 2020-12-12 02:10:11,891 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
om2_1       | GC pool 'ParNew' had collection(s): count=17 time=838ms
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om1_1       | GC pool 'ParNew' had collection(s): count=14 time=446ms
datanode_2  | GC pool 'ParNew' had collection(s): count=361 time=10822ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=23 time=657ms
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=9 time=271ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
datanode_2  | 2020-12-12 02:10:12,897 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:06:24,872 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
datanode_2  | GC pool 'ParNew' had collection(s): count=362 time=10841ms
datanode_3  | GC pool 'ParNew' had collection(s): count=3661 time=11591ms
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
om2_1       | 2020-12-12 02:03:13,836 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=23 time=657ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om1_1       | 2020-12-12 02:06:10,100 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
om2_1       | GC pool 'ParNew' had collection(s): count=17 time=838ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=9 time=271ms
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_3  | 2020-12-12 02:06:32,880 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om1_1       | GC pool 'ParNew' had collection(s): count=14 time=446ms
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_2  | 2020-12-12 02:10:34,907 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=374 time=11197ms
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 2020-12-12 01:57:04,481 [qtp166454155-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-09135, with Versioning false and Storage Type set to DISK and Encryption set to false 
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=23 time=659ms
om2_1       | 2020-12-12 02:03:15,839 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | GC pool 'ParNew' had collection(s): count=3730 time=11819ms
s3g_1       | 2020-12-12 01:57:04,494 [qtp166454155-20] INFO endpoint.BucketEndpoint: Location is /bucket-09135
datanode_2  | 2020-12-12 02:10:35,415 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8ms
datanode_2  | GC pool 'ParNew' had collection(s): count=374 time=11197ms
om3_1       | 2020-12-12 01:57:36,823 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-18154/83908/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 1
om3_1       | partName: "etag1"
s3g_1       | 2020-12-12 01:57:07,739 [qtp166454155-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-18154, with Versioning false and Storage Type set to DISK and Encryption set to false 
om2_1       | GC pool 'ParNew' had collection(s): count=17 time=838ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=23 time=659ms
om3_1       | , partNumber: 2
om3_1       | partName: "etag2"
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=9 time=271ms
datanode_2  | 2020-12-12 02:10:39,419 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_2  | GC pool 'ParNew' had collection(s): count=377 time=11263ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:06:10,602 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | 2020-12-12 02:03:40,848 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=14 time=446ms
s3g_1       | 2020-12-12 01:57:07,753 [qtp166454155-20] INFO endpoint.BucketEndpoint: Location is /bucket-18154
om2_1       | GC pool 'ParNew' had collection(s): count=18 time=868ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:06:38,614 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | GC pool 'ParNew' had collection(s): count=14 time=446ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:06:48,620 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | 2020-12-12 02:06:37,390 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
datanode_3  | GC pool 'ParNew' had collection(s): count=3769 time=11936ms
s3g_1       | 2020-12-12 01:57:10,143 [qtp166454155-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-53A0A468046B->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=24 time=688ms
om1_1       | GC pool 'ParNew' had collection(s): count=14 time=446ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=295ms
s3g_1       | 2020-12-12 01:57:10,143 [qtp166454155-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om2_1       | 2020-12-12 02:03:49,353 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | GC pool 'ParNew' had collection(s): count=18 time=868ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=295ms
om2_1       | 2020-12-12 02:04:12,367 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om2_1       | GC pool 'ParNew' had collection(s): count=19 time=910ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=299ms
om2_1       | 2020-12-12 02:05:32,900 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om2_1       | GC pool 'ParNew' had collection(s): count=20 time=950ms
s3g_1       | 2020-12-12 01:57:14,291 [qtp166454155-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-B4150D573D0A->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=12 time=364ms
om3_1       | ]
om1_1       | 2020-12-12 02:07:22,636 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om1_1       | GC pool 'ParNew' had collection(s): count=14 time=446ms
om2_1       | 2020-12-12 02:05:46,411 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
om3_1       | 2020-12-12 01:57:36,835 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 83908/multipartKey3 in Volume/Bucket s3v/bucket-18154
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_2  | 2020-12-12 02:11:13,846 [Thread-250] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-AA778650C8DF->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=164, seq=0, Watch-ALL_COMMITTED(165), Message:<EMPTY>, reply=RaftClientReply:client-AA778650C8DF->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=164, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 164 and log index 165 is not yet replicated to ALL_COMMITTED, logIndex=165, commits[2efbbdc8-7434-4046-ac05-b8a2df4b2a7b:c175, c825d659-cfaa-4cfc-8134-552ad3e9db61:c127, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9:c175]
datanode_2  | 2020-12-12 02:11:17,938 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_2  | GC pool 'ParNew' had collection(s): count=398 time=11843ms
datanode_3  | 2020-12-12 02:06:57,904 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
om3_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3
om3_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:167)
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
datanode_3  | GC pool 'ParNew' had collection(s): count=3954 time=12453ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:07:07,912 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=4046 time=12731ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:07:32,423 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=4254 time=13276ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:07:54,439 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=4452 time=13799ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:08:02,945 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=4525 time=14087ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:08:06,950 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=4561 time=14231ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:08:13,459 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=4622 time=14382ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:08:18,461 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=4671 time=14510ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:08:27,489 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 22ms
datanode_3  | GC pool 'ParNew' had collection(s): count=4728 time=14682ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:08:39,997 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=4842 time=15032ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:09:17,514 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=5174 time=16194ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:09:35,028 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_3  | GC pool 'ParNew' had collection(s): count=5334 time=16617ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:09:49,538 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=5464 time=17000ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:09:53,042 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=5496 time=17104ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:09:53,544 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=5501 time=17118ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:09:55,549 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | GC pool 'ParNew' had collection(s): count=5519 time=17159ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:10:00,556 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | GC pool 'ParNew' had collection(s): count=5569 time=17321ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:10:26,568 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=5811 time=18074ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:10:31,571 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=25 time=708ms
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 2020-12-12 01:57:14,293 [qtp166454155-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
datanode_3  | GC pool 'ParNew' had collection(s): count=5860 time=18184ms
datanode_2  | 2020-12-12 02:11:25,944 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | GC pool 'ParNew' had collection(s): count=20 time=950ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=12 time=364ms
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1       | 2020-12-12 01:57:37,360 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: Complete MultipartUpload failed for key /s3v/bucket-18154/83908/multipartKey3 , MPU Key has no parts in OM, parts given to upload are [partNumber: 2
om3_1       | partName: "etag1"
datanode_2  | GC pool 'ParNew' had collection(s): count=402 time=11953ms
s3g_1       | 2020-12-12 01:57:18,563 [qtp166454155-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-733BE519F17C->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:57:18,563 [qtp166454155-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om2_1       | 2020-12-12 02:05:56,416 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=20 time=950ms
om3_1       | , partNumber: 1
om3_1       | partName: "etag2"
s3g_1       | 2020-12-12 01:57:22,190 [qtp166454155-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-20C72F186B66->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:57:22,196 [qtp166454155-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:57:29,021 [qtp166454155-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-F30E7B1C08AD->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=12 time=364ms
om2_1       | 2020-12-12 02:06:39,933 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | GC pool 'ParNew' had collection(s): count=21 time=986ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=13 time=411ms
s3g_1       | 2020-12-12 01:57:29,021 [qtp166454155-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
om3_1       | ]
om3_1       | 2020-12-12 01:57:37,362 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 83908/multipartKey3 in Volume/Bucket s3v/bucket-18154
om3_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3
om2_1       | 2020-12-12 02:07:40,956 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=22 time=1010ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=14 time=427ms
om2_1       | 2020-12-12 02:07:55,961 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=23 time=1045ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=455ms
s3g_1       | 2020-12-12 01:57:32,339 [qtp166454155-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-7062333937F2->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
om2_1       | 2020-12-12 02:07:56,965 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om2_1       | GC pool 'ParNew' had collection(s): count=23 time=1045ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=25 time=708ms
om1_1       | 2020-12-12 02:08:01,152 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=14 time=446ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:08:05,156 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=455ms
om2_1       | 2020-12-12 02:08:05,475 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
om2_1       | GC pool 'ParNew' had collection(s): count=23 time=1045ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=455ms
om2_1       | 2020-12-12 02:08:06,477 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=23 time=1045ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=455ms
om2_1       | 2020-12-12 02:08:21,484 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | GC pool 'ParNew' had collection(s): count=23 time=1045ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=455ms
om2_1       | 2020-12-12 02:08:27,488 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 2020-12-12 01:57:32,339 [qtp166454155-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
datanode_2  | 2020-12-12 02:11:26,455 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10ms
om2_1       | GC pool 'ParNew' had collection(s): count=23 time=1045ms
om3_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:167)
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
datanode_2  | GC pool 'ParNew' had collection(s): count=403 time=11967ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=455ms
om2_1       | 2020-12-12 02:08:50,997 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | GC pool 'ParNew' had collection(s): count=24 time=1079ms
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
s3g_1       | 2020-12-12 01:57:35,660 [qtp166454155-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-18154, , key: 36516/multipartKey2
s3g_1       | ENTITY_TOO_SMALL org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 36516/multipartKey2. Entity too small.
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:602)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:947)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:951)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:634)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:509)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=483ms
om1_1       | GC pool 'ParNew' had collection(s): count=14 time=446ms
datanode_3  | 2020-12-12 02:10:39,576 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=5930 time=18418ms
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
om2_1       | 2020-12-12 02:08:59,005 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:08:30,174 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=25 time=708ms
datanode_2  | 2020-12-12 02:11:37,960 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=485ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:11:09,096 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | GC pool 'ParNew' had collection(s): count=6224 time=19248ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:11:50,113 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
datanode_3  | GC pool 'ParNew' had collection(s): count=6551 time=20180ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om2_1       | GC pool 'ParNew' had collection(s): count=24 time=1079ms
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | GC pool 'ParNew' had collection(s): count=408 time=12122ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=26 time=725ms
datanode_2  | 2020-12-12 02:11:41,463 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=410 time=12206ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=483ms
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
datanode_3  | 2020-12-12 02:11:51,616 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | 2020-12-12 02:09:00,507 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=24 time=1079ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=483ms
om2_1       | 2020-12-12 02:09:12,015 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=26 time=725ms
datanode_3  | GC pool 'ParNew' had collection(s): count=6563 time=20218ms
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:08:38,679 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=485ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:08:53,197 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12ms
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=485ms
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1       | 2020-12-12 01:57:48,548 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 83908/multipartKey3 in Volume/Bucket s3v/bucket-18154
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
om2_1       | GC pool 'ParNew' had collection(s): count=24 time=1079ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=483ms
datanode_2  | 2020-12-12 02:11:52,970 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ParNew' had collection(s): count=416 time=12417ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=26 time=725ms
datanode_2  | 2020-12-12 02:11:59,495 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 19ms
om3_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-18154/83908/multipartKey3105364734474453005
om3_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:11:52,621 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | GC pool 'ParNew' had collection(s): count=6572 time=20239ms
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om2_1       | 2020-12-12 02:09:18,522 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om2_1       | GC pool 'ParNew' had collection(s): count=24 time=1079ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=483ms
om2_1       | 2020-12-12 02:09:24,028 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om2_1       | GC pool 'ParNew' had collection(s): count=24 time=1079ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:09:11,708 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=485ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
datanode_2  | GC pool 'ParNew' had collection(s): count=420 time=12547ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=26 time=725ms
datanode_2  | 2020-12-12 02:12:03,035 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 38ms
datanode_2  | GC pool 'ParNew' had collection(s): count=422 time=12602ms
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:11:57,624 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=6618 time=20363ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=483ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=26 time=725ms
datanode_2  | 2020-12-12 02:12:10,051 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13ms
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
om1_1       | 2020-12-12 02:09:21,212 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=485ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om2_1       | 2020-12-12 02:09:56,542 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om2_1       | GC pool 'ParNew' had collection(s): count=25 time=1134ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=17 time=508ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:12:13,644 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 14ms
datanode_3  | GC pool 'ParNew' had collection(s): count=6768 time=20822ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:12:35,156 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=6960 time=21338ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1       | 2020-12-12 01:57:49,119 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 83908/multipartKey3 in Volume/Bucket s3v/bucket-18154
om3_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-18154/83908/multipartKey3105364734706188302
om3_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:209)
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
datanode_2  | GC pool 'ParNew' had collection(s): count=426 time=12696ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=26 time=727ms
datanode_2  | 2020-12-12 02:12:11,874 [Thread-257] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-36C1BB3B9A68->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=169, seq=0, Watch-ALL_COMMITTED(169), Message:<EMPTY>, reply=RaftClientReply:client-36C1BB3B9A68->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=169, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 169 and log index 169 is not yet replicated to ALL_COMMITTED, logIndex=169, commits[2efbbdc8-7434-4046-ac05-b8a2df4b2a7b:c179, c825d659-cfaa-4cfc-8134-552ad3e9db61:c127, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9:c179]
datanode_2  | 2020-12-12 02:12:21,055 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=431 time=12821ms
om1_1       | 2020-12-12 02:09:32,216 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=485ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om2_1       | 2020-12-12 02:10:05,046 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=25 time=1134ms
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=17 time=508ms
om2_1       | 2020-12-12 02:10:09,049 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | 2020-12-12 02:10:00,229 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=485ms
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om2_1       | GC pool 'ParNew' had collection(s): count=25 time=1134ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=17 time=508ms
om2_1       | 2020-12-12 02:10:16,055 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om2_1       | GC pool 'ParNew' had collection(s): count=25 time=1134ms
datanode_3  | 2020-12-12 02:12:40,174 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 15ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=27 time=780ms
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:10:01,733 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1       | 2020-12-12 01:57:49,724 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: PartNumber at index 1 is 2, and its previous partNumber at index 0 is 4 for ozonekey is /s3v/bucket-18154/83908/multipartKey3
datanode_2  | 2020-12-12 02:12:47,088 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 24ms
datanode_2  | GC pool 'ParNew' had collection(s): count=446 time=13232ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=27 time=782ms
datanode_2  | 2020-12-12 02:12:54,111 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 20ms
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
datanode_3  | GC pool 'ParNew' had collection(s): count=7004 time=21479ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:12:42,680 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | GC pool 'ParNew' had collection(s): count=7026 time=21538ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=485ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:10:13,238 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=485ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=17 time=508ms
om2_1       | 2020-12-12 02:11:23,592 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 16ms
datanode_2  | GC pool 'ParNew' had collection(s): count=450 time=13350ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=28 time=803ms
datanode_2  | 2020-12-12 02:13:12,848 [Thread-264] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-EA89F7E0E2C3->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=174, seq=0, Watch-ALL_COMMITTED(173), Message:<EMPTY>, reply=RaftClientReply:client-EA89F7E0E2C3->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=174, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 174 and log index 173 is not yet replicated to ALL_COMMITTED, logIndex=173, commits[2efbbdc8-7434-4046-ac05-b8a2df4b2a7b:c182, c825d659-cfaa-4cfc-8134-552ad3e9db61:c127, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9:c182]
datanode_2  | 2020-12-12 02:13:17,142 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 23ms
datanode_2  | GC pool 'ParNew' had collection(s): count=462 time=13742ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=28 time=803ms
om3_1       | 2020-12-12 01:57:49,725 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadCompleteRequest: MultipartUpload Complete request failed for Key: 83908/multipartKey3 in Volume/Bucket s3v/bucket-18154
om3_1       | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3 because parts are in Invalid order.
om3_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadCompleteRequest.validateAndUpdateCache(S3MultipartUploadCompleteRequest.java:184)
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:10:54,259 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=485ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:10:55,265 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_3  | 2020-12-12 02:12:51,189 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om2_1       | GC pool 'ParNew' had collection(s): count=27 time=1206ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=18 time=531ms
om2_1       | 2020-12-12 02:11:52,606 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om2_1       | GC pool 'ParNew' had collection(s): count=27 time=1206ms
datanode_3  | GC pool 'ParNew' had collection(s): count=7101 time=21751ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:13:12,700 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | GC pool 'ParNew' had collection(s): count=7285 time=22222ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:13:16,205 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
datanode_2  | 2020-12-12 02:13:20,673 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 29ms
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=485ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:11:22,776 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om1_1       | GC pool 'ParNew' had collection(s): count=15 time=485ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=19 time=555ms
om2_1       | 2020-12-12 02:12:05,115 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om2_1       | GC pool 'ParNew' had collection(s): count=27 time=1206ms
datanode_2  | GC pool 'ParNew' had collection(s): count=464 time=13816ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=28 time=805ms
datanode_2  | 2020-12-12 02:13:33,190 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12ms
datanode_2  | GC pool 'ParNew' had collection(s): count=471 time=13999ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=29 time=847ms
datanode_2  | 2020-12-12 02:13:41,696 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | GC pool 'ParNew' had collection(s): count=7320 time=22321ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=19 time=555ms
om2_1       | 2020-12-12 02:12:05,617 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:11:49,288 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | GC pool 'ParNew' had collection(s): count=16 time=497ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:12:08,797 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | GC pool 'ParNew' had collection(s): count=16 time=497ms
datanode_3  | 2020-12-12 02:13:21,214 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
om2_1       | GC pool 'ParNew' had collection(s): count=27 time=1206ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=19 time=555ms
om2_1       | 2020-12-12 02:12:14,621 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_2  | GC pool 'ParNew' had collection(s): count=475 time=14108ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
datanode_3  | GC pool 'ParNew' had collection(s): count=7369 time=22471ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:13:43,727 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om3_1       | 2020-12-12 01:57:50,124 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=29 time=847ms
om1_1       | 2020-12-12 02:12:16,301 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om3_1       | GC pool 'ParNew' had collection(s): count=9 time=545ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=76ms
datanode_2  | 2020-12-12 02:13:48,199 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=16 time=497ms
om2_1       | GC pool 'ParNew' had collection(s): count=27 time=1206ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=19 time=555ms
om3_1       | 2020-12-12 01:57:51,126 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=9 time=545ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=76ms
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
datanode_3  | GC pool 'ParNew' had collection(s): count=7578 time=23087ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om3_1       | 2020-12-12 01:57:53,014 [OM StateMachine ApplyTransaction Thread - 0] ERROR multipart.S3MultipartUploadAbortRequest: Abort Multipart request is failed for KeyName 05213/multipartKey5 in VolumeName/Bucket s3v/bucket-18154
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
datanode_3  | 2020-12-12 02:14:00,736 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | 2020-12-12 02:12:15,625 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om2_1       | GC pool 'ParNew' had collection(s): count=27 time=1206ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=19 time=555ms
om2_1       | 2020-12-12 02:12:50,640 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om2_1       | GC pool 'ParNew' had collection(s): count=28 time=1264ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=20 time=582ms
om2_1       | 2020-12-12 02:13:09,148 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om2_1       | GC pool 'ParNew' had collection(s): count=28 time=1264ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=20 time=582ms
om2_1       | 2020-12-12 02:13:37,663 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
om2_1       | GC pool 'ParNew' had collection(s): count=29 time=1284ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=21 time=614ms
om2_1       | 2020-12-12 02:13:38,165 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=29 time=1284ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=21 time=614ms
om2_1       | 2020-12-12 02:14:05,691 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 17ms
datanode_3  | GC pool 'ParNew' had collection(s): count=7735 time=23659ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:14:04,243 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | GC pool 'ParNew' had collection(s): count=7768 time=23751ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:12:18,813 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 11ms
om1_1       | GC pool 'ParNew' had collection(s): count=16 time=497ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
datanode_3  | 2020-12-12 02:14:05,748 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | GC pool 'ParNew' had collection(s): count=7782 time=23784ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
datanode_3  | 2020-12-12 02:14:11,685 [grpc-default-executor-8] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 173 .Container 1 bcsId is 127. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
om1_1       | 2020-12-12 02:12:33,824 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
om1_1       | GC pool 'ParNew' had collection(s): count=16 time=497ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:12:39,329 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 173 .Container 1 bcsId is 127.
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:196)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:483)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om2_1       | GC pool 'ParNew' had collection(s): count=30 time=1319ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=21 time=614ms
om2_1       | 2020-12-12 02:14:25,698 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om2_1       | GC pool 'ParNew' had collection(s): count=30 time=1319ms
om2_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=22 time=646ms
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:189)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:163)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:309)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.lambda$dispatch$0(HddsDispatcher.java:171)
datanode_3  | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
om1_1       | GC pool 'ParNew' had collection(s): count=16 time=497ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:12:56,336 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om1_1       | GC pool 'ParNew' had collection(s): count=16 time=497ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:13:17,845 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om1_1       | GC pool 'ParNew' had collection(s): count=16 time=497ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:13:23,350 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
s3g_1       | 2020-12-12 01:57:35,676 [qtp166454155-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>EntityTooSmall</Code>
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:170)
om1_1       | GC pool 'ParNew' had collection(s): count=16 time=497ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:13:25,853 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_3  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:783)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-12-12 02:14:13,502 [grpc-default-executor-9] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 173 .Container 1 bcsId is 127. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_2  | GC pool 'ParNew' had collection(s): count=479 time=14195ms
om3_1       | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Abort Multipart Upload Failed: volume: s3vbucket: bucket-18154key: 05213/multipartKey5
om3_1       | 	at org.apache.hadoop.ozone.om.request.s3.multipart.S3MultipartUploadAbortRequest.validateAndUpdateCache(S3MultipartUploadAbortRequest.java:134)
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
s3g_1       |   <Message>Your proposed upload is smaller than the minimum allowed object size. Each part must be at least 5 MB in size, except the last part.</Message>
s3g_1       |   <Resource>36516/multipartKey2</Resource>
s3g_1       |   <RequestId/>
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=29 time=847ms
datanode_2  | 2020-12-12 02:14:07,218 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 12ms
s3g_1       | </Error>
s3g_1       | 
om1_1       | GC pool 'ParNew' had collection(s): count=16 time=497ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om1_1       | 2020-12-12 02:14:24,885 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13ms
om1_1       | GC pool 'ParNew' had collection(s): count=17 time=513ms
datanode_2  | GC pool 'ParNew' had collection(s): count=490 time=14547ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=30 time=879ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
datanode_2  | 2020-12-12 02:14:14,846 [Thread-271] INFO client.GrpcClientProtocolService: Failed RaftClientRequest:client-590DCA55C51D->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=179, seq=0, Watch-ALL_COMMITTED(177), Message:<EMPTY>, reply=RaftClientReply:client-590DCA55C51D->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b@group-45C2E0698F41, cid=179, FAILED org.apache.ratis.protocol.exceptions.NotReplicatedException: Request with call Id 179 and log index 177 is not yet replicated to ALL_COMMITTED, logIndex=177, commits[2efbbdc8-7434-4046-ac05-b8a2df4b2a7b:c186, c825d659-cfaa-4cfc-8134-552ad3e9db61:c127, 2cbe4a56-f48d-46d2-9e37-17202fd9dde9:c186]
s3g_1       | 2020-12-12 01:57:36,823 [qtp166454155-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-18154, , key: 83908/multipartKey3
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1       | 2020-12-12 01:57:53,556 [OM StateMachine ApplyTransaction Thread - 0] ERROR key.OMKeyCreateRequest: Key creation failed. Volume:s3v, Bucket:bucket-18154, Key65217/multipartKey. Exception:{}
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:602)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:947)
datanode_2  | 2020-12-12 02:14:25,744 [org.apache.ratis.server.JvmPauseMonitor@741534ff-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 19ms
datanode_2  | GC pool 'ParNew' had collection(s): count=499 time=14872ms
datanode_2  | GC pool 'ConcurrentMarkSweep' had collection(s): count=30 time=879ms
om1_1       | 2020-12-12 02:14:25,890 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om1_1       | GC pool 'ParNew' had collection(s): count=17 time=513ms
om1_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=68ms
om3_1       | NO_SUCH_MULTIPART_UPLOAD_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: No such Multipart upload is with specified uploadId random
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:951)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:634)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:509)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 173 .Container 1 bcsId is 127.
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:196)
om3_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareMultipartKeyInfo(OMKeyRequest.java:400)
om3_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyRequest.prepareKeyInfo(OMKeyRequest.java:341)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:483)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:189)
om3_1       | 	at org.apache.hadoop.ozone.om.request.key.OMKeyCreateRequest.validateAndUpdateCache(OMKeyCreateRequest.java:274)
om3_1       | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:227)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:415)
om3_1       | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$applyTransaction$1(OzoneManagerStateMachine.java:240)
om3_1       | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om3_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1       | 2020-12-12 01:57:54,629 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=10 time=594ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=106ms
om3_1       | 2020-12-12 01:58:04,636 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=10 time=594ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=106ms
om3_1       | 2020-12-12 01:58:08,644 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
om3_1       | GC pool 'ParNew' had collection(s): count=10 time=594ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=3 time=106ms
om3_1       | 2020-12-12 01:58:50,165 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | GC pool 'ParNew' had collection(s): count=12 time=688ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=4 time=143ms
om3_1       | 2020-12-12 01:59:08,179 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:163)
om3_1       | GC pool 'ParNew' had collection(s): count=13 time=720ms
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:309)
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=5 time=167ms
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.lambda$dispatch$0(HddsDispatcher.java:171)
datanode_3  | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:170)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
om3_1       | 2020-12-12 01:59:30,190 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=13 time=720ms
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_3  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=5 time=167ms
om3_1       | 2020-12-12 01:59:31,693 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=13 time=720ms
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=5 time=167ms
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
om3_1       | 2020-12-12 02:00:04,710 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om3_1       | GC pool 'ParNew' had collection(s): count=14 time=737ms
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:783)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=5 time=167ms
om3_1       | 2020-12-12 02:01:16,242 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1       | GC pool 'ParNew' had collection(s): count=15 time=759ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=180ms
datanode_3  | 2020-12-12 02:14:15,415 [grpc-default-executor-9] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 177 .Container 1 bcsId is 127. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 177 .Container 1 bcsId is 127.
om3_1       | 2020-12-12 02:01:20,247 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om3_1       | GC pool 'ParNew' had collection(s): count=15 time=759ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=180ms
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:196)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:483)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:189)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:163)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:309)
om3_1       | 2020-12-12 02:01:36,256 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | GC pool 'ParNew' had collection(s): count=15 time=759ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=180ms
om3_1       | 2020-12-12 02:01:37,759 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=15 time=759ms
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.lambda$dispatch$0(HddsDispatcher.java:171)
datanode_3  | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:170)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=6 time=180ms
om3_1       | 2020-12-12 02:01:52,271 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
om3_1       | GC pool 'ParNew' had collection(s): count=16 time=819ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=7 time=208ms
om3_1       | 2020-12-12 02:02:03,778 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=16 time=819ms
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_3  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=7 time=208ms
om3_1       | 2020-12-12 02:02:37,792 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=17 time=848ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=7 time=208ms
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:783)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
om3_1       | 2020-12-12 02:02:58,807 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
om3_1       | GC pool 'ParNew' had collection(s): count=17 time=848ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=7 time=208ms
om3_1       | 2020-12-12 02:03:21,319 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
datanode_3  | 2020-12-12 02:14:16,096 [grpc-default-executor-8] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 177 .Container 1 bcsId is 127. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 177 .Container 1 bcsId is 127.
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:196)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:483)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:189)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:163)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:309)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.lambda$dispatch$0(HddsDispatcher.java:171)
datanode_3  | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:170)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_3  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:783)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-12-12 02:14:17,442 [grpc-default-executor-8] INFO keyvalue.KeyValueHandler: Operation: GetBlock , Trace ID:  , Message: Unable to find the block with bcsID 177 .Container 1 bcsId is 127. , Result: UNKNOWN_BCSID , StorageContainerException Occurred.
datanode_3  | org.apache.hadoop.hdds.scm.container.common.helpers.StorageContainerException: Unable to find the block with bcsID 177 .Container 1 bcsId is 127.
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.impl.BlockManagerImpl.getBlock(BlockManagerImpl.java:196)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handleGetBlock(KeyValueHandler.java:483)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.dispatchRequest(KeyValueHandler.java:189)
datanode_3  | 	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.handle(KeyValueHandler.java:163)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatchRequest(HddsDispatcher.java:309)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.lambda$dispatch$0(HddsDispatcher.java:171)
datanode_3  | 	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:87)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.impl.HddsDispatcher.dispatch(HddsDispatcher.java:170)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:57)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.transport.server.GrpcXceiverService$1.onNext(GrpcXceiverService.java:50)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:251)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
datanode_3  | 	at org.apache.hadoop.hdds.tracing.GrpcServerInterceptor$1.onMessage(GrpcServerInterceptor.java:49)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:309)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:292)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:783)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode_3  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:123)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:834)
datanode_3  | 2020-12-12 02:14:22,279 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
datanode_3  | GC pool 'ParNew' had collection(s): count=7914 time=24407ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om3_1       | GC pool 'ParNew' had collection(s): count=17 time=848ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=7 time=208ms
om3_1       | 2020-12-12 02:04:34,346 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=19 time=905ms
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=8 time=230ms
om3_1       | 2020-12-12 02:05:17,364 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=20 time=922ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=9 time=257ms
om3_1       | 2020-12-12 02:05:39,376 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5ms
om3_1       | GC pool 'ParNew' had collection(s): count=20 time=922ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=9 time=257ms
om3_1       | 2020-12-12 02:05:56,386 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | GC pool 'ParNew' had collection(s): count=20 time=922ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=9 time=257ms
om3_1       | 2020-12-12 02:06:09,897 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=20 time=922ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=9 time=257ms
om3_1       | 2020-12-12 02:06:38,908 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=21 time=997ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=289ms
om3_1       | 2020-12-12 02:06:51,416 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | GC pool 'ParNew' had collection(s): count=21 time=997ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=289ms
om3_1       | 2020-12-12 02:06:51,921 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om3_1       | GC pool 'ParNew' had collection(s): count=21 time=997ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=289ms
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-12-12 01:57:36,828 [qtp166454155-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidPart</Code>
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1       |   <Resource>83908/multipartKey3</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-12 01:57:37,361 [qtp166454155-22] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-18154, , key: 83908/multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:602)
om3_1       | 2020-12-12 02:06:53,923 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=21 time=997ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=289ms
om3_1       | 2020-12-12 02:07:11,934 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om3_1       | GC pool 'ParNew' had collection(s): count=22 time=1065ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=289ms
om3_1       | 2020-12-12 02:07:12,437 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | GC pool 'ParNew' had collection(s): count=22 time=1065ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=289ms
om3_1       | 2020-12-12 02:07:33,446 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | GC pool 'ParNew' had collection(s): count=22 time=1065ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=10 time=289ms
om3_1       | 2020-12-12 02:08:23,965 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=23 time=1091ms
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:947)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:951)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:634)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:509)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=11 time=337ms
om3_1       | 2020-12-12 02:08:52,476 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=24 time=1117ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=12 time=358ms
om3_1       | 2020-12-12 02:09:03,483 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
datanode_3  | 2020-12-12 02:14:24,784 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
datanode_3  | GC pool 'ParNew' had collection(s): count=7933 time=24492ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om3_1       | GC pool 'ParNew' had collection(s): count=24 time=1117ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=12 time=358ms
om3_1       | 2020-12-12 02:09:08,491 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 6ms
om3_1       | GC pool 'ParNew' had collection(s): count=24 time=1117ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=12 time=358ms
datanode_3  | 2020-12-12 02:14:26,785 [org.apache.ratis.server.JvmPauseMonitor@7af39145-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
datanode_3  | GC pool 'ParNew' had collection(s): count=7945 time=24579ms
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=2 time=54ms
om3_1       | 2020-12-12 02:09:12,495 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=24 time=1117ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=12 time=358ms
om3_1       | 2020-12-12 02:09:26,006 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
om3_1       | GC pool 'ParNew' had collection(s): count=24 time=1117ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=12 time=358ms
om3_1       | 2020-12-12 02:09:31,509 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=24 time=1117ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=12 time=358ms
om3_1       | 2020-12-12 02:09:45,018 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om3_1       | GC pool 'ParNew' had collection(s): count=25 time=1147ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=13 time=379ms
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
om3_1       | 2020-12-12 02:10:10,528 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=25 time=1147ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=13 time=379ms
om3_1       | 2020-12-12 02:10:22,036 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om3_1       | GC pool 'ParNew' had collection(s): count=25 time=1147ms
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=13 time=379ms
om3_1       | 2020-12-12 02:10:31,046 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 7ms
om3_1       | GC pool 'ParNew' had collection(s): count=25 time=1147ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=13 time=379ms
om3_1       | 2020-12-12 02:11:28,067 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
om3_1       | GC pool 'ParNew' had collection(s): count=26 time=1176ms
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=14 time=418ms
om3_1       | 2020-12-12 02:11:30,577 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 8ms
om3_1       | GC pool 'ParNew' had collection(s): count=27 time=1195ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=14 time=418ms
om3_1       | 2020-12-12 02:11:39,585 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2ms
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
om3_1       | GC pool 'ParNew' had collection(s): count=27 time=1195ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=437ms
om3_1       | 2020-12-12 02:11:55,091 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=27 time=1195ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=437ms
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
om3_1       | 2020-12-12 02:12:15,099 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=27 time=1195ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=15 time=437ms
om3_1       | 2020-12-12 02:12:36,109 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
om3_1       | GC pool 'ParNew' had collection(s): count=28 time=1240ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=460ms
om3_1       | 2020-12-12 02:12:45,617 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3ms
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
om3_1       | GC pool 'ParNew' had collection(s): count=28 time=1240ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=460ms
om3_1       | 2020-12-12 02:12:58,124 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=28 time=1240ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=16 time=460ms
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
om3_1       | 2020-12-12 02:13:29,136 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1ms
om3_1       | GC pool 'ParNew' had collection(s): count=29 time=1265ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=17 time=477ms
om3_1       | 2020-12-12 02:13:56,649 [org.apache.ratis.server.JvmPauseMonitor@7c523bdd-Monitor] WARN server.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4ms
om3_1       | GC pool 'ParNew' had collection(s): count=29 time=1265ms
om3_1       | GC pool 'ConcurrentMarkSweep' had collection(s): count=17 time=477ms
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-12-12 01:57:37,363 [qtp166454155-22] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidPart</Code>
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1       |   <Resource>83908/multipartKey3</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-12 01:57:38,066 [qtp166454155-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-F6CC051F0B50->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:57:38,066 [qtp166454155-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:57:41,664 [qtp166454155-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-C3F953470002->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:57:41,664 [qtp166454155-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:57:45,317 [qtp166454155-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-138C9FD713C2->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:57:45,317 [qtp166454155-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:57:48,543 [qtp166454155-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-18154, , key: 83908/multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3. Provided Part info is { etag1, 1}, whereas OM has partName /s3v/bucket-18154/83908/multipartKey3105364734474453005
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:602)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:947)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:951)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:634)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:509)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-12-12 01:57:48,555 [qtp166454155-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidPart</Code>
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1       |   <Resource>83908/multipartKey3</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-12 01:57:49,107 [qtp166454155-22] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-18154, , key: 83908/multipartKey3
s3g_1       | INVALID_PART org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3. Provided Part info is { etag2, 2}, whereas OM has partName /s3v/bucket-18154/83908/multipartKey3105364734706188302
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:602)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:947)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:951)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:634)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:509)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-12-12 01:57:49,110 [qtp166454155-22] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidPart</Code>
s3g_1       |   <Message>One or more of the specified parts could not be found. The part might not have been uploaded, or the specified entity tag might not have matched the part's entity tag.</Message>
s3g_1       |   <Resource>83908/multipartKey3</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-12 01:57:49,727 [qtp166454155-20] ERROR endpoint.ObjectEndpoint: Error in Complete Multipart Upload Request for bucket: bucket-18154, , key: 83908/multipartKey3
s3g_1       | INVALID_PART_ORDER org.apache.hadoop.ozone.om.exceptions.OMException: Complete Multipart Upload Failed: volume: s3v bucket: bucket-18154 key: 83908/multipartKey3 because parts are in Invalid order.
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:602)
s3g_1       | 	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.completeMultipartUpload(OzoneManagerProtocolClientSideTranslatorPB.java:947)
s3g_1       | 	at org.apache.hadoop.ozone.client.rpc.RpcClient.completeMultipartUpload(RpcClient.java:951)
s3g_1       | 	at org.apache.hadoop.ozone.client.OzoneBucket.completeMultipartUpload(OzoneBucket.java:634)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.completeMultipartUpload(ObjectEndpoint.java:509)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
s3g_1       | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 2020-12-12 01:57:49,735 [qtp166454155-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidPartOrder</Code>
s3g_1       |   <Message>The list of parts was not in ascending order. The parts list must be specified in order by part number.</Message>
s3g_1       |   <Resource>83908/multipartKey3</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-12 01:57:53,018 [qtp166454155-22] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchUpload</Code>
s3g_1       |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1       |   <Resource>random</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-12 01:57:53,568 [qtp166454155-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchUpload</Code>
s3g_1       |   <Message>The specified multipart upload does not exist. The upload ID might be invalid, or the multipart upload might have been aborted or completed.</Message>
s3g_1       |   <Resource>random</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-12 01:57:54,912 [qtp166454155-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-CC868B7C9F30->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:57:54,912 [qtp166454155-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:57:58,418 [qtp166454155-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-B5DD8E0A2ED7->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:57:58,418 [qtp166454155-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:58:04,844 [qtp166454155-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-5099CB7C0F52->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:58:04,845 [qtp166454155-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:58:04,861 [qtp166454155-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-4F054E16C28E->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:58:04,861 [qtp166454155-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | Dec 12, 2020 1:58:04 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=51, target=172.23.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:142)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:240)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4876)
s3g_1       | 	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
s3g_1       | 	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4871)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:170)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:159)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.acquireClient(BlockInputStream.java:220)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:194)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:275)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | 2020-12-12 01:58:04,864 [qtp166454155-17] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E8C486AD30A6->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:58:04,864 [qtp166454155-17] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:58:11,987 [qtp166454155-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E1B0848BB819->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:58:11,987 [qtp166454155-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:58:16,405 [qtp166454155-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-35871F0932A5->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:58:16,406 [qtp166454155-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:58:21,401 [qtp166454155-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-DD5DB9287B2F->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:58:21,401 [qtp166454155-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | Dec 12, 2020 1:58:24 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=107, target=172.23.0.8:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:543)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.checkOpen(XceiverClientGrpc.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:462)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:371)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.lambda$sendCommandWithTraceIDAndRetry$0(XceiverClientGrpc.java:311)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInSpan(TracingUtil.java:174)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:148)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:305)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:286)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:106)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:206)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:275)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Dec 12, 2020 1:58:24 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=95, target=172.23.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:142)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:240)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4876)
s3g_1       | 	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
s3g_1       | 	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4871)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:170)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:159)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.acquireClient(BlockInputStream.java:220)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:194)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:594)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:156)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Dec 12, 2020 1:58:24 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=97, target=172.23.0.8:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:543)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.checkOpen(XceiverClientGrpc.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:462)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:371)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.lambda$sendCommandWithTraceIDAndRetry$0(XceiverClientGrpc.java:311)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInSpan(TracingUtil.java:174)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:148)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:305)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:286)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:106)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:206)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:594)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:156)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Dec 12, 2020 1:58:24 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=105, target=172.23.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:142)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:240)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4876)
s3g_1       | 	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
s3g_1       | 	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4871)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:170)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:159)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.acquireClient(BlockInputStream.java:220)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:194)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:275)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | 2020-12-12 01:58:25,614 [qtp166454155-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-CC2BA766C525->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:58:25,614 [qtp166454155-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:58:29,135 [qtp166454155-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0FA9338CE520->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:58:29,135 [qtp166454155-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | Dec 12, 2020 1:58:29 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=115, target=172.23.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:142)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:240)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4876)
s3g_1       | 	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
s3g_1       | 	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4871)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:170)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:159)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.acquireClient(BlockInputStream.java:220)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:194)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:590)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:156)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | 2020-12-12 01:58:37,549 [qtp166454155-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-17824, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-12 01:58:37,565 [qtp166454155-23] INFO endpoint.BucketEndpoint: Location is /bucket-17824
s3g_1       | 2020-12-12 01:58:38,075 [qtp166454155-24] INFO rpc.RpcClient: Creating Bucket: s3v/destbucket-03774, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-12 01:58:38,102 [qtp166454155-24] INFO endpoint.BucketEndpoint: Location is /destbucket-03774
s3g_1       | 2020-12-12 01:58:38,732 [qtp166454155-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-0D69436B9F0E->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:58:38,732 [qtp166454155-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:58:42,571 [qtp166454155-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-134F7F4E1222->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:58:42,571 [qtp166454155-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:58:46,229 [qtp166454155-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E8A48BF63794->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:58:46,234 [qtp166454155-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:58:49,904 [qtp166454155-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchBucket</Code>
s3g_1       |   <Message>The specified bucket does not exist</Message>
s3g_1       |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-12 01:58:50,429 [qtp166454155-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchBucket</Code>
s3g_1       |   <Message>The specified bucket does not exist</Message>
s3g_1       |   <Resource>dfdfdfdfdfnonexistent</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-12 01:58:51,482 [qtp166454155-24] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchKey</Code>
s3g_1       |   <Message>The specified key does not exist</Message>
s3g_1       |   <Resource>nonnonexistentkey</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-12 01:58:54,048 [qtp166454155-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-60202, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-12 01:58:54,068 [qtp166454155-23] INFO endpoint.BucketEndpoint: Location is /bucket-60202
s3g_1       | 2020-12-12 01:58:54,984 [qtp166454155-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-990DFA6026D0->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:58:54,984 [qtp166454155-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 01:59:01,524 [qtp166454155-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-F55D080FFF81->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:59:01,524 [qtp166454155-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | Dec 12, 2020 1:59:01 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=151, target=172.23.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:142)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:240)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4876)
s3g_1       | 	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
s3g_1       | 	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4871)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:170)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:159)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.acquireClient(BlockInputStream.java:220)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:194)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.copyObject(ObjectEndpoint.java:744)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:178)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Dec 12, 2020 1:59:01 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=123, target=172.23.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:142)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:240)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4876)
s3g_1       | 	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
s3g_1       | 	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4871)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:170)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:159)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.acquireClient(BlockInputStream.java:220)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:194)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2221)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2179)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.createMultipartKey(ObjectEndpoint.java:590)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:156)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Dec 12, 2020 1:59:01 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=131, target=172.23.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:142)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:240)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4876)
s3g_1       | 	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
s3g_1       | 	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4871)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:170)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:159)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.acquireClient(BlockInputStream.java:220)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:194)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:275)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Dec 12, 2020 1:59:01 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=135, target=172.23.0.8:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.reconnect(XceiverClientGrpc.java:543)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.checkOpen(XceiverClientGrpc.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandAsync(XceiverClientGrpc.java:462)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithRetry(XceiverClientGrpc.java:371)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.lambda$sendCommandWithTraceIDAndRetry$0(XceiverClientGrpc.java:311)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInSpan(TracingUtil.java:174)
s3g_1       | 	at org.apache.hadoop.hdds.tracing.TracingUtil.executeInNewSpan(TracingUtil.java:148)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommandWithTraceIDAndRetry(XceiverClientGrpc.java:305)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.sendCommand(XceiverClientGrpc.java:286)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.ContainerProtocolCalls.getBlock(ContainerProtocolCalls.java:106)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:206)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.lambda$get$0(ObjectEndpoint.java:275)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:79)
s3g_1       | 	at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:61)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.invokeWriteTo(WriterInterceptorExecutor.java:266)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:251)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:109)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:85)
s3g_1       | 	at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:163)
s3g_1       | 	at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1135)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:662)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:395)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:385)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:280)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | Dec 12, 2020 1:59:01 AM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
s3g_1       | SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=143, target=172.23.0.9:9859} was not shutdown properly!!! ~*~*~*
s3g_1       |     Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
s3g_1       | java.lang.RuntimeException: ManagedChannel allocation site
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
s3g_1       | 	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:518)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:193)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:142)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:240)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4876)
s3g_1       | 	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
s3g_1       | 	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
s3g_1       | 	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
s3g_1       | 	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4871)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:170)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClientForReadData(XceiverClientManager.java:159)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.acquireClient(BlockInputStream.java:220)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.getChunkInfos(BlockInputStream.java:194)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.initialize(BlockInputStream.java:135)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockInputStream.read(BlockInputStream.java:269)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyInputStream.read(KeyInputStream.java:199)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneInputStream.read(OzoneInputStream.java:49)
s3g_1       | 	at java.base/java.io.InputStream.read(InputStream.java:205)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2146)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2102)
s3g_1       | 	at org.apache.commons.io.IOUtils.copyLarge(IOUtils.java:2123)
s3g_1       | 	at org.apache.commons.io.IOUtils.copy(IOUtils.java:2078)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.copyObject(ObjectEndpoint.java:744)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:178)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | 
s3g_1       | 2020-12-12 01:59:04,696 [qtp166454155-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-B3F48DD8CFE6->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 01:59:04,696 [qtp166454155-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 02:00:05,184 [qtp166454155-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-DD1B1BD89B99->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 02:00:05,185 [qtp166454155-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 02:01:05,577 [qtp166454155-22] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-437A183AD5A6->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 02:01:05,577 [qtp166454155-22] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 02:02:04,789 [qtp166454155-23] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #121 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:217)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #121 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-12 02:02:04,801 [qtp166454155-23] INFO scm.XceiverClientRatis: Could not commit index 131 on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z] to all the nodes. Server c825d659-cfaa-4cfc-8134-552ad3e9db61 has failed. Committed by majority.
s3g_1       | 2020-12-12 02:02:04,802 [qtp166454155-23] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105364740156948506 bcsId: 131 on Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]. Failed nodes: [c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-12 02:02:09,111 [qtp166454155-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-7EDD794D3A70->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 02:02:09,111 [qtp166454155-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 02:03:05,229 [qtp166454155-19] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #125 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:217)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #125 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-12 02:03:05,240 [qtp166454155-19] INFO scm.XceiverClientRatis: Could not commit index 134 on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z] to all the nodes. Server c825d659-cfaa-4cfc-8134-552ad3e9db61 has failed. Committed by majority.
s3g_1       | 2020-12-12 02:03:05,240 [qtp166454155-19] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105364744120172571 bcsId: 134 on Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]. Failed nodes: [c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-12 02:03:16,895 [qtp166454155-236] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-50F8EFDB006D->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 02:03:16,895 [qtp166454155-236] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 02:04:04,644 [qtp166454155-23] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchBucket</Code>
s3g_1       |   <Message>The specified bucket does not exist</Message>
s3g_1       |   <Resource>bucket-60202-nosuchbucket</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-12 02:04:05,628 [qtp166454155-22] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #129 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:217)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #129 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-12 02:04:05,635 [qtp166454155-22] INFO scm.XceiverClientRatis: Could not commit index 139 on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z] to all the nodes. Server c825d659-cfaa-4cfc-8134-552ad3e9db61 has failed. Committed by majority.
s3g_1       | 2020-12-12 02:04:05,635 [qtp166454155-22] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105364748078284828 bcsId: 139 on Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]. Failed nodes: [c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-12 02:04:07,615 [qtp166454155-19] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-34793, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-12 02:04:07,632 [qtp166454155-19] INFO endpoint.BucketEndpoint: Location is /bucket-34793
s3g_1       | 2020-12-12 02:04:08,267 [qtp166454155-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-2769D812F4A0->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 02:04:08,268 [qtp166454155-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 02:05:08,811 [qtp166454155-21] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-A10EEBFF423A->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 02:05:08,812 [qtp166454155-21] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 02:05:09,186 [qtp166454155-24] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #134 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:217)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #134 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-12 02:05:09,196 [qtp166454155-24] INFO scm.XceiverClientRatis: Could not commit index 142 on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z] to all the nodes. Server c825d659-cfaa-4cfc-8134-552ad3e9db61 has failed. Committed by majority.
s3g_1       | 2020-12-12 02:05:09,197 [qtp166454155-24] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105364752240803869 bcsId: 142 on Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]. Failed nodes: [c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-12 02:06:10,045 [qtp166454155-20] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-BAF9CE88F264->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 02:06:10,047 [qtp166454155-20] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 02:06:16,980 [qtp166454155-236] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #139 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:217)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #139 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-12 02:06:16,985 [qtp166454155-236] INFO scm.XceiverClientRatis: Could not commit index 147 on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z] to all the nodes. Server c825d659-cfaa-4cfc-8134-552ad3e9db61 has failed. Committed by majority.
s3g_1       | 2020-12-12 02:06:16,985 [qtp166454155-236] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105364756683096094 bcsId: 147 on Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]. Failed nodes: [c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-12 02:07:08,336 [qtp166454155-23] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #144 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:217)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #144 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-12 02:07:08,353 [qtp166454155-23] INFO scm.XceiverClientRatis: Could not commit index 150 on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z] to all the nodes. Server c825d659-cfaa-4cfc-8134-552ad3e9db61 has failed. Committed by majority.
s3g_1       | 2020-12-12 02:07:08,353 [qtp166454155-23] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105364760051580959 bcsId: 150 on Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]. Failed nodes: [c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-12 02:07:11,236 [qtp166454155-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-C0BC04381E2F->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 02:07:11,237 [qtp166454155-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 02:08:08,865 [qtp166454155-21] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #148 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:217)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #148 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-12 02:08:08,890 [qtp166454155-21] INFO scm.XceiverClientRatis: Could not commit index 154 on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z] to all the nodes. Server c825d659-cfaa-4cfc-8134-552ad3e9db61 has failed. Committed by majority.
s3g_1       | 2020-12-12 02:08:08,890 [qtp166454155-21] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105364764019327008 bcsId: 154 on Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]. Failed nodes: [c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-12 02:08:12,856 [qtp166454155-236] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-AA778650C8DF->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 02:08:12,858 [qtp166454155-236] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 02:09:10,140 [qtp166454155-20] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #153 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:217)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #153 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-12 02:09:10,145 [qtp166454155-20] INFO scm.XceiverClientRatis: Could not commit index 158 on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z] to all the nodes. Server c825d659-cfaa-4cfc-8134-552ad3e9db61 has failed. Committed by majority.
s3g_1       | 2020-12-12 02:09:10,145 [qtp166454155-20] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105364768031768609 bcsId: 158 on Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]. Failed nodes: [c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-12 02:09:10,916 [qtp166454155-23] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-95619, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-12 02:09:10,925 [qtp166454155-23] INFO endpoint.BucketEndpoint: Location is /bucket-95619
s3g_1       | 2020-12-12 02:09:11,707 [qtp166454155-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-36C1BB3B9A68->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 02:09:11,707 [qtp166454155-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 02:10:11,298 [qtp166454155-19] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #159 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:217)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #159 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-12 02:10:11,313 [qtp166454155-19] INFO scm.XceiverClientRatis: Could not commit index 162 on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z] to all the nodes. Server c825d659-cfaa-4cfc-8134-552ad3e9db61 has failed. Committed by majority.
s3g_1       | 2020-12-12 02:10:11,314 [qtp166454155-19] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105364772041130018 bcsId: 162 on Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]. Failed nodes: [c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-12 02:10:12,677 [qtp166454155-24] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-EA89F7E0E2C3->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 02:10:12,685 [qtp166454155-24] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 02:11:12,936 [qtp166454155-236] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #164 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:217)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #164 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-12 02:11:12,942 [qtp166454155-236] INFO scm.XceiverClientRatis: Could not commit index 165 on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z] to all the nodes. Server c825d659-cfaa-4cfc-8134-552ad3e9db61 has failed. Committed by majority.
s3g_1       | 2020-12-12 02:11:12,943 [qtp166454155-236] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105364776079261731 bcsId: 165 on Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]. Failed nodes: [c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-12 02:11:14,020 [qtp166454155-236] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-590DCA55C51D->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 02:11:14,020 [qtp166454155-236] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 02:12:11,801 [qtp166454155-23] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #169 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:217)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #169 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-12 02:12:11,833 [qtp166454155-23] INFO scm.XceiverClientRatis: Could not commit index 169 on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z] to all the nodes. Server c825d659-cfaa-4cfc-8134-552ad3e9db61 has failed. Committed by majority.
s3g_1       | 2020-12-12 02:12:11,833 [qtp166454155-23] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105364779937497124 bcsId: 169 on Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]. Failed nodes: [c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-12 02:12:17,486 [qtp166454155-19] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-E79C49A01839->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 02:12:17,489 [qtp166454155-19] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 02:13:12,739 [qtp166454155-24] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #174 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:217)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)
s3g_1       | 	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)
s3g_1       | 	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:375)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #174 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-12 02:13:12,748 [qtp166454155-24] INFO scm.XceiverClientRatis: Could not commit index 173 on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z] to all the nodes. Server c825d659-cfaa-4cfc-8134-552ad3e9db61 has failed. Committed by majority.
s3g_1       | 2020-12-12 02:13:12,748 [qtp166454155-24] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105364783933882405 bcsId: 173 on Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]. Failed nodes: [c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-12 02:13:23,510 [qtp166454155-23] INFO metrics.RatisMetrics: Creating Metrics Registry : ratis.client_message_metrics.client-9391A61E5C6D->2efbbdc8-7434-4046-ac05-b8a2df4b2a7b
s3g_1       | 2020-12-12 02:13:23,511 [qtp166454155-23] WARN impl.MetricRegistriesImpl: First MetricRegistry has been created without registering reporters. You may need to call MetricRegistries.global().addReporterRegistration(...) before.
s3g_1       | 2020-12-12 02:14:14,062 [qtp166454155-236] WARN scm.XceiverClientRatis: 3 way commit failed on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]
s3g_1       | java.util.concurrent.ExecutionException: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #179 timeout 180s
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
s3g_1       | 	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)
s3g_1       | 	at org.apache.hadoop.hdds.scm.XceiverClientRatis.watchForCommit(XceiverClientRatis.java:263)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchForCommit(CommitWatcher.java:199)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.CommitWatcher.watchOnLastIndex(CommitWatcher.java:166)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.watchForCommit(BlockOutputStream.java:382)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.handleFlush(BlockOutputStream.java:534)
s3g_1       | 	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.close(BlockOutputStream.java:548)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.close(BlockOutputStreamEntry.java:129)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleStreamAction(KeyOutputStream.java:497)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.handleFlushOrClose(KeyOutputStream.java:471)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.KeyOutputStream.close(KeyOutputStream.java:524)
s3g_1       | 	at org.apache.hadoop.ozone.client.io.OzoneOutputStream.close(OzoneOutputStream.java:60)
s3g_1       | 	at org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.put(ObjectEndpoint.java:217)
s3g_1       | 	at jdk.internal.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
s3g_1       | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
s3g_1       | 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory.lambda$static$0(ResourceMethodInvocationHandlerFactory.java:76)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:148)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:191)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:200)
s3g_1       | 	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:103)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:493)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:415)
s3g_1       | 	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:104)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:277)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:272)
s3g_1       | 	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:316)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:298)
s3g_1       | 	at org.glassfish.jersey.internal.Errors.process(Errors.java:268)
s3g_1       | 	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:289)
s3g_1       | 	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:256)
s3g_1       | 	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:703)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:416)
s3g_1       | 	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:370)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:389)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:342)
s3g_1       | 	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:229)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder$NotAsync.service(ServletHolder.java:1452)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:791)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
s3g_1       | 	at org.apache.hadoop.ozone.s3.RootPageDisplayFilter.doFilter(RootPageDisplayFilter.java:53)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:201)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1667)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.apache.hadoop.hdds.server.http.NoCacheFilter.doFilter(NoCacheFilter.java:48)
s3g_1       | 	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
s3g_1       | 	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1612)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
s3g_1       | 	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
s3g_1       | 	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1582)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
s3g_1       | 	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
s3g_1       | 	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
s3g_1       | 	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
s3g_1       | 	at org.eclipse.jetty.server.Server.handle(Server.java:516)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:383)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:556)
s3g_1       | 	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:375)
s3g_1       | 	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:273)
s3g_1       | 	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
s3g_1       | 	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
s3g_1       | 	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:773)
s3g_1       | 	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:905)
s3g_1       | 	at java.base/java.lang.Thread.run(Thread.java:834)
s3g_1       | Caused by: org.apache.ratis.protocol.exceptions.TimeoutIOException: Request #179 timeout 180s
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$timeoutCheck$5(GrpcClientProtocolClient.java:337)
s3g_1       | 	at java.base/java.util.Optional.ifPresent(Optional.java:183)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.handleReplyFuture(GrpcClientProtocolClient.java:342)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.timeoutCheck(GrpcClientProtocolClient.java:337)
s3g_1       | 	at org.apache.ratis.grpc.client.GrpcClientProtocolClient$AsyncStreamObservers.lambda$onNext$1(GrpcClientProtocolClient.java:326)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$0(TimeoutScheduler.java:141)
s3g_1       | 	at org.apache.ratis.util.TimeoutScheduler.lambda$onTimeout$1(TimeoutScheduler.java:155)
s3g_1       | 	at org.apache.ratis.util.LogUtils.runAndLog(LogUtils.java:38)
s3g_1       | 	at org.apache.ratis.util.LogUtils$1.run(LogUtils.java:79)
s3g_1       | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
s3g_1       | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
s3g_1       | 	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
s3g_1       | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
s3g_1       | 	... 1 more
s3g_1       | 2020-12-12 02:14:14,069 [qtp166454155-236] INFO scm.XceiverClientRatis: Could not commit index 177 on pipeline Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z] to all the nodes. Server c825d659-cfaa-4cfc-8134-552ad3e9db61 has failed. Committed by majority.
s3g_1       | 2020-12-12 02:14:14,070 [qtp166454155-236] WARN storage.BlockOutputStream: Failed to commit BlockId conID: 1 locID: 105364787952353318 bcsId: 177 on Pipeline[ Id: 250da368-dbcb-48e6-92cc-45c2e0698f41, Nodes: 2cbe4a56-f48d-46d2-9e37-17202fd9dde9{ip: 172.23.0.9, host: ozone-om-ha-s3_datanode_1.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2efbbdc8-7434-4046-ac05-b8a2df4b2a7b{ip: 172.23.0.8, host: ozone-om-ha-s3_datanode_2.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: 172.23.0.7, host: ozone-om-ha-s3_datanode_3.ozone-om-ha-s3_default, networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:OPEN, leaderId:2efbbdc8-7434-4046-ac05-b8a2df4b2a7b, CreationTimestamp2020-12-12T01:55:48.613Z]. Failed nodes: [c825d659-cfaa-4cfc-8134-552ad3e9db61{ip: null, host: null, networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}]
s3g_1       | 2020-12-12 02:14:14,156 [qtp166454155-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>InvalidRange</Code>
s3g_1       |   <Message>The requested range is not satisfiable</Message>
s3g_1       |   <Resource>bytes=10000-10000</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-12 02:14:19,969 [qtp166454155-20] ERROR exception.S3ErrorTable: <?xml version="1.0" encoding="UTF-8"?>
s3g_1       | <Error>
s3g_1       |   <Code>NoSuchKey</Code>
s3g_1       |   <Message>The specified key does not exist</Message>
s3g_1       |   <Resource>46956/putobject/zerobyte</Resource>
s3g_1       |   <RequestId/>
s3g_1       | </Error>
s3g_1       | 
s3g_1       | 2020-12-12 02:14:22,931 [qtp166454155-20] INFO rpc.RpcClient: Creating Bucket: s3v/bucket-35097, with Versioning false and Storage Type set to DISK and Encryption set to false 
s3g_1       | 2020-12-12 02:14:22,945 [qtp166454155-20] INFO endpoint.BucketEndpoint: Location is /bucket-35097
