Waiting for the service scm1.org:9894
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-12-12 10:36:29,502 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm2.org/172.25.0.117
STARTUP_MSG:   args = [--bootstrap]
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.21.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.21.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.21.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.21.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.0.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/a93015a85b8ebe6a3e9423372f3337ed9b029704 ; compiled by 'runner' on 2023-12-12T10:10Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=true, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=4MB, dfs.container.ratis.segment.size=64MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60s, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.handler.type=distributed, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-address.omservice.om1=om1, ozone.om.http-address.omservice.om2=om2, ozone.om.http-address.omservice.om3=om3, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.internal.service.id=omservice, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=false, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=20s, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=5s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.enable=true, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-12-12 10:36:29,524 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-12-12 10:36:29,604 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-12 10:36:29,745 [main] INFO reflections.Reflections: Reflections took 109 ms to scan 3 urls, producing 134 keys and 291 values 
2023-12-12 10:36:29,871 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2023-12-12 10:36:29,872 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-12-12 10:36:29,897 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
2023-12-12 10:36:29,900 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
2023-12-12 10:36:30,054 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2023-12-12 10:36:30,054 [main] INFO server.StorageContainerManager: SCM login successful.
2023-12-12 10:36:30,155 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
2023-12-12 10:36:34,301 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 2.
2023-12-12 10:36:36,303 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 3.
2023-12-12 10:36:38,304 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 4.
2023-12-12 10:36:40,312 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 5.
2023-12-12 10:36:42,489 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:9d6cdba7-5750-4d18-8893-6bccaafab041 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 6.
2023-12-12 10:36:44,490 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 7.
2023-12-12 10:36:46,535 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
2023-12-12 10:36:46,957 [main] INFO client.SCMCertificateClient: Certificate serial ID set to null
2023-12-12 10:36:46,957 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
2023-12-12 10:36:46,958 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
2023-12-12 10:36:46,960 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
2023-12-12 10:36:47,505 [main] INFO client.SCMCertificateClient: Init response: GETCERT
2023-12-12 10:36:47,506 [main] INFO client.SCMCertificateClient: Creating csr for SCM->hostName:scm2.org,scmId:2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f,clusterId:CID-11911259-cbcd-4d21-80b8-1024bf673070,subject:scm-sub@scm2.org
2023-12-12 10:36:47,528 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
2023-12-12 10:36:47,528 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2023-12-12 10:36:48,110 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/CA-1.crt
2023-12-12 10:36:48,110 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDxTCCAq2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZjZGJhNy01NzUwLTRkMTgtODg5My02YmNj
YWFmYWIwNDExMTAvBgNVBAoMKENJRC0xMTkxMTI1OS1jYmNkLTRkMjEtODBiOC0x
MDI0YmY2NzMwNzAxCjAIBgNVBAUTATEwHhcNMjMxMjEyMTAzNjI1WhcNMjkwMTE5
MTAzNjI1WjCBhTEVMBMGA1UEAwwMc2NtQHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZj
ZGJhNy01NzUwLTRkMTgtODg5My02YmNjYWFmYWIwNDExMTAvBgNVBAoMKENJRC0x
MTkxMTI1OS1jYmNkLTRkMjEtODBiOC0xMDI0YmY2NzMwNzAxCjAIBgNVBAUTATEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDuP51ulJYWl58WA5s+BXzV
xiUqMkxJo5okKoCNO/mpO6wFA4FuJaw2nk0Gk75PAW8oD4uDqZNA7R+nHibbdbff
leKcHau2wCw+p0zwr50bRQyLhtYLd1ZEx4s7kmrhRoMctOUvNSoIrFoq4rMdr7gF
1Uw6MXPLzU6zV2gamVdmKLZebuZqU8c9rf8+wpfEPsRnKzgLKW7L5k+MXPLC15JP
5EsvUsytCZ08IjEKbX7V0BLqCaNAWYOBOfLlAuRZ9bWLoclaW2l/Xl9YeyNvK5HF
ZE7mBu1VkV5F1hBr5OxQnG0npVdtU2LpVdVPBlDOvwznbOXjpdlem+WZIfSg1z7r
AgMBAAGjPjA8MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMBkGA1Ud
EQQSMBCHBKwZAHSCCHNjbTEub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQDWyR811nl6
7E0qdT+f8uyQrTe/7oAeonknYsSQuh69afx7OO3QSwDezc2jp97Iw23C7yCmWxy8
sXXdjmoAxrAw6GOTLYEeJEbEgud/V12znlcsGSf3ja0S9CFKKTjqjl4tvkQlkSLW
i6mHzxI6aCG2Dkkbi1ls8V3PTnA8kb8da9O/qzHQ8PayxL7dyZr2VfNiQjoSu2cE
0RIYe4XwY5eP+lo5HjjeZbdQbjH3rxN1a7SzPNPWP5HHjUtpydWVR9j3FQXp46bW
oi8wUi3D2tK+ksSBEqWthwsLwNN3fRoommAx71wN8uYpHqKG6fjKXL1q6AC6Te6z
0wp50/+wYc6/
-----END CERTIFICATE-----

2023-12-12 10:36:48,114 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/3.crt
2023-12-12 10:36:48,114 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDyTCCArGgAwIBAgIBAzANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZjZGJhNy01NzUwLTRkMTgtODg5My02YmNj
YWFmYWIwNDExMTAvBgNVBAoMKENJRC0xMTkxMTI1OS1jYmNkLTRkMjEtODBiOC0x
MDI0YmY2NzMwNzAxCjAIBgNVBAUTATEwHhcNMjMxMjEyMTAzNjQ3WhcNMjkwMTE5
MTAzNjQ3WjCBiTEZMBcGA1UEAwwQc2NtLXN1YkBzY20yLm9yZzEtMCsGA1UECwwk
MmZjZDViYTItNDI5Ny00NTBlLWE0ZDYtN2FmNzVlOWQzZjFmMTEwLwYDVQQKDChD
SUQtMTE5MTEyNTktY2JjZC00ZDIxLTgwYjgtMTAyNGJmNjczMDcwMQowCAYDVQQF
EwEzMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAis2iYolyGxp5ZMSq
XGDXTKDTYrcPGGu/9kghd85FseTChS9cTCmsbXi1CsMg83z5Uir9bR626IuUABpG
DKbentuiMAh5/xjkMqdUIY8EWFmdQHR66D4JMRNQ5ljxgEn1qhkKd1bz2r2RzUVg
JMNR4ZItXOK4Gxj7/VDa3i4apUXoOQDUxwmnJNuqdNf4n/7Fk4VOGC/dt4hC+0vq
hl7olpCX7CPtqxkWM95wJnHRFbJSDN/ZecQ+aKYAn9+ltrvMdfV1mVIgc6GQIR/x
on9Gpo7b9yPynlsfE8DjaYfDJST6zfvgTQQPbIL39YKyeyVJLGiU5DfzeApM2NJh
SRQTWQIDAQABoz4wPDAZBgNVHREEEjAQhwSsGQB1gghzY20yLm9yZzAPBgNVHRMB
Af8EBTADAQH/MA4GA1UdDwEB/wQEAwIBvjANBgkqhkiG9w0BAQsFAAOCAQEAsSAX
fVvJR93AicI67dfqJj3S+gPCROhMR1dcdr7od6VaQnXjDXpB97k/COm+QoVEp00n
eMa7RKyZ/Xfht+YBHEvfYgXC3cuYwxd1yz14Z2Jvtjh6skDcCEkl+/obT+5sJKnT
f4myKqe1uIrCkx5cBJXzUTWC7htx05lNeO161oZXOlJyo9c7EaNSNCUHxYGjFRmG
MpDAk7UbBeirK99tW33sZr4jlVopv484BEnn0xO2ZK3u55EK4rPZE4YECMZM2Tjm
96Na/+qhuAIg99uVeOHkFFtNeCRevNXjZtY/KzIaaNuasPdr+/FZVE1sZaM0r/aH
bppq2Bwlsk2Cbf/mUg==
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDxTCCAq2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZjZGJhNy01NzUwLTRkMTgtODg5My02YmNj
YWFmYWIwNDExMTAvBgNVBAoMKENJRC0xMTkxMTI1OS1jYmNkLTRkMjEtODBiOC0x
MDI0YmY2NzMwNzAxCjAIBgNVBAUTATEwHhcNMjMxMjEyMTAzNjI1WhcNMjkwMTE5
MTAzNjI1WjCBhTEVMBMGA1UEAwwMc2NtQHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZj
ZGJhNy01NzUwLTRkMTgtODg5My02YmNjYWFmYWIwNDExMTAvBgNVBAoMKENJRC0x
MTkxMTI1OS1jYmNkLTRkMjEtODBiOC0xMDI0YmY2NzMwNzAxCjAIBgNVBAUTATEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDuP51ulJYWl58WA5s+BXzV
xiUqMkxJo5okKoCNO/mpO6wFA4FuJaw2nk0Gk75PAW8oD4uDqZNA7R+nHibbdbff
leKcHau2wCw+p0zwr50bRQyLhtYLd1ZEx4s7kmrhRoMctOUvNSoIrFoq4rMdr7gF
1Uw6MXPLzU6zV2gamVdmKLZebuZqU8c9rf8+wpfEPsRnKzgLKW7L5k+MXPLC15JP
5EsvUsytCZ08IjEKbX7V0BLqCaNAWYOBOfLlAuRZ9bWLoclaW2l/Xl9YeyNvK5HF
ZE7mBu1VkV5F1hBr5OxQnG0npVdtU2LpVdVPBlDOvwznbOXjpdlem+WZIfSg1z7r
AgMBAAGjPjA8MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMBkGA1Ud
EQQSMBCHBKwZAHSCCHNjbTEub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQDWyR811nl6
7E0qdT+f8uyQrTe/7oAeonknYsSQuh69afx7OO3QSwDezc2jp97Iw23C7yCmWxy8
sXXdjmoAxrAw6GOTLYEeJEbEgud/V12znlcsGSf3ja0S9CFKKTjqjl4tvkQlkSLW
i6mHzxI6aCG2Dkkbi1ls8V3PTnA8kb8da9O/qzHQ8PayxL7dyZr2VfNiQjoSu2cE
0RIYe4XwY5eP+lo5HjjeZbdQbjH3rxN1a7SzPNPWP5HHjUtpydWVR9j3FQXp46bW
oi8wUi3D2tK+ksSBEqWthwsLwNN3fRoommAx71wN8uYpHqKG6fjKXL1q6AC6Te6z
0wp50/+wYc6/
-----END CERTIFICATE-----

2023-12-12 10:36:48,114 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/certificate.crt
2023-12-12 10:36:48,115 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDyTCCArGgAwIBAgIBAzANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZjZGJhNy01NzUwLTRkMTgtODg5My02YmNj
YWFmYWIwNDExMTAvBgNVBAoMKENJRC0xMTkxMTI1OS1jYmNkLTRkMjEtODBiOC0x
MDI0YmY2NzMwNzAxCjAIBgNVBAUTATEwHhcNMjMxMjEyMTAzNjQ3WhcNMjkwMTE5
MTAzNjQ3WjCBiTEZMBcGA1UEAwwQc2NtLXN1YkBzY20yLm9yZzEtMCsGA1UECwwk
MmZjZDViYTItNDI5Ny00NTBlLWE0ZDYtN2FmNzVlOWQzZjFmMTEwLwYDVQQKDChD
SUQtMTE5MTEyNTktY2JjZC00ZDIxLTgwYjgtMTAyNGJmNjczMDcwMQowCAYDVQQF
EwEzMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAis2iYolyGxp5ZMSq
XGDXTKDTYrcPGGu/9kghd85FseTChS9cTCmsbXi1CsMg83z5Uir9bR626IuUABpG
DKbentuiMAh5/xjkMqdUIY8EWFmdQHR66D4JMRNQ5ljxgEn1qhkKd1bz2r2RzUVg
JMNR4ZItXOK4Gxj7/VDa3i4apUXoOQDUxwmnJNuqdNf4n/7Fk4VOGC/dt4hC+0vq
hl7olpCX7CPtqxkWM95wJnHRFbJSDN/ZecQ+aKYAn9+ltrvMdfV1mVIgc6GQIR/x
on9Gpo7b9yPynlsfE8DjaYfDJST6zfvgTQQPbIL39YKyeyVJLGiU5DfzeApM2NJh
SRQTWQIDAQABoz4wPDAZBgNVHREEEjAQhwSsGQB1gghzY20yLm9yZzAPBgNVHRMB
Af8EBTADAQH/MA4GA1UdDwEB/wQEAwIBvjANBgkqhkiG9w0BAQsFAAOCAQEAsSAX
fVvJR93AicI67dfqJj3S+gPCROhMR1dcdr7od6VaQnXjDXpB97k/COm+QoVEp00n
eMa7RKyZ/Xfht+YBHEvfYgXC3cuYwxd1yz14Z2Jvtjh6skDcCEkl+/obT+5sJKnT
f4myKqe1uIrCkx5cBJXzUTWC7htx05lNeO161oZXOlJyo9c7EaNSNCUHxYGjFRmG
MpDAk7UbBeirK99tW33sZr4jlVopv484BEnn0xO2ZK3u55EK4rPZE4YECMZM2Tjm
96Na/+qhuAIg99uVeOHkFFtNeCRevNXjZtY/KzIaaNuasPdr+/FZVE1sZaM0r/aH
bppq2Bwlsk2Cbf/mUg==
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDxTCCAq2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZjZGJhNy01NzUwLTRkMTgtODg5My02YmNj
YWFmYWIwNDExMTAvBgNVBAoMKENJRC0xMTkxMTI1OS1jYmNkLTRkMjEtODBiOC0x
MDI0YmY2NzMwNzAxCjAIBgNVBAUTATEwHhcNMjMxMjEyMTAzNjI1WhcNMjkwMTE5
MTAzNjI1WjCBhTEVMBMGA1UEAwwMc2NtQHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZj
ZGJhNy01NzUwLTRkMTgtODg5My02YmNjYWFmYWIwNDExMTAvBgNVBAoMKENJRC0x
MTkxMTI1OS1jYmNkLTRkMjEtODBiOC0xMDI0YmY2NzMwNzAxCjAIBgNVBAUTATEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDuP51ulJYWl58WA5s+BXzV
xiUqMkxJo5okKoCNO/mpO6wFA4FuJaw2nk0Gk75PAW8oD4uDqZNA7R+nHibbdbff
leKcHau2wCw+p0zwr50bRQyLhtYLd1ZEx4s7kmrhRoMctOUvNSoIrFoq4rMdr7gF
1Uw6MXPLzU6zV2gamVdmKLZebuZqU8c9rf8+wpfEPsRnKzgLKW7L5k+MXPLC15JP
5EsvUsytCZ08IjEKbX7V0BLqCaNAWYOBOfLlAuRZ9bWLoclaW2l/Xl9YeyNvK5HF
ZE7mBu1VkV5F1hBr5OxQnG0npVdtU2LpVdVPBlDOvwznbOXjpdlem+WZIfSg1z7r
AgMBAAGjPjA8MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMBkGA1Ud
EQQSMBCHBKwZAHSCCHNjbTEub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQDWyR811nl6
7E0qdT+f8uyQrTe/7oAeonknYsSQuh69afx7OO3QSwDezc2jp97Iw23C7yCmWxy8
sXXdjmoAxrAw6GOTLYEeJEbEgud/V12znlcsGSf3ja0S9CFKKTjqjl4tvkQlkSLW
i6mHzxI6aCG2Dkkbi1ls8V3PTnA8kb8da9O/qzHQ8PayxL7dyZr2VfNiQjoSu2cE
0RIYe4XwY5eP+lo5HjjeZbdQbjH3rxN1a7SzPNPWP5HHjUtpydWVR9j3FQXp46bW
oi8wUi3D2tK+ksSBEqWthwsLwNN3fRoommAx71wN8uYpHqKG6fjKXL1q6AC6Te6z
0wp50/+wYc6/
-----END CERTIFICATE-----

2023-12-12 10:36:48,116 [main] INFO client.SCMCertificateClient: Successfully stored SCM signed certificate.
2023-12-12 10:36:48,124 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-11911259-cbcd-4d21-80b8-1024bf673070, SCMID 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f
2023-12-12 10:36:48,124 [main] INFO server.StorageContainerManager: Primary SCM Node ID 9d6cdba7-5750-4d18-8893-6bccaafab041
2023-12-12 10:36:48,131 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-12-12 10:36:49,320 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm2.org/172.25.0.117
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.21.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.21.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.21.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.21.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.0.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/a93015a85b8ebe6a3e9423372f3337ed9b029704 ; compiled by 'runner' on 2023-12-12T10:10Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=true, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=4MB, dfs.container.ratis.segment.size=64MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60s, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.handler.type=distributed, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-address.omservice.om1=om1, ozone.om.http-address.omservice.om2=om2, ozone.om.http-address.omservice.om3=om3, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.internal.service.id=omservice, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=false, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=20s, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=5s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.enable=true, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-12-12 10:36:49,328 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-12-12 10:36:49,371 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-12 10:36:49,467 [main] INFO reflections.Reflections: Reflections took 69 ms to scan 3 urls, producing 134 keys and 291 values 
2023-12-12 10:36:49,540 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2023-12-12 10:36:49,548 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-12-12 10:36:49,570 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
2023-12-12 10:36:49,571 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
2023-12-12 10:36:49,705 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2023-12-12 10:36:49,705 [main] INFO server.StorageContainerManager: SCM login successful.
2023-12-12 10:36:50,182 [main] INFO client.SCMCertificateClient: Certificate serial ID set to 3
2023-12-12 10:36:50,269 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 3
             IssuerDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:36:47 UTC 2023
           Final Date: Fri Jan 19 10:36:47 UTC 2029
            SubjectDN: CN=scm-sub@scm2.org,OU=2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=3
           Public Key: RSA Public Key [dd:f6:fc:65:e8:5e:3f:90:fa:50:e9:5f:fe:8e:92:09:e2:0a:42:1e],[56:66:d1:a4]
        modulus: 8acda26289721b1a7964c4aa5c60d74ca0d362b70f186bbff6482177ce45b1e4c2852f5c4c29ac6d78b50ac320f37cf9522afd6d1eb6e88b94001a460ca6de9edba2300879ff18e432a754218f0458599d40747ae83e09311350e658f18049f5aa190a7756f3dabd91cd456024c351e1922d5ce2b81b18fbfd50dade2e1aa545e83900d4c709a724dbaa74d7f89ffec593854e182fddb78842fb4bea865ee8969097ec23edab191633de702671d115b2520cdfd979c43e68a6009fdfa5b6bbcc75f57599522073a190211ff1a27f46a68edbf723f29e5b1f13c0e36987c32524facdfbe04d040f6c82f7f582b27b25492c6894e437f3780a4cd8d26149141359
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: b120177d5bc947ddc089c23aedd7ea263dd2fa03
                       c244e84c47575c76bee877a55a4275e30d7a41f7
                       b93f08e9be428544a74d2778c6bb44ac99fd77e1
                       b7e6011c4bdf6205c2ddcb98c31775cb3d786762
                       6fb6387ab240dc084925fbfa1b4fee6c24a9d37f
                       89b22aa7b5b88ac2931e5c0495f3513582ee1b71
                       d3994d78ed7ad686573a5272a3d73b11a3523425
                       07c581a31519863290c093b51b05e8ab2bdf6d5b
                       7dec66be23955a29bf8f380449e7d313b664adee
                       e7910ae2b3d913860408c64cd938e6f7a35affea
                       a1b80220f7db9578e1e4145b4d78245ebcd5e366
                       d63f2b321a68db9ab0f76bfbf159544d6c65a334
                       aff6876e9a6ad81c25b24d826dffe652
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/certificate.crt.
2023-12-12 10:36:50,274 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 3
             IssuerDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:36:47 UTC 2023
           Final Date: Fri Jan 19 10:36:47 UTC 2029
            SubjectDN: CN=scm-sub@scm2.org,OU=2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=3
           Public Key: RSA Public Key [dd:f6:fc:65:e8:5e:3f:90:fa:50:e9:5f:fe:8e:92:09:e2:0a:42:1e],[56:66:d1:a4]
        modulus: 8acda26289721b1a7964c4aa5c60d74ca0d362b70f186bbff6482177ce45b1e4c2852f5c4c29ac6d78b50ac320f37cf9522afd6d1eb6e88b94001a460ca6de9edba2300879ff18e432a754218f0458599d40747ae83e09311350e658f18049f5aa190a7756f3dabd91cd456024c351e1922d5ce2b81b18fbfd50dade2e1aa545e83900d4c709a724dbaa74d7f89ffec593854e182fddb78842fb4bea865ee8969097ec23edab191633de702671d115b2520cdfd979c43e68a6009fdfa5b6bbcc75f57599522073a190211ff1a27f46a68edbf723f29e5b1f13c0e36987c32524facdfbe04d040f6c82f7f582b27b25492c6894e437f3780a4cd8d26149141359
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: b120177d5bc947ddc089c23aedd7ea263dd2fa03
                       c244e84c47575c76bee877a55a4275e30d7a41f7
                       b93f08e9be428544a74d2778c6bb44ac99fd77e1
                       b7e6011c4bdf6205c2ddcb98c31775cb3d786762
                       6fb6387ab240dc084925fbfa1b4fee6c24a9d37f
                       89b22aa7b5b88ac2931e5c0495f3513582ee1b71
                       d3994d78ed7ad686573a5272a3d73b11a3523425
                       07c581a31519863290c093b51b05e8ab2bdf6d5b
                       7dec66be23955a29bf8f380449e7d313b664adee
                       e7910ae2b3d913860408c64cd938e6f7a35affea
                       a1b80220f7db9578e1e4145b4d78245ebcd5e366
                       d63f2b321a68db9ab0f76bfbf159544d6c65a334
                       aff6876e9a6ad81c25b24d826dffe652
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/3.crt.
2023-12-12 10:36:50,278 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:36:25 UTC 2023
           Final Date: Fri Jan 19 10:36:25 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Public Key: RSA Public Key [1c:e1:2e:f4:24:90:4f:71:d5:81:8e:c0:f1:ba:2a:56:88:43:a7:bd],[56:66:d1:a4]
        modulus: ee3f9d6e949616979f16039b3e057cd5c6252a324c49a39a242a808d3bf9a93bac0503816e25ac369e4d0693be4f016f280f8b83a99340ed1fa71e26db75b7df95e29c1dabb6c02c3ea74cf0af9d1b450c8b86d60b775644c78b3b926ae146831cb4e52f352a08ac5a2ae2b31dafb805d54c3a3173cbcd4eb357681a99576628b65e6ee66a53c73dadff3ec297c43ec4672b380b296ecbe64f8c5cf2c2d7924fe44b2f52ccad099d3c22310a6d7ed5d012ea09a34059838139f2e502e459f5b58ba1c95a5b697f5e5f587b236f2b91c5644ee606ed55915e45d6106be4ec509c6d27a5576d5362e955d54f0650cebf0ce76ce5e3a5d95e9be59921f4a0d73eeb
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: d6c91f35d6797aec4d2a753f9ff2ec90ad37bfee
                       801ea2792762c490ba1ebd69fc7b38edd04b00de
                       cdcda3a7dec8c36dc2ef20a65b1cbcb175dd8e6a
                       00c6b030e863932d811e2446c482e77f575db39e
                       572c1927f78dad12f4214a2938ea8e5e2dbe4425
                       9122d68ba987cf123a6821b60e491b8b596cf15d
                       cf4e703c91bf1d6bd3bfab31d0f0f6b2c4beddc9
                       9af655f362423a12bb6704d112187b85f063978f
                       fa5a391e38de65b7506e31f7af13756bb4b33cd3
                       d63f91c78d4b69c9d59547d8f71505e9e3a6d6a2
                       2f30522dc3dad2be92c48112a5ad870b0bc0d377
                       7d1a289a6031ef5c0df2e6291ea286e9f8ca5cbd
                       6ae800ba4deeb3d30a79d3ffb061cebf
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

 from file: /data/metadata/scm/sub-ca/certs/CA-1.crt.
2023-12-12 10:36:50,278 [main] INFO client.SCMCertificateClient: CertificateRenewerService and root ca rotation polling is disabled for scm/sub-ca
2023-12-12 10:36:50,336 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-12 10:36:50,438 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-12 10:36:50,696 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-12-12 10:36:50,705 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2023-12-12 10:36:50,825 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2023-12-12 10:36:51,021 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f
2023-12-12 10:36:51,074 [main] INFO ssl.ReloadingX509KeyManager: Key manager is loaded with certificate chain
2023-12-12 10:36:51,075 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 3
             IssuerDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:36:47 UTC 2023
           Final Date: Fri Jan 19 10:36:47 UTC 2029
            SubjectDN: CN=scm-sub@scm2.org,OU=2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=3
           Public Key: RSA Public Key [dd:f6:fc:65:e8:5e:3f:90:fa:50:e9:5f:fe:8e:92:09:e2:0a:42:1e],[56:66:d1:a4]
        modulus: 8acda26289721b1a7964c4aa5c60d74ca0d362b70f186bbff6482177ce45b1e4c2852f5c4c29ac6d78b50ac320f37cf9522afd6d1eb6e88b94001a460ca6de9edba2300879ff18e432a754218f0458599d40747ae83e09311350e658f18049f5aa190a7756f3dabd91cd456024c351e1922d5ce2b81b18fbfd50dade2e1aa545e83900d4c709a724dbaa74d7f89ffec593854e182fddb78842fb4bea865ee8969097ec23edab191633de702671d115b2520cdfd979c43e68a6009fdfa5b6bbcc75f57599522073a190211ff1a27f46a68edbf723f29e5b1f13c0e36987c32524facdfbe04d040f6c82f7f582b27b25492c6894e437f3780a4cd8d26149141359
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: b120177d5bc947ddc089c23aedd7ea263dd2fa03
                       c244e84c47575c76bee877a55a4275e30d7a41f7
                       b93f08e9be428544a74d2778c6bb44ac99fd77e1
                       b7e6011c4bdf6205c2ddcb98c31775cb3d786762
                       6fb6387ab240dc084925fbfa1b4fee6c24a9d37f
                       89b22aa7b5b88ac2931e5c0495f3513582ee1b71
                       d3994d78ed7ad686573a5272a3d73b11a3523425
                       07c581a31519863290c093b51b05e8ab2bdf6d5b
                       7dec66be23955a29bf8f380449e7d313b664adee
                       e7910ae2b3d913860408c64cd938e6f7a35affea
                       a1b80220f7db9578e1e4145b4d78245ebcd5e366
                       d63f2b321a68db9ab0f76bfbf159544d6c65a334
                       aff6876e9a6ad81c25b24d826dffe652
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe

2023-12-12 10:36:51,090 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:36:25 UTC 2023
           Final Date: Fri Jan 19 10:36:25 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Public Key: RSA Public Key [1c:e1:2e:f4:24:90:4f:71:d5:81:8e:c0:f1:ba:2a:56:88:43:a7:bd],[56:66:d1:a4]
        modulus: ee3f9d6e949616979f16039b3e057cd5c6252a324c49a39a242a808d3bf9a93bac0503816e25ac369e4d0693be4f016f280f8b83a99340ed1fa71e26db75b7df95e29c1dabb6c02c3ea74cf0af9d1b450c8b86d60b775644c78b3b926ae146831cb4e52f352a08ac5a2ae2b31dafb805d54c3a3173cbcd4eb357681a99576628b65e6ee66a53c73dadff3ec297c43ec4672b380b296ecbe64f8c5cf2c2d7924fe44b2f52ccad099d3c22310a6d7ed5d012ea09a34059838139f2e502e459f5b58ba1c95a5b697f5e5f587b236f2b91c5644ee606ed55915e45d6106be4ec509c6d27a5576d5362e955d54f0650cebf0ce76ce5e3a5d95e9be59921f4a0d73eeb
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: d6c91f35d6797aec4d2a753f9ff2ec90ad37bfee
                       801ea2792762c490ba1ebd69fc7b38edd04b00de
                       cdcda3a7dec8c36dc2ef20a65b1cbcb175dd8e6a
                       00c6b030e863932d811e2446c482e77f575db39e
                       572c1927f78dad12f4214a2938ea8e5e2dbe4425
                       9122d68ba987cf123a6821b60e491b8b596cf15d
                       cf4e703c91bf1d6bd3bfab31d0f0f6b2c4beddc9
                       9af655f362423a12bb6704d112187b85f063978f
                       fa5a391e38de65b7506e31f7af13756bb4b33cd3
                       d63f91c78d4b69c9d59547d8f71505e9e3a6d6a2
                       2f30522dc3dad2be92c48112a5ad870b0bc0d377
                       7d1a289a6031ef5c0df2e6291ea286e9f8ca5cbd
                       6ae800ba4deeb3d30a79d3ffb061cebf
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2023-12-12 10:36:51,093 [main] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-12-12 10:36:51,094 [main] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-12-12 10:36:51,094 [main] INFO ssl.ReloadingX509TrustManager: Trust manager is loaded with certificates
2023-12-12 10:36:51,102 [main] INFO ssl.ReloadingX509TrustManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:36:25 UTC 2023
           Final Date: Fri Jan 19 10:36:25 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Public Key: RSA Public Key [1c:e1:2e:f4:24:90:4f:71:d5:81:8e:c0:f1:ba:2a:56:88:43:a7:bd],[56:66:d1:a4]
        modulus: ee3f9d6e949616979f16039b3e057cd5c6252a324c49a39a242a808d3bf9a93bac0503816e25ac369e4d0693be4f016f280f8b83a99340ed1fa71e26db75b7df95e29c1dabb6c02c3ea74cf0af9d1b450c8b86d60b775644c78b3b926ae146831cb4e52f352a08ac5a2ae2b31dafb805d54c3a3173cbcd4eb357681a99576628b65e6ee66a53c73dadff3ec297c43ec4672b380b296ecbe64f8c5cf2c2d7924fe44b2f52ccad099d3c22310a6d7ed5d012ea09a34059838139f2e502e459f5b58ba1c95a5b697f5e5f587b236f2b91c5644ee606ed55915e45d6106be4ec509c6d27a5576d5362e955d54f0650cebf0ce76ce5e3a5d95e9be59921f4a0d73eeb
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: d6c91f35d6797aec4d2a753f9ff2ec90ad37bfee
                       801ea2792762c490ba1ebd69fc7b38edd04b00de
                       cdcda3a7dec8c36dc2ef20a65b1cbcb175dd8e6a
                       00c6b030e863932d811e2446c482e77f575db39e
                       572c1927f78dad12f4214a2938ea8e5e2dbe4425
                       9122d68ba987cf123a6821b60e491b8b596cf15d
                       cf4e703c91bf1d6bd3bfab31d0f0f6b2c4beddc9
                       9af655f362423a12bb6704d112187b85f063978f
                       fa5a391e38de65b7506e31f7af13756bb4b33cd3
                       d63f91c78d4b69c9d59547d8f71505e9e3a6d6a2
                       2f30522dc3dad2be92c48112a5ad870b0bc0d377
                       7d1a289a6031ef5c0df2e6291ea286e9f8ca5cbd
                       6ae800ba4deeb3d30a79d3ffb061cebf
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2023-12-12 10:36:51,144 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-12-12 10:36:51,154 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-12-12 10:36:51,249 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2023-12-12 10:36:51,260 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-12-12 10:36:51,262 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2023-12-12 10:36:51,263 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-12-12 10:36:51,264 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2023-12-12 10:36:51,265 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2023-12-12 10:36:51,265 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2023-12-12 10:36:51,266 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2023-12-12 10:36:51,267 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 10:36:51,278 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-12-12 10:36:51,280 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-12-12 10:36:51,294 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-12-12 10:36:51,305 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-12-12 10:36:51,305 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-12-12 10:36:51,730 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2023-12-12 10:36:51,732 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2023-12-12 10:36:51,732 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2023-12-12 10:36:51,732 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-12-12 10:36:51,741 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-12-12 10:36:51,742 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2023-12-12 10:36:51,742 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2023-12-12 10:36:51,749 [main] INFO server.RaftServer: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f: addNew group-1024BF673070:[] returns group-1024BF673070:java.util.concurrent.CompletableFuture@776a3365[Not completed]
2023-12-12 10:36:51,764 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f: new RaftServerImpl for group-1024BF673070:[] with SCMStateMachine:uninitialized
2023-12-12 10:36:51,765 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2023-12-12 10:36:51,766 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2023-12-12 10:36:51,766 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2023-12-12 10:36:51,766 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2023-12-12 10:36:51,766 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-12-12 10:36:51,767 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2023-12-12 10:36:51,767 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2023-12-12 10:36:51,776 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-12-12 10:36:51,781 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2023-12-12 10:36:51,785 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2023-12-12 10:36:51,788 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2023-12-12 10:36:51,788 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2023-12-12 10:36:51,794 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2023-12-12 10:36:51,795 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2023-12-12 10:36:51,978 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-12-12 10:36:51,981 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-12-12 10:36:51,982 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2023-12-12 10:36:51,982 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2023-12-12 10:36:51,982 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2023-12-12 10:36:51,982 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2023-12-12 10:36:51,984 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2023-12-12 10:36:51,984 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-12-12 10:36:51,985 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2023-12-12 10:36:52,040 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2023-12-12 10:36:52,162 [main] INFO ha.SequenceIdGenerator: upgrade localId to 111677748019200000
2023-12-12 10:36:52,164 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2023-12-12 10:36:52,190 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2023-12-12 10:36:52,200 [main] INFO ha.SequenceIdGenerator: upgrade CertificateId to 2
2023-12-12 10:36:52,206 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2023-12-12 10:36:52,290 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2023-12-12 10:36:52,330 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2023-12-12 10:36:52,333 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-12-12 10:36:52,343 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2023-12-12 10:36:52,378 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-12-12 10:36:52,379 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-12-12 10:36:52,392 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2023-12-12 10:36:52,392 [main] INFO pipeline.BackgroundPipelineCreator: Starting scm2-RatisPipelineUtilsThread.
2023-12-12 10:36:52,398 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2023-12-12 10:36:52,400 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2023-12-12 10:36:52,413 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2023-12-12 10:36:52,414 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2023-12-12 10:36:52,465 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-12-12 10:36:52,465 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-12-12 10:36:52,489 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2023-12-12 10:36:52,630 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2023-12-12 10:36:52,646 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2023-12-12 10:36:52,646 [scm2-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2023-12-12 10:36:52,663 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2023-12-12 10:36:52,668 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:36:52,671 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-12-12 10:36:52,990 [main] INFO security.SecretKeyManagerService: Scheduling rotation checker with interval PT1M
2023-12-12 10:36:52,996 [main] INFO ha.SCMServiceManager: Registering service SecretKeyManagerService.
2023-12-12 10:36:53,027 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2023-12-12 10:36:53,064 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-12 10:36:53,099 [main] INFO ipc.Server: Listener at 0.0.0.0:9961
2023-12-12 10:36:53,100 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
2023-12-12 10:36:53,157 [main] INFO server.StorageContainerManager: SCM start with adminUsers: [testuser, recon, om, scm]
2023-12-12 10:36:53,688 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-12-12 10:36:53,696 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-12 10:36:53,696 [main] INFO ipc.Server: Listener at 0.0.0.0:9861
2023-12-12 10:36:53,710 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2023-12-12 10:36:53,787 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-12-12 10:36:53,801 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-12 10:36:53,801 [main] INFO ipc.Server: Listener at 0.0.0.0:9863
2023-12-12 10:36:53,804 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2023-12-12 10:36:53,949 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-12-12 10:36:53,993 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-12 10:36:53,993 [main] INFO ipc.Server: Listener at 0.0.0.0:9860
2023-12-12 10:36:53,998 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2023-12-12 10:36:54,116 [main] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2023-12-12 10:36:54,139 [main] INFO server.StorageContainerManager: 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB
Number of Iterations                               10
Time Limit for Single Container's Movement         65min
Time Limit for Single Container's Replication      50min
Interval between each Iteration                    70min
Whether to Enable Network Topology                 false
Whether to Trigger Refresh Datanode Usage Info     false
Container IDs to Exclude from Balancing            None
Datanodes Specified to be Balanced                 None
Datanodes Excluded from Balancing                  None

2023-12-12 10:36:54,140 [main] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-12-12 10:36:54,154 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2023-12-12 10:36:54,163 [main] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2023-12-12 10:36:54,170 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2023-12-12 10:36:54,174 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2023-12-12 10:36:54,174 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-12-12 10:36:54,197 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070 does not exist. Creating ...
2023-12-12 10:36:54,218 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070/in_use.lock acquired by nodename 7@scm2.org
2023-12-12 10:36:54,238 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070 has been successfully formatted.
2023-12-12 10:36:54,246 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2023-12-12 10:36:54,269 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2023-12-12 10:36:54,269 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 10:36:54,274 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-12-12 10:36:54,279 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2023-12-12 10:36:54,295 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-12-12 10:36:54,312 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2023-12-12 10:36:54,312 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-12-12 10:36:54,312 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 10:36:54,330 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO util.AwaitToRun: Thread[2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-cacheEviction-AwaitToRun,5,main] started
2023-12-12 10:36:54,338 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070
2023-12-12 10:36:54,339 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-12-12 10:36:54,339 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2023-12-12 10:36:54,340 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-12-12 10:36:54,340 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2023-12-12 10:36:54,341 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2023-12-12 10:36:54,341 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2023-12-12 10:36:54,341 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-12-12 10:36:54,341 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-12-12 10:36:54,353 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2023-12-12 10:36:54,368 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 10:36:54,371 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2023-12-12 10:36:54,371 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2023-12-12 10:36:54,372 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2023-12-12 10:36:54,380 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-12-12 10:36:54,381 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-12-12 10:36:54,382 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: start with initializing state, conf=-1: peers:[]|listeners:[], old=null
2023-12-12 10:36:54,386 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: changes role from      null to FOLLOWER at term 0 for startInitializing
2023-12-12 10:36:54,446 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1024BF673070,id=2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f
2023-12-12 10:36:54,452 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2023-12-12 10:36:54,452 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-12-12 10:36:54,453 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2023-12-12 10:36:54,453 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2023-12-12 10:36:54,454 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2023-12-12 10:36:54,464 [main] INFO server.RaftServer: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f: start RPC server
2023-12-12 10:36:54,549 [main] INFO server.GrpcService: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f: GrpcService started, listening on 9894
2023-12-12 10:36:54,574 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f: Started
2023-12-12 10:36:54,577 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
2023-12-12 10:36:55,327 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: receive installSnapshot: 9d6cdba7-5750-4d18-8893-6bccaafab041->2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f#0-t2,notify:(t:1, i:0)
2023-12-12 10:36:55,335 [grpc-default-executor-0] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: set firstElectionSinceStartup to false for installSnapshot
2023-12-12 10:36:55,335 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
2023-12-12 10:36:55,335 [grpc-default-executor-0] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: change Leader from null to 9d6cdba7-5750-4d18-8893-6bccaafab041 at term 2 for installSnapshot, leader elected after 3553ms
2023-12-12 10:36:55,338 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: Received notification to install snapshot at index 0
2023-12-12 10:36:55,338 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
2023-12-12 10:36:55,504 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: set new configuration index: 1
configurationEntry {
  peers {
    id: "9d6cdba7-5750-4d18-8893-6bccaafab041"
    address: "scm1.org:9894"
    startupRole: FOLLOWER
  }
}
 from snapshot
2023-12-12 10:36:55,509 [grpc-default-executor-0] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: set configuration 1: peers:[9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894]|listeners:[], old=null
2023-12-12 10:36:55,522 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: reply installSnapshot: 9d6cdba7-5750-4d18-8893-6bccaafab041<-2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f#0:OK-t0,ALREADY_INSTALLED,snapshotIndex=0
2023-12-12 10:36:55,546 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f: Completed INSTALL_SNAPSHOT, lastRequest: 9d6cdba7-5750-4d18-8893-6bccaafab041->2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f#0-t2,notify:(t:1, i:0)
2023-12-12 10:36:55,547 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f: Completed INSTALL_SNAPSHOT, lastReply: null
2023-12-12 10:36:55,678 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-server-thread1] INFO impl.RoleInfo: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f: start 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-FollowerState
2023-12-12 10:36:55,686 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-server-thread1] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:36:55,689 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-server-thread1] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:36:55,690 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-server-thread2] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:36:55,690 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-server-thread2] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:36:55,716 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-server-thread2] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:36:55,716 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-server-thread2] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f#2:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:36:55,729 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-server-thread2] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: set configuration 0: peers:[9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894]|listeners:[], old=null
2023-12-12 10:36:55,729 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-server-thread2] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: set configuration 1: peers:[9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894]|listeners:[], old=null
2023-12-12 10:36:55,732 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-server-thread2] INFO segmented.SegmentedRaftLogWorker: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-SegmentedRaftLogWorker: Starting segment from index:0
2023-12-12 10:36:55,769 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-server-thread2] INFO segmented.SegmentedRaftLogWorker: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2023-12-12 10:36:55,821 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-server-thread2] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: set configuration 15: peers:[2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f|scm2.org:9894, 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894]|listeners:[], old=peers:[9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894]|listeners:[]
2023-12-12 10:36:55,882 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070/current/log_inprogress_0
2023-12-12 10:36:55,889 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070/current/log_inprogress_0 to /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070/current/log_0-0
2023-12-12 10:36:55,904 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070/current/log_inprogress_1
2023-12-12 10:36:55,925 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:36:55,926 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2023-12-12 10:36:55,926 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-12-12 10:36:55,927 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2023-12-12 10:36:55,930 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-12 10:36:55,942 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2023-12-12 10:36:55,956 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-server-thread2] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: set configuration 17: peers:[2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f|scm2.org:9894, 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894]|listeners:[], old=null
2023-12-12 10:36:56,098 [main] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-1024BF673070:[2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f|scm2.org:9894, 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894]
2023-12-12 10:36:56,100 [main] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2023-12-12 10:36:56,138 [main] INFO SCMHATransactionMonitor: Starting SCMHATransactionMonitor Service.
2023-12-12 10:36:56,138 [main] INFO ha.SCMServiceManager: Registering service SCMHATransactionMonitor.
2023-12-12 10:36:56,138 [main] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is already running, skip start.
2023-12-12 10:36:56,225 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z)]
2023-12-12 10:36:56,229 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z)
2023-12-12 10:36:56,479 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z)] to file /data/metadata/scm/keys/secret_keys.json
2023-12-12 10:36:56,485 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:36:56,488 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2023-12-12 10:36:56,488 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2023-12-12 10:36:56,498 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2023-12-12 10:36:56,531 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for CertificateId, expected lastId is 0, actual lastId is 2.
2023-12-12 10:36:56,542 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-12-12 10:36:56,542 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2023-12-12 10:36:56,548 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:36:56,586 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:36:56,690 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO server.SCMCertStore: Scm certificate 3 for CN=scm-sub@scm2.org,OU=2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=3 is stored
2023-12-12 10:36:56,690 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:36:56,696 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:36:56,708 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:36:56,765 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2023-12-12 10:36:56,766 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-12 10:36:56,767 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2023-12-12 10:36:56,844 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2023-12-12 10:36:56,845 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2023-12-12 10:36:56,846 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-12 10:36:56,861 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2023-12-12 10:36:56,936 [main] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
2023-12-12 10:36:56,937 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-12 10:36:56,943 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
2023-12-12 10:36:56,943 [main] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
2023-12-12 10:36:57,188 [main] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f
2023-12-12 10:36:57,256 [main] INFO server.SCMCertStore: Scm certificate 1 for CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1 is stored
2023-12-12 10:36:57,267 [main] INFO server.StorageContainerManager: Persist certificate serialId 2 on Scm Bootstrap Node 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f
2023-12-12 10:36:57,277 [main] INFO server.SCMCertStore: Scm certificate 2 for CN=scm-sub@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=2 is stored
2023-12-12 10:36:57,332 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2023-12-12 10:36:57,333 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
2023-12-12 10:36:57,337 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
2023-12-12 10:36:57,390 [main] INFO util.log: Logging initialized @9026ms to org.eclipse.jetty.util.log.Slf4jLog
2023-12-12 10:36:57,641 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2023-12-12 10:36:57,656 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-12-12 10:36:57,659 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2023-12-12 10:36:57,659 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2023-12-12 10:36:57,659 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2023-12-12 10:36:57,668 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
2023-12-12 10:36:57,736 [main] INFO http.BaseHttpServer: HTTP server of scm uses base directory /data/metadata/webserver
2023-12-12 10:36:57,737 [main] INFO http.HttpServer2: Jetty bound to port 9876
2023-12-12 10:36:57,739 [main] INFO server.Server: jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 11.0.19+7-LTS
2023-12-12 10:36:57,789 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2023-12-12 10:36:57,791 [main] INFO server.session: No SessionScavenger set, using defaults
2023-12-12 10:36:57,794 [main] INFO server.session: node0 Scavenging every 600000ms
2023-12-12 10:36:57,823 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2023-12-12 10:36:57,833 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@30a816b8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2023-12-12 10:36:57,836 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2b6d4eeb{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-12-12 10:36:58,044 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2023-12-12 10:36:58,054 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@75a37ebb{scm,/,file:///data/metadata/webserver/jetty-0_0_0_0-9876-hdds-server-scm-1_4_0-SNAPSHOT_jar-_-any-10398334769097554523/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/scm}
2023-12-12 10:36:58,065 [main] INFO server.AbstractConnector: Started ServerConnector@5bbda7e2{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2023-12-12 10:36:58,065 [main] INFO server.Server: Started @9702ms
2023-12-12 10:36:58,067 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2023-12-12 10:36:58,067 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
2023-12-12 10:36:58,095 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2023-12-12 10:36:58,115 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-12-12 10:36:58,117 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-12-12 10:36:58,129 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: CA certificates are not changed.
2023-12-12 10:37:00,181 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:00,253 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO server.SCMCertStore: Scm certificate 5 for CN=scm-sub@scm3.org,OU=26d4f844-7892-4e91-8fa5-b0417f32640f,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=5 is stored
2023-12-12 10:37:00,253 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:08,083 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-server-thread2] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: set configuration 23: peers:[2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f|scm2.org:9894, 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894, 26d4f844-7892-4e91-8fa5-b0417f32640f|scm3.org:9894]|listeners:[], old=peers:[2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f|scm2.org:9894, 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894]|listeners:[]
2023-12-12 10:37:08,091 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f-server-thread2] INFO server.RaftServer$Division: 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070: set configuration 25: peers:[2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f|scm2.org:9894, 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894, 26d4f844-7892-4e91-8fa5-b0417f32640f|scm3.org:9894]|listeners:[], old=null
2023-12-12 10:37:23,346 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:23,600 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:23,913 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:24,162 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:27,026 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:27,252 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:27,669 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:27,843 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:29,832 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:30,157 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:30,929 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:31,014 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:40,239 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:48834 / 172.25.0.102:48834
2023-12-12 10:37:40,329 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:37:41,515 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:48052 / 172.25.0.103:48052
2023-12-12 10:37:41,590 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:37:42,247 [IPC Server handler 95 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/634f8a9a-5da8-49ee-a211-3e667283ff7d
2023-12-12 10:37:42,279 [IPC Server handler 95 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 634f8a9a-5da8-49ee-a211-3e667283ff7d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 6, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-12-12 10:37:42,393 [scm2-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-12-12 10:37:42,420 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
2023-12-12 10:37:42,506 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:43,390 [IPC Server handler 95 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/92849505-ef99-4e21-a442-7f5bd09606ad
2023-12-12 10:37:43,390 [IPC Server handler 95 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 92849505-ef99-4e21-a442-7f5bd09606ad{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 7, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-12-12 10:37:43,392 [scm2-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-12-12 10:37:43,394 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
2023-12-12 10:37:43,433 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:44,128 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:41412 / 172.25.0.104:41412
2023-12-12 10:37:44,212 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:37:45,671 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:45,728 [scm2-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "c00e8640-5ea9-4629-a86b-38763274a453"
  uuid128 {
    mostSigBits: -4607597757729257943
    leastSigBits: -6310888372525816749
  }
}
isLeader: false
bytesWritten: 0
 from dn=634f8a9a-5da8-49ee-a211-3e667283ff7d(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:795)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:760)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:746)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:926)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:919)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:896)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$11(RaftServerImpl.java:885)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$12(RaftServerImpl.java:885)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-12-12 10:37:46,003 [IPC Server handler 51 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/6a902a0e-b3da-4316-a0ee-cbc7bf632497
2023-12-12 10:37:46,008 [IPC Server handler 51 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 6a902a0e-b3da-4316-a0ee-cbc7bf632497{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 8, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-12-12 10:37:46,008 [scm2-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-12-12 10:37:46,010 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
2023-12-12 10:37:46,010 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2023-12-12 10:37:46,010 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2023-12-12 10:37:46,010 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-12-12 10:37:46,021 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-12-12 10:37:46,049 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:46,104 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:46,168 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:46,958 [scm2-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "4c0af17c-edd5-4e21-bd83-a0e42c03a017"
  uuid128 {
    mostSigBits: 5479457415518047777
    leastSigBits: -4790808676740653033
  }
}
isLeader: false
bytesWritten: 0
 from dn=92849505-ef99-4e21-a442-7f5bd09606ad(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:795)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:760)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:746)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:926)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:919)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:896)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$11(RaftServerImpl.java:885)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$12(RaftServerImpl.java:885)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-12-12 10:37:46,986 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:49,324 [scm2-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "dafe3ec1-ba73-44aa-a52e-dc6217ab5944"
  uuid128 {
    mostSigBits: -2666624927579028310
    leastSigBits: -6544050894660740796
  }
}
isLeader: false
bytesWritten: 0
 from dn=6a902a0e-b3da-4316-a0ee-cbc7bf632497(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:795)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:760)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:746)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:926)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:919)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:896)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$11(RaftServerImpl.java:885)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$12(RaftServerImpl.java:885)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-12-12 10:37:49,358 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:49,655 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:51,134 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:51,646 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:52,330 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:52,772 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:53,062 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:53,416 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:53,924 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:54,762 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:58,646 [scm2-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "68635585-d9de-404c-a57a-8c95f00ffae5"
  uuid128 {
    mostSigBits: 7521949836013092940
    leastSigBits: -6522746534687147291
  }
}
isLeader: true
bytesWritten: 0
 from dn=634f8a9a-5da8-49ee-a211-3e667283ff7d(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:795)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:760)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:746)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:926)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:919)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:896)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$11(RaftServerImpl.java:885)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$12(RaftServerImpl.java:885)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-12-12 10:37:58,648 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:58,680 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2023-12-12 10:37:59,916 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:59,919 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-12-12 10:37:59,919 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2023-12-12 10:37:59,919 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2023-12-12 10:37:59,919 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2023-12-12 10:37:59,919 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-12-12 10:37:59,919 [scm2-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "d9b5ea72-1356-4e6c-9444-4a46b13d771e"
  uuid128 {
    mostSigBits: -2759041421022966164
    leastSigBits: -7762998190198130914
  }
}
isLeader: true
bytesWritten: 0
 from dn=92849505-ef99-4e21-a442-7f5bd09606ad(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:795)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:760)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:746)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:926)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:919)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:896)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$11(RaftServerImpl.java:885)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$12(RaftServerImpl.java:885)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-12-12 10:38:24,800 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:34202 / 172.25.0.104:34202
2023-12-12 10:38:24,824 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:38:28,666 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:54418 / 172.25.0.102:54418
2023-12-12 10:38:28,686 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:38:29,938 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:43772 / 172.25.0.103:43772
2023-12-12 10:38:29,961 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:38:54,817 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:57712 / 172.25.0.104:57712
2023-12-12 10:38:54,830 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:38:58,678 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:37578 / 172.25.0.102:37578
2023-12-12 10:38:58,708 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:38:59,973 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:57252 / 172.25.0.103:57252
2023-12-12 10:39:00,000 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:39:01,726 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 111677748019200000.
2023-12-12 10:39:20,844 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:41864 / 172.25.0.104:41864
2023-12-12 10:39:20,856 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:48254 / 172.25.0.103:48254
2023-12-12 10:39:20,914 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:39:20,918 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:46266 / 172.25.0.102:46266
2023-12-12 10:39:21,011 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:39:21,032 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:39:50,871 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:49788 / 172.25.0.104:49788
2023-12-12 10:39:50,940 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:39800 / 172.25.0.102:39800
2023-12-12 10:39:50,945 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:39:50,960 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:52994 / 172.25.0.103:52994
2023-12-12 10:39:50,994 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:39:50,995 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:40:20,867 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:42562 / 172.25.0.102:42562
2023-12-12 10:40:20,929 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:46628 / 172.25.0.103:46628
2023-12-12 10:40:20,929 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:40:20,937 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:59010 / 172.25.0.104:59010
2023-12-12 10:40:20,962 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:40:21,005 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:40:50,853 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:43390 / 172.25.0.104:43390
2023-12-12 10:40:50,917 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:40:50,927 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:41558 / 172.25.0.103:41558
2023-12-12 10:40:50,937 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:51774 / 172.25.0.102:51774
2023-12-12 10:40:50,946 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:40:50,991 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:41:20,925 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:43938 / 172.25.0.102:43938
2023-12-12 10:41:20,932 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:52392 / 172.25.0.104:52392
2023-12-12 10:41:20,936 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:34560 / 172.25.0.103:34560
2023-12-12 10:41:20,938 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:41:20,941 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:41:20,955 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:41:50,875 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:50258 / 172.25.0.103:50258
2023-12-12 10:41:50,892 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:51788 / 172.25.0.104:51788
2023-12-12 10:41:50,899 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:41:50,926 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:41:50,954 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:50172 / 172.25.0.102:50172
2023-12-12 10:41:50,992 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:41:52,649 [scm2-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2023-12-12 10:42:20,866 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:46192 / 172.25.0.103:46192
2023-12-12 10:42:20,889 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:42900 / 172.25.0.104:42900
2023-12-12 10:42:20,908 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:36090 / 172.25.0.102:36090
2023-12-12 10:42:20,912 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:42:20,915 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:42:20,937 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:42:38,503 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z), SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z)]
2023-12-12 10:42:38,505 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z)
2023-12-12 10:42:38,506 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z), SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z)] to file /data/metadata/scm/keys/secret_keys.json
2023-12-12 10:42:50,871 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:46770 / 172.25.0.103:46770
2023-12-12 10:42:50,885 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:58686 / 172.25.0.104:58686
2023-12-12 10:42:50,897 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:55204 / 172.25.0.102:55204
2023-12-12 10:42:50,902 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:42:50,924 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:42:50,934 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:43:20,894 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:39332 / 172.25.0.102:39332
2023-12-12 10:43:20,924 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:51802 / 172.25.0.104:51802
2023-12-12 10:43:20,934 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:43:20,943 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:36944 / 172.25.0.103:36944
2023-12-12 10:43:20,950 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:43:20,973 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:43:50,897 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:59364 / 172.25.0.102:59364
2023-12-12 10:43:50,910 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:57006 / 172.25.0.103:57006
2023-12-12 10:43:50,915 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:44428 / 172.25.0.104:44428
2023-12-12 10:43:50,918 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:43:50,919 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:43:50,931 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:44:20,852 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:35558 / 172.25.0.102:35558
2023-12-12 10:44:20,863 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:43782 / 172.25.0.104:43782
2023-12-12 10:44:20,879 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:32832 / 172.25.0.103:32832
2023-12-12 10:44:20,889 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:44:20,895 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:44:20,900 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:44:50,924 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:45946 / 172.25.0.103:45946
2023-12-12 10:44:50,926 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:36510 / 172.25.0.104:36510
2023-12-12 10:44:50,926 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:36602 / 172.25.0.102:36602
2023-12-12 10:44:50,930 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:44:50,932 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:44:50,938 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:45:20,868 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:33744 / 172.25.0.102:33744
2023-12-12 10:45:20,869 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:56148 / 172.25.0.104:56148
2023-12-12 10:45:20,881 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:45:20,892 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:39184 / 172.25.0.103:39184
2023-12-12 10:45:20,900 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:45:20,908 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:45:50,893 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:49814 / 172.25.0.104:49814
2023-12-12 10:45:50,897 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:41930 / 172.25.0.102:41930
2023-12-12 10:45:50,910 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:45:50,918 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:36160 / 172.25.0.103:36160
2023-12-12 10:45:50,927 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:45:50,927 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:46:20,828 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:40772 / 172.25.0.104:40772
2023-12-12 10:46:20,832 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:55582 / 172.25.0.102:55582
2023-12-12 10:46:20,846 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:46:20,863 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:40458 / 172.25.0.103:40458
2023-12-12 10:46:20,870 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:46:20,932 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:46:50,839 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:43050 / 172.25.0.104:43050
2023-12-12 10:46:50,902 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:46:50,906 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:38098 / 172.25.0.102:38098
2023-12-12 10:46:50,907 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:59920 / 172.25.0.103:59920
2023-12-12 10:46:50,911 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:46:50,918 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:46:52,649 [scm2-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2023-12-12 10:47:20,846 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:60838 / 172.25.0.104:60838
2023-12-12 10:47:20,872 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:47:20,898 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:51190 / 172.25.0.102:51190
2023-12-12 10:47:20,901 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:38596 / 172.25.0.103:38596
2023-12-12 10:47:20,913 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:47:20,926 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:47:38,505 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z), SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z), SecretKey(id = e2d833a9-10dd-4236-a4a5-e3ba4bfd79c0, creation at: 2023-12-12T10:47:38.488Z, expire at: 2023-12-12T11:47:38.488Z)]
2023-12-12 10:47:38,506 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = e2d833a9-10dd-4236-a4a5-e3ba4bfd79c0, creation at: 2023-12-12T10:47:38.488Z, expire at: 2023-12-12T11:47:38.488Z)
2023-12-12 10:47:38,507 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = e2d833a9-10dd-4236-a4a5-e3ba4bfd79c0, creation at: 2023-12-12T10:47:38.488Z, expire at: 2023-12-12T11:47:38.488Z), SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z), SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z)] to file /data/metadata/scm/keys/secret_keys.json
2023-12-12 10:47:50,888 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:43220 / 172.25.0.102:43220
2023-12-12 10:47:50,920 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:47:50,938 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:52140 / 172.25.0.103:52140
2023-12-12 10:47:50,938 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:38960 / 172.25.0.104:38960
2023-12-12 10:47:50,945 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:47:50,951 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:48:20,829 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:59632 / 172.25.0.104:59632
2023-12-12 10:48:20,830 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:38166 / 172.25.0.102:38166
2023-12-12 10:48:20,875 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:48:20,879 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:46476 / 172.25.0.103:46476
2023-12-12 10:48:20,888 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:48:20,913 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:48:50,831 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:45300 / 172.25.0.102:45300
2023-12-12 10:48:50,835 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:43640 / 172.25.0.104:43640
2023-12-12 10:48:50,866 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:48:50,882 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:48:50,894 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:58434 / 172.25.0.103:58434
2023-12-12 10:48:50,913 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:49:20,875 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:60558 / 172.25.0.102:60558
2023-12-12 10:49:20,904 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:49:20,925 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:46212 / 172.25.0.104:46212
2023-12-12 10:49:20,931 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:49:20,939 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:57416 / 172.25.0.103:57416
2023-12-12 10:49:20,945 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:49:50,863 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:40778 / 172.25.0.104:40778
2023-12-12 10:49:50,896 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:50512 / 172.25.0.102:50512
2023-12-12 10:49:50,897 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:49:50,910 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:49:50,914 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:50290 / 172.25.0.103:50290
2023-12-12 10:49:50,920 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:50:20,843 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:37130 / 172.25.0.102:37130
2023-12-12 10:50:20,853 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:43286 / 172.25.0.103:43286
2023-12-12 10:50:20,865 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:56740 / 172.25.0.104:56740
2023-12-12 10:50:20,875 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:50:20,883 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:50:20,914 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:50:50,838 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:44640 / 172.25.0.102:44640
2023-12-12 10:50:50,865 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:55168 / 172.25.0.104:55168
2023-12-12 10:50:50,885 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:50:50,886 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:42040 / 172.25.0.103:42040
2023-12-12 10:50:50,887 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:50:50,895 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:51:20,891 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:36252 / 172.25.0.102:36252
2023-12-12 10:51:20,916 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:41662 / 172.25.0.104:41662
2023-12-12 10:51:20,917 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:51:20,922 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:44722 / 172.25.0.103:44722
2023-12-12 10:51:20,926 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:51:20,933 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:51:50,886 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:54984 / 172.25.0.104:54984
2023-12-12 10:51:50,886 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:35556 / 172.25.0.102:35556
2023-12-12 10:51:50,897 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:39938 / 172.25.0.103:39938
2023-12-12 10:51:50,898 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:51:50,898 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:51:50,918 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:51:52,649 [scm2-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2023-12-12 10:52:20,856 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:51724 / 172.25.0.104:51724
2023-12-12 10:52:20,900 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:40296 / 172.25.0.102:40296
2023-12-12 10:52:20,900 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:54460 / 172.25.0.103:54460
2023-12-12 10:52:20,910 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:52:20,922 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:52:20,931 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:52:38,495 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = e2d833a9-10dd-4236-a4a5-e3ba4bfd79c0, creation at: 2023-12-12T10:47:38.488Z, expire at: 2023-12-12T11:47:38.488Z), SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z), SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z), SecretKey(id = 9c6b0167-60c3-4e7a-bd40-f43eefebeefe, creation at: 2023-12-12T10:52:38.488Z, expire at: 2023-12-12T11:52:38.488Z)]
2023-12-12 10:52:38,496 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 9c6b0167-60c3-4e7a-bd40-f43eefebeefe, creation at: 2023-12-12T10:52:38.488Z, expire at: 2023-12-12T11:52:38.488Z)
2023-12-12 10:52:38,501 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 9c6b0167-60c3-4e7a-bd40-f43eefebeefe, creation at: 2023-12-12T10:52:38.488Z, expire at: 2023-12-12T11:52:38.488Z), SecretKey(id = e2d833a9-10dd-4236-a4a5-e3ba4bfd79c0, creation at: 2023-12-12T10:47:38.488Z, expire at: 2023-12-12T11:47:38.488Z), SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z), SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z)] to file /data/metadata/scm/keys/secret_keys.json
2023-12-12 10:52:50,833 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:38988 / 172.25.0.102:38988
2023-12-12 10:52:50,859 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:33200 / 172.25.0.104:33200
2023-12-12 10:52:50,859 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:43862 / 172.25.0.103:43862
2023-12-12 10:52:50,875 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:52:50,876 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:52:50,885 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:53:20,868 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:39904 / 172.25.0.104:39904
2023-12-12 10:53:20,879 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:57046 / 172.25.0.102:57046
2023-12-12 10:53:20,883 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:32812 / 172.25.0.103:32812
2023-12-12 10:53:20,903 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:53:20,914 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:53:20,941 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:53:50,848 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:51366 / 172.25.0.104:51366
2023-12-12 10:53:50,863 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:58888 / 172.25.0.103:58888
2023-12-12 10:53:50,873 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:38556 / 172.25.0.102:38556
2023-12-12 10:53:50,878 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:53:50,915 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:53:50,925 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:54:20,832 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:47590 / 172.25.0.102:47590
2023-12-12 10:54:20,838 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:40252 / 172.25.0.104:40252
2023-12-12 10:54:20,863 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:54:20,864 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:54:20,878 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:48320 / 172.25.0.103:48320
2023-12-12 10:54:20,905 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:54:50,869 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:52198 / 172.25.0.102:52198
2023-12-12 10:54:50,882 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:52362 / 172.25.0.104:52362
2023-12-12 10:54:50,894 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:60484 / 172.25.0.103:60484
2023-12-12 10:54:50,918 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:54:50,930 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:54:50,953 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:55:20,831 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:40302 / 172.25.0.102:40302
2023-12-12 10:55:20,849 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:55:20,875 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:51736 / 172.25.0.103:51736
2023-12-12 10:55:20,876 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:49736 / 172.25.0.104:49736
2023-12-12 10:55:20,880 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:55:20,887 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:55:50,834 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:37102 / 172.25.0.102:37102
2023-12-12 10:55:50,835 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:48420 / 172.25.0.104:48420
2023-12-12 10:55:50,840 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:55:50,863 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:45890 / 172.25.0.103:45890
2023-12-12 10:55:50,867 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:55:50,873 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:56:20,896 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:57074 / 172.25.0.102:57074
2023-12-12 10:56:20,911 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:34638 / 172.25.0.103:34638
2023-12-12 10:56:20,912 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:56:20,917 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:56:20,922 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:38098 / 172.25.0.104:38098
2023-12-12 10:56:20,933 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:56:50,909 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:35806 / 172.25.0.104:35806
2023-12-12 10:56:50,926 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:59914 / 172.25.0.103:59914
2023-12-12 10:56:50,928 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:55446 / 172.25.0.102:55446
2023-12-12 10:56:50,930 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:56:50,939 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:56:50,951 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:56:52,650 [scm2-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2023-12-12 10:57:20,833 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:58714 / 172.25.0.102:58714
2023-12-12 10:57:20,842 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:46214 / 172.25.0.104:46214
2023-12-12 10:57:20,878 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:57:20,891 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:57:20,902 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:38626 / 172.25.0.103:38626
2023-12-12 10:57:20,926 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:57:38,494 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 9c6b0167-60c3-4e7a-bd40-f43eefebeefe, creation at: 2023-12-12T10:52:38.488Z, expire at: 2023-12-12T11:52:38.488Z), SecretKey(id = e2d833a9-10dd-4236-a4a5-e3ba4bfd79c0, creation at: 2023-12-12T10:47:38.488Z, expire at: 2023-12-12T11:47:38.488Z), SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z), SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z), SecretKey(id = 3926492a-aa8f-4e25-a463-c38d685ccb88, creation at: 2023-12-12T10:57:38.488Z, expire at: 2023-12-12T11:57:38.488Z)]
2023-12-12 10:57:38,494 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 3926492a-aa8f-4e25-a463-c38d685ccb88, creation at: 2023-12-12T10:57:38.488Z, expire at: 2023-12-12T11:57:38.488Z)
2023-12-12 10:57:38,495 [2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f@group-1024BF673070-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 3926492a-aa8f-4e25-a463-c38d685ccb88, creation at: 2023-12-12T10:57:38.488Z, expire at: 2023-12-12T11:57:38.488Z), SecretKey(id = 9c6b0167-60c3-4e7a-bd40-f43eefebeefe, creation at: 2023-12-12T10:52:38.488Z, expire at: 2023-12-12T11:52:38.488Z), SecretKey(id = e2d833a9-10dd-4236-a4a5-e3ba4bfd79c0, creation at: 2023-12-12T10:47:38.488Z, expire at: 2023-12-12T11:47:38.488Z), SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z), SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z)] to file /data/metadata/scm/keys/secret_keys.json
