Waiting for the service scm2.org:9894
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-12-12 10:36:57,423 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm3.org/172.25.0.118
STARTUP_MSG:   args = [--bootstrap]
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.21.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.21.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.21.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.21.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.0.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/a93015a85b8ebe6a3e9423372f3337ed9b029704 ; compiled by 'runner' on 2023-12-12T10:10Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=true, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=4MB, dfs.container.ratis.segment.size=64MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60s, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.handler.type=distributed, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-address.omservice.om1=om1, ozone.om.http-address.omservice.om2=om2, ozone.om.http-address.omservice.om3=om3, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.internal.service.id=omservice, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=false, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=20s, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=5s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.enable=true, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-12-12 10:36:57,441 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-12-12 10:36:57,588 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-12 10:36:57,786 [main] INFO reflections.Reflections: Reflections took 152 ms to scan 3 urls, producing 134 keys and 291 values 
2023-12-12 10:36:57,926 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2023-12-12 10:36:57,927 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-12-12 10:36:57,978 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
2023-12-12 10:36:57,986 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
2023-12-12 10:36:58,265 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2023-12-12 10:36:58,266 [main] INFO server.StorageContainerManager: SCM login successful.
2023-12-12 10:36:58,345 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
2023-12-12 10:36:58,690 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
2023-12-12 10:36:59,498 [main] INFO client.SCMCertificateClient: Certificate serial ID set to null
2023-12-12 10:36:59,498 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
2023-12-12 10:36:59,498 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
2023-12-12 10:36:59,500 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
2023-12-12 10:37:00,014 [main] INFO client.SCMCertificateClient: Init response: GETCERT
2023-12-12 10:37:00,017 [main] INFO client.SCMCertificateClient: Creating csr for SCM->hostName:scm3.org,scmId:26d4f844-7892-4e91-8fa5-b0417f32640f,clusterId:CID-11911259-cbcd-4d21-80b8-1024bf673070,subject:scm-sub@scm3.org
2023-12-12 10:37:00,066 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
2023-12-12 10:37:00,066 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2023-12-12 10:37:00,325 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/CA-1.crt
2023-12-12 10:37:00,325 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDxTCCAq2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZjZGJhNy01NzUwLTRkMTgtODg5My02YmNj
YWFmYWIwNDExMTAvBgNVBAoMKENJRC0xMTkxMTI1OS1jYmNkLTRkMjEtODBiOC0x
MDI0YmY2NzMwNzAxCjAIBgNVBAUTATEwHhcNMjMxMjEyMTAzNjI1WhcNMjkwMTE5
MTAzNjI1WjCBhTEVMBMGA1UEAwwMc2NtQHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZj
ZGJhNy01NzUwLTRkMTgtODg5My02YmNjYWFmYWIwNDExMTAvBgNVBAoMKENJRC0x
MTkxMTI1OS1jYmNkLTRkMjEtODBiOC0xMDI0YmY2NzMwNzAxCjAIBgNVBAUTATEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDuP51ulJYWl58WA5s+BXzV
xiUqMkxJo5okKoCNO/mpO6wFA4FuJaw2nk0Gk75PAW8oD4uDqZNA7R+nHibbdbff
leKcHau2wCw+p0zwr50bRQyLhtYLd1ZEx4s7kmrhRoMctOUvNSoIrFoq4rMdr7gF
1Uw6MXPLzU6zV2gamVdmKLZebuZqU8c9rf8+wpfEPsRnKzgLKW7L5k+MXPLC15JP
5EsvUsytCZ08IjEKbX7V0BLqCaNAWYOBOfLlAuRZ9bWLoclaW2l/Xl9YeyNvK5HF
ZE7mBu1VkV5F1hBr5OxQnG0npVdtU2LpVdVPBlDOvwznbOXjpdlem+WZIfSg1z7r
AgMBAAGjPjA8MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMBkGA1Ud
EQQSMBCHBKwZAHSCCHNjbTEub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQDWyR811nl6
7E0qdT+f8uyQrTe/7oAeonknYsSQuh69afx7OO3QSwDezc2jp97Iw23C7yCmWxy8
sXXdjmoAxrAw6GOTLYEeJEbEgud/V12znlcsGSf3ja0S9CFKKTjqjl4tvkQlkSLW
i6mHzxI6aCG2Dkkbi1ls8V3PTnA8kb8da9O/qzHQ8PayxL7dyZr2VfNiQjoSu2cE
0RIYe4XwY5eP+lo5HjjeZbdQbjH3rxN1a7SzPNPWP5HHjUtpydWVR9j3FQXp46bW
oi8wUi3D2tK+ksSBEqWthwsLwNN3fRoommAx71wN8uYpHqKG6fjKXL1q6AC6Te6z
0wp50/+wYc6/
-----END CERTIFICATE-----

2023-12-12 10:37:00,328 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/5.crt
2023-12-12 10:37:00,328 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDyTCCArGgAwIBAgIBBTANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZjZGJhNy01NzUwLTRkMTgtODg5My02YmNj
YWFmYWIwNDExMTAvBgNVBAoMKENJRC0xMTkxMTI1OS1jYmNkLTRkMjEtODBiOC0x
MDI0YmY2NzMwNzAxCjAIBgNVBAUTATEwHhcNMjMxMjEyMTAzNzAwWhcNMjkwMTE5
MTAzNzAwWjCBiTEZMBcGA1UEAwwQc2NtLXN1YkBzY20zLm9yZzEtMCsGA1UECwwk
MjZkNGY4NDQtNzg5Mi00ZTkxLThmYTUtYjA0MTdmMzI2NDBmMTEwLwYDVQQKDChD
SUQtMTE5MTEyNTktY2JjZC00ZDIxLTgwYjgtMTAyNGJmNjczMDcwMQowCAYDVQQF
EwE1MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAulITQIQY3p/gXXyu
3JfHw8H7QAQO1cc21GDz0JlpSbfvxJkREeOnJyolSBzX17mqPmiyTlcF/esb8WFG
D9kunj5bl/5Fxhw9OC/PkoajF8ZRCalOVXCxHO/FZ4bxj7jQHGa5WLJr8HcD0UDL
lccWD2MPSHILT5v0Xn2sWIqb97CueL2ZIyM0m7FNoWFFBA+vOFj19wq52G52I7NK
u3KsRMQXhXLTgXnKhIIsfi/lC4EoyXesybsTaML7D7/YIYxtrql7/FJGSu4ovGZy
9QyhQWraE0OtYKZziLwH4QBjfV3TQSwxz8Yi/tV39ZB0QCE54SmzxImD2EcdfawL
KTFhgwIDAQABoz4wPDAZBgNVHREEEjAQhwSsGQB2gghzY20zLm9yZzAPBgNVHRMB
Af8EBTADAQH/MA4GA1UdDwEB/wQEAwIBvjANBgkqhkiG9w0BAQsFAAOCAQEAPZeQ
0L34gSvIXRgrDlwUlFmIBHGWJHlOySCkQwNwed/4zOZOchfM/Et74XZa3oAmxnPX
RtDN27COrXTGZXN/3NgU5b61fr/AemO5oAbTpo1Z2bSzUfJuraKAUbxbYCvhQs5B
DL0CS+CCyeEQLLYDfeLSFEwDR9slXtpBm5yH1fXikw7n2EZPGskyi15gv34DJsCU
IYZuvqqOb/BhAbeWg3S5RMzUjHg8ES6bSK9uexYcMldvivs/tM7fJb52f4BRP8gE
9x7ho6sTJLtA78gLHYKBhnh4wjmvvX6/nxZwRz38MP+JYpuwF+GfMzCnKkpMDGLl
heQ00hrrXIOYG2A+rQ==
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDxTCCAq2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZjZGJhNy01NzUwLTRkMTgtODg5My02YmNj
YWFmYWIwNDExMTAvBgNVBAoMKENJRC0xMTkxMTI1OS1jYmNkLTRkMjEtODBiOC0x
MDI0YmY2NzMwNzAxCjAIBgNVBAUTATEwHhcNMjMxMjEyMTAzNjI1WhcNMjkwMTE5
MTAzNjI1WjCBhTEVMBMGA1UEAwwMc2NtQHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZj
ZGJhNy01NzUwLTRkMTgtODg5My02YmNjYWFmYWIwNDExMTAvBgNVBAoMKENJRC0x
MTkxMTI1OS1jYmNkLTRkMjEtODBiOC0xMDI0YmY2NzMwNzAxCjAIBgNVBAUTATEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDuP51ulJYWl58WA5s+BXzV
xiUqMkxJo5okKoCNO/mpO6wFA4FuJaw2nk0Gk75PAW8oD4uDqZNA7R+nHibbdbff
leKcHau2wCw+p0zwr50bRQyLhtYLd1ZEx4s7kmrhRoMctOUvNSoIrFoq4rMdr7gF
1Uw6MXPLzU6zV2gamVdmKLZebuZqU8c9rf8+wpfEPsRnKzgLKW7L5k+MXPLC15JP
5EsvUsytCZ08IjEKbX7V0BLqCaNAWYOBOfLlAuRZ9bWLoclaW2l/Xl9YeyNvK5HF
ZE7mBu1VkV5F1hBr5OxQnG0npVdtU2LpVdVPBlDOvwznbOXjpdlem+WZIfSg1z7r
AgMBAAGjPjA8MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMBkGA1Ud
EQQSMBCHBKwZAHSCCHNjbTEub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQDWyR811nl6
7E0qdT+f8uyQrTe/7oAeonknYsSQuh69afx7OO3QSwDezc2jp97Iw23C7yCmWxy8
sXXdjmoAxrAw6GOTLYEeJEbEgud/V12znlcsGSf3ja0S9CFKKTjqjl4tvkQlkSLW
i6mHzxI6aCG2Dkkbi1ls8V3PTnA8kb8da9O/qzHQ8PayxL7dyZr2VfNiQjoSu2cE
0RIYe4XwY5eP+lo5HjjeZbdQbjH3rxN1a7SzPNPWP5HHjUtpydWVR9j3FQXp46bW
oi8wUi3D2tK+ksSBEqWthwsLwNN3fRoommAx71wN8uYpHqKG6fjKXL1q6AC6Te6z
0wp50/+wYc6/
-----END CERTIFICATE-----

2023-12-12 10:37:00,329 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/certificate.crt
2023-12-12 10:37:00,329 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDyTCCArGgAwIBAgIBBTANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZjZGJhNy01NzUwLTRkMTgtODg5My02YmNj
YWFmYWIwNDExMTAvBgNVBAoMKENJRC0xMTkxMTI1OS1jYmNkLTRkMjEtODBiOC0x
MDI0YmY2NzMwNzAxCjAIBgNVBAUTATEwHhcNMjMxMjEyMTAzNzAwWhcNMjkwMTE5
MTAzNzAwWjCBiTEZMBcGA1UEAwwQc2NtLXN1YkBzY20zLm9yZzEtMCsGA1UECwwk
MjZkNGY4NDQtNzg5Mi00ZTkxLThmYTUtYjA0MTdmMzI2NDBmMTEwLwYDVQQKDChD
SUQtMTE5MTEyNTktY2JjZC00ZDIxLTgwYjgtMTAyNGJmNjczMDcwMQowCAYDVQQF
EwE1MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAulITQIQY3p/gXXyu
3JfHw8H7QAQO1cc21GDz0JlpSbfvxJkREeOnJyolSBzX17mqPmiyTlcF/esb8WFG
D9kunj5bl/5Fxhw9OC/PkoajF8ZRCalOVXCxHO/FZ4bxj7jQHGa5WLJr8HcD0UDL
lccWD2MPSHILT5v0Xn2sWIqb97CueL2ZIyM0m7FNoWFFBA+vOFj19wq52G52I7NK
u3KsRMQXhXLTgXnKhIIsfi/lC4EoyXesybsTaML7D7/YIYxtrql7/FJGSu4ovGZy
9QyhQWraE0OtYKZziLwH4QBjfV3TQSwxz8Yi/tV39ZB0QCE54SmzxImD2EcdfawL
KTFhgwIDAQABoz4wPDAZBgNVHREEEjAQhwSsGQB2gghzY20zLm9yZzAPBgNVHRMB
Af8EBTADAQH/MA4GA1UdDwEB/wQEAwIBvjANBgkqhkiG9w0BAQsFAAOCAQEAPZeQ
0L34gSvIXRgrDlwUlFmIBHGWJHlOySCkQwNwed/4zOZOchfM/Et74XZa3oAmxnPX
RtDN27COrXTGZXN/3NgU5b61fr/AemO5oAbTpo1Z2bSzUfJuraKAUbxbYCvhQs5B
DL0CS+CCyeEQLLYDfeLSFEwDR9slXtpBm5yH1fXikw7n2EZPGskyi15gv34DJsCU
IYZuvqqOb/BhAbeWg3S5RMzUjHg8ES6bSK9uexYcMldvivs/tM7fJb52f4BRP8gE
9x7ho6sTJLtA78gLHYKBhnh4wjmvvX6/nxZwRz38MP+JYpuwF+GfMzCnKkpMDGLl
heQ00hrrXIOYG2A+rQ==
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDxTCCAq2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZjZGJhNy01NzUwLTRkMTgtODg5My02YmNj
YWFmYWIwNDExMTAvBgNVBAoMKENJRC0xMTkxMTI1OS1jYmNkLTRkMjEtODBiOC0x
MDI0YmY2NzMwNzAxCjAIBgNVBAUTATEwHhcNMjMxMjEyMTAzNjI1WhcNMjkwMTE5
MTAzNjI1WjCBhTEVMBMGA1UEAwwMc2NtQHNjbTEub3JnMS0wKwYDVQQLDCQ5ZDZj
ZGJhNy01NzUwLTRkMTgtODg5My02YmNjYWFmYWIwNDExMTAvBgNVBAoMKENJRC0x
MTkxMTI1OS1jYmNkLTRkMjEtODBiOC0xMDI0YmY2NzMwNzAxCjAIBgNVBAUTATEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDuP51ulJYWl58WA5s+BXzV
xiUqMkxJo5okKoCNO/mpO6wFA4FuJaw2nk0Gk75PAW8oD4uDqZNA7R+nHibbdbff
leKcHau2wCw+p0zwr50bRQyLhtYLd1ZEx4s7kmrhRoMctOUvNSoIrFoq4rMdr7gF
1Uw6MXPLzU6zV2gamVdmKLZebuZqU8c9rf8+wpfEPsRnKzgLKW7L5k+MXPLC15JP
5EsvUsytCZ08IjEKbX7V0BLqCaNAWYOBOfLlAuRZ9bWLoclaW2l/Xl9YeyNvK5HF
ZE7mBu1VkV5F1hBr5OxQnG0npVdtU2LpVdVPBlDOvwznbOXjpdlem+WZIfSg1z7r
AgMBAAGjPjA8MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMBkGA1Ud
EQQSMBCHBKwZAHSCCHNjbTEub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQDWyR811nl6
7E0qdT+f8uyQrTe/7oAeonknYsSQuh69afx7OO3QSwDezc2jp97Iw23C7yCmWxy8
sXXdjmoAxrAw6GOTLYEeJEbEgud/V12znlcsGSf3ja0S9CFKKTjqjl4tvkQlkSLW
i6mHzxI6aCG2Dkkbi1ls8V3PTnA8kb8da9O/qzHQ8PayxL7dyZr2VfNiQjoSu2cE
0RIYe4XwY5eP+lo5HjjeZbdQbjH3rxN1a7SzPNPWP5HHjUtpydWVR9j3FQXp46bW
oi8wUi3D2tK+ksSBEqWthwsLwNN3fRoommAx71wN8uYpHqKG6fjKXL1q6AC6Te6z
0wp50/+wYc6/
-----END CERTIFICATE-----

2023-12-12 10:37:00,330 [main] INFO client.SCMCertificateClient: Successfully stored SCM signed certificate.
2023-12-12 10:37:00,339 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-11911259-cbcd-4d21-80b8-1024bf673070, SCMID 26d4f844-7892-4e91-8fa5-b0417f32640f
2023-12-12 10:37:00,339 [main] INFO server.StorageContainerManager: Primary SCM Node ID 9d6cdba7-5750-4d18-8893-6bccaafab041
2023-12-12 10:37:00,356 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-12-12 10:37:01,631 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm3.org/172.25.0.118
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.21.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.21.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.21.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.21.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.0.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/a93015a85b8ebe6a3e9423372f3337ed9b029704 ; compiled by 'runner' on 2023-12-12T10:10Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=true, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=4MB, dfs.container.ratis.segment.size=64MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60s, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.handler.type=distributed, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-address.omservice.om1=om1, ozone.om.http-address.omservice.om2=om2, ozone.om.http-address.omservice.om3=om3, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.internal.service.id=omservice, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=false, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=20s, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=5s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.enable=true, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-12-12 10:37:01,643 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-12-12 10:37:01,693 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-12 10:37:01,818 [main] INFO reflections.Reflections: Reflections took 86 ms to scan 3 urls, producing 134 keys and 291 values 
2023-12-12 10:37:01,903 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2023-12-12 10:37:01,911 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-12-12 10:37:01,931 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
2023-12-12 10:37:01,931 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
2023-12-12 10:37:02,072 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2023-12-12 10:37:02,072 [main] INFO server.StorageContainerManager: SCM login successful.
2023-12-12 10:37:02,583 [main] INFO client.SCMCertificateClient: Certificate serial ID set to 5
2023-12-12 10:37:02,717 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 5
             IssuerDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:37:00 UTC 2023
           Final Date: Fri Jan 19 10:37:00 UTC 2029
            SubjectDN: CN=scm-sub@scm3.org,OU=26d4f844-7892-4e91-8fa5-b0417f32640f,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=5
           Public Key: RSA Public Key [56:08:98:1b:f2:f5:29:d3:be:96:1f:02:c7:9e:1e:65:af:d5:37:d0],[56:66:d1:a4]
        modulus: ba5213408418de9fe05d7caedc97c7c3c1fb40040ed5c736d460f3d0996949b7efc4991111e3a7272a25481cd7d7b9aa3e68b24e5705fdeb1bf161460fd92e9e3e5b97fe45c61c3d382fcf9286a317c65109a94e5570b11cefc56786f18fb8d01c66b958b26bf07703d140cb95c7160f630f48720b4f9bf45e7dac588a9bf7b0ae78bd992323349bb14da16145040faf3858f5f70ab9d86e7623b34abb72ac44c4178572d38179ca84822c7e2fe50b8128c977acc9bb1368c2fb0fbfd8218c6daea97bfc52464aee28bc6672f50ca1416ada1343ad60a67388bc07e100637d5dd3412c31cfc622fed577f59074402139e129b3c48983d8471d7dac0b29316183
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 3d9790d0bdf8812bc85d182b0e5c149459880471
                       9624794ec920a443037079dff8cce64e7217ccfc
                       4b7be1765ade8026c673d746d0cddbb08ead74c6
                       65737fdcd814e5beb57ebfc07a63b9a006d3a68d
                       59d9b4b351f26eada28051bc5b602be142ce410c
                       bd024be082c9e1102cb6037de2d2144c0347db25
                       5eda419b9c87d5f5e2930ee7d8464f1ac9328b5e
                       60bf7e0326c09421866ebeaa8e6ff06101b79683
                       74b944ccd48c783c112e9b48af6e7b161c32576f
                       8afb3fb4cedf25be767f80513fc804f71ee1a3ab
                       1324bb40efc80b1d8281867878c239afbd7ebf9f
                       1670473dfc30ff89629bb017e19f3330a72a4a4c
                       0c62e585e434d21aeb5c83981b603ead
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/certificate.crt.
2023-12-12 10:37:02,721 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 5
             IssuerDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:37:00 UTC 2023
           Final Date: Fri Jan 19 10:37:00 UTC 2029
            SubjectDN: CN=scm-sub@scm3.org,OU=26d4f844-7892-4e91-8fa5-b0417f32640f,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=5
           Public Key: RSA Public Key [56:08:98:1b:f2:f5:29:d3:be:96:1f:02:c7:9e:1e:65:af:d5:37:d0],[56:66:d1:a4]
        modulus: ba5213408418de9fe05d7caedc97c7c3c1fb40040ed5c736d460f3d0996949b7efc4991111e3a7272a25481cd7d7b9aa3e68b24e5705fdeb1bf161460fd92e9e3e5b97fe45c61c3d382fcf9286a317c65109a94e5570b11cefc56786f18fb8d01c66b958b26bf07703d140cb95c7160f630f48720b4f9bf45e7dac588a9bf7b0ae78bd992323349bb14da16145040faf3858f5f70ab9d86e7623b34abb72ac44c4178572d38179ca84822c7e2fe50b8128c977acc9bb1368c2fb0fbfd8218c6daea97bfc52464aee28bc6672f50ca1416ada1343ad60a67388bc07e100637d5dd3412c31cfc622fed577f59074402139e129b3c48983d8471d7dac0b29316183
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 3d9790d0bdf8812bc85d182b0e5c149459880471
                       9624794ec920a443037079dff8cce64e7217ccfc
                       4b7be1765ade8026c673d746d0cddbb08ead74c6
                       65737fdcd814e5beb57ebfc07a63b9a006d3a68d
                       59d9b4b351f26eada28051bc5b602be142ce410c
                       bd024be082c9e1102cb6037de2d2144c0347db25
                       5eda419b9c87d5f5e2930ee7d8464f1ac9328b5e
                       60bf7e0326c09421866ebeaa8e6ff06101b79683
                       74b944ccd48c783c112e9b48af6e7b161c32576f
                       8afb3fb4cedf25be767f80513fc804f71ee1a3ab
                       1324bb40efc80b1d8281867878c239afbd7ebf9f
                       1670473dfc30ff89629bb017e19f3330a72a4a4c
                       0c62e585e434d21aeb5c83981b603ead
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/5.crt.
2023-12-12 10:37:02,726 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:36:25 UTC 2023
           Final Date: Fri Jan 19 10:36:25 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Public Key: RSA Public Key [1c:e1:2e:f4:24:90:4f:71:d5:81:8e:c0:f1:ba:2a:56:88:43:a7:bd],[56:66:d1:a4]
        modulus: ee3f9d6e949616979f16039b3e057cd5c6252a324c49a39a242a808d3bf9a93bac0503816e25ac369e4d0693be4f016f280f8b83a99340ed1fa71e26db75b7df95e29c1dabb6c02c3ea74cf0af9d1b450c8b86d60b775644c78b3b926ae146831cb4e52f352a08ac5a2ae2b31dafb805d54c3a3173cbcd4eb357681a99576628b65e6ee66a53c73dadff3ec297c43ec4672b380b296ecbe64f8c5cf2c2d7924fe44b2f52ccad099d3c22310a6d7ed5d012ea09a34059838139f2e502e459f5b58ba1c95a5b697f5e5f587b236f2b91c5644ee606ed55915e45d6106be4ec509c6d27a5576d5362e955d54f0650cebf0ce76ce5e3a5d95e9be59921f4a0d73eeb
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: d6c91f35d6797aec4d2a753f9ff2ec90ad37bfee
                       801ea2792762c490ba1ebd69fc7b38edd04b00de
                       cdcda3a7dec8c36dc2ef20a65b1cbcb175dd8e6a
                       00c6b030e863932d811e2446c482e77f575db39e
                       572c1927f78dad12f4214a2938ea8e5e2dbe4425
                       9122d68ba987cf123a6821b60e491b8b596cf15d
                       cf4e703c91bf1d6bd3bfab31d0f0f6b2c4beddc9
                       9af655f362423a12bb6704d112187b85f063978f
                       fa5a391e38de65b7506e31f7af13756bb4b33cd3
                       d63f91c78d4b69c9d59547d8f71505e9e3a6d6a2
                       2f30522dc3dad2be92c48112a5ad870b0bc0d377
                       7d1a289a6031ef5c0df2e6291ea286e9f8ca5cbd
                       6ae800ba4deeb3d30a79d3ffb061cebf
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

 from file: /data/metadata/scm/sub-ca/certs/CA-1.crt.
2023-12-12 10:37:02,727 [main] INFO client.SCMCertificateClient: CertificateRenewerService and root ca rotation polling is disabled for scm/sub-ca
2023-12-12 10:37:02,798 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-12 10:37:02,928 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-12 10:37:03,177 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-12-12 10:37:03,179 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2023-12-12 10:37:03,245 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2023-12-12 10:37:03,390 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:26d4f844-7892-4e91-8fa5-b0417f32640f
2023-12-12 10:37:03,444 [main] INFO ssl.ReloadingX509KeyManager: Key manager is loaded with certificate chain
2023-12-12 10:37:03,450 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 5
             IssuerDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:37:00 UTC 2023
           Final Date: Fri Jan 19 10:37:00 UTC 2029
            SubjectDN: CN=scm-sub@scm3.org,OU=26d4f844-7892-4e91-8fa5-b0417f32640f,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=5
           Public Key: RSA Public Key [56:08:98:1b:f2:f5:29:d3:be:96:1f:02:c7:9e:1e:65:af:d5:37:d0],[56:66:d1:a4]
        modulus: ba5213408418de9fe05d7caedc97c7c3c1fb40040ed5c736d460f3d0996949b7efc4991111e3a7272a25481cd7d7b9aa3e68b24e5705fdeb1bf161460fd92e9e3e5b97fe45c61c3d382fcf9286a317c65109a94e5570b11cefc56786f18fb8d01c66b958b26bf07703d140cb95c7160f630f48720b4f9bf45e7dac588a9bf7b0ae78bd992323349bb14da16145040faf3858f5f70ab9d86e7623b34abb72ac44c4178572d38179ca84822c7e2fe50b8128c977acc9bb1368c2fb0fbfd8218c6daea97bfc52464aee28bc6672f50ca1416ada1343ad60a67388bc07e100637d5dd3412c31cfc622fed577f59074402139e129b3c48983d8471d7dac0b29316183
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 3d9790d0bdf8812bc85d182b0e5c149459880471
                       9624794ec920a443037079dff8cce64e7217ccfc
                       4b7be1765ade8026c673d746d0cddbb08ead74c6
                       65737fdcd814e5beb57ebfc07a63b9a006d3a68d
                       59d9b4b351f26eada28051bc5b602be142ce410c
                       bd024be082c9e1102cb6037de2d2144c0347db25
                       5eda419b9c87d5f5e2930ee7d8464f1ac9328b5e
                       60bf7e0326c09421866ebeaa8e6ff06101b79683
                       74b944ccd48c783c112e9b48af6e7b161c32576f
                       8afb3fb4cedf25be767f80513fc804f71ee1a3ab
                       1324bb40efc80b1d8281867878c239afbd7ebf9f
                       1670473dfc30ff89629bb017e19f3330a72a4a4c
                       0c62e585e434d21aeb5c83981b603ead
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe

2023-12-12 10:37:03,454 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:36:25 UTC 2023
           Final Date: Fri Jan 19 10:36:25 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Public Key: RSA Public Key [1c:e1:2e:f4:24:90:4f:71:d5:81:8e:c0:f1:ba:2a:56:88:43:a7:bd],[56:66:d1:a4]
        modulus: ee3f9d6e949616979f16039b3e057cd5c6252a324c49a39a242a808d3bf9a93bac0503816e25ac369e4d0693be4f016f280f8b83a99340ed1fa71e26db75b7df95e29c1dabb6c02c3ea74cf0af9d1b450c8b86d60b775644c78b3b926ae146831cb4e52f352a08ac5a2ae2b31dafb805d54c3a3173cbcd4eb357681a99576628b65e6ee66a53c73dadff3ec297c43ec4672b380b296ecbe64f8c5cf2c2d7924fe44b2f52ccad099d3c22310a6d7ed5d012ea09a34059838139f2e502e459f5b58ba1c95a5b697f5e5f587b236f2b91c5644ee606ed55915e45d6106be4ec509c6d27a5576d5362e955d54f0650cebf0ce76ce5e3a5d95e9be59921f4a0d73eeb
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: d6c91f35d6797aec4d2a753f9ff2ec90ad37bfee
                       801ea2792762c490ba1ebd69fc7b38edd04b00de
                       cdcda3a7dec8c36dc2ef20a65b1cbcb175dd8e6a
                       00c6b030e863932d811e2446c482e77f575db39e
                       572c1927f78dad12f4214a2938ea8e5e2dbe4425
                       9122d68ba987cf123a6821b60e491b8b596cf15d
                       cf4e703c91bf1d6bd3bfab31d0f0f6b2c4beddc9
                       9af655f362423a12bb6704d112187b85f063978f
                       fa5a391e38de65b7506e31f7af13756bb4b33cd3
                       d63f91c78d4b69c9d59547d8f71505e9e3a6d6a2
                       2f30522dc3dad2be92c48112a5ad870b0bc0d377
                       7d1a289a6031ef5c0df2e6291ea286e9f8ca5cbd
                       6ae800ba4deeb3d30a79d3ffb061cebf
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2023-12-12 10:37:03,458 [main] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-12-12 10:37:03,458 [main] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-12-12 10:37:03,458 [main] INFO ssl.ReloadingX509TrustManager: Trust manager is loaded with certificates
2023-12-12 10:37:03,463 [main] INFO ssl.ReloadingX509TrustManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:36:25 UTC 2023
           Final Date: Fri Jan 19 10:36:25 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1
           Public Key: RSA Public Key [1c:e1:2e:f4:24:90:4f:71:d5:81:8e:c0:f1:ba:2a:56:88:43:a7:bd],[56:66:d1:a4]
        modulus: ee3f9d6e949616979f16039b3e057cd5c6252a324c49a39a242a808d3bf9a93bac0503816e25ac369e4d0693be4f016f280f8b83a99340ed1fa71e26db75b7df95e29c1dabb6c02c3ea74cf0af9d1b450c8b86d60b775644c78b3b926ae146831cb4e52f352a08ac5a2ae2b31dafb805d54c3a3173cbcd4eb357681a99576628b65e6ee66a53c73dadff3ec297c43ec4672b380b296ecbe64f8c5cf2c2d7924fe44b2f52ccad099d3c22310a6d7ed5d012ea09a34059838139f2e502e459f5b58ba1c95a5b697f5e5f587b236f2b91c5644ee606ed55915e45d6106be4ec509c6d27a5576d5362e955d54f0650cebf0ce76ce5e3a5d95e9be59921f4a0d73eeb
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: d6c91f35d6797aec4d2a753f9ff2ec90ad37bfee
                       801ea2792762c490ba1ebd69fc7b38edd04b00de
                       cdcda3a7dec8c36dc2ef20a65b1cbcb175dd8e6a
                       00c6b030e863932d811e2446c482e77f575db39e
                       572c1927f78dad12f4214a2938ea8e5e2dbe4425
                       9122d68ba987cf123a6821b60e491b8b596cf15d
                       cf4e703c91bf1d6bd3bfab31d0f0f6b2c4beddc9
                       9af655f362423a12bb6704d112187b85f063978f
                       fa5a391e38de65b7506e31f7af13756bb4b33cd3
                       d63f91c78d4b69c9d59547d8f71505e9e3a6d6a2
                       2f30522dc3dad2be92c48112a5ad870b0bc0d377
                       7d1a289a6031ef5c0df2e6291ea286e9f8ca5cbd
                       6ae800ba4deeb3d30a79d3ffb061cebf
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2023-12-12 10:37:03,484 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-12-12 10:37:03,488 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-12-12 10:37:03,545 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2023-12-12 10:37:03,551 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-12-12 10:37:03,552 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2023-12-12 10:37:03,552 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-12-12 10:37:03,553 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2023-12-12 10:37:03,553 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2023-12-12 10:37:03,554 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2023-12-12 10:37:03,554 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2023-12-12 10:37:03,556 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 10:37:03,556 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-12-12 10:37:03,557 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-12-12 10:37:03,563 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-12-12 10:37:03,565 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-12-12 10:37:03,566 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-12-12 10:37:03,804 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2023-12-12 10:37:03,806 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2023-12-12 10:37:03,806 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2023-12-12 10:37:03,806 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-12-12 10:37:03,810 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-12-12 10:37:03,811 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2023-12-12 10:37:03,811 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2023-12-12 10:37:03,818 [main] INFO server.RaftServer: 26d4f844-7892-4e91-8fa5-b0417f32640f: addNew group-1024BF673070:[] returns group-1024BF673070:java.util.concurrent.CompletableFuture@776a3365[Not completed]
2023-12-12 10:37:03,834 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f: new RaftServerImpl for group-1024BF673070:[] with SCMStateMachine:uninitialized
2023-12-12 10:37:03,836 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2023-12-12 10:37:03,837 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2023-12-12 10:37:03,837 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2023-12-12 10:37:03,837 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2023-12-12 10:37:03,838 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-12-12 10:37:03,838 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2023-12-12 10:37:03,838 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2023-12-12 10:37:03,849 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-12-12 10:37:03,855 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2023-12-12 10:37:03,860 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2023-12-12 10:37:03,863 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2023-12-12 10:37:03,864 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2023-12-12 10:37:03,868 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2023-12-12 10:37:03,869 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2023-12-12 10:37:03,974 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-12-12 10:37:03,977 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-12-12 10:37:03,978 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2023-12-12 10:37:03,978 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2023-12-12 10:37:03,978 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2023-12-12 10:37:03,979 [26d4f844-7892-4e91-8fa5-b0417f32640f-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2023-12-12 10:37:03,981 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2023-12-12 10:37:03,981 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-12-12 10:37:03,982 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2023-12-12 10:37:04,015 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2023-12-12 10:37:04,071 [main] INFO ha.SequenceIdGenerator: upgrade localId to 111677748019200000
2023-12-12 10:37:04,073 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2023-12-12 10:37:04,078 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2023-12-12 10:37:04,080 [main] INFO ha.SequenceIdGenerator: upgrade CertificateId to 2
2023-12-12 10:37:04,082 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2023-12-12 10:37:04,143 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2023-12-12 10:37:04,157 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2023-12-12 10:37:04,159 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-12-12 10:37:04,168 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2023-12-12 10:37:04,183 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-12-12 10:37:04,183 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-12-12 10:37:04,189 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2023-12-12 10:37:04,189 [main] INFO pipeline.BackgroundPipelineCreator: Starting scm3-RatisPipelineUtilsThread.
2023-12-12 10:37:04,192 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2023-12-12 10:37:04,193 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2023-12-12 10:37:04,199 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2023-12-12 10:37:04,199 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2023-12-12 10:37:04,226 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-12-12 10:37:04,226 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-12-12 10:37:04,250 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2023-12-12 10:37:04,335 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2023-12-12 10:37:04,344 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2023-12-12 10:37:04,344 [scm3-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2023-12-12 10:37:04,358 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2023-12-12 10:37:04,362 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:04,364 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-12-12 10:37:04,546 [main] INFO security.SecretKeyManagerService: Scheduling rotation checker with interval PT1M
2023-12-12 10:37:04,547 [main] INFO ha.SCMServiceManager: Registering service SecretKeyManagerService.
2023-12-12 10:37:04,568 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2023-12-12 10:37:04,586 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-12 10:37:04,614 [main] INFO ipc.Server: Listener at 0.0.0.0:9961
2023-12-12 10:37:04,616 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
2023-12-12 10:37:04,662 [main] INFO server.StorageContainerManager: SCM start with adminUsers: [testuser, recon, om, scm]
2023-12-12 10:37:05,058 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-12-12 10:37:05,073 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-12 10:37:05,073 [main] INFO ipc.Server: Listener at 0.0.0.0:9861
2023-12-12 10:37:05,074 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2023-12-12 10:37:05,107 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-12-12 10:37:05,113 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-12 10:37:05,113 [main] INFO ipc.Server: Listener at 0.0.0.0:9863
2023-12-12 10:37:05,114 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2023-12-12 10:37:05,212 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-12-12 10:37:05,223 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-12 10:37:05,223 [main] INFO ipc.Server: Listener at 0.0.0.0:9860
2023-12-12 10:37:05,226 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2023-12-12 10:37:05,320 [main] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2023-12-12 10:37:05,322 [main] INFO server.StorageContainerManager: 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB
Number of Iterations                               10
Time Limit for Single Container's Movement         65min
Time Limit for Single Container's Replication      50min
Interval between each Iteration                    70min
Whether to Enable Network Topology                 false
Whether to Trigger Refresh Datanode Usage Info     false
Container IDs to Exclude from Balancing            None
Datanodes Specified to be Balanced                 None
Datanodes Excluded from Balancing                  None

2023-12-12 10:37:05,322 [main] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-12-12 10:37:05,330 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2023-12-12 10:37:05,337 [main] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2023-12-12 10:37:05,341 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2023-12-12 10:37:05,341 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2023-12-12 10:37:05,342 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-12-12 10:37:05,349 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070 does not exist. Creating ...
2023-12-12 10:37:05,358 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070/in_use.lock acquired by nodename 6@scm3.org
2023-12-12 10:37:05,368 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070 has been successfully formatted.
2023-12-12 10:37:05,372 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2023-12-12 10:37:05,393 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2023-12-12 10:37:05,393 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 10:37:05,396 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-12-12 10:37:05,397 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2023-12-12 10:37:05,405 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-12-12 10:37:05,413 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2023-12-12 10:37:05,413 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-12-12 10:37:05,413 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 10:37:05,415 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO util.AwaitToRun: Thread[26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-cacheEviction-AwaitToRun,5,main] started
2023-12-12 10:37:05,419 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070
2023-12-12 10:37:05,419 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-12-12 10:37:05,419 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2023-12-12 10:37:05,420 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-12-12 10:37:05,422 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2023-12-12 10:37:05,422 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2023-12-12 10:37:05,422 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2023-12-12 10:37:05,422 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-12-12 10:37:05,423 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-12-12 10:37:05,430 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2023-12-12 10:37:05,437 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 10:37:05,439 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2023-12-12 10:37:05,440 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2023-12-12 10:37:05,440 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2023-12-12 10:37:05,445 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-12-12 10:37:05,445 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-12-12 10:37:05,446 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: start with initializing state, conf=-1: peers:[]|listeners:[], old=null
2023-12-12 10:37:05,461 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: changes role from      null to FOLLOWER at term 0 for startInitializing
2023-12-12 10:37:05,471 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1024BF673070,id=26d4f844-7892-4e91-8fa5-b0417f32640f
2023-12-12 10:37:05,473 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2023-12-12 10:37:05,474 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-12-12 10:37:05,474 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2023-12-12 10:37:05,474 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2023-12-12 10:37:05,475 [26d4f844-7892-4e91-8fa5-b0417f32640f-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2023-12-12 10:37:05,478 [main] INFO server.RaftServer: 26d4f844-7892-4e91-8fa5-b0417f32640f: start RPC server
2023-12-12 10:37:05,514 [main] INFO server.GrpcService: 26d4f844-7892-4e91-8fa5-b0417f32640f: GrpcService started, listening on 9894
2023-12-12 10:37:05,515 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-26d4f844-7892-4e91-8fa5-b0417f32640f: Started
2023-12-12 10:37:05,534 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
2023-12-12 10:37:05,989 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: receive installSnapshot: 9d6cdba7-5750-4d18-8893-6bccaafab041->26d4f844-7892-4e91-8fa5-b0417f32640f#0-t2,notify:(t:1, i:0)
2023-12-12 10:37:05,992 [grpc-default-executor-0] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: set firstElectionSinceStartup to false for installSnapshot
2023-12-12 10:37:05,993 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
2023-12-12 10:37:05,993 [grpc-default-executor-0] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: change Leader from null to 9d6cdba7-5750-4d18-8893-6bccaafab041 at term 2 for installSnapshot, leader elected after 2137ms
2023-12-12 10:37:05,995 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Received notification to install snapshot at index 0
2023-12-12 10:37:05,996 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
2023-12-12 10:37:06,281 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: set new configuration index: 17
configurationEntry {
  peers {
    id: "2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f"
    address: "scm2.org:9894"
    startupRole: FOLLOWER
  }
  peers {
    id: "9d6cdba7-5750-4d18-8893-6bccaafab041"
    address: "scm1.org:9894"
    startupRole: FOLLOWER
  }
}
 from snapshot
2023-12-12 10:37:06,322 [grpc-default-executor-0] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: set configuration 17: peers:[2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f|scm2.org:9894, 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894]|listeners:[], old=null
2023-12-12 10:37:06,327 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: reply installSnapshot: 9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#0:OK-t0,ALREADY_INSTALLED,snapshotIndex=0
2023-12-12 10:37:06,343 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 26d4f844-7892-4e91-8fa5-b0417f32640f: Completed INSTALL_SNAPSHOT, lastRequest: 9d6cdba7-5750-4d18-8893-6bccaafab041->26d4f844-7892-4e91-8fa5-b0417f32640f#0-t2,notify:(t:1, i:0)
2023-12-12 10:37:06,344 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 26d4f844-7892-4e91-8fa5-b0417f32640f: Completed INSTALL_SNAPSHOT, lastReply: null
2023-12-12 10:37:06,555 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO impl.RoleInfo: 26d4f844-7892-4e91-8fa5-b0417f32640f: start 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-FollowerState
2023-12-12 10:37:06,561 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,564 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,564 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread1] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,565 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread1] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,632 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,632 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#2:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,636 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,641 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#3:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,648 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,648 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#4:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,666 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,666 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#5:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,677 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,677 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#6:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,703 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,703 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#7:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,729 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,729 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#8:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,753 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,754 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#9:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,803 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,805 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#10:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,848 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,848 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#11:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,873 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,874 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#12:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,898 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,898 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#13:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,920 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,922 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#14:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,940 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,941 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#15:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,955 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,957 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#16:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,975 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:06,975 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#17:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:06,998 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,007 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#18:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,065 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,065 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#19:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,077 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,080 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#20:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,095 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,095 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#21:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,117 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,117 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#22:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,129 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,130 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#23:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,147 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,147 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#24:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,167 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,167 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#25:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,185 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,185 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#26:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,203 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,204 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#27:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,223 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,223 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#28:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,239 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,239 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#29:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,251 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,251 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#30:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,263 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,263 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#31:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,274 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,274 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#32:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,282 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,282 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#33:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,296 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,296 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#34:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,311 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,311 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#35:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,322 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,339 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#36:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,342 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,342 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#37:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,352 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,352 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#38:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,361 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,367 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#39:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,386 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,387 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#40:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,421 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,421 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#41:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,426 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,427 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#42:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,431 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,433 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#43:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,443 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,445 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#44:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,451 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,452 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#45:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,459 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,461 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#46:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,477 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,477 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#47:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,481 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,486 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#48:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,490 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,493 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#49:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,501 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,511 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#50:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,533 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,533 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#51:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,547 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,547 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#52:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,553 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,553 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#53:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,562 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,562 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#54:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,583 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:37:07,584 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: inconsistency entries. Reply:9d6cdba7-5750-4d18-8893-6bccaafab041<-26d4f844-7892-4e91-8fa5-b0417f32640f#55:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:37:07,590 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: set configuration 0: peers:[9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894]|listeners:[], old=null
2023-12-12 10:37:07,590 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: set configuration 1: peers:[9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894]|listeners:[], old=null
2023-12-12 10:37:07,591 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: set configuration 15: peers:[2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f|scm2.org:9894, 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894]|listeners:[], old=peers:[9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894]|listeners:[]
2023-12-12 10:37:07,591 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: set configuration 17: peers:[2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f|scm2.org:9894, 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894]|listeners:[], old=null
2023-12-12 10:37:07,596 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO segmented.SegmentedRaftLogWorker: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-SegmentedRaftLogWorker: Starting segment from index:0
2023-12-12 10:37:07,713 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO segmented.SegmentedRaftLogWorker: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2023-12-12 10:37:07,955 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070/current/log_inprogress_0
2023-12-12 10:37:07,973 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070/current/log_inprogress_0 to /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070/current/log_0-0
2023-12-12 10:37:08,049 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/11911259-cbcd-4d21-80b8-1024bf673070/current/log_inprogress_1
2023-12-12 10:37:08,065 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:08,066 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2023-12-12 10:37:08,067 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-12-12 10:37:08,074 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2023-12-12 10:37:08,088 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2023-12-12 10:37:08,095 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: set configuration 23: peers:[2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f|scm2.org:9894, 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894, 26d4f844-7892-4e91-8fa5-b0417f32640f|scm3.org:9894]|listeners:[], old=peers:[2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f|scm2.org:9894, 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894]|listeners:[]
2023-12-12 10:37:08,097 [26d4f844-7892-4e91-8fa5-b0417f32640f-server-thread2] INFO server.RaftServer$Division: 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070: set configuration 25: peers:[2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f|scm2.org:9894, 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894, 26d4f844-7892-4e91-8fa5-b0417f32640f|scm3.org:9894]|listeners:[], old=null
2023-12-12 10:37:08,165 [main] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-1024BF673070:[2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f|scm2.org:9894, 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894, 26d4f844-7892-4e91-8fa5-b0417f32640f|scm3.org:9894]
2023-12-12 10:37:08,166 [main] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2023-12-12 10:37:08,227 [main] INFO SCMHATransactionMonitor: Starting SCMHATransactionMonitor Service.
2023-12-12 10:37:08,254 [main] INFO ha.SCMServiceManager: Registering service SCMHATransactionMonitor.
2023-12-12 10:37:08,258 [main] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is already running, skip start.
2023-12-12 10:37:08,512 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-12 10:37:08,949 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z)]
2023-12-12 10:37:08,956 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z)
2023-12-12 10:37:09,227 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2023-12-12 10:37:09,387 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-12-12 10:37:09,387 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2023-12-12 10:37:09,564 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z)] to file /data/metadata/scm/keys/secret_keys.json
2023-12-12 10:37:09,594 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:09,594 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2023-12-12 10:37:09,594 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2023-12-12 10:37:09,722 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for CertificateId, expected lastId is 0, actual lastId is 2.
2023-12-12 10:37:09,760 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:09,786 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:09,880 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO server.SCMCertStore: Scm certificate 3 for CN=scm-sub@scm2.org,OU=2fcd5ba2-4297-450e-a4d6-7af75e9d3f1f,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=3 is stored
2023-12-12 10:37:09,882 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:09,900 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2023-12-12 10:37:09,901 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:09,903 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-12 10:37:09,914 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:09,937 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2023-12-12 10:37:10,006 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2023-12-12 10:37:10,015 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2023-12-12 10:37:10,015 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-12 10:37:10,015 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:10,017 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2023-12-12 10:37:10,044 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO server.SCMCertStore: Scm certificate 5 for CN=scm-sub@scm3.org,OU=26d4f844-7892-4e91-8fa5-b0417f32640f,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=5 is stored
2023-12-12 10:37:10,047 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:10,227 [main] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
2023-12-12 10:37:10,228 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-12 10:37:10,229 [main] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
2023-12-12 10:37:10,229 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
2023-12-12 10:37:10,784 [main] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 26d4f844-7892-4e91-8fa5-b0417f32640f
2023-12-12 10:37:10,808 [main] INFO server.SCMCertStore: Scm certificate 1 for CN=scm@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=1 is stored
2023-12-12 10:37:10,811 [main] INFO server.StorageContainerManager: Persist certificate serialId 2 on Scm Bootstrap Node 26d4f844-7892-4e91-8fa5-b0417f32640f
2023-12-12 10:37:10,819 [main] INFO server.SCMCertStore: Scm certificate 2 for CN=scm-sub@scm1.org,OU=9d6cdba7-5750-4d18-8893-6bccaafab041,O=CID-11911259-cbcd-4d21-80b8-1024bf673070,SERIALNUMBER=2 is stored
2023-12-12 10:37:10,865 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2023-12-12 10:37:10,865 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
2023-12-12 10:37:10,866 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
2023-12-12 10:37:10,973 [main] INFO util.log: Logging initialized @10403ms to org.eclipse.jetty.util.log.Slf4jLog
2023-12-12 10:37:11,632 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2023-12-12 10:37:11,715 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-12-12 10:37:11,725 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2023-12-12 10:37:11,733 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2023-12-12 10:37:11,734 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2023-12-12 10:37:11,757 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
2023-12-12 10:37:12,011 [main] INFO http.BaseHttpServer: HTTP server of scm uses base directory /data/metadata/webserver
2023-12-12 10:37:12,032 [main] INFO http.HttpServer2: Jetty bound to port 9876
2023-12-12 10:37:12,042 [main] INFO server.Server: jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 11.0.19+7-LTS
2023-12-12 10:37:12,378 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2023-12-12 10:37:12,379 [main] INFO server.session: No SessionScavenger set, using defaults
2023-12-12 10:37:12,394 [main] INFO server.session: node0 Scavenging every 660000ms
2023-12-12 10:37:12,491 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2023-12-12 10:37:12,500 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6cce1f60{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2023-12-12 10:37:12,506 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@57a4ca74{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-12-12 10:37:13,175 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2023-12-12 10:37:13,262 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@433dd165{scm,/,file:///data/metadata/webserver/jetty-0_0_0_0-9876-hdds-server-scm-1_4_0-SNAPSHOT_jar-_-any-3570757864128574060/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/scm}
2023-12-12 10:37:13,335 [main] INFO server.AbstractConnector: Started ServerConnector@6fd33f5a{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2023-12-12 10:37:13,335 [main] INFO server.Server: Started @12765ms
2023-12-12 10:37:13,369 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2023-12-12 10:37:13,369 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
2023-12-12 10:37:13,374 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2023-12-12 10:37:13,428 [26d4f844-7892-4e91-8fa5-b0417f32640f-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-12-12 10:37:13,451 [26d4f844-7892-4e91-8fa5-b0417f32640f-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-12-12 10:37:13,454 [26d4f844-7892-4e91-8fa5-b0417f32640f-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: CA certificates are not changed.
2023-12-12 10:37:23,351 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:23,575 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:23,900 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:24,150 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:26,995 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:27,260 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:27,674 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:27,844 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:29,831 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:30,118 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:30,932 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:31,012 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:40,368 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:46232 / 172.25.0.102:46232
2023-12-12 10:37:40,425 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:37:41,482 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:41656 / 172.25.0.103:41656
2023-12-12 10:37:41,571 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:37:42,281 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/634f8a9a-5da8-49ee-a211-3e667283ff7d
2023-12-12 10:37:42,304 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 634f8a9a-5da8-49ee-a211-3e667283ff7d{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 6, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-12-12 10:37:42,331 [scm3-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-12-12 10:37:42,332 [scm3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
2023-12-12 10:37:42,430 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:43,389 [IPC Server handler 19 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/92849505-ef99-4e21-a442-7f5bd09606ad
2023-12-12 10:37:43,391 [IPC Server handler 19 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 92849505-ef99-4e21-a442-7f5bd09606ad{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 7, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-12-12 10:37:43,392 [scm3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
2023-12-12 10:37:43,392 [scm3-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-12-12 10:37:43,446 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:44,124 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:52960 / 172.25.0.104:52960
2023-12-12 10:37:44,212 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:37:45,680 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:45,760 [scm3-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "c00e8640-5ea9-4629-a86b-38763274a453"
  uuid128 {
    mostSigBits: -4607597757729257943
    leastSigBits: -6310888372525816749
  }
}
isLeader: false
bytesWritten: 0
 from dn=634f8a9a-5da8-49ee-a211-3e667283ff7d(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:795)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:760)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:746)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:926)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:919)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:896)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$11(RaftServerImpl.java:885)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$12(RaftServerImpl.java:885)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-12-12 10:37:45,998 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/6a902a0e-b3da-4316-a0ee-cbc7bf632497
2023-12-12 10:37:45,999 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 6a902a0e-b3da-4316-a0ee-cbc7bf632497{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 8, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-12-12 10:37:45,999 [scm3-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-12-12 10:37:46,001 [scm3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
2023-12-12 10:37:46,001 [scm3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2023-12-12 10:37:46,001 [scm3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2023-12-12 10:37:46,002 [scm3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-12-12 10:37:46,002 [scm3-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-12-12 10:37:46,042 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:46,101 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:46,162 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:46,952 [scm3-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "4c0af17c-edd5-4e21-bd83-a0e42c03a017"
  uuid128 {
    mostSigBits: 5479457415518047777
    leastSigBits: -4790808676740653033
  }
}
isLeader: false
bytesWritten: 0
 from dn=92849505-ef99-4e21-a442-7f5bd09606ad(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:795)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:760)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:746)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:926)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:919)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:896)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$11(RaftServerImpl.java:885)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$12(RaftServerImpl.java:885)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-12-12 10:37:46,980 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:49,348 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:37:49,358 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:49,662 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:51,124 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:51,636 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:52,320 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:52,744 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:53,061 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:53,402 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:53,921 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:54,761 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:58,650 [scm3-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "68635585-d9de-404c-a57a-8c95f00ffae5"
  uuid128 {
    mostSigBits: 7521949836013092940
    leastSigBits: -6522746534687147291
  }
}
isLeader: true
bytesWritten: 0
 from dn=634f8a9a-5da8-49ee-a211-3e667283ff7d(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:795)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:760)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:746)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:926)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:919)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:896)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$11(RaftServerImpl.java:885)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$12(RaftServerImpl.java:885)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-12-12 10:37:58,652 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:58,668 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2023-12-12 10:37:59,914 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:37:59,914 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-12-12 10:37:59,917 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2023-12-12 10:37:59,917 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2023-12-12 10:37:59,917 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2023-12-12 10:37:59,917 [scm3-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-12-12 10:37:59,918 [scm3-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "d9b5ea72-1356-4e6c-9444-4a46b13d771e"
  uuid128 {
    mostSigBits: -2759041421022966164
    leastSigBits: -7762998190198130914
  }
}
isLeader: true
bytesWritten: 0
 from dn=92849505-ef99-4e21-a442-7f5bd09606ad(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070 is not the leader 9d6cdba7-5750-4d18-8893-6bccaafab041|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:795)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:760)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:746)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:926)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:919)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:896)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$11(RaftServerImpl.java:885)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$12(RaftServerImpl.java:885)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-12-12 10:38:24,795 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:44230 / 172.25.0.104:44230
2023-12-12 10:38:24,812 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:38:28,673 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:60024 / 172.25.0.102:60024
2023-12-12 10:38:28,688 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:38:29,940 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:42244 / 172.25.0.103:42244
2023-12-12 10:38:29,968 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:38:54,807 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:51932 / 172.25.0.104:51932
2023-12-12 10:38:54,828 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:38:58,686 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:51084 / 172.25.0.102:51084
2023-12-12 10:38:58,709 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:38:59,953 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:33290 / 172.25.0.103:33290
2023-12-12 10:38:59,988 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:39:01,724 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 111677748019200000.
2023-12-12 10:39:20,889 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:48226 / 172.25.0.104:48226
2023-12-12 10:39:20,944 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:39:20,980 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:48490 / 172.25.0.103:48490
2023-12-12 10:39:20,997 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:34660 / 172.25.0.102:34660
2023-12-12 10:39:21,035 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:39:21,049 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:39:50,875 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:40670 / 172.25.0.104:40670
2023-12-12 10:39:50,901 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:55736 / 172.25.0.102:55736
2023-12-12 10:39:50,918 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:41096 / 172.25.0.103:41096
2023-12-12 10:39:50,931 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:39:50,983 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:39:50,990 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:40:20,890 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:52068 / 172.25.0.103:52068
2023-12-12 10:40:20,898 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:57450 / 172.25.0.104:57450
2023-12-12 10:40:20,902 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:42816 / 172.25.0.102:42816
2023-12-12 10:40:20,902 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:40:20,913 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:40:20,947 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:40:50,900 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:48756 / 172.25.0.104:48756
2023-12-12 10:40:50,910 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:40:50,916 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:43286 / 172.25.0.103:43286
2023-12-12 10:40:50,916 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:52488 / 172.25.0.102:52488
2023-12-12 10:40:50,930 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:40:50,990 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:41:20,862 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:44166 / 172.25.0.102:44166
2023-12-12 10:41:20,918 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:41:20,926 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:52844 / 172.25.0.103:52844
2023-12-12 10:41:20,926 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:42164 / 172.25.0.104:42164
2023-12-12 10:41:20,932 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:41:20,956 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:41:50,868 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:45988 / 172.25.0.102:45988
2023-12-12 10:41:50,874 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:41550 / 172.25.0.104:41550
2023-12-12 10:41:50,918 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:46470 / 172.25.0.103:46470
2023-12-12 10:41:50,920 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:41:50,928 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:41:50,953 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:42:04,345 [scm3-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2023-12-12 10:42:20,835 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:48968 / 172.25.0.104:48968
2023-12-12 10:42:20,855 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:55122 / 172.25.0.103:55122
2023-12-12 10:42:20,866 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:42:20,890 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:42:20,893 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:53624 / 172.25.0.102:53624
2023-12-12 10:42:20,929 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:42:38,506 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z), SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z)]
2023-12-12 10:42:38,506 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z)
2023-12-12 10:42:38,507 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z), SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z)] to file /data/metadata/scm/keys/secret_keys.json
2023-12-12 10:42:50,899 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:60532 / 172.25.0.102:60532
2023-12-12 10:42:50,921 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:44072 / 172.25.0.104:44072
2023-12-12 10:42:50,921 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:45292 / 172.25.0.103:45292
2023-12-12 10:42:50,928 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:42:50,939 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:42:50,945 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:43:20,887 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:45128 / 172.25.0.102:45128
2023-12-12 10:43:20,893 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:56840 / 172.25.0.104:56840
2023-12-12 10:43:20,906 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:40636 / 172.25.0.103:40636
2023-12-12 10:43:20,924 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:43:20,926 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:43:20,975 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:43:50,892 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:33468 / 172.25.0.104:33468
2023-12-12 10:43:50,895 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:39878 / 172.25.0.102:39878
2023-12-12 10:43:50,895 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:55638 / 172.25.0.103:55638
2023-12-12 10:43:50,901 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:43:50,905 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:43:50,913 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:44:20,846 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:33284 / 172.25.0.102:33284
2023-12-12 10:44:20,865 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:37204 / 172.25.0.104:37204
2023-12-12 10:44:20,873 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:37856 / 172.25.0.103:37856
2023-12-12 10:44:20,888 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:44:20,890 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:44:20,910 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:44:50,897 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:60104 / 172.25.0.104:60104
2023-12-12 10:44:50,897 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:52494 / 172.25.0.103:52494
2023-12-12 10:44:50,899 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:45560 / 172.25.0.102:45560
2023-12-12 10:44:50,910 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:44:50,911 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:44:50,911 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:45:20,889 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:52652 / 172.25.0.102:52652
2023-12-12 10:45:20,893 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:55506 / 172.25.0.104:55506
2023-12-12 10:45:20,928 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:45:20,935 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:45:20,937 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:58090 / 172.25.0.103:58090
2023-12-12 10:45:20,952 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:45:50,851 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:47206 / 172.25.0.102:47206
2023-12-12 10:45:50,860 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:52198 / 172.25.0.103:52198
2023-12-12 10:45:50,861 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:53798 / 172.25.0.104:53798
2023-12-12 10:45:50,871 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:45:50,888 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:45:50,888 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:46:20,869 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:55616 / 172.25.0.104:55616
2023-12-12 10:46:20,870 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:48720 / 172.25.0.103:48720
2023-12-12 10:46:20,896 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:46:20,914 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:46:20,921 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:36240 / 172.25.0.102:36240
2023-12-12 10:46:20,933 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:46:50,844 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:57114 / 172.25.0.104:57114
2023-12-12 10:46:50,883 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:46:50,892 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:36292 / 172.25.0.102:36292
2023-12-12 10:46:50,894 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:60780 / 172.25.0.103:60780
2023-12-12 10:46:50,896 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:46:50,910 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:47:04,346 [scm3-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2023-12-12 10:47:20,891 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:58834 / 172.25.0.104:58834
2023-12-12 10:47:20,919 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:48626 / 172.25.0.102:48626
2023-12-12 10:47:20,921 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:47:20,926 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:48624 / 172.25.0.103:48624
2023-12-12 10:47:20,939 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:47:20,953 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:47:38,503 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z), SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z), SecretKey(id = e2d833a9-10dd-4236-a4a5-e3ba4bfd79c0, creation at: 2023-12-12T10:47:38.488Z, expire at: 2023-12-12T11:47:38.488Z)]
2023-12-12 10:47:38,503 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = e2d833a9-10dd-4236-a4a5-e3ba4bfd79c0, creation at: 2023-12-12T10:47:38.488Z, expire at: 2023-12-12T11:47:38.488Z)
2023-12-12 10:47:38,504 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = e2d833a9-10dd-4236-a4a5-e3ba4bfd79c0, creation at: 2023-12-12T10:47:38.488Z, expire at: 2023-12-12T11:47:38.488Z), SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z), SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z)] to file /data/metadata/scm/keys/secret_keys.json
2023-12-12 10:47:50,846 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:53972 / 172.25.0.103:53972
2023-12-12 10:47:50,852 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:54896 / 172.25.0.104:54896
2023-12-12 10:47:50,875 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:47:50,884 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:47:50,900 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:37770 / 172.25.0.102:37770
2023-12-12 10:47:50,923 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:48:20,843 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:36292 / 172.25.0.102:36292
2023-12-12 10:48:20,844 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:33900 / 172.25.0.104:33900
2023-12-12 10:48:20,875 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:48254 / 172.25.0.103:48254
2023-12-12 10:48:20,876 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:48:20,886 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:48:20,913 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:48:50,875 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:59966 / 172.25.0.104:59966
2023-12-12 10:48:50,879 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:45984 / 172.25.0.102:45984
2023-12-12 10:48:50,890 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:58398 / 172.25.0.103:58398
2023-12-12 10:48:50,892 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:48:50,900 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:48:50,907 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:49:20,891 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:36610 / 172.25.0.102:36610
2023-12-12 10:49:20,892 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:55680 / 172.25.0.104:55680
2023-12-12 10:49:20,902 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:49:20,905 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:43034 / 172.25.0.103:43034
2023-12-12 10:49:20,907 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:49:20,926 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:49:50,854 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:48704 / 172.25.0.102:48704
2023-12-12 10:49:50,886 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:35740 / 172.25.0.104:35740
2023-12-12 10:49:50,888 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:51130 / 172.25.0.103:51130
2023-12-12 10:49:50,893 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:49:50,896 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:49:50,914 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:50:20,875 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:44928 / 172.25.0.102:44928
2023-12-12 10:50:20,881 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:48910 / 172.25.0.103:48910
2023-12-12 10:50:20,889 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:50:20,898 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:54812 / 172.25.0.104:54812
2023-12-12 10:50:20,911 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:50:20,918 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:50:50,841 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:58136 / 172.25.0.102:58136
2023-12-12 10:50:50,851 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:50584 / 172.25.0.104:50584
2023-12-12 10:50:50,883 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:50:50,883 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:50:50,891 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:48088 / 172.25.0.103:48088
2023-12-12 10:50:50,903 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:51:20,898 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:52654 / 172.25.0.103:52654
2023-12-12 10:51:20,900 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:59420 / 172.25.0.104:59420
2023-12-12 10:51:20,903 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:38612 / 172.25.0.102:38612
2023-12-12 10:51:20,908 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:51:20,913 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:51:20,920 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:51:50,846 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:46848 / 172.25.0.104:46848
2023-12-12 10:51:50,851 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:40812 / 172.25.0.102:40812
2023-12-12 10:51:50,878 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:51:50,882 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:51:50,924 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:57254 / 172.25.0.103:57254
2023-12-12 10:51:50,927 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:52:04,346 [scm3-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2023-12-12 10:52:20,834 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:39528 / 172.25.0.104:39528
2023-12-12 10:52:20,871 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:47760 / 172.25.0.103:47760
2023-12-12 10:52:20,889 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:38904 / 172.25.0.102:38904
2023-12-12 10:52:20,904 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:52:20,921 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:52:20,928 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:52:38,497 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = e2d833a9-10dd-4236-a4a5-e3ba4bfd79c0, creation at: 2023-12-12T10:47:38.488Z, expire at: 2023-12-12T11:47:38.488Z), SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z), SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z), SecretKey(id = 9c6b0167-60c3-4e7a-bd40-f43eefebeefe, creation at: 2023-12-12T10:52:38.488Z, expire at: 2023-12-12T11:52:38.488Z)]
2023-12-12 10:52:38,498 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 9c6b0167-60c3-4e7a-bd40-f43eefebeefe, creation at: 2023-12-12T10:52:38.488Z, expire at: 2023-12-12T11:52:38.488Z)
2023-12-12 10:52:38,499 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 9c6b0167-60c3-4e7a-bd40-f43eefebeefe, creation at: 2023-12-12T10:52:38.488Z, expire at: 2023-12-12T11:52:38.488Z), SecretKey(id = e2d833a9-10dd-4236-a4a5-e3ba4bfd79c0, creation at: 2023-12-12T10:47:38.488Z, expire at: 2023-12-12T11:47:38.488Z), SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z), SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z)] to file /data/metadata/scm/keys/secret_keys.json
2023-12-12 10:52:50,834 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:34254 / 172.25.0.102:34254
2023-12-12 10:52:50,842 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:36216 / 172.25.0.104:36216
2023-12-12 10:52:50,873 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:52:50,879 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:52:50,881 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:42110 / 172.25.0.103:42110
2023-12-12 10:52:50,888 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:53:20,855 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:51504 / 172.25.0.104:51504
2023-12-12 10:53:20,861 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:34880 / 172.25.0.102:34880
2023-12-12 10:53:20,878 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:57016 / 172.25.0.103:57016
2023-12-12 10:53:20,904 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:53:20,914 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:53:20,944 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:53:50,866 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:42042 / 172.25.0.104:42042
2023-12-12 10:53:50,867 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:48566 / 172.25.0.103:48566
2023-12-12 10:53:50,875 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:59542 / 172.25.0.102:59542
2023-12-12 10:53:50,889 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:53:50,914 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:53:50,936 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:54:20,857 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:57970 / 172.25.0.102:57970
2023-12-12 10:54:20,875 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:40894 / 172.25.0.104:40894
2023-12-12 10:54:20,875 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:54:20,895 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:52262 / 172.25.0.103:52262
2023-12-12 10:54:20,901 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:54:20,908 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:54:50,865 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:36448 / 172.25.0.102:36448
2023-12-12 10:54:50,882 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:59432 / 172.25.0.104:59432
2023-12-12 10:54:50,919 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:54:50,927 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:54:50,936 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:48680 / 172.25.0.103:48680
2023-12-12 10:54:50,957 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:55:20,843 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:42246 / 172.25.0.102:42246
2023-12-12 10:55:20,853 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:55:20,882 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:44154 / 172.25.0.104:44154
2023-12-12 10:55:20,889 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:43292 / 172.25.0.103:43292
2023-12-12 10:55:20,895 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:55:20,898 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:55:50,829 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:37578 / 172.25.0.102:37578
2023-12-12 10:55:50,834 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:50152 / 172.25.0.104:50152
2023-12-12 10:55:50,848 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:55:50,855 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:33052 / 172.25.0.103:33052
2023-12-12 10:55:50,861 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:55:50,870 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:56:20,863 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:44614 / 172.25.0.102:44614
2023-12-12 10:56:20,872 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:46248 / 172.25.0.103:46248
2023-12-12 10:56:20,876 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:56:20,899 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:56:20,902 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:48156 / 172.25.0.104:48156
2023-12-12 10:56:20,929 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:56:50,870 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:33028 / 172.25.0.104:33028
2023-12-12 10:56:50,871 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:48652 / 172.25.0.102:48652
2023-12-12 10:56:50,884 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:36628 / 172.25.0.103:36628
2023-12-12 10:56:50,885 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:56:50,890 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:56:50,918 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:57:04,347 [scm3-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2023-12-12 10:57:20,914 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:59550 / 172.25.0.102:59550
2023-12-12 10:57:20,914 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:37054 / 172.25.0.104:37054
2023-12-12 10:57:20,941 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:57:20,944 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:57:20,950 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:46270 / 172.25.0.103:46270
2023-12-12 10:57:20,961 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:57:38,502 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 9c6b0167-60c3-4e7a-bd40-f43eefebeefe, creation at: 2023-12-12T10:52:38.488Z, expire at: 2023-12-12T11:52:38.488Z), SecretKey(id = e2d833a9-10dd-4236-a4a5-e3ba4bfd79c0, creation at: 2023-12-12T10:47:38.488Z, expire at: 2023-12-12T11:47:38.488Z), SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z), SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z), SecretKey(id = 3926492a-aa8f-4e25-a463-c38d685ccb88, creation at: 2023-12-12T10:57:38.488Z, expire at: 2023-12-12T11:57:38.488Z)]
2023-12-12 10:57:38,502 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 3926492a-aa8f-4e25-a463-c38d685ccb88, creation at: 2023-12-12T10:57:38.488Z, expire at: 2023-12-12T11:57:38.488Z)
2023-12-12 10:57:38,503 [26d4f844-7892-4e91-8fa5-b0417f32640f@group-1024BF673070-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 3926492a-aa8f-4e25-a463-c38d685ccb88, creation at: 2023-12-12T10:57:38.488Z, expire at: 2023-12-12T11:57:38.488Z), SecretKey(id = 9c6b0167-60c3-4e7a-bd40-f43eefebeefe, creation at: 2023-12-12T10:52:38.488Z, expire at: 2023-12-12T11:52:38.488Z), SecretKey(id = e2d833a9-10dd-4236-a4a5-e3ba4bfd79c0, creation at: 2023-12-12T10:47:38.488Z, expire at: 2023-12-12T11:47:38.488Z), SecretKey(id = 0e2a0ae1-cf64-4bbf-807a-d8200a6761cc, creation at: 2023-12-12T10:42:38.488Z, expire at: 2023-12-12T11:42:38.488Z), SecretKey(id = 0d3117be-ba15-4bff-9769-bd65ba7dadcb, creation at: 2023-12-12T10:36:44.856Z, expire at: 2023-12-12T11:36:44.856Z)] to file /data/metadata/scm/keys/secret_keys.json
