Waiting for the service scm1.org:9894
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-12-12 10:31:52,213 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm2.org/172.25.0.117
STARTUP_MSG:   args = [--bootstrap]
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.21.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.21.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.21.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.21.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.0.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/a93015a85b8ebe6a3e9423372f3337ed9b029704 ; compiled by 'runner' on 2023-12-12T10:10Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=true, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=4MB, dfs.container.ratis.segment.size=64MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60s, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.handler.type=distributed, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-address.omservice.om1=om1, ozone.om.http-address.omservice.om2=om2, ozone.om.http-address.omservice.om3=om3, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.internal.service.id=omservice, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=50, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=16KB, ozone.om.ratis.segment.size=16KB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.auto.trigger.threshold=500, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=false, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=20s, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=5s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.enable=true, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-12-12 10:31:52,220 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-12-12 10:31:52,272 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-12 10:31:52,368 [main] INFO reflections.Reflections: Reflections took 72 ms to scan 3 urls, producing 134 keys and 291 values 
2023-12-12 10:31:52,436 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2023-12-12 10:31:52,437 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-12-12 10:31:52,462 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
2023-12-12 10:31:52,466 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
2023-12-12 10:31:52,592 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2023-12-12 10:31:52,592 [main] INFO server.StorageContainerManager: SCM login successful.
2023-12-12 10:31:52,639 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
2023-12-12 10:31:56,845 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 2.
2023-12-12 10:31:58,846 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 3.
2023-12-12 10:32:00,848 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 4.
2023-12-12 10:32:02,856 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 5.
2023-12-12 10:32:05,075 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:e5fdb72c-5c5c-4ba8-951b-04fd10563c04 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 6.
2023-12-12 10:32:07,076 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 7.
2023-12-12 10:32:09,126 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
2023-12-12 10:32:09,548 [main] INFO client.SCMCertificateClient: Certificate serial ID set to null
2023-12-12 10:32:09,548 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
2023-12-12 10:32:09,548 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
2023-12-12 10:32:09,550 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
2023-12-12 10:32:10,086 [main] INFO client.SCMCertificateClient: Init response: GETCERT
2023-12-12 10:32:10,087 [main] INFO client.SCMCertificateClient: Creating csr for SCM->hostName:scm2.org,scmId:707b32b6-be48-4439-b655-31ff544e1299,clusterId:CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,subject:scm-sub@scm2.org
2023-12-12 10:32:10,111 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
2023-12-12 10:32:10,111 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2023-12-12 10:32:10,710 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/CA-1.crt
2023-12-12 10:32:10,711 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDxTCCAq2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCRlNWZkYjcyYy01YzVjLTRiYTgtOTUxYi0wNGZk
MTA1NjNjMDQxMTAvBgNVBAoMKENJRC01OTE0YzUzOS04YWQzLTQ0ZDMtOGU1ZC0y
Y2M4MjAyZWE4ZDYxCjAIBgNVBAUTATEwHhcNMjMxMjEyMTAzMTQ4WhcNMjkwMTE5
MTAzMTQ4WjCBhTEVMBMGA1UEAwwMc2NtQHNjbTEub3JnMS0wKwYDVQQLDCRlNWZk
YjcyYy01YzVjLTRiYTgtOTUxYi0wNGZkMTA1NjNjMDQxMTAvBgNVBAoMKENJRC01
OTE0YzUzOS04YWQzLTQ0ZDMtOGU1ZC0yY2M4MjAyZWE4ZDYxCjAIBgNVBAUTATEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCEJZ90Lk5yGMTQWpjpWP3N
Q5QgxA3GoqWKZAKdUinFmsc4Br6FVHOT80AliopleAW07L0fSZ/ZXL9fPRGNsf36
scFTmUgvVqu01uXpV3eMLp0Hf9G3F+gzuN4rYECOLuLvrIvnu0VyQMlUkFrELa5k
oMrpLVcJTGlKhpHkEm4aChsdr2z6hTHwfDVCBHQ69+y3MGW2apu+LYkWlqM7PaC3
jsJCMiacUXBe/hEgJkRC/RG3BVGRnJB8z80AJBzxc90cAgB2+q3RLOA0+xlgJ5XP
pxbLGyMUVYJIO6VlW7SalTpIkf10PhFYAGssi9btOmkl/76MRRjlOL6IwS4T7ssJ
AgMBAAGjPjA8MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMBkGA1Ud
EQQSMBCHBKwZAHSCCHNjbTEub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQBQaNzUn/Dj
6Pco61E1BA2PCds2yOCHs9lokPI5pa5zenwKU4HffIc1Al6CSKpoBmjI3frJmLFr
oeTFrhEiY/GhC9JrWFXiHsOj0H0eRVJZBWoXqZnOr+GKWWvb4BbFHbvC3OSm0KMx
2mtEij3sh+Lb3vg6VHdo3dFa2QcXyA/vprDvVVdP3jzUfzoQ82Pz1+dibXPE9WzU
xdaJ2cEEDLBIWXsLgCCConz6WdBVne0At2LO1jXKEht52kCKw04Euciigns2/5JN
AoJAzpeXXHgRmYAJh0Dvnwt4z5TitGg9hIYFt590zkAPQOKVqOne2WhDAHt6u61m
dFMVkghZ2wzQ
-----END CERTIFICATE-----

2023-12-12 10:32:10,714 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/3.crt
2023-12-12 10:32:10,714 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDyTCCArGgAwIBAgIBAzANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCRlNWZkYjcyYy01YzVjLTRiYTgtOTUxYi0wNGZk
MTA1NjNjMDQxMTAvBgNVBAoMKENJRC01OTE0YzUzOS04YWQzLTQ0ZDMtOGU1ZC0y
Y2M4MjAyZWE4ZDYxCjAIBgNVBAUTATEwHhcNMjMxMjEyMTAzMjEwWhcNMjkwMTE5
MTAzMjEwWjCBiTEZMBcGA1UEAwwQc2NtLXN1YkBzY20yLm9yZzEtMCsGA1UECwwk
NzA3YjMyYjYtYmU0OC00NDM5LWI2NTUtMzFmZjU0NGUxMjk5MTEwLwYDVQQKDChD
SUQtNTkxNGM1MzktOGFkMy00NGQzLThlNWQtMmNjODIwMmVhOGQ2MQowCAYDVQQF
EwEzMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA2e0Gn1k+JuEQWi9o
iFAdmQELl1pce93bBNTUlsZP1ucSQONh7hF3v3HQdiCkWUIrWgSDat5F4V1A5CQ9
7G8O8F2TMlMyfw7mvd5ZmUGnkUMH1+nDILMxvI9D+xNB2qQTHTf02/UKcCVFavA0
GA5w6hAaXYTq2nNtCwy0TEmsngA47H0MHMahCCxMotDRyg7VOhkDm/dqjbjb4gI5
SAgABwXiKlukXUwx7yCHoN7j70UKebwbfPpldlgwRJ69O1g8wQZYypyumIr1pBnG
bTQRoqcSX4WI4CQPR3IBkL+1UBxvbuP/JPZ94Wf0hiF4uH2MncS9UB3PzO7iGdpy
joRTFwIDAQABoz4wPDAZBgNVHREEEjAQhwSsGQB1gghzY20yLm9yZzAPBgNVHRMB
Af8EBTADAQH/MA4GA1UdDwEB/wQEAwIBvjANBgkqhkiG9w0BAQsFAAOCAQEAFOOA
ITRl+JLjM69fa7zSmg4aQLLn1b9J6wIw/U8esRK7eW3nndWeebsonJzbCUh+RsMf
aWmyRBBP/HkrHaLoor4MOGUT7wpV1KSdH7rh0joS+RxciKUzRufXd3uZKxqZH1sJ
SdMx/me8JeK6sgAHlnpj6Q64TT3M8+urXn8Q4+1zLGkMl2H7U/qR03CiYnEIiHcs
xXwUChc/QuJfSXqs1LFBfxWxfOs4n+3M9He+VO8nIP6SymvWrFTOxyepox72Bkp9
hDVXuKctBk5sUM4y2rlbNYomQO2jX4S4Fl2UT0sMW7YfHEpFCxRCfdO/OchYEsXe
u8lA14lvfLsxG9r0UA==
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDxTCCAq2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCRlNWZkYjcyYy01YzVjLTRiYTgtOTUxYi0wNGZk
MTA1NjNjMDQxMTAvBgNVBAoMKENJRC01OTE0YzUzOS04YWQzLTQ0ZDMtOGU1ZC0y
Y2M4MjAyZWE4ZDYxCjAIBgNVBAUTATEwHhcNMjMxMjEyMTAzMTQ4WhcNMjkwMTE5
MTAzMTQ4WjCBhTEVMBMGA1UEAwwMc2NtQHNjbTEub3JnMS0wKwYDVQQLDCRlNWZk
YjcyYy01YzVjLTRiYTgtOTUxYi0wNGZkMTA1NjNjMDQxMTAvBgNVBAoMKENJRC01
OTE0YzUzOS04YWQzLTQ0ZDMtOGU1ZC0yY2M4MjAyZWE4ZDYxCjAIBgNVBAUTATEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCEJZ90Lk5yGMTQWpjpWP3N
Q5QgxA3GoqWKZAKdUinFmsc4Br6FVHOT80AliopleAW07L0fSZ/ZXL9fPRGNsf36
scFTmUgvVqu01uXpV3eMLp0Hf9G3F+gzuN4rYECOLuLvrIvnu0VyQMlUkFrELa5k
oMrpLVcJTGlKhpHkEm4aChsdr2z6hTHwfDVCBHQ69+y3MGW2apu+LYkWlqM7PaC3
jsJCMiacUXBe/hEgJkRC/RG3BVGRnJB8z80AJBzxc90cAgB2+q3RLOA0+xlgJ5XP
pxbLGyMUVYJIO6VlW7SalTpIkf10PhFYAGssi9btOmkl/76MRRjlOL6IwS4T7ssJ
AgMBAAGjPjA8MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMBkGA1Ud
EQQSMBCHBKwZAHSCCHNjbTEub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQBQaNzUn/Dj
6Pco61E1BA2PCds2yOCHs9lokPI5pa5zenwKU4HffIc1Al6CSKpoBmjI3frJmLFr
oeTFrhEiY/GhC9JrWFXiHsOj0H0eRVJZBWoXqZnOr+GKWWvb4BbFHbvC3OSm0KMx
2mtEij3sh+Lb3vg6VHdo3dFa2QcXyA/vprDvVVdP3jzUfzoQ82Pz1+dibXPE9WzU
xdaJ2cEEDLBIWXsLgCCConz6WdBVne0At2LO1jXKEht52kCKw04Euciigns2/5JN
AoJAzpeXXHgRmYAJh0Dvnwt4z5TitGg9hIYFt590zkAPQOKVqOne2WhDAHt6u61m
dFMVkghZ2wzQ
-----END CERTIFICATE-----

2023-12-12 10:32:10,714 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/certificate.crt
2023-12-12 10:32:10,715 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDyTCCArGgAwIBAgIBAzANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCRlNWZkYjcyYy01YzVjLTRiYTgtOTUxYi0wNGZk
MTA1NjNjMDQxMTAvBgNVBAoMKENJRC01OTE0YzUzOS04YWQzLTQ0ZDMtOGU1ZC0y
Y2M4MjAyZWE4ZDYxCjAIBgNVBAUTATEwHhcNMjMxMjEyMTAzMjEwWhcNMjkwMTE5
MTAzMjEwWjCBiTEZMBcGA1UEAwwQc2NtLXN1YkBzY20yLm9yZzEtMCsGA1UECwwk
NzA3YjMyYjYtYmU0OC00NDM5LWI2NTUtMzFmZjU0NGUxMjk5MTEwLwYDVQQKDChD
SUQtNTkxNGM1MzktOGFkMy00NGQzLThlNWQtMmNjODIwMmVhOGQ2MQowCAYDVQQF
EwEzMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA2e0Gn1k+JuEQWi9o
iFAdmQELl1pce93bBNTUlsZP1ucSQONh7hF3v3HQdiCkWUIrWgSDat5F4V1A5CQ9
7G8O8F2TMlMyfw7mvd5ZmUGnkUMH1+nDILMxvI9D+xNB2qQTHTf02/UKcCVFavA0
GA5w6hAaXYTq2nNtCwy0TEmsngA47H0MHMahCCxMotDRyg7VOhkDm/dqjbjb4gI5
SAgABwXiKlukXUwx7yCHoN7j70UKebwbfPpldlgwRJ69O1g8wQZYypyumIr1pBnG
bTQRoqcSX4WI4CQPR3IBkL+1UBxvbuP/JPZ94Wf0hiF4uH2MncS9UB3PzO7iGdpy
joRTFwIDAQABoz4wPDAZBgNVHREEEjAQhwSsGQB1gghzY20yLm9yZzAPBgNVHRMB
Af8EBTADAQH/MA4GA1UdDwEB/wQEAwIBvjANBgkqhkiG9w0BAQsFAAOCAQEAFOOA
ITRl+JLjM69fa7zSmg4aQLLn1b9J6wIw/U8esRK7eW3nndWeebsonJzbCUh+RsMf
aWmyRBBP/HkrHaLoor4MOGUT7wpV1KSdH7rh0joS+RxciKUzRufXd3uZKxqZH1sJ
SdMx/me8JeK6sgAHlnpj6Q64TT3M8+urXn8Q4+1zLGkMl2H7U/qR03CiYnEIiHcs
xXwUChc/QuJfSXqs1LFBfxWxfOs4n+3M9He+VO8nIP6SymvWrFTOxyepox72Bkp9
hDVXuKctBk5sUM4y2rlbNYomQO2jX4S4Fl2UT0sMW7YfHEpFCxRCfdO/OchYEsXe
u8lA14lvfLsxG9r0UA==
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDxTCCAq2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCRlNWZkYjcyYy01YzVjLTRiYTgtOTUxYi0wNGZk
MTA1NjNjMDQxMTAvBgNVBAoMKENJRC01OTE0YzUzOS04YWQzLTQ0ZDMtOGU1ZC0y
Y2M4MjAyZWE4ZDYxCjAIBgNVBAUTATEwHhcNMjMxMjEyMTAzMTQ4WhcNMjkwMTE5
MTAzMTQ4WjCBhTEVMBMGA1UEAwwMc2NtQHNjbTEub3JnMS0wKwYDVQQLDCRlNWZk
YjcyYy01YzVjLTRiYTgtOTUxYi0wNGZkMTA1NjNjMDQxMTAvBgNVBAoMKENJRC01
OTE0YzUzOS04YWQzLTQ0ZDMtOGU1ZC0yY2M4MjAyZWE4ZDYxCjAIBgNVBAUTATEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCEJZ90Lk5yGMTQWpjpWP3N
Q5QgxA3GoqWKZAKdUinFmsc4Br6FVHOT80AliopleAW07L0fSZ/ZXL9fPRGNsf36
scFTmUgvVqu01uXpV3eMLp0Hf9G3F+gzuN4rYECOLuLvrIvnu0VyQMlUkFrELa5k
oMrpLVcJTGlKhpHkEm4aChsdr2z6hTHwfDVCBHQ69+y3MGW2apu+LYkWlqM7PaC3
jsJCMiacUXBe/hEgJkRC/RG3BVGRnJB8z80AJBzxc90cAgB2+q3RLOA0+xlgJ5XP
pxbLGyMUVYJIO6VlW7SalTpIkf10PhFYAGssi9btOmkl/76MRRjlOL6IwS4T7ssJ
AgMBAAGjPjA8MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMBkGA1Ud
EQQSMBCHBKwZAHSCCHNjbTEub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQBQaNzUn/Dj
6Pco61E1BA2PCds2yOCHs9lokPI5pa5zenwKU4HffIc1Al6CSKpoBmjI3frJmLFr
oeTFrhEiY/GhC9JrWFXiHsOj0H0eRVJZBWoXqZnOr+GKWWvb4BbFHbvC3OSm0KMx
2mtEij3sh+Lb3vg6VHdo3dFa2QcXyA/vprDvVVdP3jzUfzoQ82Pz1+dibXPE9WzU
xdaJ2cEEDLBIWXsLgCCConz6WdBVne0At2LO1jXKEht52kCKw04Euciigns2/5JN
AoJAzpeXXHgRmYAJh0Dvnwt4z5TitGg9hIYFt590zkAPQOKVqOne2WhDAHt6u61m
dFMVkghZ2wzQ
-----END CERTIFICATE-----

2023-12-12 10:32:10,715 [main] INFO client.SCMCertificateClient: Successfully stored SCM signed certificate.
2023-12-12 10:32:10,724 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6, SCMID 707b32b6-be48-4439-b655-31ff544e1299
2023-12-12 10:32:10,725 [main] INFO server.StorageContainerManager: Primary SCM Node ID e5fdb72c-5c5c-4ba8-951b-04fd10563c04
2023-12-12 10:32:10,747 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-12-12 10:32:11,901 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm2.org/172.25.0.117
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.21.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.21.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.21.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.21.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.0.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/a93015a85b8ebe6a3e9423372f3337ed9b029704 ; compiled by 'runner' on 2023-12-12T10:10Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=true, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=4MB, dfs.container.ratis.segment.size=64MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60s, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.handler.type=distributed, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-address.omservice.om1=om1, ozone.om.http-address.omservice.om2=om2, ozone.om.http-address.omservice.om3=om3, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.internal.service.id=omservice, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=50, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=16KB, ozone.om.ratis.segment.size=16KB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.auto.trigger.threshold=500, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=false, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=20s, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=5s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.enable=true, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-12-12 10:32:11,910 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-12-12 10:32:11,961 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-12 10:32:12,075 [main] INFO reflections.Reflections: Reflections took 82 ms to scan 3 urls, producing 134 keys and 291 values 
2023-12-12 10:32:12,150 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2023-12-12 10:32:12,159 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-12-12 10:32:12,180 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
2023-12-12 10:32:12,181 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
2023-12-12 10:32:12,308 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2023-12-12 10:32:12,309 [main] INFO server.StorageContainerManager: SCM login successful.
2023-12-12 10:32:12,917 [main] INFO client.SCMCertificateClient: Certificate serial ID set to 3
2023-12-12 10:32:13,036 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 3
             IssuerDN: CN=scm@scm1.org,OU=e5fdb72c-5c5c-4ba8-951b-04fd10563c04,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:32:10 UTC 2023
           Final Date: Fri Jan 19 10:32:10 UTC 2029
            SubjectDN: CN=scm-sub@scm2.org,OU=707b32b6-be48-4439-b655-31ff544e1299,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=3
           Public Key: RSA Public Key [9e:8d:c2:c3:ed:1b:e0:42:cd:67:90:a7:2d:f4:d3:15:78:37:a8:75],[56:66:d1:a4]
        modulus: d9ed069f593e26e1105a2f6888501d99010b975a5c7bdddb04d4d496c64fd6e71240e361ee1177bf71d07620a459422b5a04836ade45e15d40e4243dec6f0ef05d933253327f0ee6bdde599941a7914307d7e9c320b331bc8f43fb1341daa4131d37f4dbf50a7025456af034180e70ea101a5d84eada736d0b0cb44c49ac9e0038ec7d0c1cc6a1082c4ca2d0d1ca0ed53a19039bf76a8db8dbe202394808000705e22a5ba45d4c31ef2087a0dee3ef450a79bc1b7cfa65765830449ebd3b583cc10658ca9cae988af5a419c66d3411a2a7125f8588e0240f47720190bfb5501c6f6ee3ff24f67de167f4862178b87d8c9dc4bd501dcfcceee219da728e845317
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 14e380213465f892e333af5f6bbcd29a0e1a40b2
                       e7d5bf49eb0230fd4f1eb112bb796de79dd59e79
                       bb289c9cdb09487e46c31f6969b244104ffc792b
                       1da2e8a2be0c386513ef0a55d4a49d1fbae1d23a
                       12f91c5c88a53346e7d7777b992b1a991f5b0949
                       d331fe67bc25e2bab20007967a63e90eb84d3dcc
                       f3ebab5e7f10e3ed732c690c9761fb53fa91d370
                       a262710888772cc57c140a173f42e25f497aacd4
                       b1417f15b17ceb389fedccf477be54ef2720fe92
                       ca6bd6ac54cec727a9a31ef6064a7d843557b8a7
                       2d064e6c50ce32dab95b358a2640eda35f84b816
                       5d944f4b0c5bb61f1c4a450b14427dd3bf39c858
                       12c5debbc940d7896f7cbb311bdaf450
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/certificate.crt.
2023-12-12 10:32:13,041 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 3
             IssuerDN: CN=scm@scm1.org,OU=e5fdb72c-5c5c-4ba8-951b-04fd10563c04,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:32:10 UTC 2023
           Final Date: Fri Jan 19 10:32:10 UTC 2029
            SubjectDN: CN=scm-sub@scm2.org,OU=707b32b6-be48-4439-b655-31ff544e1299,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=3
           Public Key: RSA Public Key [9e:8d:c2:c3:ed:1b:e0:42:cd:67:90:a7:2d:f4:d3:15:78:37:a8:75],[56:66:d1:a4]
        modulus: d9ed069f593e26e1105a2f6888501d99010b975a5c7bdddb04d4d496c64fd6e71240e361ee1177bf71d07620a459422b5a04836ade45e15d40e4243dec6f0ef05d933253327f0ee6bdde599941a7914307d7e9c320b331bc8f43fb1341daa4131d37f4dbf50a7025456af034180e70ea101a5d84eada736d0b0cb44c49ac9e0038ec7d0c1cc6a1082c4ca2d0d1ca0ed53a19039bf76a8db8dbe202394808000705e22a5ba45d4c31ef2087a0dee3ef450a79bc1b7cfa65765830449ebd3b583cc10658ca9cae988af5a419c66d3411a2a7125f8588e0240f47720190bfb5501c6f6ee3ff24f67de167f4862178b87d8c9dc4bd501dcfcceee219da728e845317
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 14e380213465f892e333af5f6bbcd29a0e1a40b2
                       e7d5bf49eb0230fd4f1eb112bb796de79dd59e79
                       bb289c9cdb09487e46c31f6969b244104ffc792b
                       1da2e8a2be0c386513ef0a55d4a49d1fbae1d23a
                       12f91c5c88a53346e7d7777b992b1a991f5b0949
                       d331fe67bc25e2bab20007967a63e90eb84d3dcc
                       f3ebab5e7f10e3ed732c690c9761fb53fa91d370
                       a262710888772cc57c140a173f42e25f497aacd4
                       b1417f15b17ceb389fedccf477be54ef2720fe92
                       ca6bd6ac54cec727a9a31ef6064a7d843557b8a7
                       2d064e6c50ce32dab95b358a2640eda35f84b816
                       5d944f4b0c5bb61f1c4a450b14427dd3bf39c858
                       12c5debbc940d7896f7cbb311bdaf450
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/3.crt.
2023-12-12 10:32:13,044 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=e5fdb72c-5c5c-4ba8-951b-04fd10563c04,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:31:48 UTC 2023
           Final Date: Fri Jan 19 10:31:48 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=e5fdb72c-5c5c-4ba8-951b-04fd10563c04,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=1
           Public Key: RSA Public Key [2b:58:e9:c5:fa:a5:c7:c7:fd:be:32:86:63:76:80:c4:ae:17:1b:e9],[56:66:d1:a4]
        modulus: 84259f742e4e7218c4d05a98e958fdcd439420c40dc6a2a58a64029d5229c59ac73806be85547393f340258a8a657805b4ecbd1f499fd95cbf5f3d118db1fdfab1c15399482f56abb4d6e5e957778c2e9d077fd1b717e833b8de2b60408e2ee2efac8be7bb457240c954905ac42dae64a0cae92d57094c694a8691e4126e1a0a1b1daf6cfa8531f07c354204743af7ecb73065b66a9bbe2d891696a33b3da0b78ec24232269c51705efe1120264442fd11b70551919c907ccfcd00241cf173dd1c020076faadd12ce034fb19602795cfa716cb1b23145582483ba5655bb49a953a4891fd743e1158006b2c8bd6ed3a6925ffbe8c4518e538be88c12e13eecb09
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 5068dcd49ff0e3e8f728eb5135040d8f09db36c8
                       e087b3d96890f239a5ae737a7c0a5381df7c8735
                       025e8248aa680668c8ddfac998b16ba1e4c5ae11
                       2263f1a10bd26b5855e21ec3a3d07d1e45525905
                       6a17a999ceafe18a596bdbe016c51dbbc2dce4a6
                       d0a331da6b448a3dec87e2dbdef83a547768ddd1
                       5ad90717c80fefa6b0ef55574fde3cd47f3a10f3
                       63f3d7e7626d73c4f56cd4c5d689d9c1040cb048
                       597b0b802082a27cfa59d0559ded00b762ced635
                       ca121b79da408ac34e04b9c8a2827b36ff924d02
                       8240ce97975c78119980098740ef9f0b78cf94e2
                       b4683d848605b79f74ce400f40e295a8e9ded968
                       43007b7abbad66745315920859db0cd0
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

 from file: /data/metadata/scm/sub-ca/certs/CA-1.crt.
2023-12-12 10:32:13,045 [main] INFO client.SCMCertificateClient: CertificateRenewerService and root ca rotation polling is disabled for scm/sub-ca
2023-12-12 10:32:13,111 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-12 10:32:13,230 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-12 10:32:13,427 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-12-12 10:32:13,428 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2023-12-12 10:32:13,504 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2023-12-12 10:32:13,928 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:707b32b6-be48-4439-b655-31ff544e1299
2023-12-12 10:32:13,949 [main] INFO ssl.ReloadingX509KeyManager: Key manager is loaded with certificate chain
2023-12-12 10:32:13,951 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 3
             IssuerDN: CN=scm@scm1.org,OU=e5fdb72c-5c5c-4ba8-951b-04fd10563c04,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:32:10 UTC 2023
           Final Date: Fri Jan 19 10:32:10 UTC 2029
            SubjectDN: CN=scm-sub@scm2.org,OU=707b32b6-be48-4439-b655-31ff544e1299,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=3
           Public Key: RSA Public Key [9e:8d:c2:c3:ed:1b:e0:42:cd:67:90:a7:2d:f4:d3:15:78:37:a8:75],[56:66:d1:a4]
        modulus: d9ed069f593e26e1105a2f6888501d99010b975a5c7bdddb04d4d496c64fd6e71240e361ee1177bf71d07620a459422b5a04836ade45e15d40e4243dec6f0ef05d933253327f0ee6bdde599941a7914307d7e9c320b331bc8f43fb1341daa4131d37f4dbf50a7025456af034180e70ea101a5d84eada736d0b0cb44c49ac9e0038ec7d0c1cc6a1082c4ca2d0d1ca0ed53a19039bf76a8db8dbe202394808000705e22a5ba45d4c31ef2087a0dee3ef450a79bc1b7cfa65765830449ebd3b583cc10658ca9cae988af5a419c66d3411a2a7125f8588e0240f47720190bfb5501c6f6ee3ff24f67de167f4862178b87d8c9dc4bd501dcfcceee219da728e845317
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 14e380213465f892e333af5f6bbcd29a0e1a40b2
                       e7d5bf49eb0230fd4f1eb112bb796de79dd59e79
                       bb289c9cdb09487e46c31f6969b244104ffc792b
                       1da2e8a2be0c386513ef0a55d4a49d1fbae1d23a
                       12f91c5c88a53346e7d7777b992b1a991f5b0949
                       d331fe67bc25e2bab20007967a63e90eb84d3dcc
                       f3ebab5e7f10e3ed732c690c9761fb53fa91d370
                       a262710888772cc57c140a173f42e25f497aacd4
                       b1417f15b17ceb389fedccf477be54ef2720fe92
                       ca6bd6ac54cec727a9a31ef6064a7d843557b8a7
                       2d064e6c50ce32dab95b358a2640eda35f84b816
                       5d944f4b0c5bb61f1c4a450b14427dd3bf39c858
                       12c5debbc940d7896f7cbb311bdaf450
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe

2023-12-12 10:32:13,953 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=e5fdb72c-5c5c-4ba8-951b-04fd10563c04,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:31:48 UTC 2023
           Final Date: Fri Jan 19 10:31:48 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=e5fdb72c-5c5c-4ba8-951b-04fd10563c04,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=1
           Public Key: RSA Public Key [2b:58:e9:c5:fa:a5:c7:c7:fd:be:32:86:63:76:80:c4:ae:17:1b:e9],[56:66:d1:a4]
        modulus: 84259f742e4e7218c4d05a98e958fdcd439420c40dc6a2a58a64029d5229c59ac73806be85547393f340258a8a657805b4ecbd1f499fd95cbf5f3d118db1fdfab1c15399482f56abb4d6e5e957778c2e9d077fd1b717e833b8de2b60408e2ee2efac8be7bb457240c954905ac42dae64a0cae92d57094c694a8691e4126e1a0a1b1daf6cfa8531f07c354204743af7ecb73065b66a9bbe2d891696a33b3da0b78ec24232269c51705efe1120264442fd11b70551919c907ccfcd00241cf173dd1c020076faadd12ce034fb19602795cfa716cb1b23145582483ba5655bb49a953a4891fd743e1158006b2c8bd6ed3a6925ffbe8c4518e538be88c12e13eecb09
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 5068dcd49ff0e3e8f728eb5135040d8f09db36c8
                       e087b3d96890f239a5ae737a7c0a5381df7c8735
                       025e8248aa680668c8ddfac998b16ba1e4c5ae11
                       2263f1a10bd26b5855e21ec3a3d07d1e45525905
                       6a17a999ceafe18a596bdbe016c51dbbc2dce4a6
                       d0a331da6b448a3dec87e2dbdef83a547768ddd1
                       5ad90717c80fefa6b0ef55574fde3cd47f3a10f3
                       63f3d7e7626d73c4f56cd4c5d689d9c1040cb048
                       597b0b802082a27cfa59d0559ded00b762ced635
                       ca121b79da408ac34e04b9c8a2827b36ff924d02
                       8240ce97975c78119980098740ef9f0b78cf94e2
                       b4683d848605b79f74ce400f40e295a8e9ded968
                       43007b7abbad66745315920859db0cd0
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2023-12-12 10:32:13,961 [main] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-12-12 10:32:13,961 [main] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-12-12 10:32:13,962 [main] INFO ssl.ReloadingX509TrustManager: Trust manager is loaded with certificates
2023-12-12 10:32:13,965 [main] INFO ssl.ReloadingX509TrustManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=e5fdb72c-5c5c-4ba8-951b-04fd10563c04,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=1
           Start Date: Tue Dec 12 10:31:48 UTC 2023
           Final Date: Fri Jan 19 10:31:48 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=e5fdb72c-5c5c-4ba8-951b-04fd10563c04,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=1
           Public Key: RSA Public Key [2b:58:e9:c5:fa:a5:c7:c7:fd:be:32:86:63:76:80:c4:ae:17:1b:e9],[56:66:d1:a4]
        modulus: 84259f742e4e7218c4d05a98e958fdcd439420c40dc6a2a58a64029d5229c59ac73806be85547393f340258a8a657805b4ecbd1f499fd95cbf5f3d118db1fdfab1c15399482f56abb4d6e5e957778c2e9d077fd1b717e833b8de2b60408e2ee2efac8be7bb457240c954905ac42dae64a0cae92d57094c694a8691e4126e1a0a1b1daf6cfa8531f07c354204743af7ecb73065b66a9bbe2d891696a33b3da0b78ec24232269c51705efe1120264442fd11b70551919c907ccfcd00241cf173dd1c020076faadd12ce034fb19602795cfa716cb1b23145582483ba5655bb49a953a4891fd743e1158006b2c8bd6ed3a6925ffbe8c4518e538be88c12e13eecb09
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 5068dcd49ff0e3e8f728eb5135040d8f09db36c8
                       e087b3d96890f239a5ae737a7c0a5381df7c8735
                       025e8248aa680668c8ddfac998b16ba1e4c5ae11
                       2263f1a10bd26b5855e21ec3a3d07d1e45525905
                       6a17a999ceafe18a596bdbe016c51dbbc2dce4a6
                       d0a331da6b448a3dec87e2dbdef83a547768ddd1
                       5ad90717c80fefa6b0ef55574fde3cd47f3a10f3
                       63f3d7e7626d73c4f56cd4c5d689d9c1040cb048
                       597b0b802082a27cfa59d0559ded00b762ced635
                       ca121b79da408ac34e04b9c8a2827b36ff924d02
                       8240ce97975c78119980098740ef9f0b78cf94e2
                       b4683d848605b79f74ce400f40e295a8e9ded968
                       43007b7abbad66745315920859db0cd0
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2023-12-12 10:32:14,004 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-12-12 10:32:14,010 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-12-12 10:32:14,062 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2023-12-12 10:32:14,080 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-12-12 10:32:14,082 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2023-12-12 10:32:14,084 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-12-12 10:32:14,086 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2023-12-12 10:32:14,086 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2023-12-12 10:32:14,086 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2023-12-12 10:32:14,089 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2023-12-12 10:32:14,091 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 10:32:14,105 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-12-12 10:32:14,109 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-12-12 10:32:14,119 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-12-12 10:32:14,121 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-12-12 10:32:14,122 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-12-12 10:32:14,531 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2023-12-12 10:32:14,539 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2023-12-12 10:32:14,539 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2023-12-12 10:32:14,539 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-12-12 10:32:14,549 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-12-12 10:32:14,553 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2023-12-12 10:32:14,553 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2023-12-12 10:32:14,571 [main] INFO server.RaftServer: 707b32b6-be48-4439-b655-31ff544e1299: addNew group-2CC8202EA8D6:[] returns group-2CC8202EA8D6:java.util.concurrent.CompletableFuture@4e31b64d[Not completed]
2023-12-12 10:32:14,607 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299: new RaftServerImpl for group-2CC8202EA8D6:[] with SCMStateMachine:uninitialized
2023-12-12 10:32:14,610 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2023-12-12 10:32:14,611 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2023-12-12 10:32:14,611 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2023-12-12 10:32:14,611 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2023-12-12 10:32:14,612 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-12-12 10:32:14,612 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2023-12-12 10:32:14,612 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2023-12-12 10:32:14,619 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-12-12 10:32:14,626 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2023-12-12 10:32:14,640 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2023-12-12 10:32:14,644 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2023-12-12 10:32:14,645 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2023-12-12 10:32:14,649 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2023-12-12 10:32:14,650 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2023-12-12 10:32:14,797 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-12-12 10:32:14,799 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-12-12 10:32:14,800 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2023-12-12 10:32:14,800 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2023-12-12 10:32:14,800 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2023-12-12 10:32:14,801 [707b32b6-be48-4439-b655-31ff544e1299-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2023-12-12 10:32:14,806 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2023-12-12 10:32:14,806 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-12-12 10:32:14,810 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2023-12-12 10:32:14,880 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2023-12-12 10:32:14,936 [main] INFO ha.SequenceIdGenerator: upgrade localId to 111677748019200000
2023-12-12 10:32:14,938 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2023-12-12 10:32:14,947 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2023-12-12 10:32:14,950 [main] INFO ha.SequenceIdGenerator: upgrade CertificateId to 2
2023-12-12 10:32:14,952 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2023-12-12 10:32:15,039 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2023-12-12 10:32:15,061 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2023-12-12 10:32:15,064 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-12-12 10:32:15,081 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2023-12-12 10:32:15,107 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-12-12 10:32:15,108 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-12-12 10:32:15,119 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2023-12-12 10:32:15,119 [main] INFO pipeline.BackgroundPipelineCreator: Starting scm2-RatisPipelineUtilsThread.
2023-12-12 10:32:15,123 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2023-12-12 10:32:15,125 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2023-12-12 10:32:15,132 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2023-12-12 10:32:15,138 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2023-12-12 10:32:15,167 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-12-12 10:32:15,167 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-12-12 10:32:15,188 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2023-12-12 10:32:15,301 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2023-12-12 10:32:15,304 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2023-12-12 10:32:15,307 [scm2-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2023-12-12 10:32:15,322 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2023-12-12 10:32:15,328 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:15,332 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-12-12 10:32:15,582 [main] INFO security.SecretKeyManagerService: Scheduling rotation checker with interval PT1M
2023-12-12 10:32:15,582 [main] INFO ha.SCMServiceManager: Registering service SecretKeyManagerService.
2023-12-12 10:32:15,616 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2023-12-12 10:32:15,663 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-12 10:32:15,697 [main] INFO ipc.Server: Listener at 0.0.0.0:9961
2023-12-12 10:32:15,700 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
2023-12-12 10:32:15,762 [main] INFO server.StorageContainerManager: SCM start with adminUsers: [testuser, recon, om, scm]
2023-12-12 10:32:16,246 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-12-12 10:32:16,364 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-12 10:32:16,365 [main] INFO ipc.Server: Listener at 0.0.0.0:9861
2023-12-12 10:32:16,366 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2023-12-12 10:32:16,465 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-12-12 10:32:16,476 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-12 10:32:16,477 [main] INFO ipc.Server: Listener at 0.0.0.0:9863
2023-12-12 10:32:16,479 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2023-12-12 10:32:16,529 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-12-12 10:32:16,539 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-12 10:32:16,540 [main] INFO ipc.Server: Listener at 0.0.0.0:9860
2023-12-12 10:32:16,550 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2023-12-12 10:32:16,672 [main] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2023-12-12 10:32:16,674 [main] INFO server.StorageContainerManager: 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB
Number of Iterations                               10
Time Limit for Single Container's Movement         65min
Time Limit for Single Container's Replication      50min
Interval between each Iteration                    70min
Whether to Enable Network Topology                 false
Whether to Trigger Refresh Datanode Usage Info     false
Container IDs to Exclude from Balancing            None
Datanodes Specified to be Balanced                 None
Datanodes Excluded from Balancing                  None

2023-12-12 10:32:16,675 [main] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-12-12 10:32:16,694 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2023-12-12 10:32:16,704 [main] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2023-12-12 10:32:16,706 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2023-12-12 10:32:16,710 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2023-12-12 10:32:16,710 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-12-12 10:32:16,731 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/5914c539-8ad3-44d3-8e5d-2cc8202ea8d6 does not exist. Creating ...
2023-12-12 10:32:16,739 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/5914c539-8ad3-44d3-8e5d-2cc8202ea8d6/in_use.lock acquired by nodename 6@scm2.org
2023-12-12 10:32:16,752 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/5914c539-8ad3-44d3-8e5d-2cc8202ea8d6 has been successfully formatted.
2023-12-12 10:32:16,763 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2023-12-12 10:32:16,779 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2023-12-12 10:32:16,779 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 10:32:16,789 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-12-12 10:32:16,790 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2023-12-12 10:32:16,801 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-12-12 10:32:16,811 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2023-12-12 10:32:16,811 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-12-12 10:32:16,811 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 10:32:16,815 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO util.AwaitToRun: Thread[707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-cacheEviction-AwaitToRun,5,main] started
2023-12-12 10:32:16,820 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/5914c539-8ad3-44d3-8e5d-2cc8202ea8d6
2023-12-12 10:32:16,820 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-12-12 10:32:16,821 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2023-12-12 10:32:16,822 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-12-12 10:32:16,823 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2023-12-12 10:32:16,823 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2023-12-12 10:32:16,823 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2023-12-12 10:32:16,824 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-12-12 10:32:16,824 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-12-12 10:32:16,825 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2023-12-12 10:32:16,830 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 10:32:16,832 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2023-12-12 10:32:16,832 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2023-12-12 10:32:16,833 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2023-12-12 10:32:16,862 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-12-12 10:32:16,862 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-12-12 10:32:16,865 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: start with initializing state, conf=-1: peers:[]|listeners:[], old=null
2023-12-12 10:32:16,866 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: changes role from      null to FOLLOWER at term 0 for startInitializing
2023-12-12 10:32:16,869 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2CC8202EA8D6,id=707b32b6-be48-4439-b655-31ff544e1299
2023-12-12 10:32:16,879 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2023-12-12 10:32:16,879 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-12-12 10:32:16,879 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2023-12-12 10:32:16,880 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2023-12-12 10:32:16,881 [707b32b6-be48-4439-b655-31ff544e1299-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2023-12-12 10:32:16,932 [main] INFO server.RaftServer: 707b32b6-be48-4439-b655-31ff544e1299: start RPC server
2023-12-12 10:32:16,973 [main] INFO server.GrpcService: 707b32b6-be48-4439-b655-31ff544e1299: GrpcService started, listening on 9894
2023-12-12 10:32:16,976 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-707b32b6-be48-4439-b655-31ff544e1299: Started
2023-12-12 10:32:17,001 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
2023-12-12 10:32:17,848 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: receive installSnapshot: e5fdb72c-5c5c-4ba8-951b-04fd10563c04->707b32b6-be48-4439-b655-31ff544e1299#0-t2,notify:(t:1, i:0)
2023-12-12 10:32:17,870 [grpc-default-executor-0] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: set firstElectionSinceStartup to false for installSnapshot
2023-12-12 10:32:17,870 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
2023-12-12 10:32:17,870 [grpc-default-executor-0] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: change Leader from null to e5fdb72c-5c5c-4ba8-951b-04fd10563c04 at term 2 for installSnapshot, leader elected after 3244ms
2023-12-12 10:32:17,875 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: Received notification to install snapshot at index 0
2023-12-12 10:32:17,875 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
2023-12-12 10:32:18,032 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: set new configuration index: 1
configurationEntry {
  peers {
    id: "e5fdb72c-5c5c-4ba8-951b-04fd10563c04"
    address: "scm1.org:9894"
    startupRole: FOLLOWER
  }
}
 from snapshot
2023-12-12 10:32:18,035 [grpc-default-executor-0] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: set configuration 1: peers:[e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894]|listeners:[], old=null
2023-12-12 10:32:18,040 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: reply installSnapshot: e5fdb72c-5c5c-4ba8-951b-04fd10563c04<-707b32b6-be48-4439-b655-31ff544e1299#0:OK-t0,ALREADY_INSTALLED,snapshotIndex=0
2023-12-12 10:32:18,052 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 707b32b6-be48-4439-b655-31ff544e1299: Completed INSTALL_SNAPSHOT, lastRequest: e5fdb72c-5c5c-4ba8-951b-04fd10563c04->707b32b6-be48-4439-b655-31ff544e1299#0-t2,notify:(t:1, i:0)
2023-12-12 10:32:18,052 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 707b32b6-be48-4439-b655-31ff544e1299: Completed INSTALL_SNAPSHOT, lastReply: null
2023-12-12 10:32:18,183 [707b32b6-be48-4439-b655-31ff544e1299-server-thread1] INFO impl.RoleInfo: 707b32b6-be48-4439-b655-31ff544e1299: start 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-FollowerState
2023-12-12 10:32:18,185 [707b32b6-be48-4439-b655-31ff544e1299-server-thread1] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:32:18,189 [707b32b6-be48-4439-b655-31ff544e1299-server-thread1] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: inconsistency entries. Reply:e5fdb72c-5c5c-4ba8-951b-04fd10563c04<-707b32b6-be48-4439-b655-31ff544e1299#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:32:18,190 [707b32b6-be48-4439-b655-31ff544e1299-server-thread2] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-12-12 10:32:18,191 [707b32b6-be48-4439-b655-31ff544e1299-server-thread2] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: inconsistency entries. Reply:e5fdb72c-5c5c-4ba8-951b-04fd10563c04<-707b32b6-be48-4439-b655-31ff544e1299#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-12-12 10:32:18,214 [707b32b6-be48-4439-b655-31ff544e1299-server-thread2] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: set configuration 0: peers:[e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894]|listeners:[], old=null
2023-12-12 10:32:18,214 [707b32b6-be48-4439-b655-31ff544e1299-server-thread2] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: set configuration 1: peers:[e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894]|listeners:[], old=null
2023-12-12 10:32:18,217 [707b32b6-be48-4439-b655-31ff544e1299-server-thread2] INFO segmented.SegmentedRaftLogWorker: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-SegmentedRaftLogWorker: Starting segment from index:0
2023-12-12 10:32:18,239 [707b32b6-be48-4439-b655-31ff544e1299-server-thread2] INFO segmented.SegmentedRaftLogWorker: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2023-12-12 10:32:18,368 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/5914c539-8ad3-44d3-8e5d-2cc8202ea8d6/current/log_inprogress_0
2023-12-12 10:32:18,371 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/5914c539-8ad3-44d3-8e5d-2cc8202ea8d6/current/log_inprogress_0 to /data/metadata/scm-ha/5914c539-8ad3-44d3-8e5d-2cc8202ea8d6/current/log_0-0
2023-12-12 10:32:18,390 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/5914c539-8ad3-44d3-8e5d-2cc8202ea8d6/current/log_inprogress_1
2023-12-12 10:32:18,408 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:18,410 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2023-12-12 10:32:18,420 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-12-12 10:32:18,420 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2023-12-12 10:32:18,423 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-12 10:32:18,424 [707b32b6-be48-4439-b655-31ff544e1299-server-thread2] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: set configuration 15: peers:[e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894, 707b32b6-be48-4439-b655-31ff544e1299|scm2.org:9894]|listeners:[], old=peers:[e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894]|listeners:[]
2023-12-12 10:32:18,427 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2023-12-12 10:32:18,516 [707b32b6-be48-4439-b655-31ff544e1299-server-thread2] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: set configuration 17: peers:[e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894, 707b32b6-be48-4439-b655-31ff544e1299|scm2.org:9894]|listeners:[], old=null
2023-12-12 10:32:18,628 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 937b23b2-3aef-4a5d-ad1c-4d999bfe49ab, creation at: 2023-12-12T10:32:07.595Z, expire at: 2023-12-12T11:32:07.595Z)]
2023-12-12 10:32:18,629 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 937b23b2-3aef-4a5d-ad1c-4d999bfe49ab, creation at: 2023-12-12T10:32:07.595Z, expire at: 2023-12-12T11:32:07.595Z)
2023-12-12 10:32:18,640 [main] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-2CC8202EA8D6:[e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894, 707b32b6-be48-4439-b655-31ff544e1299|scm2.org:9894]
2023-12-12 10:32:18,649 [main] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2023-12-12 10:32:18,668 [main] INFO SCMHATransactionMonitor: Starting SCMHATransactionMonitor Service.
2023-12-12 10:32:18,668 [main] INFO ha.SCMServiceManager: Registering service SCMHATransactionMonitor.
2023-12-12 10:32:18,669 [main] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is already running, skip start.
2023-12-12 10:32:18,786 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 937b23b2-3aef-4a5d-ad1c-4d999bfe49ab, creation at: 2023-12-12T10:32:07.595Z, expire at: 2023-12-12T11:32:07.595Z)] to file /data/metadata/scm/keys/secret_keys.json
2023-12-12 10:32:18,787 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:18,787 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2023-12-12 10:32:18,787 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2023-12-12 10:32:18,900 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for CertificateId, expected lastId is 0, actual lastId is 2.
2023-12-12 10:32:18,913 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:18,933 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:18,988 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO server.SCMCertStore: Scm certificate 3 for CN=scm-sub@scm2.org,OU=707b32b6-be48-4439-b655-31ff544e1299,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=3 is stored
2023-12-12 10:32:18,988 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:18,995 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:19,003 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2023-12-12 10:32:19,007 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:19,040 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-12-12 10:32:19,041 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2023-12-12 10:32:19,175 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2023-12-12 10:32:19,176 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-12 10:32:19,177 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2023-12-12 10:32:19,229 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2023-12-12 10:32:19,230 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2023-12-12 10:32:19,230 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-12 10:32:19,254 [main] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
2023-12-12 10:32:19,300 [main] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
2023-12-12 10:32:19,305 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-12 10:32:19,305 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2023-12-12 10:32:19,305 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
2023-12-12 10:32:19,466 [main] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 707b32b6-be48-4439-b655-31ff544e1299
2023-12-12 10:32:19,484 [main] INFO server.SCMCertStore: Scm certificate 1 for CN=scm@scm1.org,OU=e5fdb72c-5c5c-4ba8-951b-04fd10563c04,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=1 is stored
2023-12-12 10:32:19,490 [main] INFO server.StorageContainerManager: Persist certificate serialId 2 on Scm Bootstrap Node 707b32b6-be48-4439-b655-31ff544e1299
2023-12-12 10:32:19,493 [main] INFO server.SCMCertStore: Scm certificate 2 for CN=scm-sub@scm1.org,OU=e5fdb72c-5c5c-4ba8-951b-04fd10563c04,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=2 is stored
2023-12-12 10:32:19,556 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2023-12-12 10:32:19,556 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
2023-12-12 10:32:19,557 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
2023-12-12 10:32:19,633 [main] INFO util.log: Logging initialized @8676ms to org.eclipse.jetty.util.log.Slf4jLog
2023-12-12 10:32:19,771 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2023-12-12 10:32:19,779 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-12-12 10:32:19,780 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2023-12-12 10:32:19,780 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2023-12-12 10:32:19,782 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2023-12-12 10:32:19,785 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
2023-12-12 10:32:19,828 [main] INFO http.BaseHttpServer: HTTP server of scm uses base directory /data/metadata/webserver
2023-12-12 10:32:19,829 [main] INFO http.HttpServer2: Jetty bound to port 9876
2023-12-12 10:32:19,830 [main] INFO server.Server: jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 11.0.19+7-LTS
2023-12-12 10:32:19,896 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2023-12-12 10:32:19,896 [main] INFO server.session: No SessionScavenger set, using defaults
2023-12-12 10:32:19,898 [main] INFO server.session: node0 Scavenging every 600000ms
2023-12-12 10:32:19,933 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2023-12-12 10:32:19,942 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@29e7da9c{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2023-12-12 10:32:19,950 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3fae2cd3{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-12-12 10:32:20,114 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2023-12-12 10:32:20,124 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@c5ed57e{scm,/,file:///data/metadata/webserver/jetty-0_0_0_0-9876-hdds-server-scm-1_4_0-SNAPSHOT_jar-_-any-14779675037771809744/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/scm}
2023-12-12 10:32:20,134 [main] INFO server.AbstractConnector: Started ServerConnector@203737fb{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2023-12-12 10:32:20,134 [main] INFO server.Server: Started @9177ms
2023-12-12 10:32:20,136 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2023-12-12 10:32:20,136 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
2023-12-12 10:32:20,159 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2023-12-12 10:32:20,185 [707b32b6-be48-4439-b655-31ff544e1299-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-12-12 10:32:20,189 [707b32b6-be48-4439-b655-31ff544e1299-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-12-12 10:32:20,190 [707b32b6-be48-4439-b655-31ff544e1299-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: CA certificates are not changed.
2023-12-12 10:32:22,875 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:22,978 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO server.SCMCertStore: Scm certificate 5 for CN=scm-sub@scm3.org,OU=b01ee407-6004-400b-bafa-19d15b52321b,O=CID-5914c539-8ad3-44d3-8e5d-2cc8202ea8d6,SERIALNUMBER=5 is stored
2023-12-12 10:32:22,978 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:28,778 [707b32b6-be48-4439-b655-31ff544e1299-server-thread2] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: set configuration 23: peers:[b01ee407-6004-400b-bafa-19d15b52321b|scm3.org:9894, e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894, 707b32b6-be48-4439-b655-31ff544e1299|scm2.org:9894]|listeners:[], old=peers:[e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894, 707b32b6-be48-4439-b655-31ff544e1299|scm2.org:9894]|listeners:[]
2023-12-12 10:32:28,782 [707b32b6-be48-4439-b655-31ff544e1299-server-thread2] INFO server.RaftServer$Division: 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6: set configuration 25: peers:[b01ee407-6004-400b-bafa-19d15b52321b|scm3.org:9894, e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894, 707b32b6-be48-4439-b655-31ff544e1299|scm2.org:9894]|listeners:[], old=null
2023-12-12 10:32:44,926 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:45,132 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:45,237 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:45,525 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:45,615 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:45,876 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:45,984 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:46,158 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:46,225 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:46,434 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:32:58,709 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:57308 / 172.25.0.102:57308
2023-12-12 10:32:58,783 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:32:59,706 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:46798 / 172.25.0.103:46798
2023-12-12 10:32:59,830 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:32:59,931 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:53900 / 172.25.0.104:53900
2023-12-12 10:33:00,075 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:33:00,662 [IPC Server handler 2 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f7747e3f-639e-4a66-bee7-99ddbfccd962
2023-12-12 10:33:00,678 [IPC Server handler 2 on default port 9861] INFO node.SCMNodeManager: Registered datanode: f7747e3f-639e-4a66-bee7-99ddbfccd962{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 6, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-12-12 10:33:00,685 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
2023-12-12 10:33:00,698 [scm2-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-12-12 10:33:00,794 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:33:01,426 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/dcb40b12-80f2-4e81-b564-c9993480f099
2023-12-12 10:33:01,427 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered datanode: dcb40b12-80f2-4e81-b564-c9993480f099{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 7, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-12-12 10:33:01,428 [scm2-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-12-12 10:33:01,430 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
2023-12-12 10:33:01,443 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:33:01,708 [IPC Server handler 2 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/c093f2ea-1bd4-4965-ba81-73d5fe2850ac
2023-12-12 10:33:01,708 [IPC Server handler 2 on default port 9861] INFO node.SCMNodeManager: Registered datanode: c093f2ea-1bd4-4965-ba81-73d5fe2850ac{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 8, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-12-12 10:33:01,709 [scm2-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-12-12 10:33:01,709 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
2023-12-12 10:33:01,709 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2023-12-12 10:33:01,709 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2023-12-12 10:33:01,709 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-12-12 10:33:01,711 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-12-12 10:33:01,738 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:33:01,798 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:33:01,839 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:33:03,974 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:33:04,024 [scm2-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "3571a92d-000e-40fa-bd24-91a95fbde0ad"
  uuid128 {
    mostSigBits: 3851045167118041338
    leastSigBits: -4817565544737808211
  }
}
isLeader: false
bytesWritten: 0
 from dn=f7747e3f-639e-4a66-bee7-99ddbfccd962(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6 is not the leader e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6 is not the leader e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:795)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:760)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:746)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:926)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:919)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:896)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$11(RaftServerImpl.java:885)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$12(RaftServerImpl.java:885)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-12-12 10:33:04,164 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:33:04,849 [scm2-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "d87811d4-e23b-4171-950d-b836b13374cf"
  uuid128 {
    mostSigBits: -2848507158285565583
    leastSigBits: -7706300842320366385
  }
}
isLeader: false
bytesWritten: 0
 from dn=dcb40b12-80f2-4e81-b564-c9993480f099(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6 is not the leader e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6 is not the leader e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:795)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:760)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:746)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:926)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:919)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:896)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$11(RaftServerImpl.java:885)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$12(RaftServerImpl.java:885)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-12-12 10:33:04,867 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:33:05,216 [scm2-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "365a8c0f-832c-4cec-ac33-a5340c0bd651"
  uuid128 {
    mostSigBits: 3916596824205184236
    leastSigBits: -6038301032414718383
  }
}
isLeader: false
bytesWritten: 0
 from dn=c093f2ea-1bd4-4965-ba81-73d5fe2850ac(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6 is not the leader e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6 is not the leader e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:795)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:760)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:746)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:926)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:919)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:896)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$11(RaftServerImpl.java:885)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$12(RaftServerImpl.java:885)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-12-12 10:33:05,232 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-12-12 10:33:05,407 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:33:05,446 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:33:07,373 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:33:07,754 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:33:08,054 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:33:09,357 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:33:10,434 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:33:10,445 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:33:11,035 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:33:11,035 [scm2-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "d9688f3b-f54c-42fc-a754-0daf51d84bad"
  uuid128 {
    mostSigBits: -2780815282220023044
    leastSigBits: -6389466924688323667
  }
}
isLeader: true
bytesWritten: 0
 from dn=dcb40b12-80f2-4e81-b564-c9993480f099(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6 is not the leader e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6 is not the leader e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:795)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:760)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:746)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:926)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:919)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:896)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$11(RaftServerImpl.java:885)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$12(RaftServerImpl.java:885)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-12-12 10:33:11,063 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2023-12-12 10:33:12,675 [scm2-EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "cb84d9f1-5828-4335-9cdd-38bcf3fe9947"
  uuid128 {
    mostSigBits: -3781658156494994635
    leastSigBits: -7143491049741182649
  }
}
isLeader: true
bytesWritten: 0
 from dn=f7747e3f-639e-4a66-bee7-99ddbfccd962(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6 is not the leader e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server 707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6 is not the leader e5fdb72c-5c5c-4ba8-951b-04fd10563c04|scm1.org:9894
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:795)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:760)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:746)
	at org.apache.ratis.server.impl.RaftServerImpl.writeAsync(RaftServerImpl.java:926)
	at org.apache.ratis.server.impl.RaftServerImpl.replyFuture(RaftServerImpl.java:919)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:896)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$11(RaftServerImpl.java:885)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$12(RaftServerImpl.java:885)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-12-12 10:33:12,677 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-12 10:33:12,677 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-12-12 10:33:12,677 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2023-12-12 10:33:12,677 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2023-12-12 10:33:12,677 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2023-12-12 10:33:12,677 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-12-12 10:33:40,485 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:38208 / 172.25.0.104:38208
2023-12-12 10:33:40,497 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:33:41,082 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:58788 / 172.25.0.103:58788
2023-12-12 10:33:41,104 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:33:42,695 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:60230 / 172.25.0.102:60230
2023-12-12 10:33:42,704 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:33:53,225 [707b32b6-be48-4439-b655-31ff544e1299@group-2CC8202EA8D6-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 111677748019200000.
2023-12-12 10:34:06,245 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:45104 / 172.25.0.102:45104
2023-12-12 10:34:06,382 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:34:06,456 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:39802 / 172.25.0.103:39802
2023-12-12 10:34:06,546 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:34:06,594 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:36858 / 172.25.0.104:36858
2023-12-12 10:34:06,757 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:34:19,153 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:39874 / 172.25.0.102:39874
2023-12-12 10:34:19,154 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:54560 / 172.25.0.104:54560
2023-12-12 10:34:19,173 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:34:19,233 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:46024 / 172.25.0.103:46024
2023-12-12 10:34:19,267 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:34:19,314 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:34:49,201 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:53444 / 172.25.0.104:53444
2023-12-12 10:34:49,219 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:54254 / 172.25.0.103:54254
2023-12-12 10:34:49,243 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:34:49,263 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:34:49,264 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:51126 / 172.25.0.102:51126
2023-12-12 10:34:49,313 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:35:19,148 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:48188 / 172.25.0.103:48188
2023-12-12 10:35:19,166 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:38034 / 172.25.0.104:38034
2023-12-12 10:35:19,194 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:55540 / 172.25.0.102:55540
2023-12-12 10:35:19,198 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:35:19,199 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:35:19,237 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:35:49,158 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:34702 / 172.25.0.102:34702
2023-12-12 10:35:49,163 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:33032 / 172.25.0.104:33032
2023-12-12 10:35:49,171 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:35:49,186 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-12 10:35:49,200 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:41320 / 172.25.0.103:41320
2023-12-12 10:35:49,260 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
