rm: cannot remove '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/*': No such file or directory
Executing test ozone-csi/test.sh
Removing network ozone-csi_default
Network ozone-csi_default not found.
Creating network "ozone-csi_default" with the default driver
Pulling datanode (apache/ozone-runner:20230615-1)...
20230615-1: Pulling from apache/ozone-runner
Digest: sha256:46c59e4f69c94a8f886d621c9f1898fda8cc4d5de59059c6c74175ffa4718474
Status: Downloaded newer image for apache/ozone-runner:20230615-1
Creating ozone-csi_datanode_1 ... 
Creating ozone-csi_om_1       ... 
Creating ozone-csi_datanode_2 ... 
Creating ozone-csi_datanode_3 ... 
Creating ozone-csi_scm_1      ... 
Creating ozone-csi_csi_1      ... 
Creating ozone-csi_csi_1      ... done
Creating ozone-csi_scm_1      ... done
Creating ozone-csi_datanode_1 ... done
Creating ozone-csi_datanode_3 ... done
Creating ozone-csi_om_1       ... done
Creating ozone-csi_datanode_2 ... done
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is out of safe mode.
No OM HA service, no need to wait
==============================================================================
Csi :: Smoketest Ozone CSI service                                            
==============================================================================
Check if CSI server is started                                        | PASS |
------------------------------------------------------------------------------
Test CSI identity service                                             | PASS |
------------------------------------------------------------------------------
Csi :: Smoketest Ozone CSI service                                    | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-csi/result/robot-1.xml
Stopping ozone-csi_csi_1      ... 
Stopping ozone-csi_datanode_2 ... 
Stopping ozone-csi_om_1       ... 
Stopping ozone-csi_datanode_3 ... 
Stopping ozone-csi_datanode_1 ... 
Stopping ozone-csi_scm_1      ... 
Stopping ozone-csi_csi_1      ... done
Stopping ozone-csi_datanode_2 ... done
Stopping ozone-csi_datanode_1 ... done
Stopping ozone-csi_datanode_3 ... done
Stopping ozone-csi_om_1       ... done
Stopping ozone-csi_scm_1      ... done
Removing ozone-csi_csi_1      ... 
Removing ozone-csi_datanode_2 ... 
Removing ozone-csi_om_1       ... 
Removing ozone-csi_datanode_3 ... 
Removing ozone-csi_datanode_1 ... 
Removing ozone-csi_scm_1      ... 
Removing ozone-csi_csi_1      ... done
Removing ozone-csi_datanode_2 ... done
Removing ozone-csi_datanode_3 ... done
Removing ozone-csi_om_1       ... done
Removing ozone-csi_datanode_1 ... done
Removing ozone-csi_scm_1      ... done
Removing network ozone-csi_default
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-csi.xml
removed 'ozone-csi/result/robot-1.xml'
renamed 'ozone-csi/result/dn-audit-39d93f80684b.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-csi/dn-audit-39d93f80684b.log'
renamed 'ozone-csi/result/dn-audit-4c72712c1a11.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-csi/dn-audit-4c72712c1a11.log'
renamed 'ozone-csi/result/dn-audit-83f8c412c54e.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-csi/dn-audit-83f8c412c54e.log'
renamed 'ozone-csi/result/docker-ozone-csi_csi_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi_csi_1.log'
renamed 'ozone-csi/result/docker-ozone-csi_datanode_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi_datanode_1.log'
renamed 'ozone-csi/result/docker-ozone-csi_datanode_2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi_datanode_2.log'
renamed 'ozone-csi/result/docker-ozone-csi_datanode_3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi_datanode_3.log'
renamed 'ozone-csi/result/docker-ozone-csi_om_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi_om_1.log'
renamed 'ozone-csi/result/docker-ozone-csi_scm_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi_scm_1.log'
renamed 'ozone-csi/result/om-audit-4b7c9507b519.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-csi/om-audit-4b7c9507b519.log'
renamed 'ozone-csi/result/scm-audit-793ca986b57b.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-csi/scm-audit-793ca986b57b.log'
Executing test ozone-om-prepare/test.sh
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data/dn2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data/scm': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data/dn3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data/om2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data/om1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data/dn1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data/om3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data': Operation not permitted
Removing network ozone-om-prepare_net
Network ozone-om-prepare_net not found.
Creating network "ozone-om-prepare_net" with driver "bridge"
Creating ozone-om-prepare_dn3_1 ... 
Creating ozone-om-prepare_dn2_1 ... 
Creating ozone-om-prepare_om2_1 ... 
Creating ozone-om-prepare_scm_1 ... 
Creating ozone-om-prepare_om1_1 ... 
Creating ozone-om-prepare_dn1_1 ... 
Creating ozone-om-prepare_om3_1 ... 
Creating ozone-om-prepare_om1_1 ... done
Creating ozone-om-prepare_scm_1 ... done
Creating ozone-om-prepare_dn3_1 ... done
Creating ozone-om-prepare_om2_1 ... done
Creating ozone-om-prepare_dn1_1 ... done
Creating ozone-om-prepare_dn2_1 ... done
Creating ozone-om-prepare_om3_1 ... done
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 238
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 237
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 236
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 235
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 234
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 233
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 232
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 231
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 230
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 229
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 228
SCM is out of safe mode.
OM:om1 is not the leader. Suggested leader is OM:om2[om2/10.9.0.15].
Waiting for OM leader for service omservice
SECONDS: 12
Found OM leader for service omservice: om2 : LEADER (om2)
Replaced OM order with om2,om3,om1 in ozone-om-prepare_scm_1
==============================================================================
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.           
==============================================================================
Prepare Ozone Manager                                                 | PASS |
------------------------------------------------------------------------------
Checks if the expected data is present in OM                          | PASS |
------------------------------------------------------------------------------
Test write operation fails                                            | PASS |
------------------------------------------------------------------------------
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.   | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-1.xml
==============================================================================
Om-Cancel-Prepare :: Smoke test for ozone manager cancel prepare              
==============================================================================
Cancel Ozone Manager Prepare                                          | PASS |
------------------------------------------------------------------------------
Test write operations                                                 | PASS |
------------------------------------------------------------------------------
Om-Cancel-Prepare :: Smoke test for ozone manager cancel prepare      | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-2.xml
==============================================================================
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.           
==============================================================================
Prepare Ozone Manager                                                 | PASS |
------------------------------------------------------------------------------
Checks if the expected data is present in OM                          | PASS |
------------------------------------------------------------------------------
Test write operation fails                                            | PASS |
------------------------------------------------------------------------------
Om-Prepare :: Smoke test to test preparing OMs in an OM HA cluster.   | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-3.xml
==============================================================================
Om-Prepared :: Smoke test to test that OMs are prepared in an OM HA cluster.  
==============================================================================
Test create volume fails                                              | PASS |
------------------------------------------------------------------------------
Test list volumes succeeds                                            | PASS |
------------------------------------------------------------------------------
Om-Prepared :: Smoke test to test that OMs are prepared in an OM H... | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-4.xml
Stopping ozone-om-prepare_om3_1 ... 
Stopping ozone-om-prepare_dn1_1 ... 
Stopping ozone-om-prepare_om2_1 ... 
Stopping ozone-om-prepare_dn2_1 ... 
Stopping ozone-om-prepare_scm_1 ... 
Stopping ozone-om-prepare_om1_1 ... 
Stopping ozone-om-prepare_dn3_1 ... 
Stopping ozone-om-prepare_dn2_1 ... done
Stopping ozone-om-prepare_dn3_1 ... done
Stopping ozone-om-prepare_dn1_1 ... done
Stopping ozone-om-prepare_om1_1 ... done
Stopping ozone-om-prepare_om3_1 ... done
Stopping ozone-om-prepare_om2_1 ... done
Stopping ozone-om-prepare_scm_1 ... done
Removing ozone-om-prepare_om3_1 ... 
Removing ozone-om-prepare_dn1_1 ... 
Removing ozone-om-prepare_om2_1 ... 
Removing ozone-om-prepare_dn2_1 ... 
Removing ozone-om-prepare_scm_1 ... 
Removing ozone-om-prepare_om1_1 ... 
Removing ozone-om-prepare_dn3_1 ... 
Removing ozone-om-prepare_dn1_1 ... done
Removing ozone-om-prepare_om2_1 ... done
Removing ozone-om-prepare_om1_1 ... done
Removing ozone-om-prepare_dn3_1 ... done
Removing ozone-om-prepare_scm_1 ... done
Removing ozone-om-prepare_om3_1 ... done
Removing ozone-om-prepare_dn2_1 ... done
Removing network ozone-om-prepare_net
Removing network ozone-om-prepare_net
Network ozone-om-prepare_net not found.
Creating network "ozone-om-prepare_net" with driver "bridge"
Creating ozone-om-prepare_om3_1 ... 
Creating ozone-om-prepare_dn1_1 ... 
Creating ozone-om-prepare_om1_1 ... 
Creating ozone-om-prepare_scm_1 ... 
Creating ozone-om-prepare_dn2_1 ... 
Creating ozone-om-prepare_dn3_1 ... 
Creating ozone-om-prepare_om2_1 ... 
Creating ozone-om-prepare_om3_1 ... done
Creating ozone-om-prepare_dn2_1 ... done
Creating ozone-om-prepare_om1_1 ... done
Creating ozone-om-prepare_scm_1 ... done
Creating ozone-om-prepare_dn1_1 ... done
Creating ozone-om-prepare_om2_1 ... done
Creating ozone-om-prepare_dn3_1 ... done
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 237
SCM is out of safe mode.
Found OM leader for service omservice: om2 : LEADER (om2)
Replaced OM order with om2,om3,om1 in ozone-om-prepare_scm_1
==============================================================================
Om-Prepared :: Smoke test to test that OMs are prepared in an OM HA cluster.  
==============================================================================
Test create volume fails                                              | PASS |
------------------------------------------------------------------------------
Test list volumes succeeds                                            | PASS |
------------------------------------------------------------------------------
Om-Prepared :: Smoke test to test that OMs are prepared in an OM H... | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-5.xml
Stopping ozone-om-prepare_om2_1 ... 
Stopping ozone-om-prepare_dn1_1 ... 
Stopping ozone-om-prepare_scm_1 ... 
Stopping ozone-om-prepare_dn3_1 ... 
Stopping ozone-om-prepare_dn2_1 ... 
Stopping ozone-om-prepare_om3_1 ... 
Stopping ozone-om-prepare_om1_1 ... 
Stopping ozone-om-prepare_dn1_1 ... done
Stopping ozone-om-prepare_dn3_1 ... done
Stopping ozone-om-prepare_dn2_1 ... done
Stopping ozone-om-prepare_om3_1 ... done
Stopping ozone-om-prepare_om1_1 ... done
Stopping ozone-om-prepare_om2_1 ... done
Stopping ozone-om-prepare_scm_1 ... done
Removing ozone-om-prepare_om2_1 ... 
Removing ozone-om-prepare_dn1_1 ... 
Removing ozone-om-prepare_scm_1 ... 
Removing ozone-om-prepare_dn3_1 ... 
Removing ozone-om-prepare_dn2_1 ... 
Removing ozone-om-prepare_om3_1 ... 
Removing ozone-om-prepare_om1_1 ... 
Removing ozone-om-prepare_scm_1 ... done
Removing ozone-om-prepare_om2_1 ... done
Removing ozone-om-prepare_dn1_1 ... done
Removing ozone-om-prepare_dn3_1 ... done
Removing ozone-om-prepare_om1_1 ... done
Removing ozone-om-prepare_dn2_1 ... done
Removing ozone-om-prepare_om3_1 ... done
Removing network ozone-om-prepare_net
Removing network ozone-om-prepare_net
Network ozone-om-prepare_net not found.
Creating network "ozone-om-prepare_net" with driver "bridge"
Creating ozone-om-prepare_scm_1 ... 
Creating ozone-om-prepare_om1_1 ... 
Creating ozone-om-prepare_om2_1 ... 
Creating ozone-om-prepare_dn2_1 ... 
Creating ozone-om-prepare_dn1_1 ... 
Creating ozone-om-prepare_om3_1 ... 
Creating ozone-om-prepare_dn3_1 ... 
Creating ozone-om-prepare_scm_1 ... done
Creating ozone-om-prepare_om1_1 ... done
Creating ozone-om-prepare_om3_1 ... done
Creating ozone-om-prepare_dn2_1 ... done
Creating ozone-om-prepare_dn3_1 ... done
Creating ozone-om-prepare_dn1_1 ... done
Creating ozone-om-prepare_om2_1 ... done
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 238
SCM is out of safe mode.
OM:om1 is not the leader. Suggested leader is OM:om2[om2/10.9.0.15].
Waiting for OM leader for service omservice
SECONDS: 14
Found OM leader for service omservice: om2 : LEADER (om2)
Replaced OM order with om2,om3,om1 in ozone-om-prepare_scm_1
==============================================================================
Loaddata :: Smoketest ozone cluster startup                                   
==============================================================================
Create a volume, bucket and key                                       | PASS |
------------------------------------------------------------------------------
Loaddata :: Smoketest ozone cluster startup                           | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-6.xml
==============================================================================
Readdata :: Smoketest ozone cluster startup                                   
==============================================================================
Read data from previously created key                                 | PASS |
------------------------------------------------------------------------------
Readdata :: Smoketest ozone cluster startup                           | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-om-prepare/result/robot-7.xml
Stopping ozone-om-prepare_dn3_1 ... 
Stopping ozone-om-prepare_om3_1 ... 
Stopping ozone-om-prepare_dn1_1 ... 
Stopping ozone-om-prepare_dn2_1 ... 
Stopping ozone-om-prepare_om2_1 ... 
Stopping ozone-om-prepare_om1_1 ... 
Stopping ozone-om-prepare_scm_1 ... 
Stopping ozone-om-prepare_om1_1 ... done
Stopping ozone-om-prepare_om3_1 ... done
Stopping ozone-om-prepare_om2_1 ... done
Stopping ozone-om-prepare_dn2_1 ... done
Stopping ozone-om-prepare_dn3_1 ... done
Stopping ozone-om-prepare_dn1_1 ... done
Stopping ozone-om-prepare_scm_1 ... done
Removing ozone-om-prepare_dn3_1 ... 
Removing ozone-om-prepare_om3_1 ... 
Removing ozone-om-prepare_dn1_1 ... 
Removing ozone-om-prepare_dn2_1 ... 
Removing ozone-om-prepare_om2_1 ... 
Removing ozone-om-prepare_om1_1 ... 
Removing ozone-om-prepare_scm_1 ... 
Removing ozone-om-prepare_om3_1 ... done
Removing ozone-om-prepare_dn1_1 ... done
Removing ozone-om-prepare_dn2_1 ... done
Removing ozone-om-prepare_dn3_1 ... done
Removing ozone-om-prepare_om1_1 ... done
Removing ozone-om-prepare_om2_1 ... done
Removing ozone-om-prepare_scm_1 ... done
Removing network ozone-om-prepare_net
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare.xml
removed 'ozone-om-prepare/result/robot-1.xml'
removed 'ozone-om-prepare/result/robot-2.xml'
removed 'ozone-om-prepare/result/robot-3.xml'
removed 'ozone-om-prepare/result/robot-4.xml'
removed 'ozone-om-prepare/result/robot-5.xml'
removed 'ozone-om-prepare/result/robot-6.xml'
removed 'ozone-om-prepare/result/robot-7.xml'
renamed 'ozone-om-prepare/result/dn-audit-17bc5df70cd4.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-17bc5df70cd4.log'
renamed 'ozone-om-prepare/result/dn-audit-213d59e1d4ec.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-213d59e1d4ec.log'
renamed 'ozone-om-prepare/result/dn-audit-45b6a3b69ec8.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-45b6a3b69ec8.log'
renamed 'ozone-om-prepare/result/dn-audit-4b7423a4c1cf.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-4b7423a4c1cf.log'
renamed 'ozone-om-prepare/result/dn-audit-5cd63c5e8be9.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-5cd63c5e8be9.log'
renamed 'ozone-om-prepare/result/dn-audit-694196977ed9.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-694196977ed9.log'
renamed 'ozone-om-prepare/result/dn-audit-c9d84fb26394.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-c9d84fb26394.log'
renamed 'ozone-om-prepare/result/dn-audit-e0d55c7fcd9b.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-e0d55c7fcd9b.log'
renamed 'ozone-om-prepare/result/dn-audit-e516e9566695.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/dn-audit-e516e9566695.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare_dn1_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare_dn1_1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare_dn2_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare_dn2_1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare_dn3_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare_dn3_1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare_om1_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare_om1_1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare_om2_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare_om2_1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare_om3_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare_om3_1.log'
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare_scm_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare_scm_1.log'
renamed 'ozone-om-prepare/result/om-audit-18b3c8293751.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-18b3c8293751.log'
renamed 'ozone-om-prepare/result/om-audit-1f5638e62715.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-1f5638e62715.log'
renamed 'ozone-om-prepare/result/om-audit-599c155f0700.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-599c155f0700.log'
renamed 'ozone-om-prepare/result/om-audit-5c292d7bc0d3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-5c292d7bc0d3.log'
renamed 'ozone-om-prepare/result/om-audit-7cd63b7e4742.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-7cd63b7e4742.log'
renamed 'ozone-om-prepare/result/om-audit-828754fca42f.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-828754fca42f.log'
renamed 'ozone-om-prepare/result/om-audit-ab607bcc15fa.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-ab607bcc15fa.log'
renamed 'ozone-om-prepare/result/om-audit-bd4b9fddd5c8.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-bd4b9fddd5c8.log'
renamed 'ozone-om-prepare/result/om-audit-dcfc1b2c40a6.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-dcfc1b2c40a6.log'
renamed 'ozone-om-prepare/result/scm-audit-168edc6bc8ce.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/scm-audit-168edc6bc8ce.log'
renamed 'ozone-om-prepare/result/scm-audit-1d546174b9ee.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/scm-audit-1d546174b9ee.log'
renamed 'ozone-om-prepare/result/scm-audit-a63bc03801a8.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/scm-audit-a63bc03801a8.log'
Executing test ozone-topology/test.sh
Removing network ozone-topology_net
Network ozone-topology_net not found.
Creating network "ozone-topology_net" with driver "bridge"
Creating ozone-topology_om_1 ... 
Creating ozone-topology_datanode_5_1 ... 
Creating ozone-topology_scm_1        ... 
Creating ozone-topology_datanode_2_1 ... 
Creating ozone-topology_datanode_3_1 ... 
Creating ozone-topology_recon_1      ... 
Creating ozone-topology_datanode_1_1 ... 
Creating ozone-topology_datanode_4_1 ... 
Creating ozone-topology_datanode_6_1 ... 
Creating ozone-topology_datanode_1_1 ... done
Creating ozone-topology_datanode_5_1 ... done
Creating ozone-topology_datanode_6_1 ... done
Creating ozone-topology_om_1         ... done
Creating ozone-topology_scm_1        ... done
Creating ozone-topology_recon_1      ... done
Creating ozone-topology_datanode_3_1 ... done
Creating ozone-topology_datanode_2_1 ... done
Creating ozone-topology_datanode_4_1 ... done
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 238
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 237
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 236
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 234
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 233
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 232
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 231
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 230
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 229
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 228
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 227
SCM is out of safe mode.
No OM HA service, no need to wait
==============================================================================
Basic :: Smoketest ozone cluster startup                                      
==============================================================================
Check webui static resources                                          | PASS |
------------------------------------------------------------------------------
Basic Freon smoketest                                                 | PASS |
------------------------------------------------------------------------------
Basic :: Smoketest ozone cluster startup                              | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-1.xml
==============================================================================
Cli :: Smoketest ozone cluster startup                                        
==============================================================================
Run printTopology                                                     | PASS |
------------------------------------------------------------------------------
Run printTopology -o                                                  | PASS |
------------------------------------------------------------------------------
Run printTopology --operational-state IN_SERVICE                      | PASS |
------------------------------------------------------------------------------
Run printTopology --node-state HEALTHY                                | PASS |
------------------------------------------------------------------------------
Cli :: Smoketest ozone cluster startup                                | PASS |
4 tests, 4 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-2.xml
==============================================================================
Recon                                                                         
==============================================================================
Recon.Recon-Api :: Smoke test to start cluster with docker-compose environm...
==============================================================================
Check if Recon picks up OM data                                       | PASS |
------------------------------------------------------------------------------
Check if Recon picks up DN heartbeats                                 | PASS |
------------------------------------------------------------------------------
Check if Recon Web UI is up                                           | PASS |
------------------------------------------------------------------------------
Check web UI access                                                   | PASS |
------------------------------------------------------------------------------
Check admin only api access                                           | PASS |
------------------------------------------------------------------------------
Check unhealthy, (admin) api access                                   | PASS |
------------------------------------------------------------------------------
Check normal api access                                               | PASS |
------------------------------------------------------------------------------
Recon.Recon-Api :: Smoke test to start cluster with docker-compose... | PASS |
7 tests, 7 passed, 0 failed
==============================================================================
Recon.Recon-Nssummary :: Smoke test for Recon Namespace Summary Endpoint fo...
==============================================================================
Check volume creation                                                 | PASS |
------------------------------------------------------------------------------
Check bucket creation                                                 | PASS |
------------------------------------------------------------------------------
Check keys creation                                                   | PASS |
------------------------------------------------------------------------------
Check Summary api access                                              | PASS |
------------------------------------------------------------------------------
Check Disk Usage api access                                           | PASS |
------------------------------------------------------------------------------
Check Quota Usage api access                                          | PASS |
------------------------------------------------------------------------------
Check File Size Distribution api access                               | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Summary Root                                    | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Summary Volume                                  | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Summary Bucket                                  | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Summary Key                                     | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Summary Directory                               | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Disk Usage                                      | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Volume Quota Usage                              | PASS |
------------------------------------------------------------------------------
Check Recon Namespace Bucket Quota Usage                              | PASS |
------------------------------------------------------------------------------
Check Recon Namespace File Size Distribution Root                     | PASS |
------------------------------------------------------------------------------
Recon.Recon-Nssummary :: Smoke test for Recon Namespace Summary En... | PASS |
16 tests, 16 passed, 0 failed
==============================================================================
Recon                                                                 | PASS |
23 tests, 23 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-3.xml
==============================================================================
Loaddata :: Smoketest ozone cluster startup                                   
==============================================================================
Create a volume, bucket and key                                       | PASS |
------------------------------------------------------------------------------
Loaddata :: Smoketest ozone cluster startup                           | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-4.xml
Stopping ozone-topology_datanode_1_1 ... 
Stopping ozone-topology_datanode_3_1 ... 
Stopping ozone-topology_datanode_2_1 ... 
Stopping ozone-topology_datanode_1_1 ... done
Stopping ozone-topology_datanode_2_1 ... done
Stopping ozone-topology_datanode_3_1 ... done
==============================================================================
readdata-first-half :: Smoketest ozone cluster startup                        
==============================================================================
Read data from previously created key                                 | PASS |
------------------------------------------------------------------------------
readdata-first-half :: Smoketest ozone cluster startup                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-5.xml
Starting datanode_1 ... 
Starting datanode_2 ... 
Starting datanode_3 ... 
Starting datanode_1 ... done
Starting datanode_2 ... done
Starting datanode_3 ... done
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is not available on datanode_1 yet
Port 9858 is available on datanode_1
Port 9858 is available on datanode_2
Port 9858 is available on datanode_3
Stopping ozone-topology_datanode_6_1 ... 
Stopping ozone-topology_datanode_4_1 ... 
Stopping ozone-topology_datanode_5_1 ... 
Stopping ozone-topology_datanode_4_1 ... done
Stopping ozone-topology_datanode_5_1 ... done
Stopping ozone-topology_datanode_6_1 ... done
==============================================================================
readdata-second-half :: Smoketest ozone cluster startup                       
==============================================================================
Read data from previously created key                                 | PASS |
------------------------------------------------------------------------------
readdata-second-half :: Smoketest ozone cluster startup               | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozone-topology/result/robot-6.xml
Stopping ozone-topology_datanode_1_1 ... 
Stopping ozone-topology_recon_1      ... 
Stopping ozone-topology_datanode_3_1 ... 
Stopping ozone-topology_datanode_2_1 ... 
Stopping ozone-topology_scm_1        ... 
Stopping ozone-topology_om_1         ... 
Stopping ozone-topology_recon_1      ... done
Stopping ozone-topology_datanode_3_1 ... done
Stopping ozone-topology_datanode_2_1 ... done
Stopping ozone-topology_datanode_1_1 ... done
Stopping ozone-topology_om_1         ... done
Stopping ozone-topology_scm_1        ... done
Removing ozone-topology_datanode_6_1 ... 
Removing ozone-topology_datanode_4_1 ... 
Removing ozone-topology_datanode_1_1 ... 
Removing ozone-topology_recon_1      ... 
Removing ozone-topology_datanode_3_1 ... 
Removing ozone-topology_datanode_2_1 ... 
Removing ozone-topology_scm_1        ... 
Removing ozone-topology_datanode_5_1 ... 
Removing ozone-topology_om_1         ... 
Removing ozone-topology_datanode_6_1 ... done
Removing ozone-topology_datanode_5_1 ... done
Removing ozone-topology_datanode_2_1 ... done
Removing ozone-topology_datanode_4_1 ... done
Removing ozone-topology_datanode_3_1 ... done
Removing ozone-topology_scm_1        ... done
Removing ozone-topology_datanode_1_1 ... done
Removing ozone-topology_recon_1      ... done
Removing ozone-topology_om_1         ... done
Removing network ozone-topology_net
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology.xml
removed 'ozone-topology/result/robot-1.xml'
removed 'ozone-topology/result/robot-2.xml'
removed 'ozone-topology/result/robot-3.xml'
removed 'ozone-topology/result/robot-4.xml'
removed 'ozone-topology/result/robot-5.xml'
removed 'ozone-topology/result/robot-6.xml'
renamed 'ozone-topology/result/dn-audit-40aba79a961b.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology/dn-audit-40aba79a961b.log'
renamed 'ozone-topology/result/dn-audit-df4221a42cee.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology/dn-audit-df4221a42cee.log'
renamed 'ozone-topology/result/dn-audit-f54bacab2c94.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology/dn-audit-f54bacab2c94.log'
renamed 'ozone-topology/result/docker-ozone-topology_datanode_1_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology_datanode_1_1.log'
renamed 'ozone-topology/result/docker-ozone-topology_datanode_2_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology_datanode_2_1.log'
renamed 'ozone-topology/result/docker-ozone-topology_datanode_3_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology_datanode_3_1.log'
renamed 'ozone-topology/result/docker-ozone-topology_datanode_4_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology_datanode_4_1.log'
renamed 'ozone-topology/result/docker-ozone-topology_datanode_5_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology_datanode_5_1.log'
renamed 'ozone-topology/result/docker-ozone-topology_datanode_6_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology_datanode_6_1.log'
renamed 'ozone-topology/result/docker-ozone-topology_om_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology_om_1.log'
renamed 'ozone-topology/result/docker-ozone-topology_recon_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology_recon_1.log'
renamed 'ozone-topology/result/docker-ozone-topology_scm_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology_scm_1.log'
renamed 'ozone-topology/result/om-audit-2216c0a6f818.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology/om-audit-2216c0a6f818.log'
renamed 'ozone-topology/result/scm-audit-6139488f101f.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology/scm-audit-6139488f101f.log'
Executing test ozonescripts/test.sh
Removing network ozonescripts_default
Network ozonescripts_default not found.
Creating network "ozonescripts_default" with the default driver
Building datanode
#0 building with "default" instance using docker driver

#1 [internal] load .dockerignore
#1 transferring context: 2B done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile
#2 transferring dockerfile: 1.67kB done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/apache/ozone-runner:20230615-1
#3 DONE 0.0s

#4 [internal] load build context
#4 transferring context: 6.74kB done
#4 DONE 0.0s

#5 [ 1/14] FROM docker.io/apache/ozone-runner:20230615-1
#5 DONE 0.2s

#6 [ 2/14] RUN sudo yum install -y openssh-clients openssh-server
#6 0.278 Loaded plugins: fastestmirror, ovl
#6 0.358 Determining fastest mirrors
#6 3.251  * base: centos.mirror.shastacoe.net
#6 3.252  * epel: codingflyboy.mm.fcix.net
#6 3.253  * extras: mirror.sfo12.us.leaseweb.net
#6 3.253  * updates: mirrors.advancedhosters.com
#6 10.46 Resolving Dependencies
#6 10.46 --> Running transaction check
#6 10.46 ---> Package openssh-clients.x86_64 0:7.4p1-23.el7_9 will be installed
#6 10.47 --> Processing Dependency: openssh = 7.4p1-23.el7_9 for package: openssh-clients-7.4p1-23.el7_9.x86_64
#6 10.63 --> Processing Dependency: fipscheck-lib(x86-64) >= 1.3.0 for package: openssh-clients-7.4p1-23.el7_9.x86_64
#6 10.63 --> Processing Dependency: libfipscheck.so.1()(64bit) for package: openssh-clients-7.4p1-23.el7_9.x86_64
#6 10.63 --> Processing Dependency: libedit.so.0()(64bit) for package: openssh-clients-7.4p1-23.el7_9.x86_64
#6 10.63 ---> Package openssh-server.x86_64 0:7.4p1-23.el7_9 will be installed
#6 10.64 --> Processing Dependency: libwrap.so.0()(64bit) for package: openssh-server-7.4p1-23.el7_9.x86_64
#6 10.64 --> Running transaction check
#6 10.64 ---> Package fipscheck-lib.x86_64 0:1.4.1-6.el7 will be installed
#6 10.64 --> Processing Dependency: /usr/bin/fipscheck for package: fipscheck-lib-1.4.1-6.el7.x86_64
#6 10.64 ---> Package libedit.x86_64 0:3.0-12.20121213cvs.el7 will be installed
#6 10.64 ---> Package openssh.x86_64 0:7.4p1-23.el7_9 will be installed
#6 10.64 ---> Package tcp_wrappers-libs.x86_64 0:7.6-77.el7 will be installed
#6 10.64 --> Running transaction check
#6 10.64 ---> Package fipscheck.x86_64 0:1.4.1-6.el7 will be installed
#6 10.72 --> Finished Dependency Resolution
#6 10.72 
#6 10.72 Dependencies Resolved
#6 10.72 
#6 10.72 ================================================================================
#6 10.72  Package               Arch       Version                     Repository   Size
#6 10.72 ================================================================================
#6 10.72 Installing:
#6 10.72  openssh-clients       x86_64     7.4p1-23.el7_9              updates     655 k
#6 10.72  openssh-server        x86_64     7.4p1-23.el7_9              updates     459 k
#6 10.72 Installing for dependencies:
#6 10.72  fipscheck             x86_64     1.4.1-6.el7                 base         21 k
#6 10.72  fipscheck-lib         x86_64     1.4.1-6.el7                 base         11 k
#6 10.72  libedit               x86_64     3.0-12.20121213cvs.el7      base         92 k
#6 10.72  openssh               x86_64     7.4p1-23.el7_9              updates     510 k
#6 10.72  tcp_wrappers-libs     x86_64     7.6-77.el7                  base         66 k
#6 10.72 
#6 10.72 Transaction Summary
#6 10.72 ================================================================================
#6 10.72 Install  2 Packages (+5 Dependent packages)
#6 10.72 
#6 10.72 Total download size: 1.8 M
#6 10.72 Installed size: 5.8 M
#6 10.72 Downloading packages:
#6 11.68 --------------------------------------------------------------------------------
#6 11.68 Total                                              1.9 MB/s | 1.8 MB  00:00     
#6 11.68 Running transaction check
#6 11.69 Running transaction test
#6 11.70 Transaction test succeeded
#6 11.70 Running transaction
#6 11.72   Installing : fipscheck-1.4.1-6.el7.x86_64                                 1/7 
#6 11.73   Installing : fipscheck-lib-1.4.1-6.el7.x86_64                             2/7 
#6 12.06   Installing : openssh-7.4p1-23.el7_9.x86_64                                3/7 
#6 12.07   Installing : tcp_wrappers-libs-7.6-77.el7.x86_64                          4/7 
#6 12.23   Installing : libedit-3.0-12.20121213cvs.el7.x86_64                        5/7 
#6 12.43   Installing : openssh-clients-7.4p1-23.el7_9.x86_64                        6/7 
#6 12.63   Installing : openssh-server-7.4p1-23.el7_9.x86_64                         7/7 
#6 12.77   Verifying  : fipscheck-lib-1.4.1-6.el7.x86_64                             1/7 
#6 12.78   Verifying  : openssh-7.4p1-23.el7_9.x86_64                                2/7 
#6 12.78   Verifying  : fipscheck-1.4.1-6.el7.x86_64                                 3/7 
#6 12.79   Verifying  : libedit-3.0-12.20121213cvs.el7.x86_64                        4/7 
#6 12.79   Verifying  : tcp_wrappers-libs-7.6-77.el7.x86_64                          5/7 
#6 12.79   Verifying  : openssh-clients-7.4p1-23.el7_9.x86_64                        6/7 
#6 12.80   Verifying  : openssh-server-7.4p1-23.el7_9.x86_64                         7/7 
#6 12.82 
#6 12.82 Installed:
#6 12.82   openssh-clients.x86_64 0:7.4p1-23.el7_9                                       
#6 12.82   openssh-server.x86_64 0:7.4p1-23.el7_9                                        
#6 12.82 
#6 12.82 Dependency Installed:
#6 12.82   fipscheck.x86_64 0:1.4.1-6.el7            fipscheck-lib.x86_64 0:1.4.1-6.el7  
#6 12.82   libedit.x86_64 0:3.0-12.20121213cvs.el7   openssh.x86_64 0:7.4p1-23.el7_9     
#6 12.82   tcp_wrappers-libs.x86_64 0:7.6-77.el7    
#6 12.82 
#6 12.82 Complete!
#6 DONE 13.3s

#7 [ 3/14] RUN sudo ssh-keygen -A
#7 0.204 ssh-keygen: generating new host keys: RSA1 RSA DSA ECDSA ED25519 
#7 DONE 0.3s

#8 [ 4/14] RUN sudo mkdir -p /run/sshd
#8 DONE 0.3s

#9 [ 5/14] RUN sudo sed -i "s/.*UsePrivilegeSeparation.*/UsePrivilegeSeparation no/g" /etc/ssh/sshd_config
#9 DONE 0.3s

#10 [ 6/14] RUN sudo sed -i "s/.*PermitUserEnvironment.*/PermitUserEnvironment yes/g" /etc/ssh/sshd_config
#10 DONE 0.2s

#11 [ 7/14] RUN sudo sed 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd
#11 DONE 0.2s

#12 [ 8/14] RUN sudo usermod -d /opt hadoop
#12 DONE 0.2s

#13 [ 9/14] ADD .ssh /opt/.ssh
#13 DONE 0.0s

#14 [10/14] RUN sudo chown -R hadoop /opt/.ssh
#14 DONE 0.2s

#15 [11/14] RUN sudo chown hadoop /opt
#15 DONE 0.3s

#16 [12/14] RUN sudo chmod 600 /opt/.ssh/*
#16 DONE 0.2s

#17 [13/14] RUN sudo chmod 700 /opt/.ssh
#17 DONE 0.3s

#18 [14/14] RUN sudo sh -c 'echo "export JAVA_HOME=/usr/lib/jvm/jre/" >> /etc/profile'
#18 DONE 0.3s

#19 exporting to image
#19 exporting layers
#19 exporting layers 4.1s done
#19 writing image sha256:a966915b138f64aff521a0c14c22c187b7eb2fc26e77b13eefbe2c12ee1e769d done
#19 naming to docker.io/library/ozone-runner-scripts:20230615-1 done
#19 DONE 4.1s
Image for service datanode was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Creating ozonescripts_om_1 ... 
Creating ozonescripts_scm_1 ... 
Creating ozonescripts_datanode_1 ... 
Creating ozonescripts_om_1       ... done
Creating ozonescripts_datanode_1 ... done
Creating ozonescripts_scm_1      ... done
Port 22 is available on scm
Port 22 is available on om
Port 22 is available on datanode
No OM HA service, no need to wait
+ docker-compose ps
+ grep datanode
+ xargs -n1 docker inspect --format '{{ .Config.Hostname }}'
+ awk '{print $1}'
+ docker-compose ps
+ grep ozonescripts
+ xargs -I CONTAINER -n1 docker exec CONTAINER cp /opt/hadoop/etc/hadoop/workers /etc/hadoop/workers
+ awk '{print $1}'
+ docker-compose exec -T scm /opt/hadoop/bin/ozone scm --init
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-12-12 06:26:08,243 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = b06dd36b93de/172.19.0.4
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/okio-3.4.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.0.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/23104c258f8208874e9c997c94fb44b89add30d2 ; compiled by 'runner' on 2023-12-12T05:52Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=false, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=4MB, dfs.container.ratis.segment.size=64MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.ksm.address=ksm, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=5GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=3, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.server.default.replication=1, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-12-12 06:26:08,250 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-12-12 06:26:08,280 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-12 06:26:08,418 [main] INFO reflections.Reflections: Reflections took 110 ms to scan 3 urls, producing 134 keys and 291 values 
2023-12-12 06:26:08,464 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2023-12-12 06:26:08,469 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-12-12 06:26:08,569 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2023-12-12 06:26:08,612 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-12-12 06:26:08,613 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2023-12-12 06:26:08,614 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-12-12 06:26:08,614 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2023-12-12 06:26:08,614 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2023-12-12 06:26:08,614 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2023-12-12 06:26:08,615 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2023-12-12 06:26:08,617 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 06:26:08,618 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-12-12 06:26:08,619 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-12-12 06:26:08,626 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-12-12 06:26:08,629 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-12-12 06:26:08,630 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-12-12 06:26:08,769 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2023-12-12 06:26:08,771 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2023-12-12 06:26:08,771 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2023-12-12 06:26:08,772 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-12-12 06:26:08,775 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-12-12 06:26:08,776 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2023-12-12 06:26:08,776 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2023-12-12 06:26:08,782 [main] INFO server.RaftServer: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8: addNew group-6BFD5C0BC93B:[002c5afd-2776-4b1f-85ab-1ed86e64b0b8|b06dd36b93de:9894] returns group-6BFD5C0BC93B:java.util.concurrent.CompletableFuture@301d8120[Not completed]
2023-12-12 06:26:08,795 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServer$Division: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8: new RaftServerImpl for group-6BFD5C0BC93B:[002c5afd-2776-4b1f-85ab-1ed86e64b0b8|b06dd36b93de:9894] with SCMStateMachine:uninitialized
2023-12-12 06:26:08,796 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2023-12-12 06:26:08,797 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2023-12-12 06:26:08,797 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2023-12-12 06:26:08,797 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2023-12-12 06:26:08,797 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-12-12 06:26:08,798 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2023-12-12 06:26:08,798 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2023-12-12 06:26:08,802 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServer$Division: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B: ConfigurationManager, init=-1: peers:[002c5afd-2776-4b1f-85ab-1ed86e64b0b8|b06dd36b93de:9894]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-12-12 06:26:08,808 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2023-12-12 06:26:08,811 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2023-12-12 06:26:08,813 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2023-12-12 06:26:08,814 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2023-12-12 06:26:08,817 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2023-12-12 06:26:08,818 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2023-12-12 06:26:08,823 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2023-12-12 06:26:08,901 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-12-12 06:26:08,903 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-12-12 06:26:08,903 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2023-12-12 06:26:08,904 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2023-12-12 06:26:08,904 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2023-12-12 06:26:08,904 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2023-12-12 06:26:08,906 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2023-12-12 06:26:08,906 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2023-12-12 06:26:08,907 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-12-12 06:26:08,914 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/e242858a-b2ee-403b-b7b9-6bfd5c0bc93b does not exist. Creating ...
2023-12-12 06:26:08,923 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/e242858a-b2ee-403b-b7b9-6bfd5c0bc93b/in_use.lock acquired by nodename 38@b06dd36b93de
2023-12-12 06:26:08,931 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/e242858a-b2ee-403b-b7b9-6bfd5c0bc93b has been successfully formatted.
2023-12-12 06:26:08,935 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2023-12-12 06:26:08,942 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2023-12-12 06:26:08,942 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 06:26:08,944 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-12-12 06:26:08,945 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2023-12-12 06:26:08,949 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-12-12 06:26:08,954 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2023-12-12 06:26:08,954 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-12-12 06:26:08,954 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 06:26:08,957 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO util.AwaitToRun: Thread[002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-cacheEviction-AwaitToRun,5,main] started
2023-12-12 06:26:08,961 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/e242858a-b2ee-403b-b7b9-6bfd5c0bc93b
2023-12-12 06:26:08,962 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-12-12 06:26:08,963 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2023-12-12 06:26:08,964 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-12-12 06:26:08,965 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2023-12-12 06:26:08,966 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2023-12-12 06:26:08,967 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2023-12-12 06:26:08,967 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-12-12 06:26:08,968 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-12-12 06:26:08,970 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2023-12-12 06:26:08,977 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-12 06:26:08,980 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2023-12-12 06:26:08,980 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2023-12-12 06:26:08,980 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2023-12-12 06:26:08,986 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-12-12 06:26:08,986 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-12-12 06:26:08,991 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServer$Division: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B: start as a follower, conf=-1: peers:[002c5afd-2776-4b1f-85ab-1ed86e64b0b8|b06dd36b93de:9894]|listeners:[], old=null
2023-12-12 06:26:08,992 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServer$Division: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-12-12 06:26:08,993 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO impl.RoleInfo: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8: start 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-FollowerState
2023-12-12 06:26:08,993 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-12-12 06:26:08,994 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-12-12 06:26:08,995 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6BFD5C0BC93B,id=002c5afd-2776-4b1f-85ab-1ed86e64b0b8
2023-12-12 06:26:08,997 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2023-12-12 06:26:08,998 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-12-12 06:26:08,998 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2023-12-12 06:26:08,998 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2023-12-12 06:26:08,999 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2023-12-12 06:26:09,003 [main] INFO server.RaftServer: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8: start RPC server
2023-12-12 06:26:09,036 [main] INFO server.GrpcService: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8: GrpcService started, listening on 9894
2023-12-12 06:26:09,037 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-002c5afd-2776-4b1f-85ab-1ed86e64b0b8: Started
2023-12-12 06:26:14,182 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-FollowerState] INFO impl.FollowerState: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5188723329ns, electionTimeout:5187ms
2023-12-12 06:26:14,182 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-FollowerState] INFO impl.RoleInfo: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8: shutdown 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-FollowerState
2023-12-12 06:26:14,182 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-FollowerState] INFO server.RaftServer$Division: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-12-12 06:26:14,184 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2023-12-12 06:26:14,184 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-FollowerState] INFO impl.RoleInfo: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8: start 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1
2023-12-12 06:26:14,187 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO impl.LeaderElection: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[002c5afd-2776-4b1f-85ab-1ed86e64b0b8|b06dd36b93de:9894]|listeners:[], old=null
2023-12-12 06:26:14,188 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO impl.LeaderElection: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2023-12-12 06:26:14,190 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO impl.LeaderElection: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[002c5afd-2776-4b1f-85ab-1ed86e64b0b8|b06dd36b93de:9894]|listeners:[], old=null
2023-12-12 06:26:14,190 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO impl.LeaderElection: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2023-12-12 06:26:14,190 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO impl.RoleInfo: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8: shutdown 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1
2023-12-12 06:26:14,190 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO server.RaftServer$Division: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-12-12 06:26:14,194 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2023-12-12 06:26:14,197 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2023-12-12 06:26:14,197 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2023-12-12 06:26:14,200 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2023-12-12 06:26:14,200 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2023-12-12 06:26:14,200 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2023-12-12 06:26:14,205 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2023-12-12 06:26:14,207 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2023-12-12 06:26:14,207 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2023-12-12 06:26:14,207 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2023-12-12 06:26:14,207 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-12-12 06:26:14,208 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO impl.RoleInfo: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8: start 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderStateImpl
2023-12-12 06:26:14,208 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO server.RaftServer$Division: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B: set firstElectionSinceStartup to false for becomeLeader
2023-12-12 06:26:14,208 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO server.RaftServer$Division: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B: change Leader from null to 002c5afd-2776-4b1f-85ab-1ed86e64b0b8 at term 1 for becomeLeader, leader elected after 5400ms
2023-12-12 06:26:14,225 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-SegmentedRaftLogWorker: Starting segment from index:0
2023-12-12 06:26:14,240 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderElection1] INFO server.RaftServer$Division: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B: set configuration 0: peers:[002c5afd-2776-4b1f-85ab-1ed86e64b0b8|b06dd36b93de:9894]|listeners:[], old=null
2023-12-12 06:26:14,278 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/e242858a-b2ee-403b-b7b9-6bfd5c0bc93b/current/log_inprogress_0
2023-12-12 06:26:14,283 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-StateMachineUpdater] INFO server.RaftServer$Division: leader is ready since appliedIndex == 0 >= startIndex == 0
2023-12-12 06:26:15,039 [main] INFO server.RaftServer: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8: close
2023-12-12 06:26:15,040 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServer$Division: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B: shutdown
2023-12-12 06:26:15,040 [main] INFO server.GrpcService: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8: shutdown server GrpcServerProtocolService now
2023-12-12 06:26:15,040 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6BFD5C0BC93B,id=002c5afd-2776-4b1f-85ab-1ed86e64b0b8
2023-12-12 06:26:15,040 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO impl.RoleInfo: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8: shutdown 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-LeaderStateImpl
2023-12-12 06:26:15,053 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO impl.PendingRequests: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-PendingRequests: sendNotLeaderResponses
2023-12-12 06:26:15,057 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-StateMachineUpdater] INFO impl.StateMachineUpdater: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-StateMachineUpdater: Took a snapshot at index 0
2023-12-12 06:26:15,057 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-StateMachineUpdater] INFO impl.StateMachineUpdater: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-12-12 06:26:15,059 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO impl.StateMachineUpdater: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-StateMachineUpdater: set stopIndex = 0
2023-12-12 06:26:15,059 [main] INFO server.GrpcService: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8: shutdown server GrpcServerProtocolService successfully
2023-12-12 06:26:15,062 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO server.RaftServer$Division: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B: applyIndex: 0
2023-12-12 06:26:15,062 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-cacheEviction-AwaitToRun] INFO util.AwaitToRun: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2023-12-12 06:26:15,282 [002c5afd-2776-4b1f-85ab-1ed86e64b0b8-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 002c5afd-2776-4b1f-85ab-1ed86e64b0b8@group-6BFD5C0BC93B-SegmentedRaftLogWorker close()
2023-12-12 06:26:15,283 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-002c5afd-2776-4b1f-85ab-1ed86e64b0b8: Stopped
2023-12-12 06:26:15,286 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-12 06:26:15,289 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-e242858a-b2ee-403b-b7b9-6bfd5c0bc93b; layoutVersion=7; scmId=002c5afd-2776-4b1f-85ab-1ed86e64b0b8
2023-12-12 06:26:15,290 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at b06dd36b93de/172.19.0.4
************************************************************/
+ docker-compose exec -T scm /opt/hadoop/sbin/start-ozone.sh
Starting datanodes
f61fb69e48f2: Warning: Permanently added 'f61fb69e48f2,172.19.0.3' (ECDSA) to the list of known hosts.
f61fb69e48f2: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
f61fb69e48f2: WARNING: /opt/hadoop/logs does not exist. Creating.
Starting Ozone Manager nodes [om]
om: Warning: Permanently added 'om,172.19.0.2' (ECDSA) to the list of known hosts.
om: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
Starting storage container manager nodes [scm]
scm: Warning: Permanently added 'scm,172.19.0.4' (ECDSA) to the list of known hosts.
scm: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
+ sleep 10
+ docker-compose exec -T om /opt/hadoop/bin/ozone om --init
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-12-12 06:26:39,625 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting OzoneManager
STARTUP_MSG:   host = 774ca9e9fbd4/172.19.0.2
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.61.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/grpc-util-1.58.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/joda-time-2.12.5.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.61.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.22.0.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.61.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.58.0.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.61.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.58.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.4.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/okio-3.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.58.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.61.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.61.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.16.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.58.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.26.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.58.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.58.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.23.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.4.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.61.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.0.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/23104c258f8208874e9c997c94fb44b89add30d2 ; compiled by 'runner' on 2023-12-12T05:52Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=false, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=4MB, dfs.container.ratis.segment.size=64MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.du.refresh.period=1h, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.ksm.address=ksm, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.client.rpc.timeout=15m, ozone.om.client.trash.core.pool.size=5, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.group.rights=ALL, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.port=8981, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.ha.raft.server.log.appender.wait-time.min=0ms, ozone.om.ha.raft.server.retrycache.expirytime=300s, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.init.default.layout.version=-1, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.finalization.ratis.based.timeout=30s, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.user.rights=ALL, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=5GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=3, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.server.default.replication=1, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-12-12 06:26:39,633 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-12-12 06:26:40,147 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
2023-12-12 06:26:40,279 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2023-12-12 06:26:40,295 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.19.0.2:9862
2023-12-12 06:26:40,295 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2023-12-12 06:26:40,295 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
2023-12-12 06:26:40,304 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-12 06:26:40,365 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.19.0.4:9863]
OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-e242858a-b2ee-403b-b7b9-6bfd5c0bc93b;layoutVersion=6
2023-12-12 06:26:40,606 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down OzoneManager at 774ca9e9fbd4/172.19.0.2
************************************************************/
+ docker-compose exec -T scm /opt/hadoop/sbin/start-ozone.sh
Starting datanodes
f61fb69e48f2: Warning: Permanently added 'f61fb69e48f2,172.19.0.3' (ECDSA) to the list of known hosts.
f61fb69e48f2: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
f61fb69e48f2: datanode is running as process 94.  Stop it first.
Starting Ozone Manager nodes [om]
om: Warning: Permanently added 'om,172.19.0.2' (ECDSA) to the list of known hosts.
om: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
Starting storage container manager nodes [scm]
scm: Warning: Permanently added 'scm,172.19.0.4' (ECDSA) to the list of known hosts.
scm: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm: scm is running as process 721.  Stop it first.
    PID TTY      STAT   TIME COMMAND
      1 ?        Ss     0:00 /usr/local/bin/dumb-init -- entrypoint.sh sudo /usr/sbin/sshd -D
      7 ?        Ss     0:00 sudo /usr/sbin/sshd -D
     13 ?        S      0:00 /usr/sbin/sshd -D
     94 ?        Sl     0:11 /usr/lib/jvm/jre/bin/java -Dproc_datanode -Djava.net.preferIPv4Stack=true -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dlog4j.configurationFile=/etc/hadoop/dn-audit-log4j2.properties,/etc/hadoop/dn-container-log4j2.properties -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false --add-opens java.base/java.nio=ALL-UNNAMED -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=ozone-hadoop-datanode-f61fb69e48f2.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.ozone.HddsDatanodeService
    325 ?        Rs     0:00 ps xa
    PID TTY      STAT   TIME COMMAND
      1 ?        Ss     0:00 /usr/local/bin/dumb-init -- entrypoint.sh sudo /usr/sbin/sshd -D
      8 ?        Ss     0:00 sudo /usr/sbin/sshd -D
     14 ?        S      0:00 /usr/sbin/sshd -D
    327 ?        Sl     0:12 /usr/lib/jvm/jre/bin/java -Dproc_om -Djava.net.preferIPv4Stack=true -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false -Dlog4j.configurationFile=/etc/hadoop/om-audit-log4j2.properties --add-opens java.base/java.nio=ALL-UNNAMED -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=ozone-hadoop-om-774ca9e9fbd4.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.ozone.om.OzoneManagerStarter
    432 ?        Rs     0:00 ps xa
    PID TTY      STAT   TIME COMMAND
      1 ?        Ss     0:00 /usr/local/bin/dumb-init -- entrypoint.sh sudo /usr/sbin/sshd -D
      6 ?        Ss     0:00 sudo /usr/sbin/sshd -D
     12 ?        S      0:00 /usr/sbin/sshd -D
    721 ?        Sl     0:12 /usr/lib/jvm/jre/bin/java -Dproc_scm -Djava.net.preferIPv4Stack=true -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false -Dlog4j.configurationFile=/etc/hadoop/scm-audit-log4j2.properties --add-opens java.base/java.nio=ALL-UNNAMED -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=ozone-hadoop-scm-b06dd36b93de.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter
   1717 ?        Rs     0:00 ps xa
==============================================================================
Single Node :: Smoketest for one datanode                                     
==============================================================================
Basic Freon smoketest for one datanode                                | PASS |
------------------------------------------------------------------------------
Single Node :: Smoketest for one datanode                             | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonescripts/result/robot-1.xml
==============================================================================
Pipeline :: Test ozone admin pipeline command                                 
==============================================================================
Create pipeline                                                       | PASS |
------------------------------------------------------------------------------
List pipelines                                                        | PASS |
------------------------------------------------------------------------------
List pipeline with json option                                        | PASS |
------------------------------------------------------------------------------
List pipelines with explicit host                                     | PASS |
------------------------------------------------------------------------------
List pipelines with explicit host and json option                     | PASS |
------------------------------------------------------------------------------
Deactivate pipeline                                                   | PASS |
------------------------------------------------------------------------------
Activate pipeline                                                     | PASS |
------------------------------------------------------------------------------
Close pipeline                                                        | PASS |
------------------------------------------------------------------------------
Incomplete command                                                    | PASS |
------------------------------------------------------------------------------
Pipeline :: Test ozone admin pipeline command                         | PASS |
9 tests, 9 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonescripts/result/robot-2.xml
Stopping datanodes
f61fb69e48f2: Warning: Permanently added 'f61fb69e48f2,172.19.0.3' (ECDSA) to the list of known hosts.
f61fb69e48f2: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
Stopping Ozone Manager nodes [om]
om: Warning: Permanently added 'om,172.19.0.2' (ECDSA) to the list of known hosts.
om: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
Stopping storage container manager nodes [scm]
scm: Warning: Permanently added 'scm,172.19.0.4' (ECDSA) to the list of known hosts.
scm: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm: WARNING: scm did not stop gracefully after 60 seconds: Trying to kill with kill -9
Stopping ozonescripts_scm_1      ... 
Stopping ozonescripts_datanode_1 ... 
Stopping ozonescripts_om_1       ... 
Stopping ozonescripts_datanode_1 ... done
Stopping ozonescripts_om_1       ... done
Stopping ozonescripts_scm_1      ... done
Removing ozonescripts_scm_1      ... 
Removing ozonescripts_datanode_1 ... 
Removing ozonescripts_om_1       ... 
Removing ozonescripts_om_1       ... done
Removing ozonescripts_datanode_1 ... done
Removing ozonescripts_scm_1      ... done
Removing network ozonescripts_default
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonescripts.xml
removed 'ozonescripts/result/robot-1.xml'
removed 'ozonescripts/result/robot-2.xml'
renamed 'ozonescripts/result/docker-ozonescripts_datanode_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonescripts/docker-ozonescripts_datanode_1.log'
renamed 'ozonescripts/result/docker-ozonescripts_om_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonescripts/docker-ozonescripts_om_1.log'
renamed 'ozonescripts/result/docker-ozonescripts_scm_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonescripts/docker-ozonescripts_scm_1.log'
renamed 'ozonescripts/result/om-audit-774ca9e9fbd4.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonescripts/om-audit-774ca9e9fbd4.log'
Executing test ozonesecure-ha/test-s3g-virtual-host.sh
Removing network ozonesecure-ha_ozone_net
Network ozonesecure-ha_ozone_net not found.
Creating network "ozonesecure-ha_ozone_net" with the default driver
Pulling kms (apache/hadoop:3.3.6)...
3.3.6: Pulling from apache/hadoop
Digest: sha256:62a22627f35a1bbf29c721192c02fe311c93749cc43d51df01792b2ac40ff144
Status: Downloaded newer image for apache/hadoop:3.3.6
Pulling kdc (apache/ozone-testkrb5:20230318-1)...
20230318-1: Pulling from apache/ozone-testkrb5
Digest: sha256:6a7eeac1ebd12e8968e34ab93fb8d21f2b92ae52bc0a85b662a2d41065f05d3a
Status: Downloaded newer image for apache/ozone-testkrb5:20230318-1
Creating ozonesecure-ha_datanode1_1 ... 
Creating ozonesecure-ha_recon_1     ... 
Creating ozonesecure-ha_om1_1       ... 
Creating ozonesecure-ha_httpfs_1    ... 
Creating ozonesecure-ha_kms_1       ... 
Creating ozonesecure-ha_datanode3_1 ... 
Creating ozonesecure-ha_om3_1       ... 
Creating ozonesecure-ha_s3g_1       ... 
Creating ozonesecure-ha_scm2.org_1  ... 
Creating ozonesecure-ha_kdc_1       ... 
Creating ozonesecure-ha_datanode2_1 ... 
Creating ozonesecure-ha_om2_1       ... 
Creating ozonesecure-ha_scm3.org_1  ... 
Creating ozonesecure-ha_scm1.org_1  ... 
Creating ozonesecure-ha_recon_1     ... done
Creating ozonesecure-ha_om1_1       ... done
Creating ozonesecure-ha_datanode1_1 ... done
Creating ozonesecure-ha_httpfs_1    ... done
Creating ozonesecure-ha_om3_1       ... done
Creating ozonesecure-ha_datanode3_1 ... done
Creating ozonesecure-ha_kms_1       ... done
Creating ozonesecure-ha_om2_1       ... done
Creating ozonesecure-ha_kdc_1       ... done
Creating ozonesecure-ha_s3g_1       ... done
Creating ozonesecure-ha_datanode2_1 ... done
Creating ozonesecure-ha_scm3.org_1  ... done
Creating ozonesecure-ha_scm1.org_1  ... done
Creating ozonesecure-ha_scm2.org_1  ... done
Port 88 is available on kdc
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is not available on scm1.org yet
Port 9860 is available on scm1.org
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 239
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 238
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 237
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 236
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 235
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 234
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 233
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 232
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 231
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 230
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 229
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 228
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 227
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 226
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 225
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 224
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 223
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 222
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 221
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 220
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 219
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 218
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 217
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 216
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 215
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 214
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 213
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 212
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 211
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 210
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 209
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 208
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 207
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 206
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 205
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 204
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 203
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 202
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 201
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 200
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 199
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 198
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 197
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 196
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 195
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 194
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 193
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 192
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 191
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 190
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 189
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 188
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 187
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 186
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 185
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 184
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 183
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 182
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 181
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 180
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 179
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 178
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 177
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 176
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 175
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 174
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 173
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 172
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 171
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 170
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 169
SCM is out of safe mode.
Found OM leader for service omservice: om1 : LEADER (om1)
Replaced OM order with om1,om3,om2 in ozonesecure-ha_datanode1_1
Replaced OM order with om1,om3,om2 in ozonesecure-ha_datanode2_1
Replaced OM order with om1,om3,om2 in ozonesecure-ha_datanode3_1
Replaced OM order with om1,om3,om2 in ozonesecure-ha_recon_1
Replaced OM order with om1,om3,om2 in ozonesecure-ha_s3g_1
Replaced OM order with om1,om3,om2 in ozonesecure-ha_scm1.org_1
Replaced OM order with om1,om3,om2 in ozonesecure-ha_scm2.org_1
Replaced OM order with om1,om3,om2 in ozonesecure-ha_scm3.org_1
==============================================================================
s3-virtual-host :: S3 gateway test with aws cli using virtual host style ad...
==============================================================================
File upload and directory list with virtual style addressing          | PASS |
------------------------------------------------------------------------------
s3-virtual-host :: S3 gateway test with aws cli using virtual host... | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonesecure-ha/result/robot-1.xml
Stopping ozonesecure-ha_scm1.org_1  ... 
Stopping ozonesecure-ha_scm3.org_1  ... 
Stopping ozonesecure-ha_scm2.org_1  ... 
Stopping ozonesecure-ha_om2_1       ... 
Stopping ozonesecure-ha_datanode2_1 ... 
Stopping ozonesecure-ha_kdc_1       ... 
Stopping ozonesecure-ha_s3g_1       ... 
Stopping ozonesecure-ha_datanode3_1 ... 
Stopping ozonesecure-ha_om3_1       ... 
Stopping ozonesecure-ha_httpfs_1    ... 
Stopping ozonesecure-ha_kms_1       ... 
Stopping ozonesecure-ha_recon_1     ... 
Stopping ozonesecure-ha_om1_1       ... 
Stopping ozonesecure-ha_datanode1_1 ... 
Stopping ozonesecure-ha_kdc_1       ... done
Stopping ozonesecure-ha_kms_1       ... done
Stopping ozonesecure-ha_httpfs_1    ... done
Stopping ozonesecure-ha_recon_1     ... done
Stopping ozonesecure-ha_s3g_1       ... done
Stopping ozonesecure-ha_datanode2_1 ... done
Stopping ozonesecure-ha_datanode1_1 ... done
Stopping ozonesecure-ha_datanode3_1 ... done
Stopping ozonesecure-ha_om3_1       ... done
Stopping ozonesecure-ha_om2_1       ... done
Stopping ozonesecure-ha_om1_1       ... done
Stopping ozonesecure-ha_scm2.org_1  ... done
Stopping ozonesecure-ha_scm3.org_1  ... done
Stopping ozonesecure-ha_scm1.org_1  ... done
Removing ozonesecure-ha_scm1.org_1  ... 
Removing ozonesecure-ha_scm3.org_1  ... 
Removing ozonesecure-ha_scm2.org_1  ... 
Removing ozonesecure-ha_om2_1       ... 
Removing ozonesecure-ha_datanode2_1 ... 
Removing ozonesecure-ha_kdc_1       ... 
Removing ozonesecure-ha_s3g_1       ... 
Removing ozonesecure-ha_datanode3_1 ... 
Removing ozonesecure-ha_om3_1       ... 
Removing ozonesecure-ha_httpfs_1    ... 
Removing ozonesecure-ha_kms_1       ... 
Removing ozonesecure-ha_recon_1     ... 
Removing ozonesecure-ha_om1_1       ... 
Removing ozonesecure-ha_datanode1_1 ... 
Removing ozonesecure-ha_datanode1_1 ... done
Removing ozonesecure-ha_scm1.org_1  ... done
Removing ozonesecure-ha_datanode2_1 ... done
Removing ozonesecure-ha_om3_1       ... done
Removing ozonesecure-ha_scm3.org_1  ... done
Removing ozonesecure-ha_scm2.org_1  ... done
Removing ozonesecure-ha_s3g_1       ... done
Removing ozonesecure-ha_om1_1       ... done
Removing ozonesecure-ha_httpfs_1    ... done
Removing ozonesecure-ha_kdc_1       ... done
Removing ozonesecure-ha_kms_1       ... done
Removing ozonesecure-ha_datanode3_1 ... done
Removing ozonesecure-ha_om2_1       ... done
Removing ozonesecure-ha_recon_1     ... done
Removing network ozonesecure-ha_ozone_net
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha-s3g-virtual-host.xml
removed 'ozonesecure-ha/result/robot-1.xml'
renamed 'ozonesecure-ha/result/dn-audit-bfdf2d5aa37f.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/dn-audit-bfdf2d5aa37f.log'
renamed 'ozonesecure-ha/result/dn-audit-c37d42c0ae58.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/dn-audit-c37d42c0ae58.log'
renamed 'ozonesecure-ha/result/dn-audit-c5f2e7ad6d3c.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/dn-audit-c5f2e7ad6d3c.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha_datanode1_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha_datanode1_1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha_datanode2_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha_datanode2_1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha_datanode3_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha_datanode3_1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha_httpfs_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha_httpfs_1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha_kdc_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha_kdc_1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha_kms_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha_kms_1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha_om1_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha_om1_1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha_om2_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha_om2_1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha_om3_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha_om3_1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha_recon_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha_recon_1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha_s3g_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha_s3g_1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha_scm1.org_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha_scm1.org_1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha_scm2.org_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha_scm2.org_1.log'
renamed 'ozonesecure-ha/result/docker-ozonesecure-ha_scm3.org_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/docker-ozonesecure-ha_scm3.org_1.log'
renamed 'ozonesecure-ha/result/kms-audit.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/kms-audit.log'
renamed 'ozonesecure-ha/result/om-audit-om1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/om-audit-om1.log'
renamed 'ozonesecure-ha/result/om-audit-om2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/om-audit-om2.log'
renamed 'ozonesecure-ha/result/om-audit-om3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/om-audit-om3.log'
renamed 'ozonesecure-ha/result/s3g-audit-s3g.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/s3g-audit-s3g.log'
renamed 'ozonesecure-ha/result/scm-audit-scm1.org.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/scm-audit-scm1.org.log'
renamed 'ozonesecure-ha/result/scm-audit-scm2.org.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/scm-audit-scm2.org.log'
renamed 'ozonesecure-ha/result/scm-audit-scm3.org.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-ha/s3g-virtual-host/scm-audit-scm3.org.log'
Executing test ozonesecure/test-vault.sh
Removing network ozonesecure_default
Network ozonesecure_default not found.
Creating network "ozonesecure_default" with the default driver
Pulling vault (hashicorp/vault:1.13.2)...
1.13.2: Pulling from hashicorp/vault
Digest: sha256:c186e9bff2db0bd61dad70e7733cbfa5a0f8ddee3a6a061f3753060689aa81ab
Status: Downloaded newer image for hashicorp/vault:1.13.2
Creating ozonesecure_om_1 ... 
Creating ozonesecure_vault_1 ... 
Creating ozonesecure_recon_1 ... 
Creating ozonesecure_kdc_1   ... 
Creating ozonesecure_scm_1   ... 
Creating ozonesecure_s3g_1   ... 
Creating ozonesecure_datanode_1 ... 
Creating ozonesecure_datanode_2 ... 
Creating ozonesecure_datanode_3 ... 
Creating ozonesecure_kms_1      ... 
Creating ozonesecure_httpfs_1   ... 
Creating ozonesecure_vault_1    ... done
Creating ozonesecure_kdc_1      ... done
Creating ozonesecure_recon_1    ... done
Creating ozonesecure_om_1       ... done
Creating ozonesecure_scm_1      ... done
Creating ozonesecure_s3g_1      ... done
Creating ozonesecure_datanode_2 ... done
Creating ozonesecure_httpfs_1   ... done
Creating ozonesecure_datanode_1 ... done
Creating ozonesecure_kms_1      ... done
Creating ozonesecure_datanode_3 ... done
Port 88 is available on kdc
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 237
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 236
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 235
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 234
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 233
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 232
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 231
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 230
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 229
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 228
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 227
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 226
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 225
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 224
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 223
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 222
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 221
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 220
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 219
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 218
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 217
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 216
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 215
SCM is out of safe mode.
No OM HA service, no need to wait
==============================================================================
S3                                                                            
==============================================================================
S3.Awss3 :: S3 gateway test with aws cli                                      
==============================================================================
File upload and directory list                                        | PASS |
------------------------------------------------------------------------------
File upload with special chars                                        | PASS |
------------------------------------------------------------------------------
S3.Awss3 :: S3 gateway test with aws cli                              | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
S3.Boto3 :: S3 gateway test with Boto3 Client                                 
==============================================================================
Boto3 Client Test                                                     | PASS |
------------------------------------------------------------------------------
S3.Boto3 :: S3 gateway test with Boto3 Client                         | PASS |
1 test, 1 passed, 0 failed
==============================================================================
S3.Bucketcreate :: S3 gateway test with aws cli                               
==============================================================================
Create new bucket                                                     | PASS |
------------------------------------------------------------------------------
Create bucket which already exists                                    | PASS |
------------------------------------------------------------------------------
Create bucket with invalid bucket name                                | PASS |
------------------------------------------------------------------------------
Create new bucket and check no group ACL                              | PASS |
------------------------------------------------------------------------------
S3.Bucketcreate :: S3 gateway test with aws cli                       | PASS |
4 tests, 4 passed, 0 failed
==============================================================================
S3.Bucketdelete :: S3 gateway test with aws cli                               
==============================================================================
Delete existing bucket                                                | PASS |
------------------------------------------------------------------------------
Delete non-existent bucket                                            | PASS |
------------------------------------------------------------------------------
Delete bucket with incomplete multipart uploads                       | PASS |
------------------------------------------------------------------------------
S3.Bucketdelete :: S3 gateway test with aws cli                       | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
S3.Buckethead :: S3 gateway test with aws cli                                 
==============================================================================
Head Bucket                                                           | PASS |
------------------------------------------------------------------------------
Head Bucket not existent                                              | PASS |
------------------------------------------------------------------------------
S3.Buckethead :: S3 gateway test with aws cli                         | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
S3.Bucketlist :: S3 gateway test with aws cli                                 
==============================================================================
List buckets                                                          | PASS |
------------------------------------------------------------------------------
Get bucket info with Ozone Shell to check the owner field             | PASS |
------------------------------------------------------------------------------
List buckets with empty access id                                     | PASS |
------------------------------------------------------------------------------
S3.Bucketlist :: S3 gateway test with aws cli                         | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
S3.Freon :: S3 gateway test with aws cli                                      
==============================================================================
Run Freon S3BG                                                        | PASS |
------------------------------------------------------------------------------
S3.Freon :: S3 gateway test with aws cli                              | PASS |
1 test, 1 passed, 0 failed
==============================================================================
S3.MultipartUpload :: S3 gateway test with aws cli                            
==============================================================================
Test Multipart Upload With Adjusted Length                            | PASS |
------------------------------------------------------------------------------
Test Multipart Upload                                                 | PASS |
------------------------------------------------------------------------------
Test Multipart Upload Complete                                        | PASS |
------------------------------------------------------------------------------
Test Multipart Upload Complete Entity too small                       | PASS |
------------------------------------------------------------------------------
Test Multipart Upload Complete Invalid part errors and complete mp... | PASS |
------------------------------------------------------------------------------
Test abort Multipart upload                                           | PASS |
------------------------------------------------------------------------------
Test abort Multipart upload with invalid uploadId                     | PASS |
------------------------------------------------------------------------------
Upload part with Incorrect uploadID                                   | PASS |
------------------------------------------------------------------------------
Test list parts                                                       | PASS |
------------------------------------------------------------------------------
Test Multipart Upload with the simplified aws s3 cp API               | FAIL |
1 != 0
------------------------------------------------------------------------------
Test Multipart Upload Put With Copy                                   | PASS |
------------------------------------------------------------------------------
Test Multipart Upload Put With Copy and range                         | PASS |
------------------------------------------------------------------------------
Test Multipart Upload Put With Copy and range with IfModifiedSince    | PASS |
------------------------------------------------------------------------------
Test Multipart Upload list                                            | PASS |
------------------------------------------------------------------------------
S3.MultipartUpload :: S3 gateway test with aws cli                    | FAIL |
14 tests, 13 passed, 1 failed
==============================================================================
S3.Objectcopy :: S3 gateway test with aws cli                                 
==============================================================================
Copy Object Happy Scenario                                            | PASS |
------------------------------------------------------------------------------
Copy Object Where Bucket is not available                             | PASS |
------------------------------------------------------------------------------
Copy Object Where both source and dest are same with change to sto... | PASS |
------------------------------------------------------------------------------
Copy Object Where Key not available                                   | PASS |
------------------------------------------------------------------------------
S3.Objectcopy :: S3 gateway test with aws cli                         | PASS |
4 tests, 4 passed, 0 failed
==============================================================================
S3.Objectcopys3A :: S3 gateway test with aws cli                              
==============================================================================
Put object s3a simulation                                             | PASS |
------------------------------------------------------------------------------
S3.Objectcopys3A :: S3 gateway test with aws cli                      | PASS |
1 test, 1 passed, 0 failed
==============================================================================
S3.Objectdelete :: S3 gateway test with aws cli                               
==============================================================================
Delete file with s3api                                                | PASS |
------------------------------------------------------------------------------
Delete file with s3api, file doesn't exist                            | PASS |
------------------------------------------------------------------------------
Delete dir with s3api                                                 | PASS |
------------------------------------------------------------------------------
Delete file with s3api, file doesn't exist, prefix of a real file     | PASS |
------------------------------------------------------------------------------
Delete file with s3api, bucket doesn't exist                          | PASS |
------------------------------------------------------------------------------
S3.Objectdelete :: S3 gateway test with aws cli                       | PASS |
5 tests, 5 passed, 0 failed
==============================================================================
S3.Objecthead :: S3 gateway test with aws cli                                 
==============================================================================
Head existing object                                                  | PASS |
------------------------------------------------------------------------------
Head object in non existing bucket                                    | PASS |
------------------------------------------------------------------------------
Head object where path is a directory                                 | PASS |
------------------------------------------------------------------------------
Head directory objects                                                | PASS |
------------------------------------------------------------------------------
Head non existing key                                                 | PASS |
------------------------------------------------------------------------------
S3.Objecthead :: S3 gateway test with aws cli                         | PASS |
5 tests, 5 passed, 0 failed
==============================================================================
S3.Objectmultidelete :: S3 gateway test with aws cli                          
==============================================================================
Delete file with multi delete                                         | PASS |
------------------------------------------------------------------------------
S3.Objectmultidelete :: S3 gateway test with aws cli                  | PASS |
1 test, 1 passed, 0 failed
==============================================================================
S3.Objectputget :: S3 gateway test with aws cli                               
==============================================================================
Put object to s3                                                      | PASS |
------------------------------------------------------------------------------
Get object from s3                                                    | PASS |
------------------------------------------------------------------------------
Get object with wrong signature                                       | PASS |
------------------------------------------------------------------------------
Get Partial object from s3 with both start and endoffset              | PASS |
------------------------------------------------------------------------------
Get Partial object from s3 with both start and endoffset(start off... | PASS |
------------------------------------------------------------------------------
Get Partial object from s3 with both start and endoffset(end offse... | PASS |
------------------------------------------------------------------------------
Get Partial object from s3 with only start offset                     | PASS |
------------------------------------------------------------------------------
Get Partial object from s3 with both start and endoffset which are... | PASS |
------------------------------------------------------------------------------
Get Partial object from s3 to get last n bytes                        | PASS |
------------------------------------------------------------------------------
Incorrect values for end and start offset                             | PASS |
------------------------------------------------------------------------------
Zero byte file                                                        | PASS |
------------------------------------------------------------------------------
Create file with user defined metadata                                | PASS |
------------------------------------------------------------------------------
Create file with user defined metadata with gdpr enabled value in ... | PASS |
------------------------------------------------------------------------------
Create file with user defined metadata size larger than 2 KB          | PASS |
------------------------------------------------------------------------------
Create small file and expect ETag (MD5) in a reponse header           | PASS |
------------------------------------------------------------------------------
Download small file end expect ETag (MD5) in a response header        | PASS |
------------------------------------------------------------------------------
Create key with custom etag metadata and expect it won't conflict ... | PASS |
------------------------------------------------------------------------------
Create&Download big file by multipart upload and expect ETag in a ... | PASS |
------------------------------------------------------------------------------
Create key twice with different content and expect different ETags    | PASS |
------------------------------------------------------------------------------
S3.Objectputget :: S3 gateway test with aws cli                       | PASS |
19 tests, 19 passed, 0 failed
==============================================================================
S3.S3 Getsecret :: Test ozone s3 getsecret command                            
==============================================================================
Without OM service ID                                                 | PASS |
------------------------------------------------------------------------------
With OM service ID                                                    | PASS |
duplicate test in non-HA env.
------------------------------------------------------------------------------
S3.S3 Getsecret :: Test ozone s3 getsecret command                    | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
S3.Secretgenerate :: S3 Secret Generate test                                  
==============================================================================
S3 Gateway Generate Secret                                            | PASS |
------------------------------------------------------------------------------
S3 Gateway Generate Secret By Username                                | PASS |
------------------------------------------------------------------------------
S3.Secretgenerate :: S3 Secret Generate test                          | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
S3.Secretrevoke :: S3 Secret Revoke test                                      
==============================================================================
S3 Gateway Revoke Secret                                              | PASS |
------------------------------------------------------------------------------
S3 Gateway Revoke Secret By Username                                  | PASS |
------------------------------------------------------------------------------
S3.Secretrevoke :: S3 Secret Revoke test                              | PASS |
2 tests, 2 passed, 0 failed
==============================================================================
S3.Webui :: S3 gateway web ui test                                            
==============================================================================
S3 Gateway Web UI                                                     | PASS |
------------------------------------------------------------------------------
S3.Webui :: S3 gateway web ui test                                    | PASS |
1 test, 1 passed, 0 failed
==============================================================================
S3                                                                    | FAIL |
72 tests, 71 passed, 1 failed
==============================================================================
Output:  /tmp/smoketest/ozonesecure/result/robot-1.xml
jstack 7 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozonesecure/result/ozonesecure_datanode_1_HddsDatanodeService.stack
jstack 7 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozonesecure/result/ozonesecure_datanode_2_HddsDatanodeService.stack
jstack 7 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozonesecure/result/ozonesecure_datanode_3_HddsDatanodeService.stack
jstack 7 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozonesecure/result/ozonesecure_om_1_OzoneManagerStarter.stack
jstack 7 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozonesecure/result/ozonesecure_recon_1_ReconServer.stack
jstack 6 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozonesecure/result/ozonesecure_s3g_1_Gateway.stack
jstack 6 > /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozonesecure/result/ozonesecure_scm_1_StorageContainerManagerStarter.stack
Stopping ozonesecure_httpfs_1   ... 
Stopping ozonesecure_datanode_3 ... 
Stopping ozonesecure_datanode_1 ... 
Stopping ozonesecure_kms_1      ... 
Stopping ozonesecure_datanode_2 ... 
Stopping ozonesecure_s3g_1      ... 
Stopping ozonesecure_scm_1      ... 
Stopping ozonesecure_om_1       ... 
Stopping ozonesecure_recon_1    ... 
Stopping ozonesecure_kdc_1      ... 
Stopping ozonesecure_vault_1    ... 
Stopping ozonesecure_kms_1      ... done
Stopping ozonesecure_kdc_1      ... done
Stopping ozonesecure_vault_1    ... done
Stopping ozonesecure_httpfs_1   ... done
Stopping ozonesecure_s3g_1      ... done
Stopping ozonesecure_recon_1    ... done
Stopping ozonesecure_datanode_2 ... done
Stopping ozonesecure_datanode_1 ... done
Stopping ozonesecure_datanode_3 ... done
Stopping ozonesecure_om_1       ... done
Stopping ozonesecure_scm_1      ... done
Removing ozonesecure_httpfs_1   ... 
Removing ozonesecure_datanode_3 ... 
Removing ozonesecure_datanode_1 ... 
Removing ozonesecure_kms_1      ... 
Removing ozonesecure_datanode_2 ... 
Removing ozonesecure_s3g_1      ... 
Removing ozonesecure_scm_1      ... 
Removing ozonesecure_om_1       ... 
Removing ozonesecure_recon_1    ... 
Removing ozonesecure_kdc_1      ... 
Removing ozonesecure_vault_1    ... 
Removing ozonesecure_kms_1      ... done
Removing ozonesecure_s3g_1      ... done
Removing ozonesecure_scm_1      ... done
Removing ozonesecure_httpfs_1   ... done
Removing ozonesecure_kdc_1      ... done
Removing ozonesecure_recon_1    ... done
Removing ozonesecure_datanode_3 ... done
Removing ozonesecure_vault_1    ... done
Removing ozonesecure_om_1       ... done
Removing ozonesecure_datanode_2 ... done
Removing ozonesecure_datanode_1 ... done
Removing network ozonesecure_default
ERROR: Test execution of ozonesecure/test-vault.sh is FAILED!!!!
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure-vault.xml
removed 'ozonesecure/result/robot-1.xml'
renamed 'ozonesecure/result/dn-audit-dn.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/dn-audit-dn.log'
renamed 'ozonesecure/result/docker-ozonesecure_datanode_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure_datanode_1.log'
renamed 'ozonesecure/result/docker-ozonesecure_datanode_2.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure_datanode_2.log'
renamed 'ozonesecure/result/docker-ozonesecure_datanode_3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure_datanode_3.log'
renamed 'ozonesecure/result/docker-ozonesecure_httpfs_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure_httpfs_1.log'
renamed 'ozonesecure/result/docker-ozonesecure_kdc_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure_kdc_1.log'
renamed 'ozonesecure/result/docker-ozonesecure_kms_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure_kms_1.log'
renamed 'ozonesecure/result/docker-ozonesecure_om_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure_om_1.log'
renamed 'ozonesecure/result/docker-ozonesecure_recon_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure_recon_1.log'
renamed 'ozonesecure/result/docker-ozonesecure_s3g_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure_s3g_1.log'
renamed 'ozonesecure/result/docker-ozonesecure_scm_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure_scm_1.log'
renamed 'ozonesecure/result/docker-ozonesecure_vault_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/docker-ozonesecure_vault_1.log'
renamed 'ozonesecure/result/kms-audit.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/kms-audit.log'
renamed 'ozonesecure/result/om-audit-om.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/om-audit-om.log'
renamed 'ozonesecure/result/ozonesecure_datanode_1_HddsDatanodeService.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/ozonesecure_datanode_1_HddsDatanodeService.stack'
renamed 'ozonesecure/result/ozonesecure_datanode_2_HddsDatanodeService.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/ozonesecure_datanode_2_HddsDatanodeService.stack'
renamed 'ozonesecure/result/ozonesecure_datanode_3_HddsDatanodeService.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/ozonesecure_datanode_3_HddsDatanodeService.stack'
renamed 'ozonesecure/result/ozonesecure_om_1_OzoneManagerStarter.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/ozonesecure_om_1_OzoneManagerStarter.stack'
renamed 'ozonesecure/result/ozonesecure_recon_1_ReconServer.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/ozonesecure_recon_1_ReconServer.stack'
renamed 'ozonesecure/result/ozonesecure_s3g_1_Gateway.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/ozonesecure_s3g_1_Gateway.stack'
renamed 'ozonesecure/result/ozonesecure_scm_1_StorageContainerManagerStarter.stack' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/ozonesecure_scm_1_StorageContainerManagerStarter.stack'
renamed 'ozonesecure/result/s3g-audit-s3g.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/s3g-audit-s3g.log'
renamed 'ozonesecure/result/scm-audit-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonesecure/vault/scm-audit-scm.log'
Executing test restart/test.sh
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data/dn2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data/scm': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data/dn3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data/dn1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data/s3g': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data/om': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data/recon': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data': Operation not permitted
Removing network restart_net
Network restart_net not found.
Creating network "restart_net" with driver "bridge"
Creating restart_om_1 ... 
Creating restart_s3g_1 ... 
Creating restart_dn2_1 ... 
Creating restart_dn3_1 ... 
Creating restart_dn1_1 ... 
Creating restart_scm_1 ... 
Creating restart_recon_1 ... 
Creating restart_om_1    ... done
Creating restart_s3g_1   ... done
Creating restart_dn1_1   ... done
Creating restart_recon_1 ... done
Creating restart_scm_1   ... done
Creating restart_dn2_1   ... done
Creating restart_dn3_1   ... done
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 238
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 237
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 236
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 235
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 234
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 233
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 232
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 231
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 230
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 229
SCM is out of safe mode.
No OM HA service, no need to wait
==============================================================================
Generate :: Test freon data generation commands                               
==============================================================================
Ozone Client Key Generator                                            | PASS |
------------------------------------------------------------------------------
OM Key Generator                                                      | PASS |
------------------------------------------------------------------------------
OM Bucket Generator                                                   | PASS |
------------------------------------------------------------------------------
Generate :: Test freon data generation commands                       | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-1.xml
==============================================================================
Validate :: Test freon data validation commands                               
==============================================================================
Ozone Client Key Validator                                            | PASS |
------------------------------------------------------------------------------
Validate :: Test freon data validation commands                       | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-2.xml
==============================================================================
Generate-Chunk :: Test freon chunk generation commands                        
==============================================================================
DN Chunk Generator                                                    | PASS |
------------------------------------------------------------------------------
Generate-Chunk :: Test freon chunk generation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-3.xml
==============================================================================
Validate-Chunk :: Test freon chunk validation commands                        
==============================================================================
DN Chunk Validator                                                    | PASS |
------------------------------------------------------------------------------
Validate-Chunk :: Test freon chunk validation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-4.xml
Stopping restart_recon_1 ... 
Stopping restart_dn1_1   ... 
Stopping restart_scm_1   ... 
Stopping restart_dn3_1   ... 
Stopping restart_s3g_1   ... 
Stopping restart_dn2_1   ... 
Stopping restart_om_1    ... 
Stopping restart_s3g_1   ... done
Stopping restart_recon_1 ... done
Stopping restart_dn3_1   ... done
Stopping restart_dn2_1   ... done
Stopping restart_dn1_1   ... done
Stopping restart_om_1    ... done
Stopping restart_scm_1   ... done
Removing restart_recon_1 ... 
Removing restart_dn1_1   ... 
Removing restart_scm_1   ... 
Removing restart_dn3_1   ... 
Removing restart_s3g_1   ... 
Removing restart_dn2_1   ... 
Removing restart_om_1    ... 
Removing restart_scm_1   ... done
Removing restart_om_1    ... done
Removing restart_dn3_1   ... done
Removing restart_recon_1 ... done
Removing restart_dn1_1   ... done
Removing restart_s3g_1   ... done
Removing restart_dn2_1   ... done
Removing network restart_net
Removing network restart_net
Network restart_net not found.
Creating network "restart_net" with driver "bridge"
Creating restart_s3g_1 ... 
Creating restart_dn2_1 ... 
Creating restart_scm_1 ... 
Creating restart_dn1_1 ... 
Creating restart_om_1  ... 
Creating restart_dn3_1 ... 
Creating restart_recon_1 ... 
Creating restart_s3g_1   ... done
Creating restart_scm_1   ... done
Creating restart_om_1    ... done
Creating restart_recon_1 ... done
Creating restart_dn1_1   ... done
Creating restart_dn2_1   ... done
Creating restart_dn3_1   ... done
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is available on scm
SCM is in safe mode. Will retry in 1 sec. Remaining time (sec): 238
SCM is out of safe mode.
No OM HA service, no need to wait
==============================================================================
Validate :: Test freon data validation commands                               
==============================================================================
Ozone Client Key Validator                                            | PASS |
------------------------------------------------------------------------------
Validate :: Test freon data validation commands                       | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-5.xml
==============================================================================
Validate-Chunk :: Test freon chunk validation commands                        
==============================================================================
DN Chunk Validator                                                    | PASS |
------------------------------------------------------------------------------
Validate-Chunk :: Test freon chunk validation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-6.xml
==============================================================================
Generate :: Test freon data generation commands                               
==============================================================================
Ozone Client Key Generator                                            | PASS |
------------------------------------------------------------------------------
OM Key Generator                                                      | PASS |
------------------------------------------------------------------------------
OM Bucket Generator                                                   | PASS |
------------------------------------------------------------------------------
Generate :: Test freon data generation commands                       | PASS |
3 tests, 3 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-7.xml
==============================================================================
Validate :: Test freon data validation commands                               
==============================================================================
Ozone Client Key Validator                                            | PASS |
------------------------------------------------------------------------------
Validate :: Test freon data validation commands                       | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-8.xml
==============================================================================
Generate-Chunk :: Test freon chunk generation commands                        
==============================================================================
DN Chunk Generator                                                    | PASS |
------------------------------------------------------------------------------
Generate-Chunk :: Test freon chunk generation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-9.xml
==============================================================================
Validate-Chunk :: Test freon chunk validation commands                        
==============================================================================
DN Chunk Validator                                                    | PASS |
------------------------------------------------------------------------------
Validate-Chunk :: Test freon chunk validation commands                | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/restart/result/robot-10.xml
Stopping restart_om_1    ... 
Stopping restart_recon_1 ... 
Stopping restart_dn3_1   ... 
Stopping restart_dn1_1   ... 
Stopping restart_dn2_1   ... 
Stopping restart_scm_1   ... 
Stopping restart_s3g_1   ... 
Stopping restart_s3g_1   ... done
Stopping restart_recon_1 ... done
Stopping restart_dn2_1   ... done
Stopping restart_dn3_1   ... done
Stopping restart_dn1_1   ... done
Stopping restart_om_1    ... done
Stopping restart_scm_1   ... done
Removing restart_om_1    ... 
Removing restart_recon_1 ... 
Removing restart_dn3_1   ... 
Removing restart_dn1_1   ... 
Removing restart_dn2_1   ... 
Removing restart_scm_1   ... 
Removing restart_s3g_1   ... 
Removing restart_recon_1 ... done
Removing restart_dn2_1   ... done
Removing restart_dn3_1   ... done
Removing restart_om_1    ... done
Removing restart_s3g_1   ... done
Removing restart_dn1_1   ... done
Removing restart_scm_1   ... done
Removing network restart_net
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart.xml
removed 'restart/result/robot-1.xml'
removed 'restart/result/robot-10.xml'
removed 'restart/result/robot-2.xml'
removed 'restart/result/robot-3.xml'
removed 'restart/result/robot-4.xml'
removed 'restart/result/robot-5.xml'
removed 'restart/result/robot-6.xml'
removed 'restart/result/robot-7.xml'
removed 'restart/result/robot-8.xml'
removed 'restart/result/robot-9.xml'
renamed 'restart/result/dn-audit-2a4189ce9479.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/dn-audit-2a4189ce9479.log'
renamed 'restart/result/dn-audit-475b56f1beba.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/dn-audit-475b56f1beba.log'
renamed 'restart/result/dn-audit-5f536bc29539.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/dn-audit-5f536bc29539.log'
renamed 'restart/result/dn-audit-9500a9568904.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/dn-audit-9500a9568904.log'
renamed 'restart/result/dn-audit-cd8c1d2bf898.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/dn-audit-cd8c1d2bf898.log'
renamed 'restart/result/dn-audit-effaeb041a4a.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/dn-audit-effaeb041a4a.log'
renamed 'restart/result/docker-restart_dn1_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/docker-restart_dn1_1.log'
renamed 'restart/result/docker-restart_dn2_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/docker-restart_dn2_1.log'
renamed 'restart/result/docker-restart_dn3_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/docker-restart_dn3_1.log'
renamed 'restart/result/docker-restart_om_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/docker-restart_om_1.log'
renamed 'restart/result/docker-restart_recon_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/docker-restart_recon_1.log'
renamed 'restart/result/docker-restart_s3g_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/docker-restart_s3g_1.log'
renamed 'restart/result/docker-restart_scm_1.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/docker-restart_scm_1.log'
renamed 'restart/result/om-audit-27eb96bcded3.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/om-audit-27eb96bcded3.log'
renamed 'restart/result/om-audit-dfedcd8458f7.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/om-audit-dfedcd8458f7.log'
renamed 'restart/result/s3g-audit-1440f3f9bf87.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/s3g-audit-1440f3f9bf87.log'
renamed 'restart/result/s3g-audit-1ad0aa599414.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/s3g-audit-1ad0aa599414.log'
renamed 'restart/result/scm-audit-231beb6690c8.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/scm-audit-231beb6690c8.log'
renamed 'restart/result/scm-audit-75391a538852.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/scm-audit-75391a538852.log'
Executing test upgrade/testlib.sh
find: upgrade/result: No such file or directory
mv: cannot stat 'upgrade/result/*': No such file or directory
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/report.html
