Waiting for the service scm1.org:9894
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-12-07 16:44:52,027 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm2.org/10.9.0.15
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.8.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/okio-3.4.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.0.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/961403f2ccf2e58f8159d2b8a478e9865d80c02a ; compiled by 'runner' on 2023-12-07T16:19Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=false, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=4MB, dfs.container.ratis.segment.size=64MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5s, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=10m, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=6, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3, ozone.scm.pipeline.allocated.timeout=2m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=1m, ozone.scm.primordial.node.id=scm1, ozone.scm.ratis.enable=true, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-12-07 16:44:52,037 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-12-07 16:44:52,071 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-07 16:44:52,428 [main] INFO reflections.Reflections: Reflections took 273 ms to scan 3 urls, producing 134 keys and 291 values 
2023-12-07 16:44:52,488 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2023-12-07 16:44:52,503 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-12-07 16:44:52,531 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
2023-12-07 16:44:52,532 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
2023-12-07 16:44:52,893 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2023-12-07 16:44:52,893 [main] INFO server.StorageContainerManager: SCM login successful.
2023-12-07 16:44:54,028 [main] INFO client.SCMCertificateClient: Certificate serial ID set to 329823819739
2023-12-07 16:44:54,294 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 329823819739
             IssuerDN: CN=scm@scm1.org,OU=80d298fa-03d7-48e5-97c8-2742aa8c32f0,O=CID-c0e69b3f-1be0-4713-bc71-64e201c54dc7
           Start Date: Thu Dec 07 00:00:00 UTC 2023
           Final Date: Sun Jan 14 00:00:00 UTC 2029
            SubjectDN: CN=scm-sub@scm2.org,OU=649a6984-f1f7-4d32-87eb-63a4943659c8,O=CID-c0e69b3f-1be0-4713-bc71-64e201c54dc7
           Public Key: RSA Public Key [9e:69:9f:c3:a0:f6:25:91:fb:d7:4f:8d:0b:26:65:ee:1b:7d:ae:8f],[56:66:d1:a4]
        modulus: c40190e6d31606f5270f00f93bc1f1eb07cabe469a7efbaa642e983ef89906b655f88457b090abcf5040aa9ff2009fb1b77dafe6da29c04cd21194cbcba93904ed6c1e7d72d168635fd2ee2286bdb9760292a2bf8cba141df44b5b0aaabd41e298667121512760431e905400e20771e691a470788c7711cd8581f30930ab7ecf5c5eaf288253a9328d62d6c7b0edc1cb4204c9018a8a47d2a6951fab5be6afaf5cf4ebfe8438ed269ada011a9baedf80d75a460bba96e7191c58a8cbcb421bafa7d2018b6b8d78fc1ddda7dc5352cf787c58362d458bb49d5d708b4ae1227c7abbadb2a0f923a9a658be229c2f40669a982ae106f4d4c5240a3c63e662357e85
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 66e70b63e92ea2dedb8c2652bc1de5d1c57c7801
                       d6ff4825dbfdc23b75977dc5fa76a729a7fb51f5
                       552084c5693a895ae5bb9f0f5eefe639109ef49c
                       25ae1b994dc362cb137d2ebea108aff2f492366e
                       aa372da1ca53b2a40f9d296337194498ead80ad0
                       dfbf92e4a62102232bc154eb9b468cbc8e00eaf5
                       1972935d0844a66cec0e2f8b33984880588e5e1b
                       6ea576eb14729c6e8bdfe1fcfcf8296393c78409
                       edc365e7149240d6b3136f73a9c8a7e75c7e89bf
                       6260a0f5acb58de909a469f2fb7d22c53b7f6096
                       1ef57492b773a36f9fad3ccd95920281d46f88a5
                       7d8a260bf79acb1cb214f4c31ccdf310c7da38da
                       fbbb9f90a126e89b04bb05e42659dbd4
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/certificate.crt.
2023-12-07 16:44:54,315 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 329823819739
             IssuerDN: CN=scm@scm1.org,OU=80d298fa-03d7-48e5-97c8-2742aa8c32f0,O=CID-c0e69b3f-1be0-4713-bc71-64e201c54dc7
           Start Date: Thu Dec 07 00:00:00 UTC 2023
           Final Date: Sun Jan 14 00:00:00 UTC 2029
            SubjectDN: CN=scm-sub@scm2.org,OU=649a6984-f1f7-4d32-87eb-63a4943659c8,O=CID-c0e69b3f-1be0-4713-bc71-64e201c54dc7
           Public Key: RSA Public Key [9e:69:9f:c3:a0:f6:25:91:fb:d7:4f:8d:0b:26:65:ee:1b:7d:ae:8f],[56:66:d1:a4]
        modulus: c40190e6d31606f5270f00f93bc1f1eb07cabe469a7efbaa642e983ef89906b655f88457b090abcf5040aa9ff2009fb1b77dafe6da29c04cd21194cbcba93904ed6c1e7d72d168635fd2ee2286bdb9760292a2bf8cba141df44b5b0aaabd41e298667121512760431e905400e20771e691a470788c7711cd8581f30930ab7ecf5c5eaf288253a9328d62d6c7b0edc1cb4204c9018a8a47d2a6951fab5be6afaf5cf4ebfe8438ed269ada011a9baedf80d75a460bba96e7191c58a8cbcb421bafa7d2018b6b8d78fc1ddda7dc5352cf787c58362d458bb49d5d708b4ae1227c7abbadb2a0f923a9a658be229c2f40669a982ae106f4d4c5240a3c63e662357e85
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 66e70b63e92ea2dedb8c2652bc1de5d1c57c7801
                       d6ff4825dbfdc23b75977dc5fa76a729a7fb51f5
                       552084c5693a895ae5bb9f0f5eefe639109ef49c
                       25ae1b994dc362cb137d2ebea108aff2f492366e
                       aa372da1ca53b2a40f9d296337194498ead80ad0
                       dfbf92e4a62102232bc154eb9b468cbc8e00eaf5
                       1972935d0844a66cec0e2f8b33984880588e5e1b
                       6ea576eb14729c6e8bdfe1fcfcf8296393c78409
                       edc365e7149240d6b3136f73a9c8a7e75c7e89bf
                       6260a0f5acb58de909a469f2fb7d22c53b7f6096
                       1ef57492b773a36f9fad3ccd95920281d46f88a5
                       7d8a260bf79acb1cb214f4c31ccdf310c7da38da
                       fbbb9f90a126e89b04bb05e42659dbd4
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/329823819739.crt.
2023-12-07 16:44:54,333 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=80d298fa-03d7-48e5-97c8-2742aa8c32f0,O=CID-c0e69b3f-1be0-4713-bc71-64e201c54dc7
           Start Date: Thu Dec 07 00:00:00 UTC 2023
           Final Date: Sun Jan 14 23:59:59 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=80d298fa-03d7-48e5-97c8-2742aa8c32f0,O=CID-c0e69b3f-1be0-4713-bc71-64e201c54dc7
           Public Key: RSA Public Key [04:a5:f0:0a:c8:c4:18:80:b4:36:e1:8f:31:c0:81:51:12:b5:05:32],[56:66:d1:a4]
        modulus: c1db999b70909695536531c2ea6c513eb9c798e89c6ddbf7807e8a95bbab85a1c19bb58c2db876e00275ad94808cabb98ea2249265f7418a72522482584ba1ddb4f6d294d306e7434b6bd8e686760337ef305a505ac9108e3dfc3afddd32b7c6e2218b475710b2e9f3ac75fd7577ac3d1a427ea0915786f7635c453fe464a6d41da79483ad7938dfd0defaf1c6d9ef90eed8d0e5c1656260b4050d980452b8c7e4fd9a70ab73ccb68b0ba5bfc0fd3ae8dd85594bc1ab52aa4b392170e0ac364214cd218ad576a04d182c82e0f836689e971ff13b39923689f3a76bb3a1af1935a9b588e5383388f0b368d48ac56eb3d16eae3cb40c6c9409ffcbfc03c12aad35
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 4d9e49afd4c7d77950b20d01aa65be1358573ef8
                       7009d69f02b6265531c4da4219392ad37a9ad676
                       c9269765c6f321c9d2656a08d50e1e898b550385
                       92b820f76e4bf161af19e75584efdcd659c79e1a
                       9c2d0f124538dce090bcc9e268de363196fcdfd2
                       44ba5ba630e5c3d10026d8d475febf3d5ebae985
                       83fca3acb3361bd809329e6a26e3568360cdb316
                       ea19e5a4b9d3756bcdd609fd6078b55219024539
                       5daa1e3e91e390c6f33a665880ee93e72c599a59
                       ebc647f0e9fd6434dfa7b9f049df617f4fc87283
                       427cace864184ebdd6d46a7ab310febc7bef6e8d
                       17e5584baf1edf37bf780477243731e9ba09d1c0
                       bf0a664c6749019d773e961f7ded0b3b
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

 from file: /data/metadata/scm/sub-ca/certs/CA-1.crt.
2023-12-07 16:44:54,333 [main] INFO client.SCMCertificateClient: CertificateRenewerService and root ca rotation polling is disabled for scm/sub-ca
2023-12-07 16:44:54,372 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-07 16:44:54,558 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-12-07 16:44:54,706 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-12-07 16:44:54,707 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2023-12-07 16:44:54,816 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2023-12-07 16:44:54,972 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:649a6984-f1f7-4d32-87eb-63a4943659c8
2023-12-07 16:44:54,989 [main] INFO ssl.ReloadingX509KeyManager: Key manager is loaded with certificate chain
2023-12-07 16:44:54,991 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 329823819739
             IssuerDN: CN=scm@scm1.org,OU=80d298fa-03d7-48e5-97c8-2742aa8c32f0,O=CID-c0e69b3f-1be0-4713-bc71-64e201c54dc7
           Start Date: Thu Dec 07 00:00:00 UTC 2023
           Final Date: Sun Jan 14 00:00:00 UTC 2029
            SubjectDN: CN=scm-sub@scm2.org,OU=649a6984-f1f7-4d32-87eb-63a4943659c8,O=CID-c0e69b3f-1be0-4713-bc71-64e201c54dc7
           Public Key: RSA Public Key [9e:69:9f:c3:a0:f6:25:91:fb:d7:4f:8d:0b:26:65:ee:1b:7d:ae:8f],[56:66:d1:a4]
        modulus: c40190e6d31606f5270f00f93bc1f1eb07cabe469a7efbaa642e983ef89906b655f88457b090abcf5040aa9ff2009fb1b77dafe6da29c04cd21194cbcba93904ed6c1e7d72d168635fd2ee2286bdb9760292a2bf8cba141df44b5b0aaabd41e298667121512760431e905400e20771e691a470788c7711cd8581f30930ab7ecf5c5eaf288253a9328d62d6c7b0edc1cb4204c9018a8a47d2a6951fab5be6afaf5cf4ebfe8438ed269ada011a9baedf80d75a460bba96e7191c58a8cbcb421bafa7d2018b6b8d78fc1ddda7dc5352cf787c58362d458bb49d5d708b4ae1227c7abbadb2a0f923a9a658be229c2f40669a982ae106f4d4c5240a3c63e662357e85
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 66e70b63e92ea2dedb8c2652bc1de5d1c57c7801
                       d6ff4825dbfdc23b75977dc5fa76a729a7fb51f5
                       552084c5693a895ae5bb9f0f5eefe639109ef49c
                       25ae1b994dc362cb137d2ebea108aff2f492366e
                       aa372da1ca53b2a40f9d296337194498ead80ad0
                       dfbf92e4a62102232bc154eb9b468cbc8e00eaf5
                       1972935d0844a66cec0e2f8b33984880588e5e1b
                       6ea576eb14729c6e8bdfe1fcfcf8296393c78409
                       edc365e7149240d6b3136f73a9c8a7e75c7e89bf
                       6260a0f5acb58de909a469f2fb7d22c53b7f6096
                       1ef57492b773a36f9fad3ccd95920281d46f88a5
                       7d8a260bf79acb1cb214f4c31ccdf310c7da38da
                       fbbb9f90a126e89b04bb05e42659dbd4
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe

2023-12-07 16:44:54,992 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=80d298fa-03d7-48e5-97c8-2742aa8c32f0,O=CID-c0e69b3f-1be0-4713-bc71-64e201c54dc7
           Start Date: Thu Dec 07 00:00:00 UTC 2023
           Final Date: Sun Jan 14 23:59:59 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=80d298fa-03d7-48e5-97c8-2742aa8c32f0,O=CID-c0e69b3f-1be0-4713-bc71-64e201c54dc7
           Public Key: RSA Public Key [04:a5:f0:0a:c8:c4:18:80:b4:36:e1:8f:31:c0:81:51:12:b5:05:32],[56:66:d1:a4]
        modulus: c1db999b70909695536531c2ea6c513eb9c798e89c6ddbf7807e8a95bbab85a1c19bb58c2db876e00275ad94808cabb98ea2249265f7418a72522482584ba1ddb4f6d294d306e7434b6bd8e686760337ef305a505ac9108e3dfc3afddd32b7c6e2218b475710b2e9f3ac75fd7577ac3d1a427ea0915786f7635c453fe464a6d41da79483ad7938dfd0defaf1c6d9ef90eed8d0e5c1656260b4050d980452b8c7e4fd9a70ab73ccb68b0ba5bfc0fd3ae8dd85594bc1ab52aa4b392170e0ac364214cd218ad576a04d182c82e0f836689e971ff13b39923689f3a76bb3a1af1935a9b588e5383388f0b368d48ac56eb3d16eae3cb40c6c9409ffcbfc03c12aad35
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 4d9e49afd4c7d77950b20d01aa65be1358573ef8
                       7009d69f02b6265531c4da4219392ad37a9ad676
                       c9269765c6f321c9d2656a08d50e1e898b550385
                       92b820f76e4bf161af19e75584efdcd659c79e1a
                       9c2d0f124538dce090bcc9e268de363196fcdfd2
                       44ba5ba630e5c3d10026d8d475febf3d5ebae985
                       83fca3acb3361bd809329e6a26e3568360cdb316
                       ea19e5a4b9d3756bcdd609fd6078b55219024539
                       5daa1e3e91e390c6f33a665880ee93e72c599a59
                       ebc647f0e9fd6434dfa7b9f049df617f4fc87283
                       427cace864184ebdd6d46a7ab310febc7bef6e8d
                       17e5584baf1edf37bf780477243731e9ba09d1c0
                       bf0a664c6749019d773e961f7ded0b3b
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2023-12-07 16:44:54,994 [main] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-12-07 16:44:54,994 [main] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-12-07 16:44:54,995 [main] INFO ssl.ReloadingX509TrustManager: Trust manager is loaded with certificates
2023-12-07 16:44:54,996 [main] INFO ssl.ReloadingX509TrustManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=80d298fa-03d7-48e5-97c8-2742aa8c32f0,O=CID-c0e69b3f-1be0-4713-bc71-64e201c54dc7
           Start Date: Thu Dec 07 00:00:00 UTC 2023
           Final Date: Sun Jan 14 23:59:59 UTC 2029
            SubjectDN: CN=scm@scm1.org,OU=80d298fa-03d7-48e5-97c8-2742aa8c32f0,O=CID-c0e69b3f-1be0-4713-bc71-64e201c54dc7
           Public Key: RSA Public Key [04:a5:f0:0a:c8:c4:18:80:b4:36:e1:8f:31:c0:81:51:12:b5:05:32],[56:66:d1:a4]
        modulus: c1db999b70909695536531c2ea6c513eb9c798e89c6ddbf7807e8a95bbab85a1c19bb58c2db876e00275ad94808cabb98ea2249265f7418a72522482584ba1ddb4f6d294d306e7434b6bd8e686760337ef305a505ac9108e3dfc3afddd32b7c6e2218b475710b2e9f3ac75fd7577ac3d1a427ea0915786f7635c453fe464a6d41da79483ad7938dfd0defaf1c6d9ef90eed8d0e5c1656260b4050d980452b8c7e4fd9a70ab73ccb68b0ba5bfc0fd3ae8dd85594bc1ab52aa4b392170e0ac364214cd218ad576a04d182c82e0f836689e971ff13b39923689f3a76bb3a1af1935a9b588e5383388f0b368d48ac56eb3d16eae3cb40c6c9409ffcbfc03c12aad35
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 4d9e49afd4c7d77950b20d01aa65be1358573ef8
                       7009d69f02b6265531c4da4219392ad37a9ad676
                       c9269765c6f321c9d2656a08d50e1e898b550385
                       92b820f76e4bf161af19e75584efdcd659c79e1a
                       9c2d0f124538dce090bcc9e268de363196fcdfd2
                       44ba5ba630e5c3d10026d8d475febf3d5ebae985
                       83fca3acb3361bd809329e6a26e3568360cdb316
                       ea19e5a4b9d3756bcdd609fd6078b55219024539
                       5daa1e3e91e390c6f33a665880ee93e72c599a59
                       ebc647f0e9fd6434dfa7b9f049df617f4fc87283
                       427cace864184ebdd6d46a7ab310febc7bef6e8d
                       17e5584baf1edf37bf780477243731e9ba09d1c0
                       bf0a664c6749019d773e961f7ded0b3b
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2023-12-07 16:44:55,008 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-12-07 16:44:55,011 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-12-07 16:44:55,087 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2023-12-07 16:44:55,102 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-12-07 16:44:55,104 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2023-12-07 16:44:55,105 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-12-07 16:44:55,106 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2023-12-07 16:44:55,106 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2023-12-07 16:44:55,106 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2023-12-07 16:44:55,108 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2023-12-07 16:44:55,110 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-07 16:44:55,111 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-12-07 16:44:55,112 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-12-07 16:44:55,130 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-12-07 16:44:55,133 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-12-07 16:44:55,134 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-12-07 16:44:55,706 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2023-12-07 16:44:55,710 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2023-12-07 16:44:55,710 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2023-12-07 16:44:55,710 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-12-07 16:44:55,714 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-12-07 16:44:55,717 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2023-12-07 16:44:55,718 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2023-12-07 16:44:55,723 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServer: 649a6984-f1f7-4d32-87eb-63a4943659c8: found a subdirectory /data/metadata/scm-ha/c0e69b3f-1be0-4713-bc71-64e201c54dc7
2023-12-07 16:44:55,731 [main] INFO server.RaftServer: 649a6984-f1f7-4d32-87eb-63a4943659c8: addNew group-64E201C54DC7:[] returns group-64E201C54DC7:java.util.concurrent.CompletableFuture@373052b5[Not completed]
2023-12-07 16:44:55,805 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO ha.SCMStateMachine: Updated lastAppliedTermIndex 2#70 with transactionInfo term andIndex
2023-12-07 16:44:55,806 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8: new RaftServerImpl for group-64E201C54DC7:[] with SCMStateMachine:uninitialized
2023-12-07 16:44:55,808 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2023-12-07 16:44:55,809 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2023-12-07 16:44:55,809 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2023-12-07 16:44:55,809 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2023-12-07 16:44:55,810 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-12-07 16:44:55,812 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2023-12-07 16:44:55,812 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2023-12-07 16:44:55,827 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-12-07 16:44:55,851 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2023-12-07 16:44:55,854 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2023-12-07 16:44:55,858 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2023-12-07 16:44:55,858 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2023-12-07 16:44:55,862 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2023-12-07 16:44:55,862 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2023-12-07 16:44:56,033 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-12-07 16:44:56,035 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-12-07 16:44:56,036 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2023-12-07 16:44:56,036 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2023-12-07 16:44:56,065 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2023-12-07 16:44:56,065 [649a6984-f1f7-4d32-87eb-63a4943659c8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2023-12-07 16:44:56,068 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2023-12-07 16:44:56,068 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-12-07 16:44:56,068 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2023-12-07 16:44:56,108 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2023-12-07 16:44:56,242 [main] INFO ha.SequenceIdGenerator: upgrade CertificateId to 352504082076
2023-12-07 16:44:56,245 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2023-12-07 16:44:56,336 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2023-12-07 16:44:56,347 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2023-12-07 16:44:56,349 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-12-07 16:44:56,405 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-12-07 16:44:56,405 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-12-07 16:44:56,409 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2023-12-07 16:44:56,409 [main] INFO pipeline.BackgroundPipelineCreator: Starting scm2-RatisPipelineUtilsThread.
2023-12-07 16:44:56,411 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2023-12-07 16:44:56,412 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2023-12-07 16:44:56,415 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2023-12-07 16:44:56,415 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2023-12-07 16:44:56,433 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-12-07 16:44:56,433 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-12-07 16:44:56,448 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2023-12-07 16:44:56,508 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2023-12-07 16:44:56,508 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2023-12-07 16:44:56,509 [scm2-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 5000ms after safemode exit
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.hadoop.hdds.utils.MetricsUtil (file:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar) to method java.lang.Class.annotationData()
WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.hdds.utils.MetricsUtil
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2023-12-07 16:44:56,520 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2023-12-07 16:44:56,522 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 2, healthy pipeline threshold count is 1
2023-12-07 16:44:56,523 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 2, pipeline's with at least one datanode reported threshold count is 2
2023-12-07 16:44:56,737 [main] INFO security.SecretKeyManagerService: Scheduling rotation checker with interval PT1M
2023-12-07 16:44:56,737 [main] INFO ha.SCMServiceManager: Registering service SecretKeyManagerService.
2023-12-07 16:44:56,752 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2023-12-07 16:44:56,770 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-07 16:44:56,803 [main] INFO ipc.Server: Listener at 0.0.0.0:9961
2023-12-07 16:44:56,804 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
2023-12-07 16:44:56,828 [main] INFO server.StorageContainerManager: SCM start with adminUsers: [testuser, recon, om, scm]
2023-12-07 16:44:57,117 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-12-07 16:44:57,120 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-07 16:44:57,125 [main] INFO ipc.Server: Listener at 0.0.0.0:9861
2023-12-07 16:44:57,126 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2023-12-07 16:44:57,144 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-12-07 16:44:57,147 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-07 16:44:57,147 [main] INFO ipc.Server: Listener at 0.0.0.0:9863
2023-12-07 16:44:57,148 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2023-12-07 16:44:57,168 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-12-07 16:44:57,172 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-12-07 16:44:57,173 [main] INFO ipc.Server: Listener at 0.0.0.0:9860
2023-12-07 16:44:57,173 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2023-12-07 16:44:57,200 [main] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2023-12-07 16:44:57,202 [main] INFO server.StorageContainerManager: 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB
Number of Iterations                               10
Time Limit for Single Container's Movement         65min
Time Limit for Single Container's Replication      50min
Interval between each Iteration                    70min
Whether to Enable Network Topology                 false
Whether to Trigger Refresh Datanode Usage Info     false
Container IDs to Exclude from Balancing            None
Datanodes Specified to be Balanced                 None
Datanodes Excluded from Balancing                  None

2023-12-07 16:44:57,203 [main] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-12-07 16:44:57,207 [main] INFO upgrade.UpgradeFinalizer: Running pre-finalized state validations for unfinalized layout features.
2023-12-07 16:44:57,209 [main] INFO upgrade.UpgradeFinalizer: Running first upgrade commands for unfinalized layout features.
2023-12-07 16:44:57,209 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2023-12-07 16:44:57,212 [main] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2023-12-07 16:44:57,213 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2023-12-07 16:44:57,214 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2023-12-07 16:44:57,214 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-12-07 16:44:57,304 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/c0e69b3f-1be0-4713-bc71-64e201c54dc7/in_use.lock acquired by nodename 7@scm2.org
2023-12-07 16:44:57,308 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=2, votedFor=} from /data/metadata/scm-ha/c0e69b3f-1be0-4713-bc71-64e201c54dc7/current/raft-meta
2023-12-07 16:44:57,332 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7: set configuration 31: peers:[80d298fa-03d7-48e5-97c8-2742aa8c32f0|scm1.org:9894, 649a6984-f1f7-4d32-87eb-63a4943659c8|scm2.org:9894, f9c069af-6343-4368-94fc-0472b33aacc0|scm3.org:9894]|listeners:[], old=null
2023-12-07 16:44:57,335 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2023-12-07 16:44:57,342 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2023-12-07 16:44:57,342 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-07 16:44:57,344 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-12-07 16:44:57,344 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2023-12-07 16:44:57,348 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-12-07 16:44:57,353 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2023-12-07 16:44:57,354 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-12-07 16:44:57,355 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-07 16:44:57,367 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO util.AwaitToRun: Thread[649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-cacheEviction-AwaitToRun,5,main] started
2023-12-07 16:44:57,372 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/c0e69b3f-1be0-4713-bc71-64e201c54dc7
2023-12-07 16:44:57,372 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-12-07 16:44:57,373 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2023-12-07 16:44:57,375 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-12-07 16:44:57,375 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2023-12-07 16:44:57,375 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2023-12-07 16:44:57,376 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2023-12-07 16:44:57,377 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-12-07 16:44:57,377 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-12-07 16:44:57,379 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2023-12-07 16:44:57,386 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-07 16:44:57,389 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2023-12-07 16:44:57,390 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2023-12-07 16:44:57,390 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2023-12-07 16:44:57,427 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7: set configuration 0: peers:[80d298fa-03d7-48e5-97c8-2742aa8c32f0|scm1.org:9894]|listeners:[], old=null
2023-12-07 16:44:57,427 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/c0e69b3f-1be0-4713-bc71-64e201c54dc7/current/log_0-0
2023-12-07 16:44:57,429 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7: set configuration 1: peers:[80d298fa-03d7-48e5-97c8-2742aa8c32f0|scm1.org:9894]|listeners:[], old=null
2023-12-07 16:44:57,434 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7: set configuration 23: peers:[80d298fa-03d7-48e5-97c8-2742aa8c32f0|scm1.org:9894, 649a6984-f1f7-4d32-87eb-63a4943659c8|scm2.org:9894]|listeners:[], old=peers:[80d298fa-03d7-48e5-97c8-2742aa8c32f0|scm1.org:9894]|listeners:[]
2023-12-07 16:44:57,435 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7: set configuration 25: peers:[80d298fa-03d7-48e5-97c8-2742aa8c32f0|scm1.org:9894, 649a6984-f1f7-4d32-87eb-63a4943659c8|scm2.org:9894]|listeners:[], old=null
2023-12-07 16:44:57,435 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7: set configuration 29: peers:[80d298fa-03d7-48e5-97c8-2742aa8c32f0|scm1.org:9894, 649a6984-f1f7-4d32-87eb-63a4943659c8|scm2.org:9894, f9c069af-6343-4368-94fc-0472b33aacc0|scm3.org:9894]|listeners:[], old=peers:[80d298fa-03d7-48e5-97c8-2742aa8c32f0|scm1.org:9894, 649a6984-f1f7-4d32-87eb-63a4943659c8|scm2.org:9894]|listeners:[]
2023-12-07 16:44:57,436 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7: set configuration 31: peers:[80d298fa-03d7-48e5-97c8-2742aa8c32f0|scm1.org:9894, 649a6984-f1f7-4d32-87eb-63a4943659c8|scm2.org:9894, f9c069af-6343-4368-94fc-0472b33aacc0|scm3.org:9894]|listeners:[], old=null
2023-12-07 16:44:57,467 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO segmented.LogSegment: Successfully read 70 entries from segment file /data/metadata/scm-ha/c0e69b3f-1be0-4713-bc71-64e201c54dc7/current/log_inprogress_1
2023-12-07 16:44:57,480 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 70
2023-12-07 16:44:57,520 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7: start as a follower, conf=31: peers:[80d298fa-03d7-48e5-97c8-2742aa8c32f0|scm1.org:9894, 649a6984-f1f7-4d32-87eb-63a4943659c8|scm2.org:9894, f9c069af-6343-4368-94fc-0472b33aacc0|scm3.org:9894]|listeners:[], old=null
2023-12-07 16:44:57,520 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7: changes role from      null to FOLLOWER at term 2 for startAsFollower
2023-12-07 16:44:57,521 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO impl.RoleInfo: 649a6984-f1f7-4d32-87eb-63a4943659c8: start 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-FollowerState
2023-12-07 16:44:57,522 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-12-07 16:44:57,522 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-12-07 16:44:57,523 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-64E201C54DC7,id=649a6984-f1f7-4d32-87eb-63a4943659c8
2023-12-07 16:44:57,524 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2023-12-07 16:44:57,524 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-12-07 16:44:57,525 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2023-12-07 16:44:57,525 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2023-12-07 16:44:57,525 [649a6984-f1f7-4d32-87eb-63a4943659c8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2023-12-07 16:44:57,527 [main] INFO server.RaftServer: 649a6984-f1f7-4d32-87eb-63a4943659c8: start RPC server
2023-12-07 16:44:57,579 [main] INFO server.GrpcService: 649a6984-f1f7-4d32-87eb-63a4943659c8: GrpcService started, listening on 9894
2023-12-07 16:44:57,581 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-649a6984-f1f7-4d32-87eb-63a4943659c8: Started
2023-12-07 16:44:57,587 [main] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [80d298fa-03d7-48e5-97c8-2742aa8c32f0|scm1.org:9894, 649a6984-f1f7-4d32-87eb-63a4943659c8|scm2.org:9894, f9c069af-6343-4368-94fc-0472b33aacc0|scm3.org:9894]
2023-12-07 16:44:57,587 [main] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2023-12-07 16:44:57,589 [main] INFO SCMHATransactionMonitor: Starting SCMHATransactionMonitor Service.
2023-12-07 16:44:57,600 [main] INFO ha.SCMServiceManager: Registering service SCMHATransactionMonitor.
2023-12-07 16:44:57,600 [main] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is already running, skip start.
2023-12-07 16:44:57,682 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2023-12-07 16:44:57,693 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-12-07 16:44:57,693 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2023-12-07 16:44:57,753 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2023-12-07 16:44:57,753 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-07 16:44:57,762 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2023-12-07 16:44:57,859 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2023-12-07 16:44:57,860 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2023-12-07 16:44:57,867 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-07 16:44:57,872 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2023-12-07 16:44:57,884 [main] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
2023-12-07 16:44:57,885 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-07 16:44:57,891 [main] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
2023-12-07 16:44:57,892 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
2023-12-07 16:44:58,503 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:34426 / 10.9.0.19:34426
2023-12-07 16:44:58,526 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2023-12-07 16:44:58,527 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:41490 / 10.9.0.13:41490
2023-12-07 16:44:58,534 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-12-07 16:44:58,574 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:55034 / 10.9.0.17:55034
2023-12-07 16:44:58,588 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2023-12-07 16:44:58,591 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:58686 / 10.9.0.18:58686
2023-12-07 16:44:58,594 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2023-12-07 16:44:58,684 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode.submitRequest from ha_dn1_1.ha_net:55034 / 10.9.0.17:55034
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:649a6984-f1f7-4d32-87eb-63a4943659c8 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SecretKeyProtocolServerSideTranslatorPB.submitRequest(SecretKeyProtocolServerSideTranslatorPB.java:76)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecretKeyProtocolProtos$SCMSecretKeyProtocolService$2.callBlockingMethod(SCMSecretKeyProtocolProtos.java:7548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2023-12-07 16:44:58,686 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode.submitRequest from ha_dn3_1.ha_net:34426 / 10.9.0.19:34426
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:649a6984-f1f7-4d32-87eb-63a4943659c8 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SecretKeyProtocolServerSideTranslatorPB.submitRequest(SecretKeyProtocolServerSideTranslatorPB.java:76)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecretKeyProtocolProtos$SCMSecretKeyProtocolService$2.callBlockingMethod(SCMSecretKeyProtocolProtos.java:7548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2023-12-07 16:44:58,721 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#7 org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode.submitRequest from ha_dn2_1.ha_net:58686 / 10.9.0.18:58686
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:649a6984-f1f7-4d32-87eb-63a4943659c8 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SecretKeyProtocolServerSideTranslatorPB.submitRequest(SecretKeyProtocolServerSideTranslatorPB.java:76)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecretKeyProtocolProtos$SCMSecretKeyProtocolService$2.callBlockingMethod(SCMSecretKeyProtocolProtos.java:7548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2023-12-07 16:44:58,726 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from ha_scm1_1.ha_net:37780 / 10.9.0.14:37780
2023-12-07 16:44:58,737 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-12-07 16:44:58,866 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om1_1.ha_net:51324 / 10.9.0.11:51324
2023-12-07 16:44:58,879 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:60878 / 10.9.0.12:60878
2023-12-07 16:44:58,880 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-12-07 16:44:58,887 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-12-07 16:44:59,753 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from ha_scm1_1.ha_net:43176 / 10.9.0.14:43176
2023-12-07 16:44:59,768 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-12-07 16:44:59,773 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#4 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from ha_scm1_1.ha_net:43176 / 10.9.0.14:43176
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:649a6984-f1f7-4d32-87eb-63a4943659c8 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2023-12-07 16:45:00,059 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from scm2.org:33484 / 10.9.0.15:33484
2023-12-07 16:45:00,066 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-12-07 16:45:00,067 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#1 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from scm2.org:33484 / 10.9.0.15:33484
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:649a6984-f1f7-4d32-87eb-63a4943659c8 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2023-12-07 16:45:00,477 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:58446 / 10.9.0.20:58446
2023-12-07 16:45:00,480 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2023-12-07 16:45:00,481 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#10 org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode.submitRequest from ha_dn4_1.ha_net:58446 / 10.9.0.20:58446
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:649a6984-f1f7-4d32-87eb-63a4943659c8 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SecretKeyProtocolServerSideTranslatorPB.submitRequest(SecretKeyProtocolServerSideTranslatorPB.java:76)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecretKeyProtocolProtos$SCMSecretKeyProtocolService$2.callBlockingMethod(SCMSecretKeyProtocolProtos.java:7548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2023-12-07 16:45:00,833 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:56484 / 10.9.0.21:56484
2023-12-07 16:45:00,834 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2023-12-07 16:45:00,835 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#10 org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode.submitRequest from ha_dn5_1.ha_net:56484 / 10.9.0.21:56484
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:649a6984-f1f7-4d32-87eb-63a4943659c8 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:110)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SecretKeyProtocolServerSideTranslatorPB.submitRequest(SecretKeyProtocolServerSideTranslatorPB.java:76)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecretKeyProtocolProtos$SCMSecretKeyProtocolService$2.callBlockingMethod(SCMSecretKeyProtocolProtos.java:7548)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2023-12-07 16:45:02,527 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ha_recon_1.ha_net:37521 / 10.9.0.22:37521
2023-12-07 16:45:02,535 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-12-07 16:45:02,625 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-FollowerState] INFO impl.FollowerState: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5103662605ns, electionTimeout:5102ms
2023-12-07 16:45:02,625 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-FollowerState] INFO impl.RoleInfo: 649a6984-f1f7-4d32-87eb-63a4943659c8: shutdown 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-FollowerState
2023-12-07 16:45:02,626 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-FollowerState] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2023-12-07 16:45:02,628 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2023-12-07 16:45:02,628 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-FollowerState] INFO impl.RoleInfo: 649a6984-f1f7-4d32-87eb-63a4943659c8: start 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1
2023-12-07 16:45:02,631 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO impl.LeaderElection: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 2 for 31: peers:[80d298fa-03d7-48e5-97c8-2742aa8c32f0|scm1.org:9894, 649a6984-f1f7-4d32-87eb-63a4943659c8|scm2.org:9894, f9c069af-6343-4368-94fc-0472b33aacc0|scm3.org:9894]|listeners:[], old=null
2023-12-07 16:45:02,648 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-12-07 16:45:02,648 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-12-07 16:45:02,649 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1-1] INFO server.GrpcServerProtocolClient: Build channel for 80d298fa-03d7-48e5-97c8-2742aa8c32f0
2023-12-07 16:45:02,649 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1-2] INFO server.GrpcServerProtocolClient: Build channel for f9c069af-6343-4368-94fc-0472b33aacc0
2023-12-07 16:45:02,838 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO impl.LeaderElection: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,081 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO impl.LeaderElection: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1: PRE_VOTE PASSED received 1 response(s) and 1 exception(s):
2023-12-07 16:45:03,081 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO impl.LeaderElection:   Response 0: 649a6984-f1f7-4d32-87eb-63a4943659c8<-80d298fa-03d7-48e5-97c8-2742aa8c32f0#0:OK-t2
2023-12-07 16:45:03,082 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,082 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO impl.LeaderElection: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1 PRE_VOTE round 0: result PASSED
2023-12-07 16:45:03,090 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO impl.LeaderElection: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1 ELECTION round 0: submit vote requests at term 3 for 31: peers:[80d298fa-03d7-48e5-97c8-2742aa8c32f0|scm1.org:9894, 649a6984-f1f7-4d32-87eb-63a4943659c8|scm2.org:9894, f9c069af-6343-4368-94fc-0472b33aacc0|scm3.org:9894]|listeners:[], old=null
2023-12-07 16:45:03,092 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-12-07 16:45:03,092 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-12-07 16:45:03,093 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO impl.LeaderElection: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,138 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO impl.LeaderElection: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1: ELECTION PASSED received 1 response(s) and 1 exception(s):
2023-12-07 16:45:03,138 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO impl.LeaderElection:   Response 0: 649a6984-f1f7-4d32-87eb-63a4943659c8<-80d298fa-03d7-48e5-97c8-2742aa8c32f0#0:OK-t3
2023-12-07 16:45:03,139 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,139 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO impl.LeaderElection: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1 ELECTION round 0: result PASSED
2023-12-07 16:45:03,141 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO impl.RoleInfo: 649a6984-f1f7-4d32-87eb-63a4943659c8: shutdown 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1
2023-12-07 16:45:03,142 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
2023-12-07 16:45:03,148 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2023-12-07 16:45:03,159 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2023-12-07 16:45:03,159 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2023-12-07 16:45:03,164 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2023-12-07 16:45:03,166 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2023-12-07 16:45:03,167 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2023-12-07 16:45:03,181 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2023-12-07 16:45:03,183 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2023-12-07 16:45:03,184 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2023-12-07 16:45:03,184 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2023-12-07 16:45:03,184 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-12-07 16:45:03,211 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-12-07 16:45:03,211 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-07 16:45:03,211 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
2023-12-07 16:45:03,214 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 0ms (custom)
2023-12-07 16:45:03,215 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2023-12-07 16:45:03,215 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-12-07 16:45:03,215 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2023-12-07 16:45:03,216 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2023-12-07 16:45:03,216 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-12-07 16:45:03,216 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-12-07 16:45:03,221 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-12-07 16:45:03,221 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-12-07 16:45:03,221 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
2023-12-07 16:45:03,221 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 0ms (custom)
2023-12-07 16:45:03,221 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2023-12-07 16:45:03,221 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-12-07 16:45:03,222 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2023-12-07 16:45:03,223 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2023-12-07 16:45:03,223 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-12-07 16:45:03,223 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-12-07 16:45:03,229 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO impl.RoleInfo: 649a6984-f1f7-4d32-87eb-63a4943659c8: start 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderStateImpl
2023-12-07 16:45:03,229 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7: set firstElectionSinceStartup to false for becomeLeader
2023-12-07 16:45:03,229 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 3.
2023-12-07 16:45:03,230 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,3>
2023-12-07 16:45:03,235 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7: change Leader from null to 649a6984-f1f7-4d32-87eb-63a4943659c8 at term 3 for becomeLeader, leader elected after 7378ms
2023-12-07 16:45:03,243 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-SegmentedRaftLogWorker: Rolling segment log-1_70 to index:70
2023-12-07 16:45:03,246 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/c0e69b3f-1be0-4713-bc71-64e201c54dc7/current/log_inprogress_1 to /data/metadata/scm-ha/c0e69b3f-1be0-4713-bc71-64e201c54dc7/current/log_1-70
2023-12-07 16:45:03,264 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-LeaderElection1] INFO server.RaftServer$Division: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7: set configuration 71: peers:[80d298fa-03d7-48e5-97c8-2742aa8c32f0|scm1.org:9894, 649a6984-f1f7-4d32-87eb-63a4943659c8|scm2.org:9894, f9c069af-6343-4368-94fc-0472b33aacc0|scm3.org:9894]|listeners:[], old=null
2023-12-07 16:45:03,265 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/c0e69b3f-1be0-4713-bc71-64e201c54dc7/current/log_inprogress_71
2023-12-07 16:45:03,302 [grpc-default-executor-1] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,312 [grpc-default-executor-1] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-GrpcLogAppender: Follower failed and request == null,  keep nextIndex (71) unchanged and retry.
2023-12-07 16:45:03,317 [grpc-default-executor-1] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,320 [grpc-default-executor-1] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-GrpcLogAppender: Follower failed and request == null,  keep nextIndex (71) unchanged and retry.
2023-12-07 16:45:03,331 [grpc-default-executor-1] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,333 [grpc-default-executor-1] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-GrpcLogAppender: Follower failed and request == null,  keep nextIndex (71) unchanged and retry.
2023-12-07 16:45:03,335 [grpc-default-executor-1] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,332 [grpc-default-executor-3] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,346 [grpc-default-executor-2] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,350 [grpc-default-executor-1] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-GrpcLogAppender: Follower failed and request == null,  keep nextIndex (71) unchanged and retry.
2023-12-07 16:45:03,350 [grpc-default-executor-3] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-GrpcLogAppender: Follower failed and request == null,  keep nextIndex (71) unchanged and retry.
2023-12-07 16:45:03,352 [grpc-default-executor-2] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-GrpcLogAppender: Follower failed and request == null,  keep nextIndex (71) unchanged and retry.
2023-12-07 16:45:03,371 [grpc-default-executor-3] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,375 [grpc-default-executor-3] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-GrpcLogAppender: Follower failed and request == null,  keep nextIndex (72) unchanged and retry.
2023-12-07 16:45:03,375 [grpc-default-executor-2] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,376 [grpc-default-executor-2] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-GrpcLogAppender: Follower failed and request == null,  keep nextIndex (72) unchanged and retry.
2023-12-07 16:45:03,449 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-StateMachineUpdater] INFO server.RaftServer$Division: leader is ready since appliedIndex == 71 >= startIndex == 71
2023-12-07 16:45:03,449 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
2023-12-07 16:45:03,451 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
2023-12-07 16:45:03,453 [scm2-SecretKeyManagerService] INFO symmetric.SecretKeyManager: Initializing SecretKeys.
2023-12-07 16:45:03,454 [scm2-SecretKeyManagerService] INFO symmetric.SecretKeyManager: No valid key has been loaded. A new key is generated: SecretKey(id = 4a21404d-6e90-42e4-a45a-e201192866d8, creation at: 2023-12-07T16:45:03.453865Z, expire at: 2023-12-07T17:45:03.453865Z)
2023-12-07 16:45:03,455 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 2, healthy pipeline threshold count is 1
2023-12-07 16:45:03,463 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2023-12-07 16:45:03,464 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 2, pipeline's with at least one datanode reported threshold count is 2
2023-12-07 16:45:03,464 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2023-12-07 16:45:03,472 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2023-12-07 16:45:03,506 [grpc-default-executor-2] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,506 [grpc-default-executor-3] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,509 [grpc-default-executor-2] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-GrpcLogAppender: Follower failed and request == null,  keep nextIndex (73) unchanged and retry.
2023-12-07 16:45:03,509 [grpc-default-executor-3] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-GrpcLogAppender: Follower failed and request == null,  keep nextIndex (73) unchanged and retry.
2023-12-07 16:45:03,521 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-12-07 16:45:03,665 [grpc-default-executor-2] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,665 [grpc-default-executor-2] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-GrpcLogAppender: Follower failed and request == null,  keep nextIndex (74) unchanged and retry.
2023-12-07 16:45:03,666 [grpc-default-executor-3] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,666 [grpc-default-executor-3] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-GrpcLogAppender: Follower failed and request == null,  keep nextIndex (74) unchanged and retry.
2023-12-07 16:45:03,718 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 4a21404d-6e90-42e4-a45a-e201192866d8, creation at: 2023-12-07T16:45:03.453Z, expire at: 2023-12-07T17:45:03.453Z)]
2023-12-07 16:45:03,720 [grpc-default-executor-2] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,720 [grpc-default-executor-2] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-GrpcLogAppender: Follower failed and request == null,  keep nextIndex (75) unchanged and retry.
2023-12-07 16:45:03,720 [grpc-default-executor-3] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-12-07 16:45:03,720 [grpc-default-executor-3] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-GrpcLogAppender: Follower failed and request == null,  keep nextIndex (75) unchanged and retry.
2023-12-07 16:45:03,725 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 4a21404d-6e90-42e4-a45a-e201192866d8, creation at: 2023-12-07T16:45:03.453Z, expire at: 2023-12-07T17:45:03.453Z)
2023-12-07 16:45:03,797 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 4a21404d-6e90-42e4-a45a-e201192866d8, creation at: 2023-12-07T16:45:03.453Z, expire at: 2023-12-07T17:45:03.453Z)] to file /data/metadata/scm/keys/secret_keys.json
2023-12-07 16:45:03,799 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 2, healthy pipeline threshold count is 1
2023-12-07 16:45:03,799 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2023-12-07 16:45:03,799 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 2, pipeline's with at least one datanode reported threshold count is 2
2023-12-07 16:45:04,081 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:80d298fa-03d7-48e5-97c8-2742aa8c32f0 is not the leader. Suggested leader is Server:scm2.org:9961.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:107)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
, while invoking $Proxy14.submitRequest over nodeId=scm1,nodeAddress=scm1.org/10.9.0.14:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms. Current retry count: 3.
2023-12-07 16:45:05,982 [grpc-default-executor-3] WARN server.GrpcLogAppender: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0-AppendLogResponseHandler: received INCONSISTENCY reply with nextIndex 71, request=AppendEntriesRequest:cid=151,entriesCount=0
2023-12-07 16:45:05,997 [grpc-default-executor-3] INFO leader.FollowerInfo: 649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7->f9c069af-6343-4368-94fc-0472b33aacc0: setNextIndex nextIndex: updateUnconditionally 75 -> 71
2023-12-07 16:45:06,038 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-12-07 16:45:06,057 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-12-07 16:45:06,276 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2023-12-07 16:45:06,277 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
2023-12-07 16:45:06,278 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
2023-12-07 16:45:06,525 [main] INFO util.log: Logging initialized @16642ms to org.eclipse.jetty.util.log.Slf4jLog
2023-12-07 16:45:06,762 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from ha_scm3_1.ha_net:52056 / 10.9.0.16:52056
2023-12-07 16:45:06,813 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-12-07 16:45:07,309 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2023-12-07 16:45:07,365 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-12-07 16:45:07,377 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2023-12-07 16:45:07,377 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2023-12-07 16:45:07,377 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2023-12-07 16:45:07,397 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
2023-12-07 16:45:07,813 [main] INFO http.BaseHttpServer: HTTP server of scm uses base directory /data/metadata/webserver
2023-12-07 16:45:07,818 [main] INFO http.HttpServer2: Jetty bound to port 9876
2023-12-07 16:45:07,823 [main] INFO server.Server: jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 11.0.19+7-LTS
2023-12-07 16:45:07,964 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2023-12-07 16:45:07,964 [main] INFO server.session: No SessionScavenger set, using defaults
2023-12-07 16:45:07,973 [main] INFO server.session: node0 Scavenging every 660000ms
2023-12-07 16:45:08,063 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2023-12-07 16:45:08,078 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@646d58cd{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2023-12-07 16:45:08,083 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@fb2c2f3{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-12-07 16:45:09,379 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2023-12-07 16:45:09,567 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@425f94d7{scm,/,file:///data/metadata/webserver/jetty-0_0_0_0-9876-hdds-server-scm-1_4_0-SNAPSHOT_jar-_-any-10096708334586129865/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/scm}
2023-12-07 16:45:09,688 [main] INFO server.AbstractConnector: Started ServerConnector@d190639{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2023-12-07 16:45:09,688 [main] INFO server.Server: Started @19858ms
2023-12-07 16:45:09,692 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2023-12-07 16:45:09,692 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
2023-12-07 16:45:09,695 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2023-12-07 16:45:09,743 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-12-07 16:45:09,743 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-12-07 16:45:09,753 [649a6984-f1f7-4d32-87eb-63a4943659c8-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-12-07 16:45:09,753 [649a6984-f1f7-4d32-87eb-63a4943659c8-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-12-07 16:45:09,760 [649a6984-f1f7-4d32-87eb-63a4943659c8-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: CA certificates are not changed.
2023-12-07 16:45:11,339 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-12-07 16:45:11,339 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-12-07 16:45:15,123 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:56154 / 10.9.0.18:56154
2023-12-07 16:45:15,139 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-12-07 16:45:16,566 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:43426 / 10.9.0.19:43426
2023-12-07 16:45:16,600 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-12-07 16:45:17,547 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:53498 / 10.9.0.17:53498
2023-12-07 16:45:17,604 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-12-07 16:45:19,394 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:57354 / 10.9.0.20:57354
2023-12-07 16:45:19,410 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-12-07 16:45:21,921 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:43522 / 10.9.0.21:43522
2023-12-07 16:45:21,940 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-12-07 16:45:21,993 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:53964 / 10.9.0.18:53964
2023-12-07 16:45:22,024 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:45:23,048 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:54108 / 10.9.0.19:54108
2023-12-07 16:45:23,150 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:45:24,093 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:40678 / 10.9.0.12:40678
2023-12-07 16:45:24,104 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2023-12-07 16:45:24,310 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:36718 / 10.9.0.17:36718
2023-12-07 16:45:24,314 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:45:24,642 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om3_1.ha_net:33860 / 10.9.0.13:33860
2023-12-07 16:45:24,656 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2023-12-07 16:45:24,760 [IPC Server handler 4 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/348732b1-b038-4fda-94bc-0fdf732ef5a7
2023-12-07 16:45:24,763 [IPC Server handler 4 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 348732b1-b038-4fda-94bc-0fdf732ef5a7{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 333996477524, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-12-07 16:45:24,792 [scm2-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm2-RatisPipelineUtilsThread.
2023-12-07 16:45:24,805 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
2023-12-07 16:45:24,821 [scm2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 2
2023-12-07 16:45:24,826 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-07 16:45:24,974 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om1_1.ha_net:34178 / 10.9.0.11:34178
2023-12-07 16:45:24,992 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2023-12-07 16:45:25,285 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:51360 / 10.9.0.20:51360
2023-12-07 16:45:25,313 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:45:25,473 [IPC Server handler 7 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/99c8476b-1141-4853-8684-02c17a5aec5f
2023-12-07 16:45:25,474 [IPC Server handler 7 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 99c8476b-1141-4853-8684-02c17a5aec5f{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 333740056393, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-12-07 16:45:25,477 [scm2-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm2-RatisPipelineUtilsThread.
2023-12-07 16:45:25,477 [scm2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 2
2023-12-07 16:45:25,479 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
2023-12-07 16:45:25,483 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-07 16:45:26,094 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:48294 / 10.9.0.21:48294
2023-12-07 16:45:26,133 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:45:26,548 [IPC Server handler 6 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/53e1949c-a03b-482b-9244-c00cc40d2b71
2023-12-07 16:45:26,548 [IPC Server handler 6 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 53e1949c-a03b-482b-9244-c00cc40d2b71{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 331515626529, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-12-07 16:45:26,551 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-07 16:45:26,551 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
2023-12-07 16:45:26,551 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2023-12-07 16:45:26,551 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2023-12-07 16:45:26,551 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-12-07 16:45:26,551 [scm2-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm2-RatisPipelineUtilsThread.
2023-12-07 16:45:26,552 [scm2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Pipelines with at least one datanode reported count is 2, required at least one datanode reported per pipeline count is 2
2023-12-07 16:45:26,552 [scm2-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2023-12-07 16:45:26,554 [scm2-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm2-RatisPipelineUtilsThread.
2023-12-07 16:45:26,733 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-07 16:45:27,468 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-07 16:45:27,785 [IPC Server handler 2 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/087d58c8-2b85-454f-9617-84988dd12443
2023-12-07 16:45:27,785 [IPC Server handler 2 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 087d58c8-2b85-454f-9617-84988dd12443{ip: 10.9.0.20, host: ha_dn4_1.ha_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 330292768016, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-12-07 16:45:27,786 [scm2-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm2-RatisPipelineUtilsThread.
2023-12-07 16:45:27,786 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-12-07 16:45:28,482 [IPC Server handler 6 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/59ea17ff-e3e4-471f-8428-c22899b45be3
2023-12-07 16:45:28,482 [IPC Server handler 6 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 59ea17ff-e3e4-471f-8428-c22899b45be3{ip: 10.9.0.21, host: ha_dn5_1.ha_net, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 331071227729, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-12-07 16:45:28,482 [scm2-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm2-RatisPipelineUtilsThread.
2023-12-07 16:45:28,484 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-12-07 16:45:28,485 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2023-12-07 16:45:28,491 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2023-12-07 16:45:28,491 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2023-12-07 16:45:28,492 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-12-07 16:45:28,492 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
2023-12-07 16:45:28,492 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-12-07 16:45:28,492 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
2023-12-07 16:45:28,495 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-12-07 16:45:28,496 [scm2-EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO SCMHATransactionMonitor: Service SCMHATransactionMonitor transitions to RUNNING.
2023-12-07 16:45:39,529 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ha_recon_1.ha_net:33545 / 10.9.0.22:33545
2023-12-07 16:45:39,634 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-12-07 16:45:48,594 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:44248 / 10.9.0.12:44248
2023-12-07 16:45:48,607 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-12-07 16:45:50,726 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:50094 / 10.9.0.12:50094
2023-12-07 16:45:50,729 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-12-07 16:45:50,731 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.14
2023-12-07 16:45:51,925 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:35936 / 10.9.0.21:35936
2023-12-07 16:45:51,942 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2023-12-07 16:45:58,612 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:44514 / 10.9.0.18:44514
2023-12-07 16:45:58,616 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:45:59,007 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:60376 / 10.9.0.19:60376
2023-12-07 16:45:59,026 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:46:01,501 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:45390 / 10.9.0.17:45390
2023-12-07 16:46:01,525 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:46:02,563 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:38080 / 10.9.0.21:38080
2023-12-07 16:46:02,593 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:45456 / 10.9.0.20:45456
2023-12-07 16:46:02,605 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:46:02,619 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:46:05,131 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:39998 / 10.9.0.12:39998
2023-12-07 16:46:05,138 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-12-07 16:46:05,138 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.23
2023-12-07 16:46:05,950 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:53926 / 10.9.0.20:53926
2023-12-07 16:46:05,953 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2023-12-07 16:46:09,381 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ha_recon_1.ha_net:46563 / 10.9.0.22:46563
2023-12-07 16:46:09,382 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-12-07 16:46:17,295 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:47436 / 10.9.0.12:47436
2023-12-07 16:46:17,298 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-12-07 16:46:17,310 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:51662 / 10.9.0.12:51662
2023-12-07 16:46:17,314 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-12-07 16:46:17,315 [IPC Server handler 48 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.23
2023-12-07 16:46:24,649 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for containerId, expected lastId is 0, actual lastId is 1000.
2023-12-07 16:46:24,680 [IPC Server handler 63 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 1000 to 2000.
2023-12-07 16:46:24,728 [649a6984-f1f7-4d32-87eb-63a4943659c8@group-64E201C54DC7-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 111677748019201000.
2023-12-07 16:46:24,742 [IPC Server handler 63 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 111677748019201000 to 111677748019202000.
2023-12-07 16:46:24,747 [IPC Server handler 63 on default port 9863] WARN node.SCMNodeManager: address is null
2023-12-07 16:46:26,313 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:45908 / 10.9.0.20:45908
2023-12-07 16:46:26,370 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:54470 / 10.9.0.21:54470
2023-12-07 16:46:26,388 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:46:26,422 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:46:26,469 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:43044 / 10.9.0.17:43044
2023-12-07 16:46:26,518 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ha_recon_1.ha_net:42249 / 10.9.0.22:42249
2023-12-07 16:46:26,519 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:46:26,555 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-12-07 16:46:28,602 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:55366 / 10.9.0.18:55366
2023-12-07 16:46:28,643 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:46:28,998 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:46718 / 10.9.0.19:46718
2023-12-07 16:46:29,001 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:46:30,716 [IPC Server handler 63 on default port 9863] WARN node.SCMNodeManager: address is null
2023-12-07 16:46:44,811 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:53292 / 10.9.0.12:53292
2023-12-07 16:46:44,813 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-12-07 16:46:44,826 [IPC Server handler 70 on default port 9863] WARN node.SCMNodeManager: address is null
2023-12-07 16:46:45,151 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:47792 / 10.9.0.17:47792
2023-12-07 16:46:45,152 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2023-12-07 16:46:45,238 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:39964 / 10.9.0.21:39964
2023-12-07 16:46:45,262 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:39586 / 10.9.0.20:39586
2023-12-07 16:46:45,276 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:46:45,288 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:51724 / 10.9.0.17:51724
2023-12-07 16:46:45,338 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ha_recon_1.ha_net:38189 / 10.9.0.22:38189
2023-12-07 16:46:45,344 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-12-07 16:46:45,360 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:46:45,406 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:46:58,631 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:57880 / 10.9.0.18:57880
2023-12-07 16:46:58,668 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:46:59,029 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:38624 / 10.9.0.19:38624
2023-12-07 16:46:59,041 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:46:59,866 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:48182 / 10.9.0.12:48182
2023-12-07 16:46:59,870 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-12-07 16:46:59,871 [IPC Server handler 65 on default port 9863] WARN node.SCMNodeManager: address is null
2023-12-07 16:47:09,188 [IPC Server handler 48 on default port 9863] WARN node.SCMNodeManager: address is null
2023-12-07 16:47:15,255 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:42408 / 10.9.0.17:42408
2023-12-07 16:47:15,256 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:44970 / 10.9.0.21:44970
2023-12-07 16:47:15,258 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:59108 / 10.9.0.20:59108
2023-12-07 16:47:15,302 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:47:15,302 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:47:15,323 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:47:23,087 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:50990 / 10.9.0.12:50990
2023-12-07 16:47:23,093 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-12-07 16:47:23,094 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: address is null
2023-12-07 16:47:24,300 [IPC Server handler 63 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
2023-12-07 16:47:28,629 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:57580 / 10.9.0.18:57580
2023-12-07 16:47:28,666 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:47:29,033 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:60802 / 10.9.0.19:60802
2023-12-07 16:47:29,076 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:47:30,553 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:39114 / 10.9.0.12:39114
2023-12-07 16:47:30,557 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-12-07 16:47:30,561 [IPC Server handler 70 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.14
2023-12-07 16:47:42,397 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:52560 / 10.9.0.12:52560
2023-12-07 16:47:42,404 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-12-07 16:47:42,413 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:40100 / 10.9.0.12:40100
2023-12-07 16:47:42,417 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-12-07 16:47:42,418 [IPC Server handler 70 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.23
2023-12-07 16:47:45,216 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:46794 / 10.9.0.17:46794
2023-12-07 16:47:45,253 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:58170 / 10.9.0.21:58170
2023-12-07 16:47:45,261 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:54932 / 10.9.0.20:54932
2023-12-07 16:47:45,286 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:47:45,303 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:47:45,314 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:47:53,079 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from ha_om2_1.ha_net:55404 / 10.9.0.12:55404
2023-12-07 16:47:53,081 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-12-07 16:47:53,081 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 10.9.0.23
2023-12-07 16:47:58,609 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:58452 / 10.9.0.18:58452
2023-12-07 16:47:58,643 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:47:59,006 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:49096 / 10.9.0.19:49096
2023-12-07 16:47:59,066 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:48:04,809 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from ha_scm1_1.ha_net:33812 / 10.9.0.14:33812
2023-12-07 16:48:04,811 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-12-07 16:48:15,221 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn1_1.ha_net:46802 / 10.9.0.17:46802
2023-12-07 16:48:15,223 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn5_1.ha_net:33514 / 10.9.0.21:33514
2023-12-07 16:48:15,249 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:48:15,256 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn4_1.ha_net:48594 / 10.9.0.20:48594
2023-12-07 16:48:15,267 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:48:15,272 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:48:28,611 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn2_1.ha_net:47594 / 10.9.0.18:47594
2023-12-07 16:48:28,641 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-12-07 16:48:29,016 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ha_dn3_1.ha_net:33902 / 10.9.0.19:33902
2023-12-07 16:48:29,043 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
