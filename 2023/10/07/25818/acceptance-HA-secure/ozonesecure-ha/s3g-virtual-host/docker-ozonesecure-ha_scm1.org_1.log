No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-10-07 05:17:52,739 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm1.org/172.25.0.116
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.5.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.5.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.5.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.5.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/okio-3.4.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.5.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.5.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.5.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.5.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.4.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/0a11bba5aa277a26c9b7c24adb6367fd13c9c1aa ; compiled by 'runner' on 2023-10-07T04:45Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=true, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=16KB, dfs.container.ratis.segment.size=1MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.retries=-1, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60s, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=9864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=1ms, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=64KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.handler.type=distributed, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-address.omservice.om1=om1, ozone.om.http-address.omservice.om2=om2, ozone.om.http-address.omservice.om3=om3, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.internal.service.id=omservice, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=0, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.GrpcOmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=false, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=20s, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.domain.name=s3g.internal, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=5s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.enable=true, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-10-07 05:17:52,930 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-10-07 05:17:53,567 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-10-07 05:17:54,759 [main] INFO reflections.Reflections: Reflections took 763 ms to scan 3 urls, producing 133 keys and 289 values 
2023-10-07 05:17:55,234 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2023-10-07 05:17:55,407 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-10-07 05:17:55,653 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
2023-10-07 05:17:55,704 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
2023-10-07 05:17:55,770 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
2023-10-07 05:18:00,716 [main] INFO client.SCMCertificateClient: Certificate serial ID set to null
2023-10-07 05:18:00,717 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
2023-10-07 05:18:00,717 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
2023-10-07 05:18:00,718 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
2023-10-07 05:18:03,334 [main] INFO ha.HASecurityUtils: Init response: GETCERT
2023-10-07 05:18:04,726 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
2023-10-07 05:18:04,744 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2023-10-07 05:18:04,981 [main] INFO utils.SelfSignedCertificate: Certificate 1 is issued by CN=scm-1@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4 to CN=scm-1@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4, valid from Sat Oct 07 05:18:04 UTC 2023 to Tue Nov 14 05:18:04 UTC 2028
2023-10-07 05:18:05,014 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/ca/certs/certificate.crt
2023-10-07 05:18:05,015 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDrzCCApegAwIBAgIBATANBgkqhkiG9w0BAQsFADB7MRcwFQYDVQQDDA5zY20t
MUBzY20xLm9yZzEtMCsGA1UECwwkZTg0NTFiNjYtNTQ5OS00NjU4LWJhZTktYTE4
MDBlYTQ1N2MzMTEwLwYDVQQKDChDSUQtM2IxZmQyMjUtYzIzMi00Y2FiLWFjNDct
YWFiY2Q1YTk2ZmQ0MB4XDTIzMTAwNzA1MTgwNFoXDTI4MTExNDA1MTgwNFowezEX
MBUGA1UEAwwOc2NtLTFAc2NtMS5vcmcxLTArBgNVBAsMJGU4NDUxYjY2LTU0OTkt
NDY1OC1iYWU5LWExODAwZWE0NTdjMzExMC8GA1UECgwoQ0lELTNiMWZkMjI1LWMy
MzItNGNhYi1hYzQ3LWFhYmNkNWE5NmZkNDCCASIwDQYJKoZIhvcNAQEBBQADggEP
ADCCAQoCggEBAPURnJOeX6nYRM9+BN+iGRxnHqK1aFvBZJXdVwbrZ3M4yVfGOGi7
VodYbPrx5r9uMNRpkrqAt3yr9T00WJeiQ+KKKmp6dvZ2tYOYothobP7NyvshtZa2
9V2eicMvc8ChArt0hVLbkayh01lXcI5dTh+m7fDcY6jS+kvUxbmxCBUCD0MHwDcu
zSv4jQrBkiKjPfWVZsVZCUK2vEJ/NECSUN7CRjLL5rUhXHsAnsspjN+6mzHX0pwl
F9y1k0OjbqZHSRfyUSZTFc2rUd0NslJJMRfON39mGmkNPA03D4Za0AG/1Lftpi78
kroUpK8IVpTQdWsuX4nLiL8nf8vBYVuoqN8CAwEAAaM+MDwwDwYDVR0TAQH/BAUw
AwEB/zAOBgNVHQ8BAf8EBAMCAQYwGQYDVR0RBBIwEIcErBkAdIIIc2NtMS5vcmcw
DQYJKoZIhvcNAQELBQADggEBAJYu6WrcpVKt5Ay2c54DXVypD+3I+Z5YKguFHZmw
sHv2vZirQYiP8TUDoAr6GMsepVl4WcT4KB9w4xydwD+tQZ4cT+Ihjp1irTTzzOT3
mmwEXPY/nAwmzQnLWjsFJ7FHMGnxfMeQJlElAajA63ci51ZPWtdcYe7uy5IQArvd
UacEURGJZP0b489uHVMTK6j4InOKKztkpw/2Hhg/vfsbJtzpFf1I9+xd/oWZfZ1I
a3QrrRz2lWZmD+p0r4Dv3flBTdc6AL52DweUo9gfF8IERotvt7FPsV7PUJv+oKbF
JUCZQbJSHx9PWnroQxDujQe/VOP98QcLfXC4WbFrhLSn2Fg=
-----END CERTIFICATE-----

2023-10-07 05:18:05,050 [main] INFO client.SCMCertificateClient: Creating csr for SCM->hostName:scm1.org,scmId:e8451b66-5499-4658-bae9-a1800ea457c3,clusterId:CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4,subject:scm-sub-240442943361@scm1.org
2023-10-07 05:18:05,059 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
2023-10-07 05:18:05,060 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2023-10-07 05:18:05,061 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:e8451b66-5499-4658-bae9-a1800ea457c3,clusterId:CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4,subject:scm-sub-240453426541@scm1.org
2023-10-07 05:18:05,194 [main] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.19, 2.5.29.15, 2.5.29.17
2023-10-07 05:18:05,195 [main] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.17, 2.5.29.19, 1.3.6.1.5.5.7.1.12, 2.5.29.35, 2.5.29.15, 2.5.29.37
2023-10-07 05:18:05,269 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/CA-1.crt
2023-10-07 05:18:05,269 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDrzCCApegAwIBAgIBATANBgkqhkiG9w0BAQsFADB7MRcwFQYDVQQDDA5zY20t
MUBzY20xLm9yZzEtMCsGA1UECwwkZTg0NTFiNjYtNTQ5OS00NjU4LWJhZTktYTE4
MDBlYTQ1N2MzMTEwLwYDVQQKDChDSUQtM2IxZmQyMjUtYzIzMi00Y2FiLWFjNDct
YWFiY2Q1YTk2ZmQ0MB4XDTIzMTAwNzA1MTgwNFoXDTI4MTExNDA1MTgwNFowezEX
MBUGA1UEAwwOc2NtLTFAc2NtMS5vcmcxLTArBgNVBAsMJGU4NDUxYjY2LTU0OTkt
NDY1OC1iYWU5LWExODAwZWE0NTdjMzExMC8GA1UECgwoQ0lELTNiMWZkMjI1LWMy
MzItNGNhYi1hYzQ3LWFhYmNkNWE5NmZkNDCCASIwDQYJKoZIhvcNAQEBBQADggEP
ADCCAQoCggEBAPURnJOeX6nYRM9+BN+iGRxnHqK1aFvBZJXdVwbrZ3M4yVfGOGi7
VodYbPrx5r9uMNRpkrqAt3yr9T00WJeiQ+KKKmp6dvZ2tYOYothobP7NyvshtZa2
9V2eicMvc8ChArt0hVLbkayh01lXcI5dTh+m7fDcY6jS+kvUxbmxCBUCD0MHwDcu
zSv4jQrBkiKjPfWVZsVZCUK2vEJ/NECSUN7CRjLL5rUhXHsAnsspjN+6mzHX0pwl
F9y1k0OjbqZHSRfyUSZTFc2rUd0NslJJMRfON39mGmkNPA03D4Za0AG/1Lftpi78
kroUpK8IVpTQdWsuX4nLiL8nf8vBYVuoqN8CAwEAAaM+MDwwDwYDVR0TAQH/BAUw
AwEB/zAOBgNVHQ8BAf8EBAMCAQYwGQYDVR0RBBIwEIcErBkAdIIIc2NtMS5vcmcw
DQYJKoZIhvcNAQELBQADggEBAJYu6WrcpVKt5Ay2c54DXVypD+3I+Z5YKguFHZmw
sHv2vZirQYiP8TUDoAr6GMsepVl4WcT4KB9w4xydwD+tQZ4cT+Ihjp1irTTzzOT3
mmwEXPY/nAwmzQnLWjsFJ7FHMGnxfMeQJlElAajA63ci51ZPWtdcYe7uy5IQArvd
UacEURGJZP0b489uHVMTK6j4InOKKztkpw/2Hhg/vfsbJtzpFf1I9+xd/oWZfZ1I
a3QrrRz2lWZmD+p0r4Dv3flBTdc6AL52DweUo9gfF8IERotvt7FPsV7PUJv+oKbF
JUCZQbJSHx9PWnroQxDujQe/VOP98QcLfXC4WbFrhLSn2Fg=
-----END CERTIFICATE-----

2023-10-07 05:18:05,276 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/240572405378.crt
2023-10-07 05:18:05,280 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDwzCCAqugAwIBAgIFOAM7loIwDQYJKoZIhvcNAQELBQAwezEXMBUGA1UEAwwO
c2NtLTFAc2NtMS5vcmcxLTArBgNVBAsMJGU4NDUxYjY2LTU0OTktNDY1OC1iYWU5
LWExODAwZWE0NTdjMzExMC8GA1UECgwoQ0lELTNiMWZkMjI1LWMyMzItNGNhYi1h
YzQ3LWFhYmNkNWE5NmZkNDAeFw0yMzEwMDcwNTE4MDVaFw0yODExMTQwNTE4MDVa
MIGKMSYwJAYDVQQDDB1zY20tc3ViLTI0MDQ1MzQyNjU0MUBzY20xLm9yZzEtMCsG
A1UECwwkZTg0NTFiNjYtNTQ5OS00NjU4LWJhZTktYTE4MDBlYTQ1N2MzMTEwLwYD
VQQKDChDSUQtM2IxZmQyMjUtYzIzMi00Y2FiLWFjNDctYWFiY2Q1YTk2ZmQ0MIIB
IjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAuodn3AADa3qe2SAnYdw4VBAZ
wlYsxYng6e3XQI1Xu3FU8/jwMdgjkorcEk4StX4+UeYVzbczGfxCFHk/wjKMbO/d
gAY2f8AqUuxLpl0JJY4QAcZGCPlCUvqFJ/5Fu4rNgvq+y1yudJSZfQqhYv7VIHKc
Wx7+L5cwRgBB/UWeAx1GNMbHYEgMVlAhcNgXxM9T1iRUP/sQmcLzOgU7UPnHWnAs
BmyHr5Px3IYFF5uH+gY8e1W9VXVfvXBru+Ls6tSxlKQFwH4icCUPnmIqpqp5fRtw
BreIm7UKXMKp6h+l8kr9Za46LTGYgsMAx9+5kULo3VBr2YUfoAut4lOfmfgEiwID
AQABoz4wPDAZBgNVHREEEjAQhwSsGQB0gghzY20xLm9yZzAPBgNVHRMBAf8EBTAD
AQH/MA4GA1UdDwEB/wQEAwIBvjANBgkqhkiG9w0BAQsFAAOCAQEAtkdKlPhr2ZkB
Gv2jHMvveST+GMonRlVLv5WnwdmzMkO7y9WV8lc4Y25NrfP97gMIes1mooigkvEV
Eo+z5i9aHbJ7AQvfE6j/WwGuAHG/xPrUyRyu6WQ5WjKzt6sVLEfYgAuO4aBIyMOB
34hRBLhNHwsQpkKDLIZ3LPKLgj8qSPhK+St4uwvFKX21RalFRMzmQStvAtj2t+jC
Vo/eyUMrj/29LF/yXXkYrA8vUhg7pelPVlFUwobO59Dcgze3ocpKlY3+um55P4SV
PcyVAwNYc8QfynQE9Wy5RiVVJnGE9DfX3cJ7QDqeFejuIRvUZk1fV0pYeCdChIUv
gXpcNzsKZw==
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDrzCCApegAwIBAgIBATANBgkqhkiG9w0BAQsFADB7MRcwFQYDVQQDDA5zY20t
MUBzY20xLm9yZzEtMCsGA1UECwwkZTg0NTFiNjYtNTQ5OS00NjU4LWJhZTktYTE4
MDBlYTQ1N2MzMTEwLwYDVQQKDChDSUQtM2IxZmQyMjUtYzIzMi00Y2FiLWFjNDct
YWFiY2Q1YTk2ZmQ0MB4XDTIzMTAwNzA1MTgwNFoXDTI4MTExNDA1MTgwNFowezEX
MBUGA1UEAwwOc2NtLTFAc2NtMS5vcmcxLTArBgNVBAsMJGU4NDUxYjY2LTU0OTkt
NDY1OC1iYWU5LWExODAwZWE0NTdjMzExMC8GA1UECgwoQ0lELTNiMWZkMjI1LWMy
MzItNGNhYi1hYzQ3LWFhYmNkNWE5NmZkNDCCASIwDQYJKoZIhvcNAQEBBQADggEP
ADCCAQoCggEBAPURnJOeX6nYRM9+BN+iGRxnHqK1aFvBZJXdVwbrZ3M4yVfGOGi7
VodYbPrx5r9uMNRpkrqAt3yr9T00WJeiQ+KKKmp6dvZ2tYOYothobP7NyvshtZa2
9V2eicMvc8ChArt0hVLbkayh01lXcI5dTh+m7fDcY6jS+kvUxbmxCBUCD0MHwDcu
zSv4jQrBkiKjPfWVZsVZCUK2vEJ/NECSUN7CRjLL5rUhXHsAnsspjN+6mzHX0pwl
F9y1k0OjbqZHSRfyUSZTFc2rUd0NslJJMRfON39mGmkNPA03D4Za0AG/1Lftpi78
kroUpK8IVpTQdWsuX4nLiL8nf8vBYVuoqN8CAwEAAaM+MDwwDwYDVR0TAQH/BAUw
AwEB/zAOBgNVHQ8BAf8EBAMCAQYwGQYDVR0RBBIwEIcErBkAdIIIc2NtMS5vcmcw
DQYJKoZIhvcNAQELBQADggEBAJYu6WrcpVKt5Ay2c54DXVypD+3I+Z5YKguFHZmw
sHv2vZirQYiP8TUDoAr6GMsepVl4WcT4KB9w4xydwD+tQZ4cT+Ihjp1irTTzzOT3
mmwEXPY/nAwmzQnLWjsFJ7FHMGnxfMeQJlElAajA63ci51ZPWtdcYe7uy5IQArvd
UacEURGJZP0b489uHVMTK6j4InOKKztkpw/2Hhg/vfsbJtzpFf1I9+xd/oWZfZ1I
a3QrrRz2lWZmD+p0r4Dv3flBTdc6AL52DweUo9gfF8IERotvt7FPsV7PUJv+oKbF
JUCZQbJSHx9PWnroQxDujQe/VOP98QcLfXC4WbFrhLSn2Fg=
-----END CERTIFICATE-----

2023-10-07 05:18:05,281 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/certificate.crt
2023-10-07 05:18:05,286 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDwzCCAqugAwIBAgIFOAM7loIwDQYJKoZIhvcNAQELBQAwezEXMBUGA1UEAwwO
c2NtLTFAc2NtMS5vcmcxLTArBgNVBAsMJGU4NDUxYjY2LTU0OTktNDY1OC1iYWU5
LWExODAwZWE0NTdjMzExMC8GA1UECgwoQ0lELTNiMWZkMjI1LWMyMzItNGNhYi1h
YzQ3LWFhYmNkNWE5NmZkNDAeFw0yMzEwMDcwNTE4MDVaFw0yODExMTQwNTE4MDVa
MIGKMSYwJAYDVQQDDB1zY20tc3ViLTI0MDQ1MzQyNjU0MUBzY20xLm9yZzEtMCsG
A1UECwwkZTg0NTFiNjYtNTQ5OS00NjU4LWJhZTktYTE4MDBlYTQ1N2MzMTEwLwYD
VQQKDChDSUQtM2IxZmQyMjUtYzIzMi00Y2FiLWFjNDctYWFiY2Q1YTk2ZmQ0MIIB
IjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAuodn3AADa3qe2SAnYdw4VBAZ
wlYsxYng6e3XQI1Xu3FU8/jwMdgjkorcEk4StX4+UeYVzbczGfxCFHk/wjKMbO/d
gAY2f8AqUuxLpl0JJY4QAcZGCPlCUvqFJ/5Fu4rNgvq+y1yudJSZfQqhYv7VIHKc
Wx7+L5cwRgBB/UWeAx1GNMbHYEgMVlAhcNgXxM9T1iRUP/sQmcLzOgU7UPnHWnAs
BmyHr5Px3IYFF5uH+gY8e1W9VXVfvXBru+Ls6tSxlKQFwH4icCUPnmIqpqp5fRtw
BreIm7UKXMKp6h+l8kr9Za46LTGYgsMAx9+5kULo3VBr2YUfoAut4lOfmfgEiwID
AQABoz4wPDAZBgNVHREEEjAQhwSsGQB0gghzY20xLm9yZzAPBgNVHRMBAf8EBTAD
AQH/MA4GA1UdDwEB/wQEAwIBvjANBgkqhkiG9w0BAQsFAAOCAQEAtkdKlPhr2ZkB
Gv2jHMvveST+GMonRlVLv5WnwdmzMkO7y9WV8lc4Y25NrfP97gMIes1mooigkvEV
Eo+z5i9aHbJ7AQvfE6j/WwGuAHG/xPrUyRyu6WQ5WjKzt6sVLEfYgAuO4aBIyMOB
34hRBLhNHwsQpkKDLIZ3LPKLgj8qSPhK+St4uwvFKX21RalFRMzmQStvAtj2t+jC
Vo/eyUMrj/29LF/yXXkYrA8vUhg7pelPVlFUwobO59Dcgze3ocpKlY3+um55P4SV
PcyVAwNYc8QfynQE9Wy5RiVVJnGE9DfX3cJ7QDqeFejuIRvUZk1fV0pYeCdChIUv
gXpcNzsKZw==
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDrzCCApegAwIBAgIBATANBgkqhkiG9w0BAQsFADB7MRcwFQYDVQQDDA5zY20t
MUBzY20xLm9yZzEtMCsGA1UECwwkZTg0NTFiNjYtNTQ5OS00NjU4LWJhZTktYTE4
MDBlYTQ1N2MzMTEwLwYDVQQKDChDSUQtM2IxZmQyMjUtYzIzMi00Y2FiLWFjNDct
YWFiY2Q1YTk2ZmQ0MB4XDTIzMTAwNzA1MTgwNFoXDTI4MTExNDA1MTgwNFowezEX
MBUGA1UEAwwOc2NtLTFAc2NtMS5vcmcxLTArBgNVBAsMJGU4NDUxYjY2LTU0OTkt
NDY1OC1iYWU5LWExODAwZWE0NTdjMzExMC8GA1UECgwoQ0lELTNiMWZkMjI1LWMy
MzItNGNhYi1hYzQ3LWFhYmNkNWE5NmZkNDCCASIwDQYJKoZIhvcNAQEBBQADggEP
ADCCAQoCggEBAPURnJOeX6nYRM9+BN+iGRxnHqK1aFvBZJXdVwbrZ3M4yVfGOGi7
VodYbPrx5r9uMNRpkrqAt3yr9T00WJeiQ+KKKmp6dvZ2tYOYothobP7NyvshtZa2
9V2eicMvc8ChArt0hVLbkayh01lXcI5dTh+m7fDcY6jS+kvUxbmxCBUCD0MHwDcu
zSv4jQrBkiKjPfWVZsVZCUK2vEJ/NECSUN7CRjLL5rUhXHsAnsspjN+6mzHX0pwl
F9y1k0OjbqZHSRfyUSZTFc2rUd0NslJJMRfON39mGmkNPA03D4Za0AG/1Lftpi78
kroUpK8IVpTQdWsuX4nLiL8nf8vBYVuoqN8CAwEAAaM+MDwwDwYDVR0TAQH/BAUw
AwEB/zAOBgNVHQ8BAf8EBAMCAQYwGQYDVR0RBBIwEIcErBkAdIIIc2NtMS5vcmcw
DQYJKoZIhvcNAQELBQADggEBAJYu6WrcpVKt5Ay2c54DXVypD+3I+Z5YKguFHZmw
sHv2vZirQYiP8TUDoAr6GMsepVl4WcT4KB9w4xydwD+tQZ4cT+Ihjp1irTTzzOT3
mmwEXPY/nAwmzQnLWjsFJ7FHMGnxfMeQJlElAajA63ci51ZPWtdcYe7uy5IQArvd
UacEURGJZP0b489uHVMTK6j4InOKKztkpw/2Hhg/vfsbJtzpFf1I9+xd/oWZfZ1I
a3QrrRz2lWZmD+p0r4Dv3flBTdc6AL52DweUo9gfF8IERotvt7FPsV7PUJv+oKbF
JUCZQbJSHx9PWnroQxDujQe/VOP98QcLfXC4WbFrhLSn2Fg=
-----END CERTIFICATE-----

2023-10-07 05:18:05,288 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
2023-10-07 05:18:05,645 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2023-10-07 05:18:05,951 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-10-07 05:18:05,955 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2023-10-07 05:18:05,984 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-10-07 05:18:05,985 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2023-10-07 05:18:05,985 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2023-10-07 05:18:05,991 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2023-10-07 05:18:05,992 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2023-10-07 05:18:05,999 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-10-07 05:18:06,000 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-10-07 05:18:06,000 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-10-07 05:18:06,076 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-10-07 05:18:06,085 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-10-07 05:18:06,104 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-10-07 05:18:07,440 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2023-10-07 05:18:07,443 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2023-10-07 05:18:07,448 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2023-10-07 05:18:07,448 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2023-10-07 05:18:07,448 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-10-07 05:18:07,453 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-10-07 05:18:07,474 [main] INFO server.RaftServer: e8451b66-5499-4658-bae9-a1800ea457c3: addNew group-AABCD5A96FD4:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER] returns group-AABCD5A96FD4:java.util.concurrent.CompletableFuture@1c6ac73c[Not completed]
2023-10-07 05:18:07,562 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3: new RaftServerImpl for group-AABCD5A96FD4:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER] with SCMStateMachine:uninitialized
2023-10-07 05:18:07,565 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2023-10-07 05:18:07,575 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2023-10-07 05:18:07,576 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2023-10-07 05:18:07,576 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2023-10-07 05:18:07,576 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-10-07 05:18:07,577 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2023-10-07 05:18:07,601 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: ConfigurationManager, init=-1: peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-10-07 05:18:07,601 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-10-07 05:18:07,608 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2023-10-07 05:18:07,623 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2023-10-07 05:18:07,647 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2023-10-07 05:18:07,657 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2023-10-07 05:18:07,677 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2023-10-07 05:18:07,681 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
2023-10-07 05:18:07,737 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2023-10-07 05:18:07,756 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2023-10-07 05:18:08,059 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-10-07 05:18:08,066 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-10-07 05:18:08,068 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2023-10-07 05:18:08,069 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2023-10-07 05:18:08,070 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2023-10-07 05:18:08,071 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2023-10-07 05:18:08,073 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/3b1fd225-c232-4cab-ac47-aabcd5a96fd4 does not exist. Creating ...
2023-10-07 05:18:08,084 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/3b1fd225-c232-4cab-ac47-aabcd5a96fd4/in_use.lock acquired by nodename 13@scm1.org
2023-10-07 05:18:08,119 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/3b1fd225-c232-4cab-ac47-aabcd5a96fd4 has been successfully formatted.
2023-10-07 05:18:08,133 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2023-10-07 05:18:08,146 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2023-10-07 05:18:08,151 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-10-07 05:18:08,153 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-10-07 05:18:08,153 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2023-10-07 05:18:08,157 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-10-07 05:18:08,171 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2023-10-07 05:18:08,185 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-10-07 05:18:08,186 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-10-07 05:18:08,206 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/3b1fd225-c232-4cab-ac47-aabcd5a96fd4
2023-10-07 05:18:08,207 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-10-07 05:18:08,207 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2023-10-07 05:18:08,208 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-10-07 05:18:08,214 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2023-10-07 05:18:08,214 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2023-10-07 05:18:08,215 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2023-10-07 05:18:08,215 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-10-07 05:18:08,216 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-10-07 05:18:08,271 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
2023-10-07 05:18:08,275 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-10-07 05:18:08,314 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2023-10-07 05:18:08,327 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2023-10-07 05:18:08,328 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2023-10-07 05:18:08,364 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-10-07 05:18:08,372 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-10-07 05:18:08,375 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: start as a follower, conf=-1: peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-10-07 05:18:08,392 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-10-07 05:18:08,393 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO impl.RoleInfo: e8451b66-5499-4658-bae9-a1800ea457c3: start e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState
2023-10-07 05:18:08,401 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AABCD5A96FD4,id=e8451b66-5499-4658-bae9-a1800ea457c3
2023-10-07 05:18:08,403 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-10-07 05:18:08,415 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2023-10-07 05:18:08,423 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2023-10-07 05:18:08,424 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2023-10-07 05:18:08,426 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-10-07 05:18:08,431 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-10-07 05:18:08,467 [main] INFO server.RaftServer: e8451b66-5499-4658-bae9-a1800ea457c3: start RPC server
2023-10-07 05:18:08,655 [main] INFO server.GrpcService: e8451b66-5499-4658-bae9-a1800ea457c3: GrpcService started, listening on 9894
2023-10-07 05:18:08,691 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-e8451b66-5499-4658-bae9-a1800ea457c3: Started
2023-10-07 05:18:13,454 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState] INFO impl.FollowerState: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5061232517ns, electionTimeout:5017ms
2023-10-07 05:18:13,456 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState] INFO impl.RoleInfo: e8451b66-5499-4658-bae9-a1800ea457c3: shutdown e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState
2023-10-07 05:18:13,456 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-10-07 05:18:13,460 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2023-10-07 05:18:13,460 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState] INFO impl.RoleInfo: e8451b66-5499-4658-bae9-a1800ea457c3: start e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1
2023-10-07 05:18:13,462 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO impl.LeaderElection: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-10-07 05:18:13,463 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO impl.LeaderElection: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2023-10-07 05:18:13,466 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO impl.LeaderElection: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-10-07 05:18:13,466 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO impl.LeaderElection: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2023-10-07 05:18:13,466 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO impl.RoleInfo: e8451b66-5499-4658-bae9-a1800ea457c3: shutdown e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1
2023-10-07 05:18:13,467 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-10-07 05:18:13,467 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: change Leader from null to e8451b66-5499-4658-bae9-a1800ea457c3 at term 1 for becomeLeader, leader elected after 5820ms
2023-10-07 05:18:13,473 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2023-10-07 05:18:13,476 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2023-10-07 05:18:13,477 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2023-10-07 05:18:13,481 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2023-10-07 05:18:13,481 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2023-10-07 05:18:13,482 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2023-10-07 05:18:13,531 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2023-10-07 05:18:13,540 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-10-07 05:18:13,542 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO impl.RoleInfo: e8451b66-5499-4658-bae9-a1800ea457c3: start e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderStateImpl
2023-10-07 05:18:13,624 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-SegmentedRaftLogWorker: Starting segment from index:0
2023-10-07 05:18:13,821 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: set configuration 0: peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-10-07 05:18:14,020 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/3b1fd225-c232-4cab-ac47-aabcd5a96fd4/current/log_inprogress_0
2023-10-07 05:18:14,661 [main] INFO server.RaftServer: e8451b66-5499-4658-bae9-a1800ea457c3: close
2023-10-07 05:18:14,661 [main] INFO server.GrpcService: e8451b66-5499-4658-bae9-a1800ea457c3: shutdown server GrpcServerProtocolService now
2023-10-07 05:18:14,662 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: shutdown
2023-10-07 05:18:14,662 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AABCD5A96FD4,id=e8451b66-5499-4658-bae9-a1800ea457c3
2023-10-07 05:18:14,662 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO impl.RoleInfo: e8451b66-5499-4658-bae9-a1800ea457c3: shutdown e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderStateImpl
2023-10-07 05:18:14,684 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO impl.PendingRequests: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-PendingRequests: sendNotLeaderResponses
2023-10-07 05:18:14,687 [main] INFO server.GrpcService: e8451b66-5499-4658-bae9-a1800ea457c3: shutdown server GrpcServerProtocolService successfully
2023-10-07 05:18:14,700 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO impl.StateMachineUpdater: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater: set stopIndex = 0
2023-10-07 05:18:14,707 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO impl.StateMachineUpdater: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater: Took a snapshot at index 0
2023-10-07 05:18:14,708 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO impl.StateMachineUpdater: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-10-07 05:18:14,714 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: closes. applyIndex: 0
2023-10-07 05:18:15,041 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-SegmentedRaftLogWorker close()
2023-10-07 05:18:15,042 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-e8451b66-5499-4658-bae9-a1800ea457c3: Stopped
2023-10-07 05:18:15,043 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-10-07 05:18:15,046 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4; layoutVersion=7; scmId=e8451b66-5499-4658-bae9-a1800ea457c3
2023-10-07 05:18:15,069 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-10-07 05:18:17,611 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm1.org/172.25.0.116
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.5.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.5.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.5.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.5.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/okio-3.4.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.5.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.5.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.5.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.5.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.4.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.52.v20230823.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/0a11bba5aa277a26c9b7c24adb6367fd13c9c1aa ; compiled by 'runner' on 2023-10-07T04:45Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=true, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=16KB, dfs.container.ratis.segment.size=1MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.retries=-1, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60s, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=9864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=1ms, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=64KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.handler.type=distributed, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-address.omservice.om1=om1, ozone.om.http-address.omservice.om2=om2, ozone.om.http-address.omservice.om3=om3, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.internal.service.id=omservice, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=0, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.GrpcOmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=false, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=20s, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.domain.name=s3g.internal, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=5s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.enable=true, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-10-07 05:18:17,621 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-10-07 05:18:17,678 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-10-07 05:18:17,856 [main] INFO reflections.Reflections: Reflections took 106 ms to scan 3 urls, producing 133 keys and 289 values 
2023-10-07 05:18:17,960 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2023-10-07 05:18:17,968 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-10-07 05:18:17,988 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
2023-10-07 05:18:17,988 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
2023-10-07 05:18:18,188 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2023-10-07 05:18:18,188 [main] INFO server.StorageContainerManager: SCM login successful.
2023-10-07 05:18:19,310 [main] INFO client.SCMCertificateClient: Certificate serial ID set to 240572405378
2023-10-07 05:18:19,572 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 240572405378
             IssuerDN: CN=scm-1@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4
           Start Date: Sat Oct 07 05:18:05 UTC 2023
           Final Date: Tue Nov 14 05:18:05 UTC 2028
            SubjectDN: CN=scm-sub-240453426541@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4
           Public Key: RSA Public Key [cc:7a:84:f0:b7:ad:23:e0:fd:3e:5b:17:34:2a:c5:7f:91:93:72:54],[56:66:d1:a4]
        modulus: ba8767dc00036b7a9ed9202761dc38541019c2562cc589e0e9edd7408d57bb7154f3f8f031d823928adc124e12b57e3e51e615cdb73319fc4214793fc2328c6cefdd8006367fc02a52ec4ba65d09258e1001c64608f94252fa8527fe45bb8acd82fabecb5cae7494997d0aa162fed520729c5b1efe2f9730460041fd459e031d4634c6c760480c56502170d817c4cf53d624543ffb1099c2f33a053b50f9c75a702c066c87af93f1dc8605179b87fa063c7b55bd55755fbd706bbbe2ecead4b194a405c07e2270250f9e622aa6aa797d1b7006b7889bb50a5cc2a9ea1fa5f24afd65ae3a2d319882c300c7dfb99142e8dd506bd9851fa00bade2539f99f8048b
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: b6474a94f86bd999011afda31ccbef7924fe18ca
                       2746554bbf95a7c1d9b33243bbcbd595f2573863
                       6e4dadf3fdee03087acd66a288a092f115128fb3
                       e62f5a1db27b010bdf13a8ff5b01ae0071bfc4fa
                       d4c91caee964395a32b3b7ab152c47d8800b8ee1
                       a048c8c381df885104b84d1f0b10a642832c8677
                       2cf28b823f2a48f84af92b78bb0bc5297db545a9
                       4544cce6412b6f02d8f6b7e8c2568fdec9432b8f
                       fdbd2c5ff25d7918ac0f2f52183ba5e94f565154
                       c286cee7d0dc8337b7a1ca4a958dfeba6e793f84
                       953dcc9503035873c41fca7404f56cb946255526
                       7184f437d7ddc27b403a9e15e8ee211bd4664d5f
                       574a5878274284852f817a5c373b0a67
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/certificate.crt.
2023-10-07 05:18:19,580 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 240572405378
             IssuerDN: CN=scm-1@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4
           Start Date: Sat Oct 07 05:18:05 UTC 2023
           Final Date: Tue Nov 14 05:18:05 UTC 2028
            SubjectDN: CN=scm-sub-240453426541@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4
           Public Key: RSA Public Key [cc:7a:84:f0:b7:ad:23:e0:fd:3e:5b:17:34:2a:c5:7f:91:93:72:54],[56:66:d1:a4]
        modulus: ba8767dc00036b7a9ed9202761dc38541019c2562cc589e0e9edd7408d57bb7154f3f8f031d823928adc124e12b57e3e51e615cdb73319fc4214793fc2328c6cefdd8006367fc02a52ec4ba65d09258e1001c64608f94252fa8527fe45bb8acd82fabecb5cae7494997d0aa162fed520729c5b1efe2f9730460041fd459e031d4634c6c760480c56502170d817c4cf53d624543ffb1099c2f33a053b50f9c75a702c066c87af93f1dc8605179b87fa063c7b55bd55755fbd706bbbe2ecead4b194a405c07e2270250f9e622aa6aa797d1b7006b7889bb50a5cc2a9ea1fa5f24afd65ae3a2d319882c300c7dfb99142e8dd506bd9851fa00bade2539f99f8048b
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: b6474a94f86bd999011afda31ccbef7924fe18ca
                       2746554bbf95a7c1d9b33243bbcbd595f2573863
                       6e4dadf3fdee03087acd66a288a092f115128fb3
                       e62f5a1db27b010bdf13a8ff5b01ae0071bfc4fa
                       d4c91caee964395a32b3b7ab152c47d8800b8ee1
                       a048c8c381df885104b84d1f0b10a642832c8677
                       2cf28b823f2a48f84af92b78bb0bc5297db545a9
                       4544cce6412b6f02d8f6b7e8c2568fdec9432b8f
                       fdbd2c5ff25d7918ac0f2f52183ba5e94f565154
                       c286cee7d0dc8337b7a1ca4a958dfeba6e793f84
                       953dcc9503035873c41fca7404f56cb946255526
                       7184f437d7ddc27b403a9e15e8ee211bd4664d5f
                       574a5878274284852f817a5c373b0a67
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/240572405378.crt.
2023-10-07 05:18:19,594 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm-1@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4
           Start Date: Sat Oct 07 05:18:04 UTC 2023
           Final Date: Tue Nov 14 05:18:04 UTC 2028
            SubjectDN: CN=scm-1@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4
           Public Key: RSA Public Key [7f:74:36:e8:65:e9:f4:dc:98:d5:e3:55:f0:f8:ad:04:d8:fc:15:45],[56:66:d1:a4]
        modulus: f5119c939e5fa9d844cf7e04dfa2191c671ea2b5685bc16495dd5706eb677338c957c63868bb5687586cfaf1e6bf6e30d46992ba80b77cabf53d345897a243e28a2a6a7a76f676b58398a2d8686cfecdcafb21b596b6f55d9e89c32f73c0a102bb748552db91aca1d35957708e5d4e1fa6edf0dc63a8d2fa4bd4c5b9b10815020f4307c0372ecd2bf88d0ac19222a33df59566c5590942b6bc427f34409250dec24632cbe6b5215c7b009ecb298cdfba9b31d7d29c2517dcb59343a36ea6474917f251265315cdab51dd0db252493117ce377f661a690d3c0d370f865ad001bfd4b7eda62efc92ba14a4af085694d0756b2e5f89cb88bf277fcbc1615ba8a8df
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 962ee96adca552ade40cb6739e035d5ca90fedc8
                       f99e582a0b851d99b0b07bf6bd98ab41888ff135
                       03a00afa18cb1ea5597859c4f8281f70e31c9dc0
                       3fad419e1c4fe2218e9d62ad34f3cce4f79a6c04
                       5cf63f9c0c26cd09cb5a3b0527b1473069f17cc7
                       9026512501a8c0eb7722e7564f5ad75c61eeeecb
                       921002bbdd51a70451118964fd1be3cf6e1d5313
                       2ba8f822738a2b3b64a70ff61e183fbdfb1b26dc
                       e915fd48f7ec5dfe85997d9d486b742bad1cf695
                       66660fea74af80efddf9414dd73a00be760f0794
                       a3d81f17c204468b6fb7b14fb15ecf509bfea0a6
                       c525409941b2521f1f4f5a7ae84310ee8d07bf54
                       e3fdf1070b7d70b859b16b84b4a7d858
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

 from file: /data/metadata/scm/sub-ca/certs/CA-1.crt.
2023-10-07 05:18:19,594 [main] INFO client.SCMCertificateClient: CertificateRenewerService and root ca rotation polling is disabled for scm/sub-ca
2023-10-07 05:18:19,763 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-10-07 05:18:19,971 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-10-07 05:18:20,228 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-10-07 05:18:20,229 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2023-10-07 05:18:20,296 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2023-10-07 05:18:20,528 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:e8451b66-5499-4658-bae9-a1800ea457c3
2023-10-07 05:18:20,575 [main] INFO ssl.ReloadingX509KeyManager: Key manager is loaded with certificate chain
2023-10-07 05:18:20,580 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 240572405378
             IssuerDN: CN=scm-1@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4
           Start Date: Sat Oct 07 05:18:05 UTC 2023
           Final Date: Tue Nov 14 05:18:05 UTC 2028
            SubjectDN: CN=scm-sub-240453426541@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4
           Public Key: RSA Public Key [cc:7a:84:f0:b7:ad:23:e0:fd:3e:5b:17:34:2a:c5:7f:91:93:72:54],[56:66:d1:a4]
        modulus: ba8767dc00036b7a9ed9202761dc38541019c2562cc589e0e9edd7408d57bb7154f3f8f031d823928adc124e12b57e3e51e615cdb73319fc4214793fc2328c6cefdd8006367fc02a52ec4ba65d09258e1001c64608f94252fa8527fe45bb8acd82fabecb5cae7494997d0aa162fed520729c5b1efe2f9730460041fd459e031d4634c6c760480c56502170d817c4cf53d624543ffb1099c2f33a053b50f9c75a702c066c87af93f1dc8605179b87fa063c7b55bd55755fbd706bbbe2ecead4b194a405c07e2270250f9e622aa6aa797d1b7006b7889bb50a5cc2a9ea1fa5f24afd65ae3a2d319882c300c7dfb99142e8dd506bd9851fa00bade2539f99f8048b
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: b6474a94f86bd999011afda31ccbef7924fe18ca
                       2746554bbf95a7c1d9b33243bbcbd595f2573863
                       6e4dadf3fdee03087acd66a288a092f115128fb3
                       e62f5a1db27b010bdf13a8ff5b01ae0071bfc4fa
                       d4c91caee964395a32b3b7ab152c47d8800b8ee1
                       a048c8c381df885104b84d1f0b10a642832c8677
                       2cf28b823f2a48f84af92b78bb0bc5297db545a9
                       4544cce6412b6f02d8f6b7e8c2568fdec9432b8f
                       fdbd2c5ff25d7918ac0f2f52183ba5e94f565154
                       c286cee7d0dc8337b7a1ca4a958dfeba6e793f84
                       953dcc9503035873c41fca7404f56cb946255526
                       7184f437d7ddc27b403a9e15e8ee211bd4664d5f
                       574a5878274284852f817a5c373b0a67
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe

2023-10-07 05:18:20,583 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm-1@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4
           Start Date: Sat Oct 07 05:18:04 UTC 2023
           Final Date: Tue Nov 14 05:18:04 UTC 2028
            SubjectDN: CN=scm-1@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4
           Public Key: RSA Public Key [7f:74:36:e8:65:e9:f4:dc:98:d5:e3:55:f0:f8:ad:04:d8:fc:15:45],[56:66:d1:a4]
        modulus: f5119c939e5fa9d844cf7e04dfa2191c671ea2b5685bc16495dd5706eb677338c957c63868bb5687586cfaf1e6bf6e30d46992ba80b77cabf53d345897a243e28a2a6a7a76f676b58398a2d8686cfecdcafb21b596b6f55d9e89c32f73c0a102bb748552db91aca1d35957708e5d4e1fa6edf0dc63a8d2fa4bd4c5b9b10815020f4307c0372ecd2bf88d0ac19222a33df59566c5590942b6bc427f34409250dec24632cbe6b5215c7b009ecb298cdfba9b31d7d29c2517dcb59343a36ea6474917f251265315cdab51dd0db252493117ce377f661a690d3c0d370f865ad001bfd4b7eda62efc92ba14a4af085694d0756b2e5f89cb88bf277fcbc1615ba8a8df
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 962ee96adca552ade40cb6739e035d5ca90fedc8
                       f99e582a0b851d99b0b07bf6bd98ab41888ff135
                       03a00afa18cb1ea5597859c4f8281f70e31c9dc0
                       3fad419e1c4fe2218e9d62ad34f3cce4f79a6c04
                       5cf63f9c0c26cd09cb5a3b0527b1473069f17cc7
                       9026512501a8c0eb7722e7564f5ad75c61eeeecb
                       921002bbdd51a70451118964fd1be3cf6e1d5313
                       2ba8f822738a2b3b64a70ff61e183fbdfb1b26dc
                       e915fd48f7ec5dfe85997d9d486b742bad1cf695
                       66660fea74af80efddf9414dd73a00be760f0794
                       a3d81f17c204468b6fb7b14fb15ecf509bfea0a6
                       c525409941b2521f1f4f5a7ae84310ee8d07bf54
                       e3fdf1070b7d70b859b16b84b4a7d858
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2023-10-07 05:18:20,611 [main] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-10-07 05:18:20,612 [main] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-10-07 05:18:20,612 [main] INFO ssl.ReloadingX509TrustManager: Trust manager is loaded with certificates
2023-10-07 05:18:20,613 [main] INFO ssl.ReloadingX509TrustManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm-1@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4
           Start Date: Sat Oct 07 05:18:04 UTC 2023
           Final Date: Tue Nov 14 05:18:04 UTC 2028
            SubjectDN: CN=scm-1@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4
           Public Key: RSA Public Key [7f:74:36:e8:65:e9:f4:dc:98:d5:e3:55:f0:f8:ad:04:d8:fc:15:45],[56:66:d1:a4]
        modulus: f5119c939e5fa9d844cf7e04dfa2191c671ea2b5685bc16495dd5706eb677338c957c63868bb5687586cfaf1e6bf6e30d46992ba80b77cabf53d345897a243e28a2a6a7a76f676b58398a2d8686cfecdcafb21b596b6f55d9e89c32f73c0a102bb748552db91aca1d35957708e5d4e1fa6edf0dc63a8d2fa4bd4c5b9b10815020f4307c0372ecd2bf88d0ac19222a33df59566c5590942b6bc427f34409250dec24632cbe6b5215c7b009ecb298cdfba9b31d7d29c2517dcb59343a36ea6474917f251265315cdab51dd0db252493117ce377f661a690d3c0d370f865ad001bfd4b7eda62efc92ba14a4af085694d0756b2e5f89cb88bf277fcbc1615ba8a8df
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 962ee96adca552ade40cb6739e035d5ca90fedc8
                       f99e582a0b851d99b0b07bf6bd98ab41888ff135
                       03a00afa18cb1ea5597859c4f8281f70e31c9dc0
                       3fad419e1c4fe2218e9d62ad34f3cce4f79a6c04
                       5cf63f9c0c26cd09cb5a3b0527b1473069f17cc7
                       9026512501a8c0eb7722e7564f5ad75c61eeeecb
                       921002bbdd51a70451118964fd1be3cf6e1d5313
                       2ba8f822738a2b3b64a70ff61e183fbdfb1b26dc
                       e915fd48f7ec5dfe85997d9d486b742bad1cf695
                       66660fea74af80efddf9414dd73a00be760f0794
                       a3d81f17c204468b6fb7b14fb15ecf509bfea0a6
                       c525409941b2521f1f4f5a7ae84310ee8d07bf54
                       e3fdf1070b7d70b859b16b84b4a7d858
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2023-10-07 05:18:20,627 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-10-07 05:18:20,630 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-10-07 05:18:20,666 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2023-10-07 05:18:20,672 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-10-07 05:18:20,673 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2023-10-07 05:18:20,674 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-10-07 05:18:20,674 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2023-10-07 05:18:20,675 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2023-10-07 05:18:20,675 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2023-10-07 05:18:20,675 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2023-10-07 05:18:20,677 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-10-07 05:18:20,677 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-10-07 05:18:20,678 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-10-07 05:18:20,687 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-10-07 05:18:20,690 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-10-07 05:18:20,690 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-10-07 05:18:21,088 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2023-10-07 05:18:21,090 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2023-10-07 05:18:21,090 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2023-10-07 05:18:21,090 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2023-10-07 05:18:21,091 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-10-07 05:18:21,097 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-10-07 05:18:21,131 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServer: e8451b66-5499-4658-bae9-a1800ea457c3: found a subdirectory /data/metadata/scm-ha/3b1fd225-c232-4cab-ac47-aabcd5a96fd4
2023-10-07 05:18:21,160 [main] INFO server.RaftServer: e8451b66-5499-4658-bae9-a1800ea457c3: addNew group-AABCD5A96FD4:[] returns group-AABCD5A96FD4:java.util.concurrent.CompletableFuture@52e92f6[Not completed]
2023-10-07 05:18:21,237 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3: new RaftServerImpl for group-AABCD5A96FD4:[] with SCMStateMachine:uninitialized
2023-10-07 05:18:21,244 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2023-10-07 05:18:21,244 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2023-10-07 05:18:21,245 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2023-10-07 05:18:21,245 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2023-10-07 05:18:21,246 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-10-07 05:18:21,246 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2023-10-07 05:18:21,260 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-10-07 05:18:21,261 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-10-07 05:18:21,265 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2023-10-07 05:18:21,265 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2023-10-07 05:18:21,300 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2023-10-07 05:18:21,303 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2023-10-07 05:18:21,314 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2023-10-07 05:18:21,314 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
2023-10-07 05:18:21,349 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2023-10-07 05:18:21,554 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-10-07 05:18:21,557 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-10-07 05:18:21,557 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2023-10-07 05:18:21,558 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2023-10-07 05:18:21,558 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2023-10-07 05:18:21,558 [e8451b66-5499-4658-bae9-a1800ea457c3-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2023-10-07 05:18:21,560 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2023-10-07 05:18:21,560 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-10-07 05:18:21,561 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2023-10-07 05:18:21,650 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2023-10-07 05:18:21,730 [main] INFO ha.SequenceIdGenerator: upgrade localId to 111677748019200000
2023-10-07 05:18:21,733 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2023-10-07 05:18:21,748 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2023-10-07 05:18:21,751 [main] INFO ha.SequenceIdGenerator: upgrade rootCertificateId to 1
2023-10-07 05:18:21,753 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2023-10-07 05:18:21,904 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2023-10-07 05:18:21,937 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2023-10-07 05:18:21,939 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-10-07 05:18:21,961 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2023-10-07 05:18:21,996 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-10-07 05:18:21,997 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-10-07 05:18:22,007 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2023-10-07 05:18:22,012 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
2023-10-07 05:18:22,021 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2023-10-07 05:18:22,031 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2023-10-07 05:18:22,038 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2023-10-07 05:18:22,048 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2023-10-07 05:18:22,090 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-10-07 05:18:22,090 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-10-07 05:18:22,121 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2023-10-07 05:18:22,348 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2023-10-07 05:18:22,356 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2023-10-07 05:18:22,356 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2023-10-07 05:18:22,369 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2023-10-07 05:18:22,375 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:18:22,377 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-10-07 05:18:22,616 [main] INFO security.SecretKeyManagerService: Scheduling rotation checker with interval PT1M
2023-10-07 05:18:22,616 [main] INFO ha.SCMServiceManager: Registering service SecretKeyManagerService.
2023-10-07 05:18:22,641 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2023-10-07 05:18:22,647 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2023-10-07 05:18:22,648 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 240572405378 on primary SCM
2023-10-07 05:18:22,663 [main] INFO server.SCMCertStore: Scm certificate 240572405378 for CN=scm-sub-240453426541@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4 is stored
2023-10-07 05:18:22,664 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
2023-10-07 05:18:22,667 [main] INFO server.SCMCertStore: Scm certificate 1 for CN=scm-1@scm1.org,OU=e8451b66-5499-4658-bae9-a1800ea457c3,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4 is stored
2023-10-07 05:18:22,698 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-10-07 05:18:22,728 [main] INFO ipc.Server: Listener at 0.0.0.0:9961
2023-10-07 05:18:22,732 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
2023-10-07 05:18:22,768 [main] INFO server.StorageContainerManager: SCM start with adminUsers: [testuser, recon, om, scm]
2023-10-07 05:18:23,516 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-10-07 05:18:23,534 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-10-07 05:18:23,537 [main] INFO ipc.Server: Listener at 0.0.0.0:9861
2023-10-07 05:18:23,537 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2023-10-07 05:18:23,610 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-10-07 05:18:23,624 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-10-07 05:18:23,635 [main] INFO ipc.Server: Listener at 0.0.0.0:9863
2023-10-07 05:18:23,640 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2023-10-07 05:18:23,725 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-10-07 05:18:23,749 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-10-07 05:18:23,750 [main] INFO ipc.Server: Listener at 0.0.0.0:9860
2023-10-07 05:18:23,755 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2023-10-07 05:18:24,009 [main] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2023-10-07 05:18:24,011 [main] INFO server.StorageContainerManager: 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB
Number of Iterations                               10
Time Limit for Single Container's Movement         65min
Time Limit for Single Container's Replication      50min
Interval between each Iteration                    70min
Whether to Enable Network Topology                 false
Whether to Trigger Refresh Datanode Usage Info     false
Container IDs to Exclude from Balancing            None
Datanodes Specified to be Balanced                 None
Datanodes Excluded from Balancing                  None

2023-10-07 05:18:24,013 [main] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-10-07 05:18:24,022 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2023-10-07 05:18:24,031 [main] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2023-10-07 05:18:24,038 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/3b1fd225-c232-4cab-ac47-aabcd5a96fd4/in_use.lock acquired by nodename 7@scm1.org
2023-10-07 05:18:24,049 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=e8451b66-5499-4658-bae9-a1800ea457c3} from /data/metadata/scm-ha/3b1fd225-c232-4cab-ac47-aabcd5a96fd4/current/raft-meta
2023-10-07 05:18:24,123 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: set configuration 0: peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-10-07 05:18:24,128 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2023-10-07 05:18:24,149 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2023-10-07 05:18:24,150 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-10-07 05:18:24,154 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-10-07 05:18:24,157 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2023-10-07 05:18:24,162 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-10-07 05:18:24,178 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2023-10-07 05:18:24,179 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-10-07 05:18:24,180 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-10-07 05:18:24,201 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/3b1fd225-c232-4cab-ac47-aabcd5a96fd4
2023-10-07 05:18:24,203 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-10-07 05:18:24,211 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2023-10-07 05:18:24,213 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-10-07 05:18:24,221 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2023-10-07 05:18:24,221 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2023-10-07 05:18:24,223 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2023-10-07 05:18:24,223 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-10-07 05:18:24,224 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-10-07 05:18:24,258 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
2023-10-07 05:18:24,259 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-10-07 05:18:24,517 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2023-10-07 05:18:24,517 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2023-10-07 05:18:24,536 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2023-10-07 05:18:24,603 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: set configuration 0: peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-10-07 05:18:24,606 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/3b1fd225-c232-4cab-ac47-aabcd5a96fd4/current/log_inprogress_0
2023-10-07 05:18:24,610 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO segmented.SegmentedRaftLogWorker: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-10-07 05:18:24,722 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: start as a follower, conf=0: peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-10-07 05:18:24,723 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: changes role from      null to FOLLOWER at term 1 for startAsFollower
2023-10-07 05:18:24,724 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO impl.RoleInfo: e8451b66-5499-4658-bae9-a1800ea457c3: start e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState
2023-10-07 05:18:24,726 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AABCD5A96FD4,id=e8451b66-5499-4658-bae9-a1800ea457c3
2023-10-07 05:18:24,737 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-10-07 05:18:24,738 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2023-10-07 05:18:24,738 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2023-10-07 05:18:24,742 [e8451b66-5499-4658-bae9-a1800ea457c3-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2023-10-07 05:18:24,743 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-10-07 05:18:24,744 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-10-07 05:18:24,753 [main] INFO server.RaftServer: e8451b66-5499-4658-bae9-a1800ea457c3: start RPC server
2023-10-07 05:18:24,831 [main] INFO server.GrpcService: e8451b66-5499-4658-bae9-a1800ea457c3: GrpcService started, listening on 9894
2023-10-07 05:18:24,838 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-e8451b66-5499-4658-bae9-a1800ea457c3: Started
2023-10-07 05:18:24,851 [main] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]
2023-10-07 05:18:24,853 [main] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2023-10-07 05:18:24,856 [main] INFO SCMHATransactionMonitor: Starting SCMHATransactionMonitor Service.
2023-10-07 05:18:24,857 [main] INFO ha.SCMServiceManager: Registering service SCMHATransactionMonitor.
2023-10-07 05:18:24,857 [main] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is already running, skip start.
2023-10-07 05:18:25,013 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2023-10-07 05:18:25,271 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-10-07 05:18:25,271 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2023-10-07 05:18:25,490 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2023-10-07 05:18:25,492 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-10-07 05:18:25,516 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2023-10-07 05:18:25,680 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2023-10-07 05:18:25,681 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2023-10-07 05:18:25,681 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-10-07 05:18:25,687 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2023-10-07 05:18:25,792 [main] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
2023-10-07 05:18:25,793 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-10-07 05:18:25,793 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
2023-10-07 05:18:25,799 [main] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
2023-10-07 05:18:25,918 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2023-10-07 05:18:25,918 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
2023-10-07 05:18:25,919 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
2023-10-07 05:18:25,963 [main] INFO util.log: Logging initialized @10345ms to org.eclipse.jetty.util.log.Slf4jLog
2023-10-07 05:18:26,145 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2023-10-07 05:18:26,157 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-10-07 05:18:26,158 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2023-10-07 05:18:26,158 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2023-10-07 05:18:26,158 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2023-10-07 05:18:26,161 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
2023-10-07 05:18:26,246 [main] INFO http.BaseHttpServer: HTTP server of scm uses base directory /data/metadata/webserver
2023-10-07 05:18:26,248 [main] INFO http.HttpServer2: Jetty bound to port 9876
2023-10-07 05:18:26,250 [main] INFO server.Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 11.0.19+7-LTS
2023-10-07 05:18:26,436 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2023-10-07 05:18:26,436 [main] INFO server.session: No SessionScavenger set, using defaults
2023-10-07 05:18:26,446 [main] INFO server.session: node0 Scavenging every 660000ms
2023-10-07 05:18:26,540 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2023-10-07 05:18:26,579 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@78a4914d{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2023-10-07 05:18:26,581 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@42eaa429{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-10-07 05:18:26,635 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from scm2.org:60194 / 172.25.0.117:60194
2023-10-07 05:18:26,727 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-10-07 05:18:26,899 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2023-10-07 05:18:26,926 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@108817cc{scm,/,file:///data/metadata/webserver/jetty-0_0_0_0-9876-hdds-server-scm-1_4_0-SNAPSHOT_jar-_-any-17536608021955054489/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/scm}
2023-10-07 05:18:27,008 [main] INFO server.AbstractConnector: Started ServerConnector@321f97d9{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2023-10-07 05:18:27,008 [main] INFO server.Server: Started @11390ms
2023-10-07 05:18:27,027 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2023-10-07 05:18:27,027 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
2023-10-07 05:18:27,029 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2023-10-07 05:18:27,164 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from scm1.org:39216 / 172.25.0.116:39216
2023-10-07 05:18:27,182 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-10-07 05:18:27,188 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#0 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from scm1.org:39216 / 172.25.0.116:39216
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:e8451b66-5499-4658-bae9-a1800ea457c3 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:244)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2023-10-07 05:18:28,112 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_recon_1.ozonesecure-ha_ozone_net:41781 / 172.25.0.115:41781
2023-10-07 05:18:28,142 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-10-07 05:18:28,143 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#9 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from ozonesecure-ha_recon_1.ozonesecure-ha_ozone_net:41781 / 172.25.0.115:41781
org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:e8451b66-5499-4658-bae9-a1800ea457c3 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:244)
	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:90)
	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:18732)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2023-10-07 05:18:29,824 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState] INFO impl.FollowerState: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5099859855ns, electionTimeout:5079ms
2023-10-07 05:18:29,825 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState] INFO impl.RoleInfo: e8451b66-5499-4658-bae9-a1800ea457c3: shutdown e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState
2023-10-07 05:18:29,827 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2023-10-07 05:18:29,830 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2023-10-07 05:18:29,830 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-FollowerState] INFO impl.RoleInfo: e8451b66-5499-4658-bae9-a1800ea457c3: start e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1
2023-10-07 05:18:29,843 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO impl.LeaderElection: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 1 for 0: peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-10-07 05:18:29,844 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO impl.LeaderElection: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1 PRE_VOTE round 0: result PASSED (term=1)
2023-10-07 05:18:29,853 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO impl.LeaderElection: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-10-07 05:18:29,854 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO impl.LeaderElection: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1 ELECTION round 0: result PASSED (term=2)
2023-10-07 05:18:29,854 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO impl.RoleInfo: e8451b66-5499-4658-bae9-a1800ea457c3: shutdown e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1
2023-10-07 05:18:29,854 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2023-10-07 05:18:29,854 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
2023-10-07 05:18:29,855 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
2023-10-07 05:18:29,858 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: change Leader from null to e8451b66-5499-4658-bae9-a1800ea457c3 at term 2 for becomeLeader, leader elected after 8554ms
2023-10-07 05:18:29,872 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2023-10-07 05:18:29,882 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2023-10-07 05:18:29,883 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2023-10-07 05:18:29,896 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2023-10-07 05:18:29,897 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2023-10-07 05:18:29,900 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2023-10-07 05:18:29,905 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2023-10-07 05:18:29,908 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-10-07 05:18:29,910 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO impl.RoleInfo: e8451b66-5499-4658-bae9-a1800ea457c3: start e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderStateImpl
2023-10-07 05:18:29,923 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2023-10-07 05:18:29,934 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/3b1fd225-c232-4cab-ac47-aabcd5a96fd4/current/log_inprogress_0 to /data/metadata/scm-ha/3b1fd225-c232-4cab-ac47-aabcd5a96fd4/current/log_0-0
2023-10-07 05:18:29,956 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderElection1] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: set configuration 1: peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-10-07 05:18:29,960 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/3b1fd225-c232-4cab-ac47-aabcd5a96fd4/current/log_inprogress_1
2023-10-07 05:18:29,969 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
2023-10-07 05:18:29,973 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
2023-10-07 05:18:29,974 [SecretKeyManagerService] INFO symmetric.SecretKeyManager: Initializing SecretKeys.
2023-10-07 05:18:29,976 [SecretKeyManagerService] INFO symmetric.SecretKeyManager: No valid key has been loaded. A new key is generated: SecretKey(id = 3c895003-cc05-4f8f-b886-3a5d65caa75b, creation at: 2023-10-07T05:18:29.974932Z, expire at: 2023-10-07T06:18:29.974932Z)
2023-10-07 05:18:29,993 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:18:29,995 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2023-10-07 05:18:29,996 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-10-07 05:18:29,996 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2023-10-07 05:18:30,012 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-10-07 05:18:30,017 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2023-10-07 05:18:30,328 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 3c895003-cc05-4f8f-b886-3a5d65caa75b, creation at: 2023-10-07T05:18:29.974Z, expire at: 2023-10-07T06:18:29.974Z)]
2023-10-07 05:18:30,329 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 3c895003-cc05-4f8f-b886-3a5d65caa75b, creation at: 2023-10-07T05:18:29.974Z, expire at: 2023-10-07T06:18:29.974Z)
2023-10-07 05:18:30,378 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 3c895003-cc05-4f8f-b886-3a5d65caa75b, creation at: 2023-10-07T05:18:29.974Z, expire at: 2023-10-07T06:18:29.974Z)] to file /data/metadata/scm/keys/secret_keys.json
2023-10-07 05:18:30,379 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:18:30,380 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2023-10-07 05:18:30,380 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2023-10-07 05:18:31,752 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from scm1.org:58718 / 172.25.0.116:58718
2023-10-07 05:18:31,789 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-10-07 05:18:33,336 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-10-07 05:18:33,340 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-10-07 05:18:33,351 [scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-10-07 05:18:33,352 [scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-10-07 05:18:33,369 [scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: CA certificates are not changed.
2023-10-07 05:18:33,656 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from scm2.org:52618 / 172.25.0.117:52618
2023-10-07 05:18:33,676 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-10-07 05:18:33,676 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: c9313ac6-fbde-44ed-9bca-27d68533c9b6
2023-10-07 05:18:33,817 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.19, 2.5.29.15, 2.5.29.17
2023-10-07 05:18:33,818 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.17, 2.5.29.19, 1.3.6.1.5.5.7.1.12, 2.5.29.35, 2.5.29.15, 2.5.29.37
2023-10-07 05:18:33,904 [IPC Server handler 1 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-10-07 05:18:34,179 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: dba3be25-2426-42ae-8680-0b201f39c659
2023-10-07 05:18:34,528 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO server.SCMCertStore: Scm certificate 269197834155 for CN=scm-sub-268820794603@scm2.org,OU=c9313ac6-fbde-44ed-9bca-27d68533c9b6,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4 is stored
2023-10-07 05:18:34,529 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:18:34,564 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2023-10-07 05:18:34,566 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.17, 2.5.29.19, 1.3.6.1.5.5.7.1.12, 2.5.29.35, 2.5.29.15, 2.5.29.37
2023-10-07 05:18:34,577 [IPC Server handler 0 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-10-07 05:18:34,632 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:18:34,782 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-10-07 05:18:34,782 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-10-07 05:18:48,519 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from scm2.org:55866 / 172.25.0.117:55866
2023-10-07 05:18:48,561 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-10-07 05:18:48,563 [IPC Server handler 0 on default port 9863] INFO ha.SCMRatisServerImpl: e8451b66-5499-4658-bae9-a1800ea457c3: Submitting SetConfiguration request to Ratis server with new SCM peers list: [e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, c9313ac6-fbde-44ed-9bca-27d68533c9b6|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]
2023-10-07 05:18:48,566 [IPC Server handler 0 on default port 9863] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: receive setConfiguration SetConfigurationRequest:client-93B0DE8B3E65->e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4, cid=1, seq=0, RW, null, SET_UNCONDITIONALLY, servers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, c9313ac6-fbde-44ed-9bca-27d68533c9b6|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER], listeners:[]
2023-10-07 05:18:48,567 [IPC Server handler 0 on default port 9863] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-93B0DE8B3E65->e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4, cid=1, seq=0, RW, null, SET_UNCONDITIONALLY, servers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, c9313ac6-fbde-44ed-9bca-27d68533c9b6|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER], listeners:[]
2023-10-07 05:18:48,606 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-10-07 05:18:48,609 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-10-07 05:18:48,610 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
2023-10-07 05:18:48,616 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 0ms (custom)
2023-10-07 05:18:48,617 [IPC Server handler 0 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-10-07 05:18:48,617 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-10-07 05:18:48,619 [IPC Server handler 0 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2023-10-07 05:18:48,619 [IPC Server handler 0 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2023-10-07 05:18:48,620 [IPC Server handler 0 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-10-07 05:18:48,620 [IPC Server handler 0 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-10-07 05:18:48,624 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c9313ac6-fbde-44ed-9bca-27d68533c9b6-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c9313ac6-fbde-44ed-9bca-27d68533c9b6-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
2023-10-07 05:18:48,651 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c9313ac6-fbde-44ed-9bca-27d68533c9b6-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c9313ac6-fbde-44ed-9bca-27d68533c9b6-GrpcLogAppender: send e8451b66-5499-4658-bae9-a1800ea457c3->c9313ac6-fbde-44ed-9bca-27d68533c9b6#0-t2,notify:(t:1, i:0)
2023-10-07 05:18:48,654 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c9313ac6-fbde-44ed-9bca-27d68533c9b6-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcServerProtocolClient: Build channel for c9313ac6-fbde-44ed-9bca-27d68533c9b6
2023-10-07 05:18:48,794 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_recon_1.ozonesecure-ha_ozone_net:37845 / 172.25.0.115:37845
2023-10-07 05:18:48,802 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-10-07 05:18:49,861 [grpc-default-executor-1] INFO server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c9313ac6-fbde-44ed-9bca-27d68533c9b6-InstallSnapshotResponseHandler: received the first reply e8451b66-5499-4658-bae9-a1800ea457c3<-c9313ac6-fbde-44ed-9bca-27d68533c9b6#0:OK-t0,ALREADY_INSTALLED
2023-10-07 05:18:49,868 [grpc-default-executor-1] INFO server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c9313ac6-fbde-44ed-9bca-27d68533c9b6-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
2023-10-07 05:18:49,875 [grpc-default-executor-1] INFO leader.FollowerInfo: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c9313ac6-fbde-44ed-9bca-27d68533c9b6: matchIndex: setUnconditionally -1 -> 0
2023-10-07 05:18:49,876 [grpc-default-executor-1] INFO leader.FollowerInfo: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c9313ac6-fbde-44ed-9bca-27d68533c9b6: nextIndex: setUnconditionally 0 -> 1
2023-10-07 05:18:49,876 [grpc-default-executor-1] INFO leader.FollowerInfo: Follower e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c9313ac6-fbde-44ed-9bca-27d68533c9b6 acknowledged installing snapshot
2023-10-07 05:18:49,879 [grpc-default-executor-1] INFO server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c9313ac6-fbde-44ed-9bca-27d68533c9b6-GrpcLogAppender: updateNextIndex 1 for ALREADY_INSTALLED
2023-10-07 05:18:50,169 [grpc-default-executor-1] WARN server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c9313ac6-fbde-44ed-9bca-27d68533c9b6-AppendLogResponseHandler: received INCONSISTENCY reply with nextIndex 0
2023-10-07 05:18:50,170 [grpc-default-executor-2] WARN server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c9313ac6-fbde-44ed-9bca-27d68533c9b6-AppendLogResponseHandler: received INCONSISTENCY reply with nextIndex 0
2023-10-07 05:18:50,174 [grpc-default-executor-2] INFO leader.FollowerInfo: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c9313ac6-fbde-44ed-9bca-27d68533c9b6: setNextIndex nextIndex: updateUnconditionally 9 -> 0
2023-10-07 05:18:50,241 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderStateImpl] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: set configuration 9: peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, c9313ac6-fbde-44ed-9bca-27d68533c9b6|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
2023-10-07 05:18:50,539 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderStateImpl] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: set configuration 11: peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, c9313ac6-fbde-44ed-9bca-27d68533c9b6|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-10-07 05:18:50,605 [IPC Server handler 0 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: c9313ac6-fbde-44ed-9bca-27d68533c9b6.
2023-10-07 05:18:51,913 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from scm2.org:57100 / 172.25.0.117:57100
2023-10-07 05:18:51,927 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-10-07 05:18:53,103 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-10-07 05:18:53,104 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-10-07 05:18:53,999 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from scm3.org:54698 / 172.25.0.118:54698
2023-10-07 05:18:54,013 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-10-07 05:18:55,675 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from scm3.org:57004 / 172.25.0.118:57004
2023-10-07 05:18:55,691 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-10-07 05:18:55,692 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: c89c64e1-69bc-47b7-8334-240d44a217cb
2023-10-07 05:18:55,696 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.19, 2.5.29.15, 2.5.29.17
2023-10-07 05:18:55,699 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.17, 2.5.29.19, 1.3.6.1.5.5.7.1.12, 2.5.29.35, 2.5.29.15, 2.5.29.37
2023-10-07 05:18:55,720 [IPC Server handler 1 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-10-07 05:18:55,777 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO server.SCMCertStore: Scm certificate 291088109622 for CN=scm-sub-290971838080@scm3.org,OU=c89c64e1-69bc-47b7-8334-240d44a217cb,O=CID-3b1fd225-c232-4cab-ac47-aabcd5a96fd4 is stored
2023-10-07 05:18:55,777 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:19:06,517 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from scm3.org:54520 / 172.25.0.118:54520
2023-10-07 05:19:06,714 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-10-07 05:19:06,716 [IPC Server handler 14 on default port 9863] INFO ha.SCMRatisServerImpl: e8451b66-5499-4658-bae9-a1800ea457c3: Submitting SetConfiguration request to Ratis server with new SCM peers list: [e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, c9313ac6-fbde-44ed-9bca-27d68533c9b6|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER, c89c64e1-69bc-47b7-8334-240d44a217cb|rpc:scm3.org:9894|priority:0|startupRole:FOLLOWER]
2023-10-07 05:19:06,717 [IPC Server handler 14 on default port 9863] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: receive setConfiguration SetConfigurationRequest:client-93B0DE8B3E65->e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4, cid=2, seq=0, RW, null, SET_UNCONDITIONALLY, servers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, c9313ac6-fbde-44ed-9bca-27d68533c9b6|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER, c89c64e1-69bc-47b7-8334-240d44a217cb|rpc:scm3.org:9894|priority:0|startupRole:FOLLOWER], listeners:[]
2023-10-07 05:19:06,717 [IPC Server handler 14 on default port 9863] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-93B0DE8B3E65->e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4, cid=2, seq=0, RW, null, SET_UNCONDITIONALLY, servers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, c9313ac6-fbde-44ed-9bca-27d68533c9b6|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER, c89c64e1-69bc-47b7-8334-240d44a217cb|rpc:scm3.org:9894|priority:0|startupRole:FOLLOWER], listeners:[]
2023-10-07 05:19:06,718 [IPC Server handler 14 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-10-07 05:19:06,718 [IPC Server handler 14 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-10-07 05:19:06,718 [IPC Server handler 14 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
2023-10-07 05:19:06,719 [IPC Server handler 14 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 0ms (custom)
2023-10-07 05:19:06,719 [IPC Server handler 14 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-10-07 05:19:06,720 [IPC Server handler 14 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-10-07 05:19:06,720 [IPC Server handler 14 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2023-10-07 05:19:06,720 [IPC Server handler 14 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2023-10-07 05:19:06,720 [IPC Server handler 14 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-10-07 05:19:06,721 [IPC Server handler 14 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-10-07 05:19:06,726 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
2023-10-07 05:19:06,730 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb-GrpcLogAppender: send e8451b66-5499-4658-bae9-a1800ea457c3->c89c64e1-69bc-47b7-8334-240d44a217cb#0-t2,notify:(t:1, i:0)
2023-10-07 05:19:06,731 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcServerProtocolClient: Build channel for c89c64e1-69bc-47b7-8334-240d44a217cb
2023-10-07 05:19:10,957 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb-InstallSnapshotResponseHandler: received the first reply e8451b66-5499-4658-bae9-a1800ea457c3<-c89c64e1-69bc-47b7-8334-240d44a217cb#0:OK-t0,ALREADY_INSTALLED
2023-10-07 05:19:10,957 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
2023-10-07 05:19:10,957 [grpc-default-executor-2] INFO leader.FollowerInfo: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb: matchIndex: setUnconditionally -1 -> 0
2023-10-07 05:19:10,957 [grpc-default-executor-2] INFO leader.FollowerInfo: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb: nextIndex: setUnconditionally 0 -> 1
2023-10-07 05:19:10,957 [grpc-default-executor-2] INFO leader.FollowerInfo: Follower e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb acknowledged installing snapshot
2023-10-07 05:19:10,958 [grpc-default-executor-2] INFO server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb-GrpcLogAppender: updateNextIndex 1 for ALREADY_INSTALLED
2023-10-07 05:19:11,398 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderStateImpl] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: set configuration 15: peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, c89c64e1-69bc-47b7-8334-240d44a217cb|rpc:scm3.org:9894|priority:0|startupRole:FOLLOWER, c9313ac6-fbde-44ed-9bca-27d68533c9b6|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, c9313ac6-fbde-44ed-9bca-27d68533c9b6|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[]
2023-10-07 05:19:11,433 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-LeaderStateImpl] INFO server.RaftServer$Division: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4: set configuration 17: peers:[e8451b66-5499-4658-bae9-a1800ea457c3|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, c89c64e1-69bc-47b7-8334-240d44a217cb|rpc:scm3.org:9894|priority:0|startupRole:FOLLOWER, c9313ac6-fbde-44ed-9bca-27d68533c9b6|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-10-07 05:19:11,566 [IPC Server handler 14 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: c89c64e1-69bc-47b7-8334-240d44a217cb.
2023-10-07 05:19:11,689 [grpc-default-executor-0] WARN server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb-AppendLogResponseHandler: received INCONSISTENCY reply with nextIndex 0
2023-10-07 05:19:11,690 [grpc-default-executor-0] INFO leader.FollowerInfo: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb: setNextIndex nextIndex: updateUnconditionally 19 -> 0
2023-10-07 05:19:11,761 [grpc-default-executor-0] WARN server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb-AppendLogResponseHandler: received INCONSISTENCY reply with nextIndex 0
2023-10-07 05:19:11,761 [grpc-default-executor-0] INFO leader.FollowerInfo: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb: setNextIndex nextIndex: updateUnconditionally 19 -> 0
2023-10-07 05:19:11,775 [grpc-default-executor-0] WARN server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb-AppendLogResponseHandler: received INCONSISTENCY reply with nextIndex 0
2023-10-07 05:19:11,778 [grpc-default-executor-0] INFO leader.FollowerInfo: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb: setNextIndex nextIndex: updateUnconditionally 19 -> 0
2023-10-07 05:19:11,795 [grpc-default-executor-0] WARN server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb-AppendLogResponseHandler: received INCONSISTENCY reply with nextIndex 0
2023-10-07 05:19:11,795 [grpc-default-executor-0] INFO leader.FollowerInfo: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb: setNextIndex nextIndex: updateUnconditionally 19 -> 0
2023-10-07 05:19:11,802 [grpc-default-executor-0] WARN server.GrpcLogAppender: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb-AppendLogResponseHandler: received INCONSISTENCY reply with nextIndex 0
2023-10-07 05:19:11,802 [grpc-default-executor-0] INFO leader.FollowerInfo: e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4->c89c64e1-69bc-47b7-8334-240d44a217cb: setNextIndex nextIndex: updateUnconditionally 19 -> 0
2023-10-07 05:19:17,464 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from scm3.org:58736 / 172.25.0.118:58736
2023-10-07 05:19:17,542 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-10-07 05:19:23,728 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-10-07 05:19:23,728 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-10-07 05:19:38,040 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from om2:47892 / 172.25.0.112:47892
2023-10-07 05:19:38,132 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-10-07 05:19:39,219 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from om1:41210 / 172.25.0.111:41210
2023-10-07 05:19:39,327 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-10-07 05:19:39,545 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from om3:57390 / 172.25.0.113:57390
2023-10-07 05:19:39,684 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-10-07 05:19:39,758 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:35586 / 172.25.0.102:35586
2023-10-07 05:19:39,820 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-10-07 05:19:39,821 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn a99085019d04, UUID: 3e3af573-fc4a-4265-8b8b-0220a847ddf5
2023-10-07 05:19:39,831 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2023-10-07 05:19:39,832 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.17, 2.5.29.19, 1.3.6.1.5.5.7.1.12, 2.5.29.35, 2.5.29.15, 2.5.29.37
2023-10-07 05:19:39,866 [IPC Server handler 1 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-10-07 05:19:40,320 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:19:40,597 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:60956 / 172.25.0.104:60956
2023-10-07 05:19:40,700 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-10-07 05:19:40,704 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn ef19d0e36725, UUID: c3359367-544d-4de9-8fa7-4ff0e170a1a8
2023-10-07 05:19:40,831 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2023-10-07 05:19:40,846 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.17, 2.5.29.19, 1.3.6.1.5.5.7.1.12, 2.5.29.35, 2.5.29.15, 2.5.29.37
2023-10-07 05:19:40,939 [IPC Server handler 0 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-10-07 05:19:41,298 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:19:41,513 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-10-07 05:19:41,516 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-10-07 05:19:42,183 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-10-07 05:19:42,183 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-10-07 05:19:43,120 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:50956 / 172.25.0.103:50956
2023-10-07 05:19:43,200 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:35602 / 172.25.0.102:35602
2023-10-07 05:19:43,248 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2023-10-07 05:19:43,275 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-10-07 05:19:43,277 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn b20c23001d7a, UUID: ca1726d2-a852-4f0d-9c22-4d33cf07eab3
2023-10-07 05:19:43,321 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2023-10-07 05:19:43,331 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.17, 2.5.29.19, 1.3.6.1.5.5.7.1.12, 2.5.29.35, 2.5.29.15, 2.5.29.37
2023-10-07 05:19:43,453 [IPC Server handler 1 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-10-07 05:19:43,700 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:19:43,940 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:60972 / 172.25.0.104:60972
2023-10-07 05:19:44,124 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2023-10-07 05:19:44,126 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-e8451b66-5499-4658-bae9-a1800ea457c3: Detected pause in JVM or host machine approximately 0.161s with 0.166s GC time.
GC pool 'ParNew' had collection(s): count=1 time=166ms
2023-10-07 05:19:44,274 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-10-07 05:19:44,278 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-10-07 05:19:45,796 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:50958 / 172.25.0.103:50958
2023-10-07 05:19:45,838 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2023-10-07 05:19:48,859 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from om2:54040 / 172.25.0.112:54040
2023-10-07 05:19:48,894 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-10-07 05:19:48,898 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: b3c4dc5e-73b6-4b15-a54c-84ebd0451c1a
2023-10-07 05:19:48,978 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2023-10-07 05:19:48,978 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.17, 2.5.29.19, 1.3.6.1.5.5.7.1.12, 2.5.29.35, 2.5.29.15, 2.5.29.37
2023-10-07 05:19:49,065 [IPC Server handler 1 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-10-07 05:19:49,316 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_recon_1.ozonesecure-ha_ozone_net:42965 / 172.25.0.115:42965
2023-10-07 05:19:49,320 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from om3:49016 / 172.25.0.113:49016
2023-10-07 05:19:49,399 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-10-07 05:19:49,403 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-10-07 05:19:49,411 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: d55891f1-2c20-427e-a173-4a04cb868c65
2023-10-07 05:19:49,543 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:19:49,911 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2023-10-07 05:19:49,911 [IPC Server handler 0 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.17, 2.5.29.19, 1.3.6.1.5.5.7.1.12, 2.5.29.35, 2.5.29.15, 2.5.29.37
2023-10-07 05:19:49,959 [IPC Server handler 0 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-10-07 05:19:50,180 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:19:50,927 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-10-07 05:19:50,927 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-10-07 05:19:50,939 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-10-07 05:19:50,939 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-10-07 05:19:51,041 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from om1:44364 / 172.25.0.111:44364
2023-10-07 05:19:51,078 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-10-07 05:19:51,079 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: f7d8e8b7-bc54-4e5f-a6c2-6c6e61a4dc84
2023-10-07 05:19:51,091 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2023-10-07 05:19:51,094 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.17, 2.5.29.19, 1.3.6.1.5.5.7.1.12, 2.5.29.35, 2.5.29.15, 2.5.29.37
2023-10-07 05:19:51,124 [IPC Server handler 1 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-10-07 05:19:51,388 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:19:52,229 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-10-07 05:19:52,229 [IPC Server handler 1 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-10-07 05:20:02,484 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:60096 / 172.25.0.102:60096
2023-10-07 05:20:02,521 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-10-07 05:20:05,425 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:35988 / 172.25.0.104:35988
2023-10-07 05:20:05,451 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-10-07 05:20:06,097 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:47788 / 172.25.0.103:47788
2023-10-07 05:20:06,126 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-10-07 05:20:11,796 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:58598 / 172.25.0.102:58598
2023-10-07 05:20:11,974 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-10-07 05:20:15,250 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:56636 / 172.25.0.103:56636
2023-10-07 05:20:15,317 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-10-07 05:20:15,877 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:60886 / 172.25.0.104:60886
2023-10-07 05:20:15,880 [IPC Server handler 6 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3e3af573-fc4a-4265-8b8b-0220a847ddf5
2023-10-07 05:20:15,982 [IPC Server handler 6 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3e3af573-fc4a-4265-8b8b-0220a847ddf5{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=9864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 335221913043, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-10-07 05:20:16,077 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
2023-10-07 05:20:16,147 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2023-10-07 05:20:16,222 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-10-07 05:20:16,273 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a170259b-3335-49f4-b5bc-d4630bed8932 to datanode:3e3af573-fc4a-4265-8b8b-0220a847ddf5
2023-10-07 05:20:16,705 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:20:16,731 [RatisPipelineUtilsThread - 0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: a170259b-3335-49f4-b5bc-d4630bed8932, Nodes: 3e3af573-fc4a-4265-8b8b-0220a847ddf5(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-10-07T05:20:16.250533Z[UTC]]
2023-10-07 05:20:19,055 [IPC Server handler 3 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ca1726d2-a852-4f0d-9c22-4d33cf07eab3
2023-10-07 05:20:19,093 [IPC Server handler 3 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ca1726d2-a852-4f0d-9c22-4d33cf07eab3{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=9864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 338707873065, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-10-07 05:20:19,135 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
2023-10-07 05:20:19,132 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2023-10-07 05:20:19,185 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=72d25dcc-8085-4d0e-ba3c-c1a757d89efe to datanode:ca1726d2-a852-4f0d-9c22-4d33cf07eab3
2023-10-07 05:20:19,237 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:20:19,242 [RatisPipelineUtilsThread - 0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 72d25dcc-8085-4d0e-ba3c-c1a757d89efe, Nodes: ca1726d2-a852-4f0d-9c22-4d33cf07eab3(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-10-07T05:20:19.182073Z[UTC]]
2023-10-07 05:20:19,347 [IPC Server handler 95 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/c3359367-544d-4de9-8fa7-4ff0e170a1a8
2023-10-07 05:20:19,357 [IPC Server handler 95 on default port 9861] INFO node.SCMNodeManager: Registered Data node : c3359367-544d-4de9-8fa7-4ff0e170a1a8{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=9864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 336206132301, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-10-07 05:20:19,378 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2023-10-07 05:20:19,388 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fb0c3a70-8bb1-490d-9498-3be5493d9694 to datanode:c3359367-544d-4de9-8fa7-4ff0e170a1a8
2023-10-07 05:20:19,434 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:20:19,472 [RatisPipelineUtilsThread - 0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: fb0c3a70-8bb1-490d-9498-3be5493d9694, Nodes: c3359367-544d-4de9-8fa7-4ff0e170a1a8(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-10-07T05:20:19.388838Z[UTC]]
2023-10-07 05:20:19,519 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
2023-10-07 05:20:19,519 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2023-10-07 05:20:19,519 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2023-10-07 05:20:19,521 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-10-07 05:20:19,522 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2023-10-07 05:20:19,593 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=83297fa2-d4eb-4f9f-86fa-23072373ffc4 to datanode:ca1726d2-a852-4f0d-9c22-4d33cf07eab3
2023-10-07 05:20:19,594 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=83297fa2-d4eb-4f9f-86fa-23072373ffc4 to datanode:c3359367-544d-4de9-8fa7-4ff0e170a1a8
2023-10-07 05:20:19,595 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=83297fa2-d4eb-4f9f-86fa-23072373ffc4 to datanode:3e3af573-fc4a-4265-8b8b-0220a847ddf5
2023-10-07 05:20:19,687 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:20:19,699 [RatisPipelineUtilsThread - 0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 83297fa2-d4eb-4f9f-86fa-23072373ffc4, Nodes: ca1726d2-a852-4f0d-9c22-4d33cf07eab3(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103)c3359367-544d-4de9-8fa7-4ff0e170a1a8(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104)3e3af573-fc4a-4265-8b8b-0220a847ddf5(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-10-07T05:20:19.593172Z[UTC]]
2023-10-07 05:20:19,726 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=adedbb24-36d7-4947-9d2d-7e4d221479e2 to datanode:ca1726d2-a852-4f0d-9c22-4d33cf07eab3
2023-10-07 05:20:19,734 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=adedbb24-36d7-4947-9d2d-7e4d221479e2 to datanode:3e3af573-fc4a-4265-8b8b-0220a847ddf5
2023-10-07 05:20:19,740 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=adedbb24-36d7-4947-9d2d-7e4d221479e2 to datanode:c3359367-544d-4de9-8fa7-4ff0e170a1a8
2023-10-07 05:20:19,861 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:20:19,885 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=adedbb24-36d7-4947-9d2d-7e4d221479e2 contains same datanodes as previous pipelines: PipelineID=83297fa2-d4eb-4f9f-86fa-23072373ffc4 nodeIds: ca1726d2-a852-4f0d-9c22-4d33cf07eab3, 3e3af573-fc4a-4265-8b8b-0220a847ddf5, c3359367-544d-4de9-8fa7-4ff0e170a1a8
2023-10-07 05:20:19,897 [RatisPipelineUtilsThread - 0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: adedbb24-36d7-4947-9d2d-7e4d221479e2, Nodes: ca1726d2-a852-4f0d-9c22-4d33cf07eab3(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103)3e3af573-fc4a-4265-8b8b-0220a847ddf5(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102)c3359367-544d-4de9-8fa7-4ff0e170a1a8(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-10-07T05:20:19.726672Z[UTC]]
2023-10-07 05:20:23,346 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:20:23,363 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=72d25dcc-8085-4d0e-ba3c-c1a757d89efe
2023-10-07 05:20:23,383 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-10-07 05:20:23,564 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_recon_1.ozonesecure-ha_ozone_net:36709 / 172.25.0.115:36709
2023-10-07 05:20:23,651 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-10-07 05:20:24,149 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-10-07 05:20:24,153 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=fb0c3a70-8bb1-490d-9498-3be5493d9694
2023-10-07 05:20:24,154 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-10-07 05:20:24,275 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-10-07 05:20:24,950 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-10-07 05:20:28,777 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from om3:34966 / 172.25.0.113:34966
2023-10-07 05:20:28,877 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-10-07 05:20:29,519 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-10-07 05:20:29,823 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from om1:52216 / 172.25.0.111:52216
2023-10-07 05:20:29,915 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-10-07 05:20:30,041 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-10-07 05:20:31,281 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from om2:37250 / 172.25.0.112:37250
2023-10-07 05:20:31,406 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-10-07 05:20:32,649 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-10-07 05:20:34,258 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-10-07 05:20:36,101 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:49260 / 172.25.0.102:49260
2023-10-07 05:20:36,224 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-10-07 05:20:36,252 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2023-10-07 05:20:36,292 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=83297fa2-d4eb-4f9f-86fa-23072373ffc4
2023-10-07 05:20:36,293 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-10-07 05:20:36,293 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2023-10-07 05:20:36,293 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2023-10-07 05:20:36,293 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2023-10-07 05:20:36,293 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-10-07 05:20:36,293 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
2023-10-07 05:20:36,294 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-10-07 05:20:36,294 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
2023-10-07 05:20:36,326 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-10-07 05:20:36,327 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO SCMHATransactionMonitor: Service SCMHATransactionMonitor transitions to RUNNING.
2023-10-07 05:20:40,602 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=adedbb24-36d7-4947-9d2d-7e4d221479e2
2023-10-07 05:20:48,742 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:39122 / 172.25.0.102:39122
2023-10-07 05:20:49,682 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_recon_1.ozonesecure-ha_ozone_net:34277 / 172.25.0.115:34277
2023-10-07 05:20:49,772 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-10-07 05:20:49,844 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-10-07 05:20:49,914 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=a170259b-3335-49f4-b5bc-d4630bed8932
2023-10-07 05:20:59,934 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from om1:41168 / 172.25.0.111:41168
2023-10-07 05:20:59,988 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2023-10-07 05:21:00,222 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from om3:34614 / 172.25.0.113:34614
2023-10-07 05:21:00,271 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2023-10-07 05:21:02,215 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from om2:44724 / 172.25.0.112:44724
2023-10-07 05:21:02,267 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolOm
2023-10-07 05:21:11,458 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:53140 / 172.25.0.104:53140
2023-10-07 05:21:11,540 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-10-07 05:21:11,719 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:38150 / 172.25.0.103:38150
2023-10-07 05:21:11,869 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-10-07 05:21:24,989 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:55518 / 172.25.0.102:55518
2023-10-07 05:21:25,058 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-10-07 05:21:40,555 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:58516 / 172.25.0.103:58516
2023-10-07 05:21:40,601 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-10-07 05:21:41,203 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:39128 / 172.25.0.104:39128
2023-10-07 05:21:41,271 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-10-07 05:21:45,551 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from om2:39996 / 172.25.0.112:39996
2023-10-07 05:21:45,564 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
2023-10-07 05:21:45,639 [IPC Server handler 9 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
2023-10-07 05:21:45,748 [e8451b66-5499-4658-bae9-a1800ea457c3@group-AABCD5A96FD4-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 111677748019200000.
2023-10-07 05:21:45,782 [IPC Server handler 9 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 111677748019200000 to 111677748019201000.
2023-10-07 05:21:49,454 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:37338 / 172.25.0.103:37338
2023-10-07 05:21:49,469 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2023-10-07 05:21:49,796 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:56728 / 172.25.0.104:56728
2023-10-07 05:21:49,819 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2023-10-07 05:21:50,023 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_recon_1.ozonesecure-ha_ozone_net:34773 / 172.25.0.115:34773
2023-10-07 05:21:50,075 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-10-07 05:21:50,786 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:51478 / 172.25.0.102:51478
2023-10-07 05:21:50,847 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2023-10-07 05:21:51,452 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:38932 / 172.25.0.102:38932
2023-10-07 05:21:51,618 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-10-07 05:21:54,428 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from om2:46454 / 172.25.0.112:46454
2023-10-07 05:21:54,447 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
