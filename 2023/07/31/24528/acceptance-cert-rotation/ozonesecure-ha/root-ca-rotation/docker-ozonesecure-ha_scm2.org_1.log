Waiting for the service scm1.org:9894
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-07-31 22:11:14,319 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm2.org/172.25.0.117
STARTUP_MSG:   args = [--bootstrap]
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.5.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.5.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.5.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.5.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/okio-3.4.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.5.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.5.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.5.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.5.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.4.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/10f74f7806195f34008d1533fda8253a52ae73f1 ; compiled by 'runner' on 2023-07-31T21:45Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=true, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=16KB, dfs.container.ratis.segment.size=1MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.retries=-1, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=15s, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60s, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=9864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=5GB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=60, hdds.scmclient.failover.retry.interval=1s, hdds.scmclient.max.retry.timeout=60s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT20S, hdds.x509.ca.rotation.check.interval=PT1S, hdds.x509.ca.rotation.enabled=true, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=PT60S, hdds.x509.dir.name=certs, hdds.x509.file.name=certificate.crt, hdds.x509.grace.duration.token.checks.enabled=false, hdds.x509.max.duration=PT240S, hdds.x509.renew.grace.duration=PT45S, hdds.x509.rootca.certificate.polling.interval=PT10s, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=64KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.handler.type=distributed, ozone.http.filter.initializers=org.apache.hadoop.security.HttpCrossOriginFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=15s, ozone.manager.delegation.token.renew-interval=15s, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-address.omservice.om1=om1, ozone.om.http-address.omservice.om2=om2, ozone.om.http-address.omservice.om3=om3, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.internal.service.id=omservice, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.GrpcOmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=false, ozone.path.deleting.limit.per.task=10000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=20s, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication=3, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.volume.name=s3v, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=5s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=2s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=60s, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.enable=true, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-07-31 22:11:14,352 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-07-31 22:11:14,620 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-07-31 22:11:14,993 [main] INFO reflections.Reflections: Reflections took 294 ms to scan 3 urls, producing 132 keys and 288 values 
2023-07-31 22:11:15,247 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2023-07-31 22:11:15,248 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-07-31 22:11:15,304 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
2023-07-31 22:11:15,304 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
2023-07-31 22:11:15,709 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2023-07-31 22:11:15,709 [main] INFO server.StorageContainerManager: SCM login successful.
2023-07-31 22:11:15,859 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
2023-07-31 22:11:18,268 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 2 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 2.
2023-07-31 22:11:19,270 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 3 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 3.
2023-07-31 22:11:20,272 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 4 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 4.
2023-07-31 22:11:21,276 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 5.
2023-07-31 22:11:22,279 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 6.
2023-07-31 22:11:23,283 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 7 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 7.
2023-07-31 22:11:24,285 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 8 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 8.
2023-07-31 22:11:25,287 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 9 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 9.
2023-07-31 22:11:26,297 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 10 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 10.
2023-07-31 22:11:27,308 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 11 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 11.
2023-07-31 22:11:28,316 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 12 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 12.
2023-07-31 22:11:29,319 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 13 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 13.
2023-07-31 22:11:33,430 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:b3eb2f0a-5909-482e-a9d5-3889ae439a51 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:249)
	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14238)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 14 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 14.
2023-07-31 22:11:34,434 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 15 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 15.
2023-07-31 22:11:35,443 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:b3eb2f0a-5909-482e-a9d5-3889ae439a51 is not the leader. Could not determine the leader node.
	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:249)
	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14238)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 16 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 16.
2023-07-31 22:11:36,453 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 17 failover attempts. Trying to failover after sleeping for 1000ms. Current retry count: 17.
2023-07-31 22:11:37,855 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
2023-07-31 22:11:39,392 [main] INFO client.SCMCertificateClient: Certificate serial ID set to null
2023-07-31 22:11:39,392 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
2023-07-31 22:11:39,393 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
2023-07-31 22:11:39,395 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
2023-07-31 22:11:43,443 [main] INFO ha.HASecurityUtils: Init response: GETCERT
2023-07-31 22:11:43,449 [main] INFO client.SCMCertificateClient: Creating csr for SCM->hostName:scm2.org,scmId:b53d55b0-45af-42f4-b8d0-0e961b856622,clusterId:CID-f41bf459-4c9d-447b-9f29-2da7612f2f26,subject:scm-sub-380168255993@scm2.org
2023-07-31 22:11:43,566 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
2023-07-31 22:11:43,566 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2023-07-31 22:11:43,593 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:b53d55b0-45af-42f4-b8d0-0e961b856622,clusterId:CID-f41bf459-4c9d-447b-9f29-2da7612f2f26,subject:scm-sub-380314319338@scm2.org
2023-07-31 22:11:44,508 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/CA-1.crt
2023-07-31 22:11:44,508 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDrzCCApegAwIBAgIBATANBgkqhkiG9w0BAQsFADB7MRcwFQYDVQQDDA5zY20t
MUBzY20xLm9yZzEtMCsGA1UECwwkYjNlYjJmMGEtNTkwOS00ODJlLWE5ZDUtMzg4
OWFlNDM5YTUxMTEwLwYDVQQKDChDSUQtZjQxYmY0NTktNGM5ZC00NDdiLTlmMjkt
MmRhNzYxMmYyZjI2MB4XDTIzMDczMTIyMTEwNVoXDTIzMDczMTIyMTUwNVowezEX
MBUGA1UEAwwOc2NtLTFAc2NtMS5vcmcxLTArBgNVBAsMJGIzZWIyZjBhLTU5MDkt
NDgyZS1hOWQ1LTM4ODlhZTQzOWE1MTExMC8GA1UECgwoQ0lELWY0MWJmNDU5LTRj
OWQtNDQ3Yi05ZjI5LTJkYTc2MTJmMmYyNjCCASIwDQYJKoZIhvcNAQEBBQADggEP
ADCCAQoCggEBAJaoZ/2meKDqu0bRt6k8AwX8IhJre0zJ3YYlLOQkukyIl/FIuQkx
BxBweeediQy8Nzu52hAs8Ee5sfZVqkILaRjU/63po8wxeiryOeyPqY8y/FLRNgnD
Z8Af4wYoLJMZ0fWmvWZj6nlfVOD4wmS046oAGAfNpm9EqsSYEzfuSteTFKz1IYwV
NYy9eonUgsHQqO3+ABX4ntP8PHF4uDr2bfpSuY/ioniNxkzdM9YLpxrSkibDeVnc
CN0gythPItpHL3PasN0RMG/Bd7J5fXPDtNYSoB59yiAQTUQwMMmMyaVADjCrFL/7
EL2E+d6yBeeen2/BPg1LePa3vMv/RSbW5rUCAwEAAaM+MDwwDwYDVR0TAQH/BAUw
AwEB/zAOBgNVHQ8BAf8EBAMCAQYwGQYDVR0RBBIwEIcErBkAdIIIc2NtMS5vcmcw
DQYJKoZIhvcNAQELBQADggEBAFGko1BUQO9Dh5jBPhMAqx/0W9wMUC3QWE63vYFr
yObzYM4+LHNycfz9Mex2Gdojdr0utKYAG4u59d9QnxQT+IlMd/I60H1YoW2F2+e4
yzP5M3TTsFelZg6CrduCAst3Oelo8j1kOVe12VRlohDaX130LVQQNd4AubL6W6bU
buRTcXNhBpMItuAKrHLYjHZ7fSS3ifCtpg355Hm3shdGVSnslKYevSLzwbxp2oww
oFLYIVm+tQ+lgWNF5key/iVIjRpHD5TobzCsihdN9PSgU3q75x8m59poBN/MYPgv
7FgXDPl3dX/mJH4ZfwjL/NSjEOdHSezf+Rb8OZfVa+dsehE=
-----END CERTIFICATE-----

2023-07-31 22:11:44,522 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/380798471158.crt
2023-07-31 22:11:44,522 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDwzCCAqugAwIBAgIFWKlbi/YwDQYJKoZIhvcNAQELBQAwezEXMBUGA1UEAwwO
c2NtLTFAc2NtMS5vcmcxLTArBgNVBAsMJGIzZWIyZjBhLTU5MDktNDgyZS1hOWQ1
LTM4ODlhZTQzOWE1MTExMC8GA1UECgwoQ0lELWY0MWJmNDU5LTRjOWQtNDQ3Yi05
ZjI5LTJkYTc2MTJmMmYyNjAeFw0yMzA3MzEyMjExNDNaFw0yMzA3MzEyMjE1NDNa
MIGKMSYwJAYDVQQDDB1zY20tc3ViLTM4MDMxNDMxOTMzOEBzY20yLm9yZzEtMCsG
A1UECwwkYjUzZDU1YjAtNDVhZi00MmY0LWI4ZDAtMGU5NjFiODU2NjIyMTEwLwYD
VQQKDChDSUQtZjQxYmY0NTktNGM5ZC00NDdiLTlmMjktMmRhNzYxMmYyZjI2MIIB
IjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAo5a88c+apbvMqa3hmSYx+dv0
6pIcTsAcOKVODi9oblwCjHCjzPdUGs/6q7c/39azN6h0psxuN/wYQmrjskSm1GwY
GBR0RQlfFGhpbzskZCfnjw86QJ3sIBpapL/Q9ORhT+98W0sh3/BhOmV1kD07hjVE
HAqwa+6Pxw9kNuqozEvlxkdDFTNECn2lVVl2wy7+zlx1zgBoHSua7EvsgXa2nexd
8eyxXs5LzOMhj3Tnxr4Pl/VoFJzfJqJLvHw541k4yi0tQ8FxHz/g0AX0aGS5zEnj
sbVY1gLz2vHgmGhUJZsTMgr1CwBEQqYaeRQjA8D/F9gARRwYk9RckmsrlVRDYwID
AQABoz4wPDAZBgNVHREEEjAQhwSsGQB1gghzY20yLm9yZzAPBgNVHRMBAf8EBTAD
AQH/MA4GA1UdDwEB/wQEAwIBvjANBgkqhkiG9w0BAQsFAAOCAQEAYbdsEx0Yp/Sr
Rsnn6reX/iZRFRIg6QCU7zPEHGGIkREXMzIYgwD/+Ug7rIw7cmeSbuZo5WWK4017
VbTAH2a9lqypxJcM6pRzv/jkk0peYsuLsia4pepzCStTBgbx6/z57kzb+zW/KMQv
tKx52LE9Cdm6LLKDaYaAZj/XYb3ztGNmGb6K5w8O1xrZvLIZFdvRWWxcWAJqWMBq
kMhKECiA+OVQSWihXwmNoX61PdXyXKUtqIcCjYW7kPun5A3qVzMAaOgK8dX390CB
adPr0C9jHgqJWy1y3T13AQrtYCY/HyxpBReXEARupqbtJvSbU0mpGPgtAAXkDPRe
MPcDnN2tNQ==
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDrzCCApegAwIBAgIBATANBgkqhkiG9w0BAQsFADB7MRcwFQYDVQQDDA5zY20t
MUBzY20xLm9yZzEtMCsGA1UECwwkYjNlYjJmMGEtNTkwOS00ODJlLWE5ZDUtMzg4
OWFlNDM5YTUxMTEwLwYDVQQKDChDSUQtZjQxYmY0NTktNGM5ZC00NDdiLTlmMjkt
MmRhNzYxMmYyZjI2MB4XDTIzMDczMTIyMTEwNVoXDTIzMDczMTIyMTUwNVowezEX
MBUGA1UEAwwOc2NtLTFAc2NtMS5vcmcxLTArBgNVBAsMJGIzZWIyZjBhLTU5MDkt
NDgyZS1hOWQ1LTM4ODlhZTQzOWE1MTExMC8GA1UECgwoQ0lELWY0MWJmNDU5LTRj
OWQtNDQ3Yi05ZjI5LTJkYTc2MTJmMmYyNjCCASIwDQYJKoZIhvcNAQEBBQADggEP
ADCCAQoCggEBAJaoZ/2meKDqu0bRt6k8AwX8IhJre0zJ3YYlLOQkukyIl/FIuQkx
BxBweeediQy8Nzu52hAs8Ee5sfZVqkILaRjU/63po8wxeiryOeyPqY8y/FLRNgnD
Z8Af4wYoLJMZ0fWmvWZj6nlfVOD4wmS046oAGAfNpm9EqsSYEzfuSteTFKz1IYwV
NYy9eonUgsHQqO3+ABX4ntP8PHF4uDr2bfpSuY/ioniNxkzdM9YLpxrSkibDeVnc
CN0gythPItpHL3PasN0RMG/Bd7J5fXPDtNYSoB59yiAQTUQwMMmMyaVADjCrFL/7
EL2E+d6yBeeen2/BPg1LePa3vMv/RSbW5rUCAwEAAaM+MDwwDwYDVR0TAQH/BAUw
AwEB/zAOBgNVHQ8BAf8EBAMCAQYwGQYDVR0RBBIwEIcErBkAdIIIc2NtMS5vcmcw
DQYJKoZIhvcNAQELBQADggEBAFGko1BUQO9Dh5jBPhMAqx/0W9wMUC3QWE63vYFr
yObzYM4+LHNycfz9Mex2Gdojdr0utKYAG4u59d9QnxQT+IlMd/I60H1YoW2F2+e4
yzP5M3TTsFelZg6CrduCAst3Oelo8j1kOVe12VRlohDaX130LVQQNd4AubL6W6bU
buRTcXNhBpMItuAKrHLYjHZ7fSS3ifCtpg355Hm3shdGVSnslKYevSLzwbxp2oww
oFLYIVm+tQ+lgWNF5key/iVIjRpHD5TobzCsihdN9PSgU3q75x8m59poBN/MYPgv
7FgXDPl3dX/mJH4ZfwjL/NSjEOdHSezf+Rb8OZfVa+dsehE=
-----END CERTIFICATE-----

2023-07-31 22:11:44,557 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/certificate.crt
2023-07-31 22:11:44,562 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDwzCCAqugAwIBAgIFWKlbi/YwDQYJKoZIhvcNAQELBQAwezEXMBUGA1UEAwwO
c2NtLTFAc2NtMS5vcmcxLTArBgNVBAsMJGIzZWIyZjBhLTU5MDktNDgyZS1hOWQ1
LTM4ODlhZTQzOWE1MTExMC8GA1UECgwoQ0lELWY0MWJmNDU5LTRjOWQtNDQ3Yi05
ZjI5LTJkYTc2MTJmMmYyNjAeFw0yMzA3MzEyMjExNDNaFw0yMzA3MzEyMjE1NDNa
MIGKMSYwJAYDVQQDDB1zY20tc3ViLTM4MDMxNDMxOTMzOEBzY20yLm9yZzEtMCsG
A1UECwwkYjUzZDU1YjAtNDVhZi00MmY0LWI4ZDAtMGU5NjFiODU2NjIyMTEwLwYD
VQQKDChDSUQtZjQxYmY0NTktNGM5ZC00NDdiLTlmMjktMmRhNzYxMmYyZjI2MIIB
IjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAo5a88c+apbvMqa3hmSYx+dv0
6pIcTsAcOKVODi9oblwCjHCjzPdUGs/6q7c/39azN6h0psxuN/wYQmrjskSm1GwY
GBR0RQlfFGhpbzskZCfnjw86QJ3sIBpapL/Q9ORhT+98W0sh3/BhOmV1kD07hjVE
HAqwa+6Pxw9kNuqozEvlxkdDFTNECn2lVVl2wy7+zlx1zgBoHSua7EvsgXa2nexd
8eyxXs5LzOMhj3Tnxr4Pl/VoFJzfJqJLvHw541k4yi0tQ8FxHz/g0AX0aGS5zEnj
sbVY1gLz2vHgmGhUJZsTMgr1CwBEQqYaeRQjA8D/F9gARRwYk9RckmsrlVRDYwID
AQABoz4wPDAZBgNVHREEEjAQhwSsGQB1gghzY20yLm9yZzAPBgNVHRMBAf8EBTAD
AQH/MA4GA1UdDwEB/wQEAwIBvjANBgkqhkiG9w0BAQsFAAOCAQEAYbdsEx0Yp/Sr
Rsnn6reX/iZRFRIg6QCU7zPEHGGIkREXMzIYgwD/+Ug7rIw7cmeSbuZo5WWK4017
VbTAH2a9lqypxJcM6pRzv/jkk0peYsuLsia4pepzCStTBgbx6/z57kzb+zW/KMQv
tKx52LE9Cdm6LLKDaYaAZj/XYb3ztGNmGb6K5w8O1xrZvLIZFdvRWWxcWAJqWMBq
kMhKECiA+OVQSWihXwmNoX61PdXyXKUtqIcCjYW7kPun5A3qVzMAaOgK8dX390CB
adPr0C9jHgqJWy1y3T13AQrtYCY/HyxpBReXEARupqbtJvSbU0mpGPgtAAXkDPRe
MPcDnN2tNQ==
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDrzCCApegAwIBAgIBATANBgkqhkiG9w0BAQsFADB7MRcwFQYDVQQDDA5zY20t
MUBzY20xLm9yZzEtMCsGA1UECwwkYjNlYjJmMGEtNTkwOS00ODJlLWE5ZDUtMzg4
OWFlNDM5YTUxMTEwLwYDVQQKDChDSUQtZjQxYmY0NTktNGM5ZC00NDdiLTlmMjkt
MmRhNzYxMmYyZjI2MB4XDTIzMDczMTIyMTEwNVoXDTIzMDczMTIyMTUwNVowezEX
MBUGA1UEAwwOc2NtLTFAc2NtMS5vcmcxLTArBgNVBAsMJGIzZWIyZjBhLTU5MDkt
NDgyZS1hOWQ1LTM4ODlhZTQzOWE1MTExMC8GA1UECgwoQ0lELWY0MWJmNDU5LTRj
OWQtNDQ3Yi05ZjI5LTJkYTc2MTJmMmYyNjCCASIwDQYJKoZIhvcNAQEBBQADggEP
ADCCAQoCggEBAJaoZ/2meKDqu0bRt6k8AwX8IhJre0zJ3YYlLOQkukyIl/FIuQkx
BxBweeediQy8Nzu52hAs8Ee5sfZVqkILaRjU/63po8wxeiryOeyPqY8y/FLRNgnD
Z8Af4wYoLJMZ0fWmvWZj6nlfVOD4wmS046oAGAfNpm9EqsSYEzfuSteTFKz1IYwV
NYy9eonUgsHQqO3+ABX4ntP8PHF4uDr2bfpSuY/ioniNxkzdM9YLpxrSkibDeVnc
CN0gythPItpHL3PasN0RMG/Bd7J5fXPDtNYSoB59yiAQTUQwMMmMyaVADjCrFL/7
EL2E+d6yBeeen2/BPg1LePa3vMv/RSbW5rUCAwEAAaM+MDwwDwYDVR0TAQH/BAUw
AwEB/zAOBgNVHQ8BAf8EBAMCAQYwGQYDVR0RBBIwEIcErBkAdIIIc2NtMS5vcmcw
DQYJKoZIhvcNAQELBQADggEBAFGko1BUQO9Dh5jBPhMAqx/0W9wMUC3QWE63vYFr
yObzYM4+LHNycfz9Mex2Gdojdr0utKYAG4u59d9QnxQT+IlMd/I60H1YoW2F2+e4
yzP5M3TTsFelZg6CrduCAst3Oelo8j1kOVe12VRlohDaX130LVQQNd4AubL6W6bU
buRTcXNhBpMItuAKrHLYjHZ7fSS3ifCtpg355Hm3shdGVSnslKYevSLzwbxp2oww
oFLYIVm+tQ+lgWNF5key/iVIjRpHD5TobzCsihdN9PSgU3q75x8m59poBN/MYPgv
7FgXDPl3dX/mJH4ZfwjL/NSjEOdHSezf+Rb8OZfVa+dsehE=
-----END CERTIFICATE-----

2023-07-31 22:11:44,563 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
2023-07-31 22:11:44,595 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, SCMID b53d55b0-45af-42f4-b8d0-0e961b856622
2023-07-31 22:11:44,595 [main] INFO server.StorageContainerManager: Primary SCM Node ID b3eb2f0a-5909-482e-a9d5-3889ae439a51
2023-07-31 22:11:44,636 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-07-31 22:11:50,512 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm2.org/172.25.0.117
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.5.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.5.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.5.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.5.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/okio-3.4.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.5.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.5.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.5.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.5.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.4.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/10f74f7806195f34008d1533fda8253a52ae73f1 ; compiled by 'runner' on 2023-07-31T21:45Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=true, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=16KB, dfs.container.ratis.segment.size=1MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.retries=-1, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=15s, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60s, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=9864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=5GB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=60, hdds.scmclient.failover.retry.interval=1s, hdds.scmclient.max.retry.timeout=60s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT20S, hdds.x509.ca.rotation.check.interval=PT1S, hdds.x509.ca.rotation.enabled=true, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=PT60S, hdds.x509.dir.name=certs, hdds.x509.file.name=certificate.crt, hdds.x509.grace.duration.token.checks.enabled=false, hdds.x509.max.duration=PT240S, hdds.x509.renew.grace.duration=PT45S, hdds.x509.rootca.certificate.polling.interval=PT10s, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=64KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.handler.type=distributed, ozone.http.filter.initializers=org.apache.hadoop.security.HttpCrossOriginFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=15s, ozone.manager.delegation.token.renew-interval=15s, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-address.omservice.om1=om1, ozone.om.http-address.omservice.om2=om2, ozone.om.http-address.omservice.om3=om3, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.internal.service.id=omservice, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.GrpcOmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=false, ozone.path.deleting.limit.per.task=10000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=20s, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication=3, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.volume.name=s3v, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=5s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=2s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=60s, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.enable=true, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-07-31 22:11:50,558 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-07-31 22:11:50,858 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-07-31 22:11:51,414 [main] INFO reflections.Reflections: Reflections took 421 ms to scan 3 urls, producing 132 keys and 288 values 
2023-07-31 22:11:51,815 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2023-07-31 22:11:51,857 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-07-31 22:11:51,975 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
2023-07-31 22:11:51,975 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
2023-07-31 22:11:52,513 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2023-07-31 22:11:52,513 [main] INFO server.StorageContainerManager: SCM login successful.
2023-07-31 22:11:54,555 [main] INFO client.SCMCertificateClient: Certificate serial ID set to 380798471158
2023-07-31 22:11:54,930 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm-1@scm1.org,OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26
           Start Date: Mon Jul 31 22:11:05 UTC 2023
           Final Date: Mon Jul 31 22:15:05 UTC 2023
            SubjectDN: CN=scm-1@scm1.org,OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26
           Public Key: RSA Public Key [8d:25:d5:6b:44:c5:9e:0f:34:df:b8:b8:58:9c:e4:0b:e9:4f:e9:ba],[56:66:d1:a4]
        modulus: 96a867fda678a0eabb46d1b7a93c0305fc22126b7b4cc9dd86252ce424ba4c8897f148b9093107107079e79d890cbc373bb9da102cf047b9b1f655aa420b6918d4ffade9a3cc317a2af239ec8fa98f32fc52d13609c367c01fe306282c9319d1f5a6bd6663ea795f54e0f8c264b4e3aa001807cda66f44aac4981337ee4ad79314acf5218c15358cbd7a89d482c1d0a8edfe0015f89ed3fc3c7178b83af66dfa52b98fe2a2788dc64cdd33d60ba71ad29226c37959dc08dd20cad84f22da472f73dab0dd11306fc177b2797d73c3b4d612a01e7dca20104d443030c98cc9a5400e30ab14bffb10bd84f9deb205e79e9f6fc13e0d4b78f6b7bccbff4526d6e6b5
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 51a4a3505440ef438798c13e1300ab1ff45bdc0c
                       502dd0584eb7bd816bc8e6f360ce3e2c737271fc
                       fd31ec7619da2376bd2eb4a6001b8bb9f5df509f
                       1413f8894c77f23ad07d58a16d85dbe7b8cb33f9
                       3374d3b057a5660e82addb8202cb7739e968f23d
                       643957b5d95465a210da5f5df42d541035de00b9
                       b2fa5ba6d46ee453717361069308b6e00aac72d8
                       8c767b7d24b789f0ada60df9e479b7b217465529
                       ec94a61ebd22f3c1bc69da8c30a052d82159beb5
                       0fa5816345e647b2fe25488d1a470f94e86f30ac
                       8a174df4f4a0537abbe71f26e7da6804dfcc60f8
                       2fec58170cf977757fe6247e197f08cbfcd4a310
                       e74749ecdff916fc3997d56be76c7a11
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

 from file: /data/metadata/scm/sub-ca/certs/CA-1.crt.
2023-07-31 22:11:54,947 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 380798471158
             IssuerDN: CN=scm-1@scm1.org,OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26
           Start Date: Mon Jul 31 22:11:43 UTC 2023
           Final Date: Mon Jul 31 22:15:43 UTC 2023
            SubjectDN: CN=scm-sub-380314319338@scm2.org,OU=b53d55b0-45af-42f4-b8d0-0e961b856622,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26
           Public Key: RSA Public Key [5c:65:0c:8a:a0:56:92:b5:08:44:3d:a1:21:5a:17:5f:26:a6:0c:dd],[56:66:d1:a4]
        modulus: a396bcf1cf9aa5bbcca9ade1992631f9dbf4ea921c4ec01c38a54e0e2f686e5c028c70a3ccf7541acffaabb73fdfd6b337a874a6cc6e37fc18426ae3b244a6d46c1818147445095f1468696f3b246427e78f0f3a409dec201a5aa4bfd0f4e4614fef7c5b4b21dff0613a6575903d3b8635441c0ab06bee8fc70f6436eaa8cc4be5c647431533440a7da5555976c32efece5c75ce00681d2b9aec4bec8176b69dec5df1ecb15ece4bcce3218f74e7c6be0f97f568149cdf26a24bbc7c39e35938ca2d2d43c1711f3fe0d005f46864b9cc49e3b1b558d602f3daf1e0986854259b13320af50b004442a61a79142303c0ff17d800451c1893d45c926b2b95544363
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 61b76c131d18a7f4ab46c9e7eab797fe26511512
                       20e90094ef33c41c61889111173332188300fff9
                       483bac8c3b7267926ee668e5658ae34d7b55b4c0
                       1f66bd96aca9c4970cea9473bff8e4934a5e62cb
                       8bb226b8a5ea73092b530606f1ebfcf9ee4cdbfb
                       35bf28c42fb4ac79d8b13d09d9ba2cb283698680
                       663fd761bdf3b4636619be8ae70f0ed71ad9bcb2
                       1915dbd1596c5c58026a58c06a90c84a102880f8
                       e5504968a15f098da17eb53dd5f25ca52da88702
                       8d85bb90fba7e40dea57330068e80af1d5f7f740
                       8169d3ebd02f631e0a895b2d72dd3d77010aed60
                       263f1f2c6905179710046ea6a6ed26f49b5349a9
                       18f82d0005e40cf45e30f7039cddad35
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/certificate.crt.
2023-07-31 22:11:54,969 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 380798471158
             IssuerDN: CN=scm-1@scm1.org,OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26
           Start Date: Mon Jul 31 22:11:43 UTC 2023
           Final Date: Mon Jul 31 22:15:43 UTC 2023
            SubjectDN: CN=scm-sub-380314319338@scm2.org,OU=b53d55b0-45af-42f4-b8d0-0e961b856622,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26
           Public Key: RSA Public Key [5c:65:0c:8a:a0:56:92:b5:08:44:3d:a1:21:5a:17:5f:26:a6:0c:dd],[56:66:d1:a4]
        modulus: a396bcf1cf9aa5bbcca9ade1992631f9dbf4ea921c4ec01c38a54e0e2f686e5c028c70a3ccf7541acffaabb73fdfd6b337a874a6cc6e37fc18426ae3b244a6d46c1818147445095f1468696f3b246427e78f0f3a409dec201a5aa4bfd0f4e4614fef7c5b4b21dff0613a6575903d3b8635441c0ab06bee8fc70f6436eaa8cc4be5c647431533440a7da5555976c32efece5c75ce00681d2b9aec4bec8176b69dec5df1ecb15ece4bcce3218f74e7c6be0f97f568149cdf26a24bbc7c39e35938ca2d2d43c1711f3fe0d005f46864b9cc49e3b1b558d602f3daf1e0986854259b13320af50b004442a61a79142303c0ff17d800451c1893d45c926b2b95544363
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 61b76c131d18a7f4ab46c9e7eab797fe26511512
                       20e90094ef33c41c61889111173332188300fff9
                       483bac8c3b7267926ee668e5658ae34d7b55b4c0
                       1f66bd96aca9c4970cea9473bff8e4934a5e62cb
                       8bb226b8a5ea73092b530606f1ebfcf9ee4cdbfb
                       35bf28c42fb4ac79d8b13d09d9ba2cb283698680
                       663fd761bdf3b4636619be8ae70f0ed71ad9bcb2
                       1915dbd1596c5c58026a58c06a90c84a102880f8
                       e5504968a15f098da17eb53dd5f25ca52da88702
                       8d85bb90fba7e40dea57330068e80af1d5f7f740
                       8169d3ebd02f631e0a895b2d72dd3d77010aed60
                       263f1f2c6905179710046ea6a6ed26f49b5349a9
                       18f82d0005e40cf45e30f7039cddad35
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/380798471158.crt.
2023-07-31 22:11:54,971 [main] INFO client.SCMCertificateClient: CertificateRenewerService and root ca rotation polling is disabled for scm/sub-ca
2023-07-31 22:11:55,236 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-07-31 22:11:55,655 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-07-31 22:11:56,386 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-07-31 22:11:56,389 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2023-07-31 22:11:56,584 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2023-07-31 22:11:57,175 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:b53d55b0-45af-42f4-b8d0-0e961b856622
2023-07-31 22:11:57,232 [main] INFO ssl.ReloadingX509KeyManager: Key manager is loaded with certificate chain
2023-07-31 22:11:57,236 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 380798471158
             IssuerDN: CN=scm-1@scm1.org,OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26
           Start Date: Mon Jul 31 22:11:43 UTC 2023
           Final Date: Mon Jul 31 22:15:43 UTC 2023
            SubjectDN: CN=scm-sub-380314319338@scm2.org,OU=b53d55b0-45af-42f4-b8d0-0e961b856622,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26
           Public Key: RSA Public Key [5c:65:0c:8a:a0:56:92:b5:08:44:3d:a1:21:5a:17:5f:26:a6:0c:dd],[56:66:d1:a4]
        modulus: a396bcf1cf9aa5bbcca9ade1992631f9dbf4ea921c4ec01c38a54e0e2f686e5c028c70a3ccf7541acffaabb73fdfd6b337a874a6cc6e37fc18426ae3b244a6d46c1818147445095f1468696f3b246427e78f0f3a409dec201a5aa4bfd0f4e4614fef7c5b4b21dff0613a6575903d3b8635441c0ab06bee8fc70f6436eaa8cc4be5c647431533440a7da5555976c32efece5c75ce00681d2b9aec4bec8176b69dec5df1ecb15ece4bcce3218f74e7c6be0f97f568149cdf26a24bbc7c39e35938ca2d2d43c1711f3fe0d005f46864b9cc49e3b1b558d602f3daf1e0986854259b13320af50b004442a61a79142303c0ff17d800451c1893d45c926b2b95544363
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 61b76c131d18a7f4ab46c9e7eab797fe26511512
                       20e90094ef33c41c61889111173332188300fff9
                       483bac8c3b7267926ee668e5658ae34d7b55b4c0
                       1f66bd96aca9c4970cea9473bff8e4934a5e62cb
                       8bb226b8a5ea73092b530606f1ebfcf9ee4cdbfb
                       35bf28c42fb4ac79d8b13d09d9ba2cb283698680
                       663fd761bdf3b4636619be8ae70f0ed71ad9bcb2
                       1915dbd1596c5c58026a58c06a90c84a102880f8
                       e5504968a15f098da17eb53dd5f25ca52da88702
                       8d85bb90fba7e40dea57330068e80af1d5f7f740
                       8169d3ebd02f631e0a895b2d72dd3d77010aed60
                       263f1f2c6905179710046ea6a6ed26f49b5349a9
                       18f82d0005e40cf45e30f7039cddad35
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe

2023-07-31 22:11:57,244 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm-1@scm1.org,OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26
           Start Date: Mon Jul 31 22:11:05 UTC 2023
           Final Date: Mon Jul 31 22:15:05 UTC 2023
            SubjectDN: CN=scm-1@scm1.org,OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26
           Public Key: RSA Public Key [8d:25:d5:6b:44:c5:9e:0f:34:df:b8:b8:58:9c:e4:0b:e9:4f:e9:ba],[56:66:d1:a4]
        modulus: 96a867fda678a0eabb46d1b7a93c0305fc22126b7b4cc9dd86252ce424ba4c8897f148b9093107107079e79d890cbc373bb9da102cf047b9b1f655aa420b6918d4ffade9a3cc317a2af239ec8fa98f32fc52d13609c367c01fe306282c9319d1f5a6bd6663ea795f54e0f8c264b4e3aa001807cda66f44aac4981337ee4ad79314acf5218c15358cbd7a89d482c1d0a8edfe0015f89ed3fc3c7178b83af66dfa52b98fe2a2788dc64cdd33d60ba71ad29226c37959dc08dd20cad84f22da472f73dab0dd11306fc177b2797d73c3b4d612a01e7dca20104d443030c98cc9a5400e30ab14bffb10bd84f9deb205e79e9f6fc13e0d4b78f6b7bccbff4526d6e6b5
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 51a4a3505440ef438798c13e1300ab1ff45bdc0c
                       502dd0584eb7bd816bc8e6f360ce3e2c737271fc
                       fd31ec7619da2376bd2eb4a6001b8bb9f5df509f
                       1413f8894c77f23ad07d58a16d85dbe7b8cb33f9
                       3374d3b057a5660e82addb8202cb7739e968f23d
                       643957b5d95465a210da5f5df42d541035de00b9
                       b2fa5ba6d46ee453717361069308b6e00aac72d8
                       8c767b7d24b789f0ada60df9e479b7b217465529
                       ec94a61ebd22f3c1bc69da8c30a052d82159beb5
                       0fa5816345e647b2fe25488d1a470f94e86f30ac
                       8a174df4f4a0537abbe71f26e7da6804dfcc60f8
                       2fec58170cf977757fe6247e197f08cbfcd4a310
                       e74749ecdff916fc3997d56be76c7a11
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2023-07-31 22:11:57,252 [main] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-07-31 22:11:57,252 [main] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-07-31 22:11:57,254 [main] INFO ssl.ReloadingX509TrustManager: Trust manager is loaded with certificates
2023-07-31 22:11:57,261 [main] INFO ssl.ReloadingX509TrustManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm-1@scm1.org,OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26
           Start Date: Mon Jul 31 22:11:05 UTC 2023
           Final Date: Mon Jul 31 22:15:05 UTC 2023
            SubjectDN: CN=scm-1@scm1.org,OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26
           Public Key: RSA Public Key [8d:25:d5:6b:44:c5:9e:0f:34:df:b8:b8:58:9c:e4:0b:e9:4f:e9:ba],[56:66:d1:a4]
        modulus: 96a867fda678a0eabb46d1b7a93c0305fc22126b7b4cc9dd86252ce424ba4c8897f148b9093107107079e79d890cbc373bb9da102cf047b9b1f655aa420b6918d4ffade9a3cc317a2af239ec8fa98f32fc52d13609c367c01fe306282c9319d1f5a6bd6663ea795f54e0f8c264b4e3aa001807cda66f44aac4981337ee4ad79314acf5218c15358cbd7a89d482c1d0a8edfe0015f89ed3fc3c7178b83af66dfa52b98fe2a2788dc64cdd33d60ba71ad29226c37959dc08dd20cad84f22da472f73dab0dd11306fc177b2797d73c3b4d612a01e7dca20104d443030c98cc9a5400e30ab14bffb10bd84f9deb205e79e9f6fc13e0d4b78f6b7bccbff4526d6e6b5
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 51a4a3505440ef438798c13e1300ab1ff45bdc0c
                       502dd0584eb7bd816bc8e6f360ce3e2c737271fc
                       fd31ec7619da2376bd2eb4a6001b8bb9f5df509f
                       1413f8894c77f23ad07d58a16d85dbe7b8cb33f9
                       3374d3b057a5660e82addb8202cb7739e968f23d
                       643957b5d95465a210da5f5df42d541035de00b9
                       b2fa5ba6d46ee453717361069308b6e00aac72d8
                       8c767b7d24b789f0ada60df9e479b7b217465529
                       ec94a61ebd22f3c1bc69da8c30a052d82159beb5
                       0fa5816345e647b2fe25488d1a470f94e86f30ac
                       8a174df4f4a0537abbe71f26e7da6804dfcc60f8
                       2fec58170cf977757fe6247e197f08cbfcd4a310
                       e74749ecdff916fc3997d56be76c7a11
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2023-07-31 22:11:57,303 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-07-31 22:11:57,314 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-07-31 22:11:57,490 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2023-07-31 22:11:57,517 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-07-31 22:11:57,521 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2023-07-31 22:11:57,523 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-07-31 22:11:57,523 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2023-07-31 22:11:57,525 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2023-07-31 22:11:57,525 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2023-07-31 22:11:57,526 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2023-07-31 22:11:57,530 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-07-31 22:11:57,532 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-07-31 22:11:57,540 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 2000ms (custom)
2023-07-31 22:11:57,576 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-07-31 22:11:57,597 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-07-31 22:11:57,599 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-07-31 22:11:58,835 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2023-07-31 22:11:58,843 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2023-07-31 22:11:58,845 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2023-07-31 22:11:58,847 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2023-07-31 22:11:58,848 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-07-31 22:11:58,856 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-07-31 22:11:58,881 [main] INFO server.RaftServer: b53d55b0-45af-42f4-b8d0-0e961b856622: addNew group-2DA7612F2F26:[] returns group-2DA7612F2F26:java.util.concurrent.CompletableFuture@507f7cd1[Not completed]
2023-07-31 22:11:58,922 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServer$Division: b53d55b0-45af-42f4-b8d0-0e961b856622: new RaftServerImpl for group-2DA7612F2F26:[] with SCMStateMachine:uninitialized
2023-07-31 22:11:58,925 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2023-07-31 22:11:58,926 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2023-07-31 22:11:58,926 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2023-07-31 22:11:58,926 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2023-07-31 22:11:58,927 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-07-31 22:11:58,927 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2023-07-31 22:11:58,939 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServer$Division: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-07-31 22:11:58,941 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-07-31 22:11:58,948 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2023-07-31 22:11:58,949 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2023-07-31 22:11:58,973 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2023-07-31 22:11:59,016 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2023-07-31 22:11:59,025 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2023-07-31 22:11:59,026 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
2023-07-31 22:11:59,081 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2023-07-31 22:11:59,325 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 2000ms (custom)
2023-07-31 22:11:59,334 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-07-31 22:11:59,335 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2023-07-31 22:11:59,336 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2023-07-31 22:11:59,338 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2023-07-31 22:11:59,339 [b53d55b0-45af-42f4-b8d0-0e961b856622-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2023-07-31 22:11:59,343 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2023-07-31 22:11:59,344 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-07-31 22:11:59,347 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2023-07-31 22:11:59,492 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2023-07-31 22:11:59,579 [main] INFO ha.SequenceIdGenerator: upgrade localId to 111677748019200000
2023-07-31 22:11:59,580 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2023-07-31 22:11:59,639 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2023-07-31 22:11:59,646 [main] INFO ha.SequenceIdGenerator: upgrade rootCertificateId to 1
2023-07-31 22:11:59,652 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2023-07-31 22:11:59,846 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2023-07-31 22:11:59,886 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2023-07-31 22:11:59,889 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-07-31 22:11:59,911 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2023-07-31 22:11:59,950 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-07-31 22:11:59,951 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-07-31 22:11:59,965 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2023-07-31 22:11:59,966 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
2023-07-31 22:11:59,971 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2023-07-31 22:11:59,972 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2023-07-31 22:11:59,982 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2023-07-31 22:11:59,983 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2023-07-31 22:12:00,036 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-07-31 22:12:00,037 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-07-31 22:12:00,092 [main] WARN util.MBeans: Failed to register MBean "Hadoop:service=BlockManager,name=BlockManagerImpl"
javax.management.NotCompliantMBeanException: MBean class org.apache.hadoop.hdds.scm.block.BlockManagerImpl does not implement DynamicMBean, and neither follows the Standard MBean conventions (javax.management.NotCompliantMBeanException: Class org.apache.hadoop.hdds.scm.block.BlockManagerImpl is not a JMX compliant Standard MBean) nor the MXBean conventions (javax.management.NotCompliantMBeanException: org.apache.hadoop.hdds.scm.block.BlockManagerImpl: Class org.apache.hadoop.hdds.scm.block.BlockManagerImpl is not a JMX compliant MXBean)
	at java.management/com.sun.jmx.mbeanserver.Introspector.checkCompliance(Introspector.java:177)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:313)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:100)
	at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:73)
	at org.apache.hadoop.hdds.scm.block.BlockManagerImpl.<init>(BlockManagerImpl.java:94)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.initializeSystemManagers(StorageContainerManager.java:786)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.<init>(StorageContainerManager.java:400)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.createSCM(StorageContainerManager.java:597)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.createSCM(StorageContainerManager.java:609)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter$SCMStarterHelper.start(StorageContainerManagerStarter.java:171)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter.startScm(StorageContainerManagerStarter.java:145)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter.call(StorageContainerManagerStarter.java:74)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter.call(StorageContainerManagerStarter.java:48)
	at picocli.CommandLine.executeUserObject(CommandLine.java:1953)
	at picocli.CommandLine.access$1300(CommandLine.java:145)
	at picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2352)
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2346)
	at picocli.CommandLine$RunLast.handle(CommandLine.java:2311)
	at picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2179)
	at picocli.CommandLine.execute(CommandLine.java:2078)
	at org.apache.hadoop.hdds.cli.GenericCli.execute(GenericCli.java:100)
	at org.apache.hadoop.hdds.cli.GenericCli.run(GenericCli.java:91)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter.main(StorageContainerManagerStarter.java:63)
2023-07-31 22:12:00,111 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2023-07-31 22:12:00,397 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2023-07-31 22:12:00,409 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2023-07-31 22:12:00,409 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2023-07-31 22:12:00,466 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2023-07-31 22:12:00,481 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:12:00,490 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-07-31 22:12:01,168 [main] INFO security.SecretKeyManagerService: Scheduling rotation checker with interval PT1M
2023-07-31 22:12:01,184 [main] INFO ha.SCMServiceManager: Registering service SecretKeyManagerService.
2023-07-31 22:12:01,268 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2023-07-31 22:12:01,359 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-07-31 22:12:01,508 [main] INFO ipc.Server: Listener at 0.0.0.0:9961
2023-07-31 22:12:01,547 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
2023-07-31 22:12:01,719 [main] INFO ha.SCMServiceManager: Registering service RootCARotationManager.
2023-07-31 22:12:01,729 [main] INFO server.StorageContainerManager: SCM start with adminUsers: [testuser, recon, om, scm]
2023-07-31 22:12:03,650 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-07-31 22:12:03,826 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-07-31 22:12:03,827 [main] INFO ipc.Server: Listener at 0.0.0.0:9861
2023-07-31 22:12:03,852 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2023-07-31 22:12:03,928 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-07-31 22:12:03,943 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-07-31 22:12:03,945 [main] INFO ipc.Server: Listener at 0.0.0.0:9863
2023-07-31 22:12:03,949 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2023-07-31 22:12:04,121 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-07-31 22:12:04,162 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-07-31 22:12:04,163 [main] INFO ipc.Server: Listener at 0.0.0.0:9860
2023-07-31 22:12:04,169 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2023-07-31 22:12:04,524 [main] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2023-07-31 22:12:04,525 [main] INFO server.StorageContainerManager: 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-07-31 22:12:04,525 [main] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-07-31 22:12:04,545 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2023-07-31 22:12:04,558 [main] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2023-07-31 22:12:04,565 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/f41bf459-4c9d-447b-9f29-2da7612f2f26 does not exist. Creating ...
2023-07-31 22:12:04,575 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/f41bf459-4c9d-447b-9f29-2da7612f2f26/in_use.lock acquired by nodename 6@scm2.org
2023-07-31 22:12:04,620 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/f41bf459-4c9d-447b-9f29-2da7612f2f26 has been successfully formatted.
2023-07-31 22:12:04,633 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2023-07-31 22:12:04,668 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2023-07-31 22:12:04,669 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-07-31 22:12:04,671 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-07-31 22:12:04,672 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2023-07-31 22:12:04,675 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-07-31 22:12:04,683 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2023-07-31 22:12:04,683 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-07-31 22:12:04,683 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-07-31 22:12:04,691 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/f41bf459-4c9d-447b-9f29-2da7612f2f26
2023-07-31 22:12:04,691 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-07-31 22:12:04,692 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2023-07-31 22:12:04,693 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-07-31 22:12:04,694 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2023-07-31 22:12:04,695 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2023-07-31 22:12:04,696 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2023-07-31 22:12:04,696 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-07-31 22:12:04,697 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-07-31 22:12:04,782 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
2023-07-31 22:12:04,783 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-07-31 22:12:04,869 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2023-07-31 22:12:04,871 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2023-07-31 22:12:04,871 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2023-07-31 22:12:04,896 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO segmented.SegmentedRaftLogWorker: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-07-31 22:12:04,897 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO segmented.SegmentedRaftLogWorker: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-07-31 22:12:04,905 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServer$Division: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: start with initializing state, conf=-1: peers:[]|listeners:[], old=null
2023-07-31 22:12:04,915 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServer$Division: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: changes role from      null to FOLLOWER at term 0 for startInitializing
2023-07-31 22:12:04,918 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2DA7612F2F26,id=b53d55b0-45af-42f4-b8d0-0e961b856622
2023-07-31 22:12:04,927 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-07-31 22:12:04,929 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2023-07-31 22:12:04,937 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2023-07-31 22:12:04,940 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2023-07-31 22:12:04,945 [main] INFO server.RaftServer: b53d55b0-45af-42f4-b8d0-0e961b856622: start RPC server
2023-07-31 22:12:05,032 [main] INFO server.GrpcService: b53d55b0-45af-42f4-b8d0-0e961b856622: GrpcService started, listening on 9894
2023-07-31 22:12:05,049 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-b53d55b0-45af-42f4-b8d0-0e961b856622: Started
2023-07-31 22:12:05,065 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
2023-07-31 22:12:06,957 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: receive installSnapshot: b3eb2f0a-5909-482e-a9d5-3889ae439a51->b53d55b0-45af-42f4-b8d0-0e961b856622#0-t2,notify:(t:1, i:0)
2023-07-31 22:12:06,973 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
2023-07-31 22:12:06,973 [grpc-default-executor-0] INFO server.RaftServer$Division: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: change Leader from null to b3eb2f0a-5909-482e-a9d5-3889ae439a51 at term 2 for installSnapshot, leader elected after 8000ms
2023-07-31 22:12:06,989 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: Received notification to install snapshot at index 0
2023-07-31 22:12:06,996 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
2023-07-31 22:12:07,324 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: set new configuration index: 1
configurationEntry {
  peers {
    id: "b3eb2f0a-5909-482e-a9d5-3889ae439a51"
    address: "scm1.org:9894"
    startupRole: FOLLOWER
  }
}
 from snapshot
2023-07-31 22:12:07,331 [grpc-default-executor-0] INFO server.RaftServer$Division: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: set configuration 1: peers:[b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-07-31 22:12:07,344 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: reply installSnapshot: b3eb2f0a-5909-482e-a9d5-3889ae439a51<-b53d55b0-45af-42f4-b8d0-0e961b856622#0:OK-t0,ALREADY_INSTALLED
2023-07-31 22:12:07,385 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: b53d55b0-45af-42f4-b8d0-0e961b856622: Completed INSTALL_SNAPSHOT, lastRequest: b3eb2f0a-5909-482e-a9d5-3889ae439a51->b53d55b0-45af-42f4-b8d0-0e961b856622#0-t2,notify:(t:1, i:0)
2023-07-31 22:12:07,386 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: b53d55b0-45af-42f4-b8d0-0e961b856622: Completed INSTALL_SNAPSHOT, lastReply: null
2023-07-31 22:12:07,501 [b53d55b0-45af-42f4-b8d0-0e961b856622-server-thread1] INFO impl.RoleInfo: b53d55b0-45af-42f4-b8d0-0e961b856622: start b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState
2023-07-31 22:12:07,511 [b53d55b0-45af-42f4-b8d0-0e961b856622-server-thread1] INFO server.RaftServer$Division: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-07-31 22:12:07,516 [b53d55b0-45af-42f4-b8d0-0e961b856622-server-thread1] INFO server.RaftServer$Division: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: inconsistency entries. Reply:b3eb2f0a-5909-482e-a9d5-3889ae439a51<-b53d55b0-45af-42f4-b8d0-0e961b856622#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-07-31 22:12:07,543 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:12:07,543 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:12:07,549 [b53d55b0-45af-42f4-b8d0-0e961b856622-server-thread1] INFO server.RaftServer$Division: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: set configuration 0: peers:[b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-07-31 22:12:07,551 [b53d55b0-45af-42f4-b8d0-0e961b856622-server-thread1] INFO server.RaftServer$Division: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: set configuration 1: peers:[b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-07-31 22:12:07,585 [b53d55b0-45af-42f4-b8d0-0e961b856622-server-thread1] INFO segmented.SegmentedRaftLogWorker: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-SegmentedRaftLogWorker: Starting segment from index:0
2023-07-31 22:12:07,659 [b53d55b0-45af-42f4-b8d0-0e961b856622-server-thread1] INFO segmented.SegmentedRaftLogWorker: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2023-07-31 22:12:08,274 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f41bf459-4c9d-447b-9f29-2da7612f2f26/current/log_inprogress_0
2023-07-31 22:12:08,282 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/f41bf459-4c9d-447b-9f29-2da7612f2f26/current/log_inprogress_0 to /data/metadata/scm-ha/f41bf459-4c9d-447b-9f29-2da7612f2f26/current/log_0-0
2023-07-31 22:12:08,322 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f41bf459-4c9d-447b-9f29-2da7612f2f26/current/log_inprogress_1
2023-07-31 22:12:08,401 [b53d55b0-45af-42f4-b8d0-0e961b856622-server-thread2] INFO server.RaftServer$Division: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: set configuration 11: peers:[b53d55b0-45af-42f4-b8d0-0e961b856622|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
2023-07-31 22:12:08,401 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:12:08,408 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2023-07-31 22:12:08,408 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-07-31 22:12:08,410 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2023-07-31 22:12:08,453 [b53d55b0-45af-42f4-b8d0-0e961b856622-server-thread2] INFO server.RaftServer$Division: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: set configuration 13: peers:[b53d55b0-45af-42f4-b8d0-0e961b856622|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-07-31 22:12:08,521 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2023-07-31 22:12:08,453 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-07-31 22:12:08,796 [main] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-2DA7612F2F26:[b53d55b0-45af-42f4-b8d0-0e961b856622|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]
2023-07-31 22:12:08,798 [main] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2023-07-31 22:12:08,922 [main] INFO SCMHATransactionMonitor: Starting SCMHATransactionMonitor Service.
2023-07-31 22:12:08,935 [main] INFO ha.SCMServiceManager: Registering service SCMHATransactionMonitor.
2023-07-31 22:12:08,935 [main] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is already running, skip start.
2023-07-31 22:12:09,130 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = 13eee858-b508-4485-9d15-c4d79974bb15, creation at: 2023-07-31T22:11:36.254Z, expire at: 2023-07-31T23:11:36.254Z)]
2023-07-31 22:12:09,137 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 13eee858-b508-4485-9d15-c4d79974bb15, creation at: 2023-07-31T22:11:36.254Z, expire at: 2023-07-31T23:11:36.254Z)
2023-07-31 22:12:09,545 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2023-07-31 22:12:09,554 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 13eee858-b508-4485-9d15-c4d79974bb15, creation at: 2023-07-31T22:11:36.254Z, expire at: 2023-07-31T23:11:36.254Z)] to file /data/metadata/scm/keys/secret_keys.json
2023-07-31 22:12:09,561 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:12:09,564 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2023-07-31 22:12:09,565 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2023-07-31 22:12:09,596 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-07-31 22:12:09,596 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2023-07-31 22:12:09,757 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:12:09,842 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO server.SCMCertStore: Scm certificate 380798471158 for CN=scm-sub-380314319338@scm2.org,OU=b53d55b0-45af-42f4-b8d0-0e961b856622,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26 is stored
2023-07-31 22:12:09,843 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:12:09,855 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:12:09,953 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2023-07-31 22:12:09,960 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-07-31 22:12:09,964 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2023-07-31 22:12:10,231 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2023-07-31 22:12:10,232 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2023-07-31 22:12:10,233 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-07-31 22:12:10,234 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2023-07-31 22:12:10,350 [main] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
2023-07-31 22:12:10,351 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-07-31 22:12:10,352 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
2023-07-31 22:12:10,353 [main] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
2023-07-31 22:12:10,830 [main] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node b53d55b0-45af-42f4-b8d0-0e961b856622
2023-07-31 22:12:10,849 [main] INFO server.SCMCertStore: Scm certificate 1 for CN=scm-1@scm1.org,OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26 is stored
2023-07-31 22:12:10,856 [main] INFO server.StorageContainerManager: Persist certificate serialId 343497309243 on Scm Bootstrap Node b53d55b0-45af-42f4-b8d0-0e961b856622
2023-07-31 22:12:10,869 [main] INFO server.SCMCertStore: Scm certificate 343497309243 for CN=scm-sub-343236681062@scm1.org,OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26 is stored
2023-07-31 22:12:10,886 [main] INFO security.RootCARotationManager: Monitor task for root certificate 1 is started with interval PT1S.
2023-07-31 22:12:10,953 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2023-07-31 22:12:10,953 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
2023-07-31 22:12:10,962 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
2023-07-31 22:12:11,041 [main] INFO util.log: Logging initialized @25644ms to org.eclipse.jetty.util.log.Slf4jLog
2023-07-31 22:12:11,616 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2023-07-31 22:12:11,648 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-07-31 22:12:11,656 [main] INFO security.HttpCrossOriginFilterInitializer: CORS filter not enabled. Please set hadoop.http.cross-origin.enabled to 'true' to enable it
2023-07-31 22:12:11,667 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
2023-07-31 22:12:11,798 [main] INFO http.BaseHttpServer: HTTP server of scm uses base directory /data/metadata/webserver
2023-07-31 22:12:11,800 [main] INFO http.HttpServer2: Jetty bound to port 9876
2023-07-31 22:12:11,804 [main] INFO server.Server: jetty-9.4.51.v20230217; built: 2023-02-17T08:19:37.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm 11.0.19+7-LTS
2023-07-31 22:12:11,880 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2023-07-31 22:12:11,880 [main] INFO server.session: No SessionScavenger set, using defaults
2023-07-31 22:12:11,882 [main] INFO server.session: node0 Scavenging every 600000ms
2023-07-31 22:12:11,919 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@336f70a6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2023-07-31 22:12:11,922 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2dcfa917{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-07-31 22:12:12,232 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2023-07-31 22:12:12,252 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@8a20b8e{scm,/,file:///data/metadata/webserver/jetty-0_0_0_0-9876-hdds-server-scm-1_4_0-SNAPSHOT_jar-_-any-2491854992968378238/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/scm}
2023-07-31 22:12:12,271 [main] INFO server.AbstractConnector: Started ServerConnector@8c41677{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2023-07-31 22:12:12,272 [main] INFO server.Server: Started @26875ms
2023-07-31 22:12:12,276 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2023-07-31 22:12:12,276 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
2023-07-31 22:12:12,280 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2023-07-31 22:12:12,744 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:12:12,744 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:12:15,146 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO server.SCMCertStore: Scm certificate 411443779151 for CN=scm-sub-411236819450@scm3.org,OU=72f45f5b-02ea-498a-8bed-6d0c9b6347d5,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26 is stored
2023-07-31 22:12:15,147 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:12:17,776 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:12:17,777 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:12:21,862 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:12:22,859 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:12:22,860 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:12:28,010 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:12:28,010 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:12:33,153 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:12:33,153 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:12:37,462 [b53d55b0-45af-42f4-b8d0-0e961b856622-server-thread2] INFO server.RaftServer$Division: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: set configuration 19: peers:[b53d55b0-45af-42f4-b8d0-0e961b856622|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 72f45f5b-02ea-498a-8bed-6d0c9b6347d5|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[b53d55b0-45af-42f4-b8d0-0e961b856622|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
2023-07-31 22:12:37,528 [b53d55b0-45af-42f4-b8d0-0e961b856622-server-thread2] INFO server.RaftServer$Division: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: set configuration 21: peers:[b53d55b0-45af-42f4-b8d0-0e961b856622|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 72f45f5b-02ea-498a-8bed-6d0c9b6347d5|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-07-31 22:12:38,187 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:12:38,188 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:12:39,542 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:12:43,296 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:12:43,296 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:12:48,428 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:12:48,428 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:12:53,468 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:12:53,468 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:12:58,584 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:12:58,585 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:13:03,761 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:13:03,762 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:13:08,854 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:13:08,854 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:13:10,131 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:13:13,960 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:13:13,961 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:13:16,652 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:13:19,039 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:13:19,040 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:13:19,310 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:13:23,095 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:13:23,495 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:13:24,145 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:13:24,148 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:13:24,654 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:13:29,330 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:13:29,330 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:13:29,935 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:13:34,468 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:13:34,469 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:13:34,918 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:13:39,185 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:13:39,536 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:13:39,537 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:13:40,466 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:13:44,646 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:13:44,647 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:13:47,618 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:13:49,758 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:13:49,759 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:13:54,872 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:13:54,872 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:13:57,978 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:60808 / 172.25.0.103:60808
2023-07-31 22:13:58,278 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:14:00,061 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:14:00,063 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:14:02,354 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:40048 / 172.25.0.102:40048
2023-07-31 22:14:02,536 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:14:05,249 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:14:05,250 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:14:05,692 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/55024020-dc46-4d0a-b886-038ad654ed37
2023-07-31 22:14:05,788 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 55024020-dc46-4d0a-b886-038ad654ed37{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=9864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 490961574779, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-31 22:14:05,913 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-07-31 22:14:05,962 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
2023-07-31 22:14:07,814 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:14:08,089 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/77ec83ae-e46f-47c5-ab15-a50ca58f2d88
2023-07-31 22:14:08,090 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 77ec83ae-e46f-47c5-ab15-a50ca58f2d88{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=9864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 494987562161, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-31 22:14:08,130 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
2023-07-31 22:14:08,132 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-07-31 22:14:09,001 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:14:09,053 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:14:09,790 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:35570 / 172.25.0.104:35570
2023-07-31 22:14:10,369 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:14:10,369 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:14:10,422 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:14:11,021 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:14:14,218 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:14:15,244 [IPC Server handler 6 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/904c6b21-586f-49dc-bea6-0cdebfea75bf
2023-07-31 22:14:15,246 [IPC Server handler 6 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 904c6b21-586f-49dc-bea6-0cdebfea75bf{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=9864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 530213086935, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-31 22:14:15,247 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-07-31 22:14:15,249 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
2023-07-31 22:14:15,249 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2023-07-31 22:14:15,249 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2023-07-31 22:14:15,249 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-07-31 22:14:15,251 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
2023-07-31 22:14:15,376 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:14:15,498 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:14:15,498 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:14:15,535 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:14:15,744 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:14:16,311 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:14:20,365 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:14:20,654 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:14:20,655 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:14:20,718 [EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "04433921-4b5b-43be-8ffc-c2f7100265f9"
  uuid128 {
    mostSigBits: 307152014752302014
    leastSigBits: -8071362065773468167
  }
}
isLeader: false
bytesWritten: 0
 from dn=904c6b21-586f-49dc-bea6-0cdebfea75bf(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26 is not the leader b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26 is not the leader b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:744)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:709)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:850)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$12(RaftServerImpl.java:831)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$13(RaftServerImpl.java:831)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-07-31 22:14:21,662 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-07-31 22:14:25,770 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:14:25,770 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:14:26,901 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-07-31 22:14:28,823 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:51962 / 172.25.0.102:51962
2023-07-31 22:14:29,138 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:14:30,927 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:14:30,929 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:14:32,855 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:14:34,299 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-07-31 22:14:35,588 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:14:36,054 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:14:36,054 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:14:37,479 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:54408 / 172.25.0.103:54408
2023-07-31 22:14:37,861 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:14:39,561 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2023-07-31 22:14:40,966 [EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "22fd6901-09a3-4d2d-8d56-ae7e6eb643e8"
  uuid128 {
    mostSigBits: 2521286819574926637
    leastSigBits: -8262224608318045208
  }
}
isLeader: false
bytesWritten: 0
 from dn=55024020-dc46-4d0a-b886-038ad654ed37(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26 is not the leader b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26 is not the leader b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:744)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:709)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:850)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$12(RaftServerImpl.java:831)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$13(RaftServerImpl.java:831)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-07-31 22:14:40,969 [EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "24d94484-7178-4c08-ac9a-905786139b1e"
  uuid128 {
    mostSigBits: 2655228790941699080
    leastSigBits: -6009332047186519266
  }
}
isLeader: false
bytesWritten: 0
 from dn=55024020-dc46-4d0a-b886-038ad654ed37(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26 is not the leader b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26 is not the leader b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:744)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:709)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:850)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$12(RaftServerImpl.java:831)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$13(RaftServerImpl.java:831)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-07-31 22:14:41,134 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:14:41,137 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:14:41,232 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2023-07-31 22:14:41,381 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2023-07-31 22:14:41,608 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for rootCertificateId, expected lastId is 0, actual lastId is 1.
2023-07-31 22:14:41,717 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2023-07-31 22:14:42,063 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:47714 / 172.25.0.102:47714
2023-07-31 22:14:42,419 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2023-07-31 22:14:42,440 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-07-31 22:14:42,440 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2023-07-31 22:14:42,440 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2023-07-31 22:14:42,446 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2023-07-31 22:14:42,448 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-07-31 22:14:42,560 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:14:42,608 [EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "0c196074-92ff-4732-b538-915d61a9a91b"
  uuid128 {
    mostSigBits: 871834056671577906
    leastSigBits: -5388397123892303589
  }
}
isLeader: false
bytesWritten: 0
 from dn=77ec83ae-e46f-47c5-ab15-a50ca58f2d88(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26 is not the leader b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26 is not the leader b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:744)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:709)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:850)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$12(RaftServerImpl.java:831)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$13(RaftServerImpl.java:831)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-07-31 22:14:45,596 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:56758 / 172.25.0.104:56758
2023-07-31 22:14:46,214 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:14:46,214 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:14:46,470 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:14:51,261 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:14:51,261 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:14:52,093 [EventQueue-PipelineReportForPipelineReportHandler] ERROR pipeline.PipelineReportHandler: Could not process pipeline report=pipelineID {
  id: "9553ea14-2761-44d6-913c-db9302dceb5a"
  uuid128 {
    mostSigBits: -7686542766710373162
    leastSigBits: -7981263015152653478
  }
}
isLeader: true
bytesWritten: 0
 from dn=904c6b21-586f-49dc-bea6-0cdebfea75bf(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.NotLeaderException: Server b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26 is not the leader b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy21.updatePipelineState(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.openPipeline(PipelineManagerImpl.java:430)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.processPipelineReport(PipelineReportHandler.java:135)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:85)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.ratis.protocol.exceptions.NotLeaderException: Server b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26 is not the leader b3eb2f0a-5909-482e-a9d5-3889ae439a51|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER
	at org.apache.ratis.server.impl.RaftServerImpl.generateNotLeaderException(RaftServerImpl.java:744)
	at org.apache.ratis.server.impl.RaftServerImpl.checkLeaderState(RaftServerImpl.java:709)
	at org.apache.ratis.server.impl.RaftServerImpl.submitClientRequestAsync(RaftServerImpl.java:850)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$null$12(RaftServerImpl.java:831)
	at org.apache.ratis.util.JavaUtils.callAsUnchecked(JavaUtils.java:117)
	at org.apache.ratis.server.impl.RaftServerImpl.lambda$executeSubmitClientRequestAsync$13(RaftServerImpl.java:831)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	... 3 more
2023-07-31 22:14:53,210 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO security.RootCARotationHandlerImpl: Received rotation prepare command of root certificate 2
2023-07-31 22:14:53,239 [RootCARotationManager-Inactive] INFO security.RootCARotationManager: SubCARotationPrepareTask[rootCertId = 2] - started.
2023-07-31 22:14:56,409 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:14:56,410 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:14:57,124 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-b53d55b0-45af-42f4-b8d0-0e961b856622: Detected pause in JVM or host machine approximately 0.119s with 0.210s GC time.
GC pool 'ParNew' had collection(s): count=1 time=210ms
2023-07-31 22:15:01,523 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:15:01,525 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:15:02,105 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO server.SCMCertStore: Scm certificate 577858615505 for CN=scm-sub-575298568583@scm1.org,OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26 is stored
2023-07-31 22:15:02,139 [RootCARotationManager-Inactive] INFO security.RootCARotationManager: SubCARotationPrepareTask[rootCertId = 2] - scm key generated.
2023-07-31 22:15:02,139 [RootCARotationManager-Inactive] INFO client.SCMCertificateClient: Creating csr for SCM->hostName:scm2.org,scmId:b53d55b0-45af-42f4-b8d0-0e961b856622,clusterId:CID-f41bf459-4c9d-447b-9f29-2da7612f2f26,subject:scm-sub-578860819804@scm2.org
2023-07-31 22:15:02,261 [RootCARotationManager-Inactive] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
2023-07-31 22:15:02,267 [RootCARotationManager-Inactive] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2023-07-31 22:15:04,938 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO security.RootCARotationHandlerImpl: Received rotation prepare ack of root certificate 2 from scm b3eb2f0a-5909-482e-a9d5-3889ae439a51
2023-07-31 22:15:05,470 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO server.SCMCertStore: Scm certificate 579561321293 for CN=scm-sub-578299301093@scm3.org,OU=72f45f5b-02ea-498a-8bed-6d0c9b6347d5,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26 is stored
2023-07-31 22:15:06,548 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:15:06,552 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:15:07,702 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:10,830 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:11,691 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:15:11,693 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:15:12,622 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:16,042 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:16,754 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:15:16,754 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:15:17,817 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:48986 / 172.25.0.102:48986
2023-07-31 22:15:17,917 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:15:18,822 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:20,326 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:21,768 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:21,868 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:15:21,868 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:15:22,162 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:46074 / 172.25.0.104:46074
2023-07-31 22:15:22,263 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:15:23,701 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:25,913 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:26,776 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:53108 / 172.25.0.103:53108
2023-07-31 22:15:26,839 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:15:26,904 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:15:26,905 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:15:27,542 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:30,405 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:31,924 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:15:31,925 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:15:32,026 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:33,083 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:34,160 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:35,731 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:36,778 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:37,095 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:15:37,095 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:15:38,899 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:39,962 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:41,045 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:42,099 [grpc-default-executor-1] INFO ssl.ReloadingX509TrustManager: Client certificate chain O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-sub-343236681062@scm1.org,O=CID-f41bf459-4c9d-447b-9f29-2da7612f2f26, OU=b3eb2f0a-5909-482e-a9d5-3889ae439a51, CN=scm-1@scm1.org for authType ECDHE_ECDSA is not trusted
2023-07-31 22:15:42,251 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:15:42,251 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:15:47,354 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:15:47,354 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:15:47,792 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:44626 / 172.25.0.102:44626
2023-07-31 22:15:47,835 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:15:52,233 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:59552 / 172.25.0.104:59552
2023-07-31 22:15:52,300 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:15:52,527 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:15:52,528 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:15:56,773 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:57490 / 172.25.0.103:57490
2023-07-31 22:15:56,779 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:15:57,550 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:15:57,550 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:16:02,553 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:16:02,554 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:16:07,715 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:16:07,716 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:16:12,777 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:16:12,778 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:16:17,727 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:39164 / 172.25.0.102:39164
2023-07-31 22:16:17,744 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:16:17,862 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:16:17,862 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:16:22,117 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:60414 / 172.25.0.104:60414
2023-07-31 22:16:22,158 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:16:23,009 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:16:23,009 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:16:26,726 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:59126 / 172.25.0.103:59126
2023-07-31 22:16:26,768 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:16:28,181 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:16:28,181 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:16:33,207 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:16:33,208 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:16:38,366 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:16:38,366 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:16:43,539 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:16:43,540 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:16:47,751 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net:37410 / 172.25.0.102:37410
2023-07-31 22:16:47,783 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:16:48,655 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:16:48,655 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:16:52,115 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net:44468 / 172.25.0.104:44468
2023-07-31 22:16:52,146 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:16:53,809 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:16:53,809 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:16:56,727 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net:60546 / 172.25.0.103:60546
2023-07-31 22:16:56,790 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-07-31 22:16:58,880 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:16:58,880 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:17:00,410 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2023-07-31 22:17:03,223 [RootCARotationManager-Inactive] ERROR client.SCMCertificateClient: Error while fetching/storing SCM signed certificate.
org.apache.hadoop.hdds.security.exception.SCMSecurityException: org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.AlreadyClosedException: SlidingWindow$Client:client-8C85F4AA674A->RAFT is closed.
	at org.apache.hadoop.hdds.protocolPB.SCMSecurityProtocolClientSideTranslatorPB.handleError(SCMSecurityProtocolClientSideTranslatorPB.java:122)
	at org.apache.hadoop.hdds.protocolPB.SCMSecurityProtocolClientSideTranslatorPB.submitRequest(SCMSecurityProtocolClientSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.protocolPB.SCMSecurityProtocolClientSideTranslatorPB.getSCMCertChain(SCMSecurityProtocolClientSideTranslatorPB.java:233)
	at org.apache.hadoop.hdds.security.x509.certificate.client.SCMCertificateClient.signAndStoreCertificate(SCMCertificateClient.java:201)
	at org.apache.hadoop.hdds.scm.security.RootCARotationManager$SubCARotationPrepareTask.run(RootCARotationManager.java:546)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
2023-07-31 22:17:03,224 [RootCARotationManager-Inactive] ERROR security.RootCARotationManager: Failed to generate certificate under /data/metadata/scm/sub-ca-next-progress
java.lang.RuntimeException: org.apache.hadoop.hdds.security.exception.SCMSecurityException: org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.AlreadyClosedException: SlidingWindow$Client:client-8C85F4AA674A->RAFT is closed.
	at org.apache.hadoop.hdds.security.x509.certificate.client.SCMCertificateClient.signAndStoreCertificate(SCMCertificateClient.java:228)
	at org.apache.hadoop.hdds.scm.security.RootCARotationManager$SubCARotationPrepareTask.run(RootCARotationManager.java:546)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.hadoop.hdds.security.exception.SCMSecurityException: org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.AlreadyClosedException: SlidingWindow$Client:client-8C85F4AA674A->RAFT is closed.
	at org.apache.hadoop.hdds.protocolPB.SCMSecurityProtocolClientSideTranslatorPB.handleError(SCMSecurityProtocolClientSideTranslatorPB.java:122)
	at org.apache.hadoop.hdds.protocolPB.SCMSecurityProtocolClientSideTranslatorPB.submitRequest(SCMSecurityProtocolClientSideTranslatorPB.java:104)
	at org.apache.hadoop.hdds.protocolPB.SCMSecurityProtocolClientSideTranslatorPB.getSCMCertChain(SCMSecurityProtocolClientSideTranslatorPB.java:233)
	at org.apache.hadoop.hdds.security.x509.certificate.client.SCMCertificateClient.signAndStoreCertificate(SCMCertificateClient.java:201)
	... 7 more
2023-07-31 22:17:03,224 [RootCARotationManager-Inactive] INFO server.StorageContainerManager: Container Balancer is not running.
2023-07-31 22:17:03,294 [RootCARotationManager-Inactive] INFO server.StorageContainerManager: Stopping Replication Manager Service.
2023-07-31 22:17:03,295 [RootCARotationManager-Inactive] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
2023-07-31 22:17:03,295 [Over Replicated Processor] WARN replication.UnhealthyReplicationProcessor: Over Replicated Processor interrupted. Exiting...
2023-07-31 22:17:03,316 [RootCARotationManager-Inactive] INFO server.StorageContainerManager: Stopping the Datanode Admin Monitor.
2023-07-31 22:17:03,316 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
2023-07-31 22:17:03,296 [Under Replicated Processor] WARN replication.UnhealthyReplicationProcessor: Under Replicated Processor interrupted. Exiting...
2023-07-31 22:17:03,345 [RootCARotationManager-Inactive] INFO server.StorageContainerManager: Stopping datanode service RPC server
2023-07-31 22:17:03,347 [RootCARotationManager-Inactive] INFO server.SCMDatanodeProtocolServer: Stopping the RPC server for DataNodes
2023-07-31 22:17:03,349 [RootCARotationManager-Inactive] INFO ipc.Server: Stopping server on 9861
2023-07-31 22:17:03,372 [IPC Server listener on 9861] INFO ipc.Server: Stopping IPC Server listener on 9861
2023-07-31 22:17:03,420 [IPC Server Responder] INFO ipc.Server: Stopping IPC Server Responder
2023-07-31 22:17:03,981 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-31 22:17:03,981 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-31 22:17:06,146 [SCM Heartbeat Processing Thread - 0] WARN node.NodeStateManager: Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-07-31 22:17:06,148 [RootCARotationManager-Inactive] INFO server.StorageContainerManager: Stopping block service RPC server
2023-07-31 22:17:06,148 [RootCARotationManager-Inactive] INFO server.SCMBlockProtocolServer: Stopping the RPC server for Block Protocol
2023-07-31 22:17:06,149 [RootCARotationManager-Inactive] INFO ipc.Server: Stopping server on 9863
2023-07-31 22:17:06,174 [IPC Server Responder] INFO ipc.Server: Stopping IPC Server Responder
2023-07-31 22:17:06,174 [IPC Server listener on 9863] INFO ipc.Server: Stopping IPC Server listener on 9863
2023-07-31 22:17:06,177 [RootCARotationManager-Inactive] INFO server.StorageContainerManager: Stopping the StorageContainerLocationProtocol RPC server
2023-07-31 22:17:06,178 [RootCARotationManager-Inactive] INFO server.SCMClientProtocolServer: Stopping the RPC server for Client Protocol
2023-07-31 22:17:06,180 [RootCARotationManager-Inactive] INFO ipc.Server: Stopping server on 9860
2023-07-31 22:17:06,204 [IPC Server Responder] INFO ipc.Server: Stopping IPC Server Responder
2023-07-31 22:17:06,205 [IPC Server listener on 9860] INFO ipc.Server: Stopping IPC Server listener on 9860
2023-07-31 22:17:06,206 [RootCARotationManager-Inactive] INFO server.StorageContainerManager: Stopping Storage Container Manager HTTP server.
2023-07-31 22:17:06,211 [RootCARotationManager-Inactive] INFO handler.ContextHandler: Stopped o.e.j.w.WebAppContext@8a20b8e{scm,/,null,STOPPED}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/scm}
2023-07-31 22:17:06,217 [RootCARotationManager-Inactive] INFO server.AbstractConnector: Stopped ServerConnector@8c41677{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2023-07-31 22:17:06,217 [RootCARotationManager-Inactive] INFO server.session: node0 Stopped scavenging
2023-07-31 22:17:06,218 [RootCARotationManager-Inactive] INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@2dcfa917{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-07-31 22:17:06,219 [RootCARotationManager-Inactive] INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@336f70a6{logs,/logs,file:///var/log/hadoop/,STOPPED}
2023-07-31 22:17:06,222 [RootCARotationManager-Inactive] INFO server.StorageContainerManager: Stopping SCM LayoutVersionManager Service.
2023-07-31 22:17:06,222 [RootCARotationManager-Inactive] INFO server.SCMSecurityProtocolServer: Stopping the SCMSecurityProtocolServer.
2023-07-31 22:17:06,223 [RootCARotationManager-Inactive] INFO ipc.Server: Stopping server on 9961
2023-07-31 22:17:06,223 [IPC Server listener on 9961] INFO ipc.Server: Stopping IPC Server listener on 9961
2023-07-31 22:17:06,224 [IPC Server Responder] INFO ipc.Server: Stopping IPC Server Responder
2023-07-31 22:17:06,226 [RootCARotationManager-Inactive] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService stopping
2023-07-31 22:17:06,232 [RootCARotationManager-Inactive] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService stopped!
2023-07-31 22:17:06,233 [RootCARotationManager-Inactive] INFO server.StorageContainerManager: Stopping Block Manager Service.
2023-07-31 22:17:06,233 [RootCARotationManager-Inactive] INFO utils.BackgroundService: Shutting down service SCMBlockDeletingService
2023-07-31 22:17:06,233 [RootCARotationManager-Inactive] INFO utils.BackgroundService: Shutting down service SCMBlockDeletingService
2023-07-31 22:17:06,235 [RootCARotationManager-Inactive] INFO server.StorageContainerManager: Stopping SCM Event Queue.
2023-07-31 22:17:06,239 [RootCARotationManager-Inactive] INFO server.StorageContainerManager: Stopping SCM HA services.
2023-07-31 22:17:06,239 [RootCARotationManager-Inactive] INFO ha.SCMRatisServerImpl: stopping ratis server 0.0.0.0:9894
2023-07-31 22:17:06,241 [RootCARotationManager-Inactive] INFO server.RaftServer: b53d55b0-45af-42f4-b8d0-0e961b856622: close
2023-07-31 22:17:06,247 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread2] INFO server.RaftServer$Division: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26: shutdown
2023-07-31 22:17:06,247 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread2] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2DA7612F2F26,id=b53d55b0-45af-42f4-b8d0-0e961b856622
2023-07-31 22:17:06,247 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread2] INFO impl.RoleInfo: b53d55b0-45af-42f4-b8d0-0e961b856622: shutdown b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState
2023-07-31 22:17:06,248 [b53d55b0-45af-42f4-b8d0-0e961b856622-impl-thread2] INFO impl.StateMachineUpdater: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater: set stopIndex = 96
2023-07-31 22:17:06,248 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState] INFO impl.FollowerState: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-FollowerState was interrupted
2023-07-31 22:17:06,251 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO ha.SCMStateMachine: Current Snapshot Index 96, takeSnapshot took 2 ms
2023-07-31 22:17:06,253 [RootCARotationManager-Inactive] INFO server.GrpcService: b53d55b0-45af-42f4-b8d0-0e961b856622: shutdown server GrpcServerProtocolService now
2023-07-31 22:17:06,252 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO impl.StateMachineUpdater: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater: Took a snapshot at index 96
2023-07-31 22:17:06,253 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO impl.StateMachineUpdater: b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 96
2023-07-31 22:17:06,269 [grpc-default-executor-3] WARN server.GrpcServerProtocolService: b53d55b0-45af-42f4-b8d0-0e961b856622: APPEND_ENTRIES onError, lastRequest: b3eb2f0a-5909-482e-a9d5-3889ae439a51->b53d55b0-45af-42f4-b8d0-0e961b856622#324-t2,previous=(t:2, i:95),leaderCommit=95,initializing? true,entries: size=1, first=(t:2, i:96), METADATAENTRY(c:95): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-07-31 22:17:06,258 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO server.StorageContainerManager: Storage Container Manager is not running.
2023-07-31 22:17:06,277 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO server.StorageContainerManager: Stopping Replication Manager Service.
2023-07-31 22:17:06,278 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO replication.ReplicationManager: Replication Monitor Thread is not running.
2023-07-31 22:17:06,279 [b53d55b0-45af-42f4-b8d0-0e961b856622@group-2DA7612F2F26-StateMachineUpdater] INFO server.StorageContainerManager: Terminating with exit status 0: scm statemachine is closed by ratis, terminate SCM
2023-07-31 22:17:06,281 [grpc-default-executor-1] WARN server.GrpcServerProtocolService: b53d55b0-45af-42f4-b8d0-0e961b856622: APPEND_ENTRIES onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-07-31 22:17:06,287 [RootCARotationManager-Inactive] INFO server.GrpcService: b53d55b0-45af-42f4-b8d0-0e961b856622: shutdown server GrpcServerProtocolService successfully
2023-07-31 22:17:06,289 [RootCARotationManager-Inactive] ERROR ha.InterSCMGrpcService: failed to shutdown XceiverServerGrpc
java.lang.InterruptedException
	at java.base/java.lang.Object.wait(Native Method)
	at java.base/java.lang.Object.wait(Object.java:462)
	at java.base/java.util.concurrent.TimeUnit.timedWait(TimeUnit.java:408)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl.awaitTermination(ServerImpl.java:311)
	at org.apache.hadoop.hdds.scm.ha.InterSCMGrpcProtocolService.stop(InterSCMGrpcProtocolService.java:110)
	at org.apache.hadoop.hdds.scm.ha.SCMHAManagerImpl.stop(SCMHAManagerImpl.java:393)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.stop(StorageContainerManager.java:1682)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.shutDown(StorageContainerManager.java:1734)
	at org.apache.hadoop.hdds.scm.security.RootCARotationManager$SubCARotationPrepareTask.run(RootCARotationManager.java:558)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
2023-07-31 22:17:06,290 [RootCARotationManager-Inactive] INFO SCMHATransactionMonitor: Stopping SCMHATransactionMonitor Service.
2023-07-31 22:17:06,291 [RootCARotationManager-Inactive] INFO pipeline.BackgroundPipelineCreator: Stopping RatisPipelineUtilsThread.
2023-07-31 22:17:06,292 [RatisPipelineUtilsThread - 0] WARN pipeline.BackgroundPipelineCreator: RatisPipelineUtilsThread is interrupted.
2023-07-31 22:17:06,292 [BackgroundPipelineScrubberThread] WARN BackgroundPipelineScrubber: BackgroundPipelineScrubber is interrupted, exit
2023-07-31 22:17:06,300 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-b53d55b0-45af-42f4-b8d0-0e961b856622: Stopped
2023-07-31 22:17:06,290 [SCMHATransactionMonitorThread] WARN SCMHATransactionMonitor: SCMHATransactionMonitor is interrupted, exit
2023-07-31 22:17:06,293 [RootCARotationManager-Inactive] INFO BackgroundPipelineScrubber: Stopping BackgroundPipelineScrubber Service.
2023-07-31 22:17:06,308 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
************************************************************/
2023-07-31 22:17:06,310 [RootCARotationManager-Inactive] INFO impl.MetricsSystemImpl: Stopping StorageContainerManager metrics system...
2023-07-31 22:17:06,314 [RootCARotationManager-Inactive] WARN impl.MetricsSinkAdapter: Stop interrupted
java.lang.InterruptedException
	at java.base/java.lang.Object.wait(Native Method)
	at java.base/java.lang.Thread.join(Thread.java:1300)
	at java.base/java.lang.Thread.join(Thread.java:1375)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.stop(MetricsSinkAdapter.java:214)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.stopSinks(MetricsSystemImpl.java:476)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.stop(MetricsSystemImpl.java:213)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.stop(StorageContainerManager.java:1695)
	at org.apache.hadoop.hdds.scm.server.StorageContainerManager.shutDown(StorageContainerManager.java:1734)
	at org.apache.hadoop.hdds.scm.security.RootCARotationManager$SubCARotationPrepareTask.run(RootCARotationManager.java:558)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
2023-07-31 22:17:06,315 [RootCARotationManager-Inactive] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system stopped.
2023-07-31 22:17:06,320 [RootCARotationManager-Inactive] WARN pipeline.BackgroundPipelineCreator: RatisPipelineUtilsThread is not running, just ignore.
2023-07-31 22:17:06,320 [RootCARotationManager-Inactive] INFO BackgroundPipelineScrubber: BackgroundPipelineScrubber Service is not running, skip stop.
2023-07-31 22:17:06,320 [RootCARotationManager-Inactive] INFO ExpiredContainerReplicaOpScrubber: Stopping ExpiredContainerReplicaOpScrubber Service.
2023-07-31 22:17:06,320 [RootCARotationManager-Inactive] INFO utils.BackgroundService: Shutting down service SCMBlockDeletingService
2023-07-31 22:17:06,320 [RootCARotationManager-Inactive] INFO replication.ReplicationManager: Replication Monitor Thread is not running.
2023-07-31 22:17:06,320 [RootCARotationManager-Inactive] WARN balancer.ContainerBalancer: Cannot stop Container Balancer because it's not running or stopping
2023-07-31 22:17:06,320 [RootCARotationManager-Inactive] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is not running, skip stop.
2023-07-31 22:17:06,321 [Lease Manager-LeaseManager#LeaseMonitor] WARN lease.LeaseManager: Lease manager is interrupted. Shutting down...
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1081)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1369)
	at java.base/java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:415)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:270)
	at java.base/java.lang.Thread.run(Thread.java:829)
2023-07-31 22:17:06,322 [RootCARotationManager-Inactive] INFO server.StorageContainerManager: Stopping SCM MetadataStore.
2023-07-31 22:17:06,318 [prometheus] INFO impl.MetricsSinkAdapter: prometheus thread interrupted.
2023-07-31 22:17:06,320 [ExpiredContainerReplicaOpScrubberThread] WARN ExpiredContainerReplicaOpScrubber: ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-07-31 22:17:06,612 [RootCARotationManager-Inactive] INFO server.StorageContainerManager: Terminating with exit status 0: Terminate SCM, encounter exception(org.apache.hadoop.hdds.security.exception.SCMSecurityException: org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.AlreadyClosedException: SlidingWindow$Client:client-8C85F4AA674A->RAFT is closed.) when generating new certificate /data/metadata/scm/sub-ca-next-progress
2023-07-31 22:17:06,616 [shutdown-hook-0] INFO server.StorageContainerManager: Storage Container Manager is not running.
2023-07-31 22:17:06,616 [shutdown-hook-0] INFO server.StorageContainerManager: Stopping Replication Manager Service.
2023-07-31 22:17:06,616 [shutdown-hook-0] INFO replication.ReplicationManager: Replication Monitor Thread is not running.
2023-07-31 22:17:06,616 [shutdown-hook-0] INFO server.SCMSecurityProtocolServer: Join RPC server for SCMSecurityProtocolServer.
2023-07-31 22:17:06,616 [shutdown-hook-0] INFO server.SCMSecurityProtocolServer: Join gRPC server for SCMSecurityProtocolServer.
