rm: cannot remove '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/*': No such file or directory
Executing test ozone-csi/test.sh
Removing network ozone-csi_default
Network ozone-csi_default not found.
Creating network "ozone-csi_default" with the default driver
Pulling datanode (apache/ozone-runner:20230615-1)...
20230615-1: Pulling from apache/ozone-runner
Digest: sha256:46c59e4f69c94a8f886d621c9f1898fda8cc4d5de59059c6c74175ffa4718474
Status: Downloaded newer image for apache/ozone-runner:20230615-1
Creating ozone-csi_scm_1 ... 
Creating ozone-csi_csi_1 ... 
Creating ozone-csi_datanode_1 ... 
Creating ozone-csi_datanode_2 ... 
Creating ozone-csi_datanode_3 ... 
Creating ozone-csi_om_1       ... 
Creating ozone-csi_csi_1      ... done
Creating ozone-csi_datanode_3 ... done
Creating ozone-csi_datanode_1 ... done
Creating ozone-csi_datanode_2 ... done
Creating ozone-csi_scm_1      ... done
Creating ozone-csi_om_1       ... done
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Timed out waiting on scm 9860 to become available
Stopping ozone-csi_datanode_2 ... 
Stopping ozone-csi_om_1       ... 
Stopping ozone-csi_datanode_3 ... 
Stopping ozone-csi_csi_1      ... 
Stopping ozone-csi_scm_1      ... 
Stopping ozone-csi_datanode_1 ... 
Stopping ozone-csi_scm_1      ... done
Stopping ozone-csi_csi_1      ... done
Stopping ozone-csi_om_1       ... done
Stopping ozone-csi_datanode_2 ... done
Stopping ozone-csi_datanode_3 ... done
Stopping ozone-csi_datanode_1 ... done
Removing ozone-csi_datanode_2 ... 
Removing ozone-csi_om_1       ... 
Removing ozone-csi_datanode_3 ... 
Removing ozone-csi_csi_1      ... 
Removing ozone-csi_scm_1      ... 
Removing ozone-csi_datanode_1 ... 
Removing ozone-csi_scm_1      ... done
Removing ozone-csi_csi_1      ... done
Removing ozone-csi_datanode_1 ... done
Removing ozone-csi_om_1       ... done
Removing ozone-csi_datanode_2 ... done
Removing ozone-csi_datanode_3 ... done
Removing network ozone-csi_default
ERROR: Test execution of ozone-csi/test.sh is FAILED!!!!
renamed 'ozone-csi/result/docker-ozone-csi.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-csi/docker-ozone-csi.log'
renamed 'ozone-csi/result/om-audit-caf24d1ba4f8.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-csi/om-audit-caf24d1ba4f8.log'
Executing test ozone-om-prepare/test.sh
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data/dn1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data/dn3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data/om2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data/om3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data/om1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data/dn2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data/scm': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/ozone-om-prepare/data': Operation not permitted
Removing network ozone-om-prepare_net
Network ozone-om-prepare_net not found.
Creating network "ozone-om-prepare_net" with driver "bridge"
Creating ozone-om-prepare_scm_1 ... 
Creating ozone-om-prepare_om3_1 ... 
Creating ozone-om-prepare_dn2_1 ... 
Creating ozone-om-prepare_om1_1 ... 
Creating ozone-om-prepare_dn3_1 ... 
Creating ozone-om-prepare_om2_1 ... 
Creating ozone-om-prepare_dn1_1 ... 
Creating ozone-om-prepare_dn2_1 ... done
Creating ozone-om-prepare_om1_1 ... done
Creating ozone-om-prepare_om3_1 ... done
Creating ozone-om-prepare_dn3_1 ... done
Creating ozone-om-prepare_om2_1 ... done
Creating ozone-om-prepare_scm_1 ... done
Creating ozone-om-prepare_dn1_1 ... done
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Timed out waiting on scm 9860 to become available
Stopping ozone-om-prepare_om3_1 ... 
Stopping ozone-om-prepare_dn1_1 ... 
Stopping ozone-om-prepare_om1_1 ... 
Stopping ozone-om-prepare_om2_1 ... 
Stopping ozone-om-prepare_dn3_1 ... 
Stopping ozone-om-prepare_dn2_1 ... 
Stopping ozone-om-prepare_scm_1 ... 
Stopping ozone-om-prepare_om2_1 ... done
Stopping ozone-om-prepare_scm_1 ... done
Stopping ozone-om-prepare_om3_1 ... done
Stopping ozone-om-prepare_om1_1 ... done
Stopping ozone-om-prepare_dn3_1 ... done
Stopping ozone-om-prepare_dn1_1 ... done
Stopping ozone-om-prepare_dn2_1 ... done
Removing ozone-om-prepare_om3_1 ... 
Removing ozone-om-prepare_dn1_1 ... 
Removing ozone-om-prepare_om1_1 ... 
Removing ozone-om-prepare_om2_1 ... 
Removing ozone-om-prepare_dn3_1 ... 
Removing ozone-om-prepare_dn2_1 ... 
Removing ozone-om-prepare_scm_1 ... 
Removing ozone-om-prepare_dn2_1 ... done
Removing ozone-om-prepare_om3_1 ... done
Removing ozone-om-prepare_om2_1 ... done
Removing ozone-om-prepare_scm_1 ... done
Removing ozone-om-prepare_dn1_1 ... done
Removing ozone-om-prepare_dn3_1 ... done
Removing ozone-om-prepare_om1_1 ... done
Removing network ozone-om-prepare_net
ERROR: Test execution of ozone-om-prepare/test.sh is FAILED!!!!
renamed 'ozone-om-prepare/result/docker-ozone-om-prepare.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/docker-ozone-om-prepare.log'
renamed 'ozone-om-prepare/result/om-audit-92b06dddac33.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-92b06dddac33.log'
renamed 'ozone-om-prepare/result/om-audit-e4e252f09a78.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-om-prepare/om-audit-e4e252f09a78.log'
Executing test ozone-topology/test.sh
Removing network ozone-topology_net
Network ozone-topology_net not found.
Creating network "ozone-topology_net" with driver "bridge"
Creating ozone-topology_scm_1 ... 
Creating ozone-topology_recon_1 ... 
Creating ozone-topology_datanode_4_1 ... 
Creating ozone-topology_datanode_6_1 ... 
Creating ozone-topology_datanode_5_1 ... 
Creating ozone-topology_datanode_2_1 ... 
Creating ozone-topology_datanode_3_1 ... 
Creating ozone-topology_datanode_1_1 ... 
Creating ozone-topology_om_1         ... 
Creating ozone-topology_recon_1      ... done
Creating ozone-topology_datanode_6_1 ... done
Creating ozone-topology_datanode_1_1 ... done
Creating ozone-topology_datanode_4_1 ... done
Creating ozone-topology_datanode_5_1 ... done
Creating ozone-topology_datanode_2_1 ... done
Creating ozone-topology_scm_1        ... done
Creating ozone-topology_om_1         ... done
Creating ozone-topology_datanode_3_1 ... done
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Timed out waiting on scm 9860 to become available
Stopping ozone-topology_om_1         ... 
Stopping ozone-topology_datanode_3_1 ... 
Stopping ozone-topology_datanode_2_1 ... 
Stopping ozone-topology_datanode_1_1 ... 
Stopping ozone-topology_datanode_5_1 ... 
Stopping ozone-topology_recon_1      ... 
Stopping ozone-topology_datanode_6_1 ... 
Stopping ozone-topology_datanode_4_1 ... 
Stopping ozone-topology_scm_1        ... 
Stopping ozone-topology_om_1         ... done
Stopping ozone-topology_scm_1        ... done
Stopping ozone-topology_datanode_1_1 ... done
Stopping ozone-topology_datanode_2_1 ... done
Stopping ozone-topology_datanode_4_1 ... done
Stopping ozone-topology_recon_1      ... done
Stopping ozone-topology_datanode_5_1 ... done
Stopping ozone-topology_datanode_6_1 ... done
Stopping ozone-topology_datanode_3_1 ... done
Removing ozone-topology_om_1         ... 
Removing ozone-topology_datanode_3_1 ... 
Removing ozone-topology_datanode_2_1 ... 
Removing ozone-topology_datanode_1_1 ... 
Removing ozone-topology_datanode_5_1 ... 
Removing ozone-topology_recon_1      ... 
Removing ozone-topology_datanode_6_1 ... 
Removing ozone-topology_datanode_4_1 ... 
Removing ozone-topology_scm_1        ... 
Removing ozone-topology_scm_1        ... done
Removing ozone-topology_datanode_5_1 ... done
Removing ozone-topology_om_1         ... done
Removing ozone-topology_datanode_3_1 ... done
Removing ozone-topology_recon_1      ... done
Removing ozone-topology_datanode_6_1 ... done
Removing ozone-topology_datanode_2_1 ... done
Removing ozone-topology_datanode_1_1 ... done
Removing ozone-topology_datanode_4_1 ... done
Removing network ozone-topology_net
ERROR: Test execution of ozone-topology/test.sh is FAILED!!!!
renamed 'ozone-topology/result/docker-ozone-topology.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone-topology/docker-ozone-topology.log'
Executing test ozone/test-s3-haproxy.sh
Removing network ozone_default
Network ozone_default not found.
Creating network "ozone_default" with the default driver
Pulling s3g (haproxy:lts-alpine)...
lts-alpine: Pulling from library/haproxy
Digest: sha256:f2a5ed55791e7a47c40e6faa9ff36c0e1dc743a232f132eadc01c6aaec0387de
Status: Downloaded newer image for haproxy:lts-alpine
Creating ozone_scm_1 ... 
Creating ozone_s3g3_1 ... 
Creating ozone_datanode_1 ... 
Creating ozone_datanode_2 ... 
Creating ozone_datanode_3 ... 
Creating ozone_s3g1_1     ... 
Creating ozone_httpfs_1   ... 
Creating ozone_s3g_1      ... 
Creating ozone_om_1       ... 
Creating ozone_s3g2_1     ... 
Creating ozone_recon_1    ... 
Creating ozone_s3g3_1     ... done
Creating ozone_scm_1      ... done
Creating ozone_recon_1    ... done
Creating ozone_s3g_1      ... done
Creating ozone_s3g2_1     ... done
Creating ozone_s3g1_1     ... done
Creating ozone_datanode_2 ... done
Creating ozone_httpfs_1   ... done
Creating ozone_om_1       ... done
Creating ozone_datanode_3 ... done
Creating ozone_datanode_1 ... done
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Timed out waiting on scm 9860 to become available
Stopping ozone_recon_1    ... 
Stopping ozone_httpfs_1   ... 
Stopping ozone_om_1       ... 
Stopping ozone_s3g_1      ... 
Stopping ozone_s3g2_1     ... 
Stopping ozone_datanode_2 ... 
Stopping ozone_s3g1_1     ... 
Stopping ozone_datanode_1 ... 
Stopping ozone_datanode_3 ... 
Stopping ozone_s3g3_1     ... 
Stopping ozone_scm_1      ... 
Stopping ozone_s3g_1      ... done
Stopping ozone_om_1       ... done
Stopping ozone_scm_1      ... done
Stopping ozone_httpfs_1   ... done
Stopping ozone_datanode_2 ... done
Stopping ozone_datanode_1 ... done
Stopping ozone_s3g2_1     ... done
Stopping ozone_recon_1    ... done
Stopping ozone_s3g1_1     ... done
Stopping ozone_s3g3_1     ... done
Stopping ozone_datanode_3 ... done
Removing ozone_recon_1    ... 
Removing ozone_httpfs_1   ... 
Removing ozone_om_1       ... 
Removing ozone_s3g_1      ... 
Removing ozone_s3g2_1     ... 
Removing ozone_datanode_2 ... 
Removing ozone_s3g1_1     ... 
Removing ozone_datanode_1 ... 
Removing ozone_datanode_3 ... 
Removing ozone_s3g3_1     ... 
Removing ozone_scm_1      ... 
Removing ozone_s3g1_1     ... done
Removing ozone_om_1       ... done
Removing ozone_s3g_1      ... done
Removing ozone_s3g2_1     ... done
Removing ozone_datanode_1 ... done
Removing ozone_datanode_2 ... done
Removing ozone_recon_1    ... done
Removing ozone_scm_1      ... done
Removing ozone_s3g3_1     ... done
Removing ozone_httpfs_1   ... done
Removing ozone_datanode_3 ... done
Removing network ozone_default
ERROR: Test execution of ozone/test-s3-haproxy.sh is FAILED!!!!
renamed 'ozone/result/docker-ozone.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone/s3-haproxy/docker-ozone.log'
renamed 'ozone/result/om-audit-c496fe59e1ac.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone/s3-haproxy/om-audit-c496fe59e1ac.log'
renamed 'ozone/result/s3g-audit-4b1bb135b950.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone/s3-haproxy/s3g-audit-4b1bb135b950.log'
renamed 'ozone/result/s3g-audit-8a17931ae8ec.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone/s3-haproxy/s3g-audit-8a17931ae8ec.log'
renamed 'ozone/result/s3g-audit-ac34f07db26d.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozone/s3-haproxy/s3g-audit-ac34f07db26d.log'
Executing test ozonescripts/test.sh
Removing network ozonescripts_default
Network ozonescripts_default not found.
Creating network "ozonescripts_default" with the default driver
Building datanode
Sending build context to Docker daemon  30.21kB
Step 1/17 : ARG OZONE_RUNNER_IMAGE
Step 2/17 : ARG OZONE_RUNNER_VERSION
Step 3/17 : FROM ${OZONE_RUNNER_IMAGE}:${OZONE_RUNNER_VERSION}
 ---> adbc121b0d99
Step 4/17 : RUN sudo yum install -y openssh-clients openssh-server
 ---> Running in 94f8e6c6e4b9
Loaded plugins: fastestmirror, ovl
Determining fastest mirrors
 * base: southfront.mm.fcix.net
 * epel: mnvoip.mm.fcix.net
 * extras: centos.mirror.ndchost.com
 * updates: mirrors.wcupa.edu
Resolving Dependencies
--> Running transaction check
---> Package openssh-clients.x86_64 0:7.4p1-22.el7_9 will be installed
--> Processing Dependency: openssh = 7.4p1-22.el7_9 for package: openssh-clients-7.4p1-22.el7_9.x86_64
--> Processing Dependency: fipscheck-lib(x86-64) >= 1.3.0 for package: openssh-clients-7.4p1-22.el7_9.x86_64
--> Processing Dependency: libfipscheck.so.1()(64bit) for package: openssh-clients-7.4p1-22.el7_9.x86_64
--> Processing Dependency: libedit.so.0()(64bit) for package: openssh-clients-7.4p1-22.el7_9.x86_64
---> Package openssh-server.x86_64 0:7.4p1-22.el7_9 will be installed
--> Processing Dependency: libwrap.so.0()(64bit) for package: openssh-server-7.4p1-22.el7_9.x86_64
--> Running transaction check
---> Package fipscheck-lib.x86_64 0:1.4.1-6.el7 will be installed
--> Processing Dependency: /usr/bin/fipscheck for package: fipscheck-lib-1.4.1-6.el7.x86_64
---> Package libedit.x86_64 0:3.0-12.20121213cvs.el7 will be installed
---> Package openssh.x86_64 0:7.4p1-22.el7_9 will be installed
---> Package tcp_wrappers-libs.x86_64 0:7.6-77.el7 will be installed
--> Running transaction check
---> Package fipscheck.x86_64 0:1.4.1-6.el7 will be installed
--> Finished Dependency Resolution

Dependencies Resolved

================================================================================
 Package               Arch       Version                     Repository   Size
================================================================================
Installing:
 openssh-clients       x86_64     7.4p1-22.el7_9              updates     655 k
 openssh-server        x86_64     7.4p1-22.el7_9              updates     459 k
Installing for dependencies:
 fipscheck             x86_64     1.4.1-6.el7                 base         21 k
 fipscheck-lib         x86_64     1.4.1-6.el7                 base         11 k
 libedit               x86_64     3.0-12.20121213cvs.el7      base         92 k
 openssh               x86_64     7.4p1-22.el7_9              updates     510 k
 tcp_wrappers-libs     x86_64     7.6-77.el7                  base         66 k

Transaction Summary
================================================================================
Install  2 Packages (+5 Dependent packages)

Total download size: 1.8 M
Installed size: 5.8 M
Downloading packages:
--------------------------------------------------------------------------------
Total                                              973 kB/s | 1.8 MB  00:01     
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : fipscheck-1.4.1-6.el7.x86_64                                 1/7 
  Installing : fipscheck-lib-1.4.1-6.el7.x86_64                             2/7 
  Installing : openssh-7.4p1-22.el7_9.x86_64                                3/7 
  Installing : tcp_wrappers-libs-7.6-77.el7.x86_64                          4/7 
  Installing : libedit-3.0-12.20121213cvs.el7.x86_64                        5/7 
  Installing : openssh-clients-7.4p1-22.el7_9.x86_64                        6/7 
  Installing : openssh-server-7.4p1-22.el7_9.x86_64                         7/7 
  Verifying  : fipscheck-lib-1.4.1-6.el7.x86_64                             1/7 
  Verifying  : openssh-server-7.4p1-22.el7_9.x86_64                         2/7 
  Verifying  : fipscheck-1.4.1-6.el7.x86_64                                 3/7 
  Verifying  : libedit-3.0-12.20121213cvs.el7.x86_64                        4/7 
  Verifying  : openssh-clients-7.4p1-22.el7_9.x86_64                        5/7 
  Verifying  : tcp_wrappers-libs-7.6-77.el7.x86_64                          6/7 
  Verifying  : openssh-7.4p1-22.el7_9.x86_64                                7/7 

Installed:
  openssh-clients.x86_64 0:7.4p1-22.el7_9                                       
  openssh-server.x86_64 0:7.4p1-22.el7_9                                        

Dependency Installed:
  fipscheck.x86_64 0:1.4.1-6.el7            fipscheck-lib.x86_64 0:1.4.1-6.el7  
  libedit.x86_64 0:3.0-12.20121213cvs.el7   openssh.x86_64 0:7.4p1-22.el7_9     
  tcp_wrappers-libs.x86_64 0:7.6-77.el7    

Complete!
Removing intermediate container 94f8e6c6e4b9
 ---> 1ff8a3a4d9c1
Step 5/17 : RUN sudo ssh-keygen -A
 ---> Running in bc38704afa0e
ssh-keygen: generating new host keys: RSA1 RSA DSA ECDSA ED25519 
Removing intermediate container bc38704afa0e
 ---> 18085718600b
Step 6/17 : RUN sudo mkdir -p /run/sshd
 ---> Running in c478f82735b6
Removing intermediate container c478f82735b6
 ---> 80fd8661885b
Step 7/17 : RUN sudo sed -i "s/.*UsePrivilegeSeparation.*/UsePrivilegeSeparation no/g" /etc/ssh/sshd_config
 ---> Running in c1c36d0a54e9
Removing intermediate container c1c36d0a54e9
 ---> 5430acbb4e93
Step 8/17 : RUN sudo sed -i "s/.*PermitUserEnvironment.*/PermitUserEnvironment yes/g" /etc/ssh/sshd_config
 ---> Running in c4a4a59264c8
Removing intermediate container c4a4a59264c8
 ---> 789f5a85d853
Step 9/17 : RUN sudo sed 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd
 ---> Running in 318ee4b227a7
Removing intermediate container 318ee4b227a7
 ---> 35d18d7944e4
Step 10/17 : RUN sudo usermod -d /opt hadoop
 ---> Running in 0b9207423047
Removing intermediate container 0b9207423047
 ---> eb88d7cf5d40
Step 11/17 : ADD .ssh /opt/.ssh
 ---> 11a9e6720cec
Step 12/17 : RUN sudo chown -R hadoop /opt/.ssh
 ---> Running in 93ab20245b6d
Removing intermediate container 93ab20245b6d
 ---> 2462eb3afaea
Step 13/17 : RUN sudo chown hadoop /opt
 ---> Running in d38240872237
Removing intermediate container d38240872237
 ---> 9b8c5e9a3b05
Step 14/17 : RUN sudo chmod 600 /opt/.ssh/*
 ---> Running in 0e68909fc75b
Removing intermediate container 0e68909fc75b
 ---> a625f679ee4f
Step 15/17 : RUN sudo chmod 700 /opt/.ssh
 ---> Running in d2fbb3bdfefb
Removing intermediate container d2fbb3bdfefb
 ---> 86db18263ba7
Step 16/17 : RUN sudo sh -c 'echo "export JAVA_HOME=/usr/lib/jvm/jre/" >> /etc/profile'
 ---> Running in 83ff98b1d0eb
Removing intermediate container 83ff98b1d0eb
 ---> 213f9485c3eb
Step 17/17 : CMD ["sudo","/usr/sbin/sshd","-D"]
 ---> Running in f7307b5984bf
Removing intermediate container f7307b5984bf
 ---> ad7015398f78
Successfully built ad7015398f78
Successfully tagged ozone-runner-scripts:20230615-1
Image for service datanode was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Creating ozonescripts_datanode_1 ... 
Creating ozonescripts_om_1       ... 
Creating ozonescripts_scm_1      ... 
Creating ozonescripts_datanode_1 ... done
Creating ozonescripts_scm_1      ... done
Creating ozonescripts_om_1       ... done
Port 22 is available on scm
Port 22 is available on om
Port 22 is available on datanode
No OM HA service, no need to wait
+ docker-compose ps
+ grep datanode
+ xargs -n1 docker inspect --format '{{ .Config.Hostname }}'
+ awk '{print $1}'
+ docker-compose ps
+ awk '{print $1}'
+ grep ozonescripts
+ xargs -I CONTAINER -n1 docker exec CONTAINER cp /opt/hadoop/etc/hadoop/workers /etc/hadoop/workers
+ docker-compose exec -T scm /opt/hadoop/bin/ozone scm --init
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-07-20 02:18:22,713 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = a550f9f52914/172.20.0.2
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.5.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.5.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.5.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.5.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/okio-3.4.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.5.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.5.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.5.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.5.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.4.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/607b67eeeca4e4f88ae7913fc898a9c22282f758 ; compiled by 'runner' on 2023-07-20T01:35Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=false, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=16KB, dfs.container.ratis.segment.size=1MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.retries=-1, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=9864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.file.size=100B, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=5GB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=64KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.ksm.address=ksm, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.GrpcOmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=10000, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.volume.name=s3v, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=5GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=3, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-07-20 02:18:22,777 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-07-20 02:18:22,877 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-07-20 02:18:23,614 [main] INFO reflections.Reflections: Reflections took 614 ms to scan 3 urls, producing 132 keys and 288 values 
2023-07-20 02:18:23,719 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2023-07-20 02:18:23,735 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-07-20 02:18:23,958 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2023-07-20 02:18:24,160 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-07-20 02:18:24,174 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2023-07-20 02:18:24,175 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-07-20 02:18:24,176 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2023-07-20 02:18:24,176 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2023-07-20 02:18:24,176 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2023-07-20 02:18:24,177 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2023-07-20 02:18:24,183 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-07-20 02:18:24,184 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-07-20 02:18:24,186 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-07-20 02:18:24,203 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-07-20 02:18:24,208 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-07-20 02:18:24,209 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-07-20 02:18:24,773 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2023-07-20 02:18:24,783 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2023-07-20 02:18:24,784 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2023-07-20 02:18:24,784 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2023-07-20 02:18:24,785 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-07-20 02:18:24,794 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-07-20 02:18:24,885 [main] INFO server.RaftServer: 2f6d078e-8fc6-4d4f-bc32-732c137cca90: addNew group-DBF347BDF9B2:[2f6d078e-8fc6-4d4f-bc32-732c137cca90|rpc:a550f9f52914:9894|priority:0|startupRole:FOLLOWER] returns group-DBF347BDF9B2:java.util.concurrent.CompletableFuture@a8a8b75[Not completed]
2023-07-20 02:18:25,085 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServer$Division: 2f6d078e-8fc6-4d4f-bc32-732c137cca90: new RaftServerImpl for group-DBF347BDF9B2:[2f6d078e-8fc6-4d4f-bc32-732c137cca90|rpc:a550f9f52914:9894|priority:0|startupRole:FOLLOWER] with SCMStateMachine:uninitialized
2023-07-20 02:18:25,098 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2023-07-20 02:18:25,099 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2023-07-20 02:18:25,099 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2023-07-20 02:18:25,101 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2023-07-20 02:18:25,101 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-07-20 02:18:25,101 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2023-07-20 02:18:25,118 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServer$Division: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2: ConfigurationManager, init=-1: peers:[2f6d078e-8fc6-4d4f-bc32-732c137cca90|rpc:a550f9f52914:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-07-20 02:18:25,121 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-07-20 02:18:25,134 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2023-07-20 02:18:25,136 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2023-07-20 02:18:25,198 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2023-07-20 02:18:25,210 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2023-07-20 02:18:25,217 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2023-07-20 02:18:25,218 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
2023-07-20 02:18:25,259 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2023-07-20 02:18:25,278 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2023-07-20 02:18:25,524 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-07-20 02:18:25,536 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-07-20 02:18:25,538 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2023-07-20 02:18:25,540 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2023-07-20 02:18:25,541 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2023-07-20 02:18:25,543 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2023-07-20 02:18:25,551 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/7ca7ccad-ae12-430e-9bea-dbf347bdf9b2 does not exist. Creating ...
2023-07-20 02:18:25,587 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/7ca7ccad-ae12-430e-9bea-dbf347bdf9b2/in_use.lock acquired by nodename 40@a550f9f52914
2023-07-20 02:18:25,654 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/7ca7ccad-ae12-430e-9bea-dbf347bdf9b2 has been successfully formatted.
2023-07-20 02:18:25,673 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2023-07-20 02:18:25,694 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2023-07-20 02:18:25,695 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-07-20 02:18:25,701 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-07-20 02:18:25,702 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2023-07-20 02:18:25,706 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-07-20 02:18:25,718 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2023-07-20 02:18:25,720 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-07-20 02:18:25,720 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-07-20 02:18:25,729 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/7ca7ccad-ae12-430e-9bea-dbf347bdf9b2
2023-07-20 02:18:25,730 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-07-20 02:18:25,731 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2023-07-20 02:18:25,734 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-07-20 02:18:25,737 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2023-07-20 02:18:25,738 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2023-07-20 02:18:25,739 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2023-07-20 02:18:25,740 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-07-20 02:18:25,741 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-07-20 02:18:25,777 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
2023-07-20 02:18:25,779 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-07-20 02:18:25,831 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2023-07-20 02:18:25,835 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2023-07-20 02:18:25,837 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2023-07-20 02:18:25,858 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-07-20 02:18:25,858 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-07-20 02:18:25,867 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServer$Division: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2: start as a follower, conf=-1: peers:[2f6d078e-8fc6-4d4f-bc32-732c137cca90|rpc:a550f9f52914:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-07-20 02:18:25,869 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServer$Division: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-07-20 02:18:25,872 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO impl.RoleInfo: 2f6d078e-8fc6-4d4f-bc32-732c137cca90: start 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-FollowerState
2023-07-20 02:18:25,874 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-07-20 02:18:25,874 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-07-20 02:18:25,888 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DBF347BDF9B2,id=2f6d078e-8fc6-4d4f-bc32-732c137cca90
2023-07-20 02:18:25,897 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-07-20 02:18:25,899 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2023-07-20 02:18:25,901 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2023-07-20 02:18:25,903 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2023-07-20 02:18:25,919 [main] INFO server.RaftServer: 2f6d078e-8fc6-4d4f-bc32-732c137cca90: start RPC server
2023-07-20 02:18:26,012 [main] INFO server.GrpcService: 2f6d078e-8fc6-4d4f-bc32-732c137cca90: GrpcService started, listening on 9894
2023-07-20 02:18:26,023 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-2f6d078e-8fc6-4d4f-bc32-732c137cca90: Started
2023-07-20 02:18:30,948 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-FollowerState] INFO impl.FollowerState: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5076331441ns, electionTimeout:5054ms
2023-07-20 02:18:30,958 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-FollowerState] INFO impl.RoleInfo: 2f6d078e-8fc6-4d4f-bc32-732c137cca90: shutdown 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-FollowerState
2023-07-20 02:18:30,964 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-FollowerState] INFO server.RaftServer$Division: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-07-20 02:18:30,983 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2023-07-20 02:18:30,983 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-FollowerState] INFO impl.RoleInfo: 2f6d078e-8fc6-4d4f-bc32-732c137cca90: start 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1
2023-07-20 02:18:30,991 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO impl.LeaderElection: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[2f6d078e-8fc6-4d4f-bc32-732c137cca90|rpc:a550f9f52914:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-07-20 02:18:30,998 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO impl.LeaderElection: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2023-07-20 02:18:31,011 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO impl.LeaderElection: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[2f6d078e-8fc6-4d4f-bc32-732c137cca90|rpc:a550f9f52914:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-07-20 02:18:31,011 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO impl.LeaderElection: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2023-07-20 02:18:31,012 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO impl.RoleInfo: 2f6d078e-8fc6-4d4f-bc32-732c137cca90: shutdown 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1
2023-07-20 02:18:31,014 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO server.RaftServer$Division: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-07-20 02:18:31,015 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO server.RaftServer$Division: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2: change Leader from null to 2f6d078e-8fc6-4d4f-bc32-732c137cca90 at term 1 for becomeLeader, leader elected after 5817ms
2023-07-20 02:18:31,034 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2023-07-20 02:18:31,039 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2023-07-20 02:18:31,040 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2023-07-20 02:18:31,048 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2023-07-20 02:18:31,049 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2023-07-20 02:18:31,051 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2023-07-20 02:18:31,102 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2023-07-20 02:18:31,117 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-07-20 02:18:31,129 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO impl.RoleInfo: 2f6d078e-8fc6-4d4f-bc32-732c137cca90: start 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderStateImpl
2023-07-20 02:18:31,184 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-SegmentedRaftLogWorker: Starting segment from index:0
2023-07-20 02:18:31,288 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderElection1] INFO server.RaftServer$Division: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2: set configuration 0: peers:[2f6d078e-8fc6-4d4f-bc32-732c137cca90|rpc:a550f9f52914:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-07-20 02:18:31,395 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/7ca7ccad-ae12-430e-9bea-dbf347bdf9b2/current/log_inprogress_0
2023-07-20 02:18:32,167 [main] INFO server.RaftServer: 2f6d078e-8fc6-4d4f-bc32-732c137cca90: close
2023-07-20 02:18:32,175 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServer$Division: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2: shutdown
2023-07-20 02:18:32,176 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DBF347BDF9B2,id=2f6d078e-8fc6-4d4f-bc32-732c137cca90
2023-07-20 02:18:32,177 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO impl.RoleInfo: 2f6d078e-8fc6-4d4f-bc32-732c137cca90: shutdown 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-LeaderStateImpl
2023-07-20 02:18:32,177 [main] INFO server.GrpcService: 2f6d078e-8fc6-4d4f-bc32-732c137cca90: shutdown server GrpcServerProtocolService now
2023-07-20 02:18:32,192 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO impl.PendingRequests: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-PendingRequests: sendNotLeaderResponses
2023-07-20 02:18:32,205 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO impl.StateMachineUpdater: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-StateMachineUpdater: set stopIndex = 0
2023-07-20 02:18:32,207 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-StateMachineUpdater] INFO impl.StateMachineUpdater: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-StateMachineUpdater: Took a snapshot at index 0
2023-07-20 02:18:32,208 [2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-StateMachineUpdater] INFO impl.StateMachineUpdater: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-07-20 02:18:32,210 [main] INFO server.GrpcService: 2f6d078e-8fc6-4d4f-bc32-732c137cca90: shutdown server GrpcServerProtocolService successfully
2023-07-20 02:18:32,226 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO server.RaftServer$Division: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2: closes. applyIndex: 0
2023-07-20 02:18:32,430 [2f6d078e-8fc6-4d4f-bc32-732c137cca90-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 2f6d078e-8fc6-4d4f-bc32-732c137cca90@group-DBF347BDF9B2-SegmentedRaftLogWorker close()
2023-07-20 02:18:32,447 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-2f6d078e-8fc6-4d4f-bc32-732c137cca90: Stopped
2023-07-20 02:18:32,451 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-07-20 02:18:32,484 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-7ca7ccad-ae12-430e-9bea-dbf347bdf9b2; layoutVersion=7; scmId=2f6d078e-8fc6-4d4f-bc32-732c137cca90
2023-07-20 02:18:32,604 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at a550f9f52914/172.20.0.2
************************************************************/
+ docker-compose exec -T scm /opt/hadoop/sbin/start-ozone.sh
Starting datanodes
a36c331557b0: Warning: Permanently added 'a36c331557b0,172.20.0.3' (ECDSA) to the list of known hosts.
a36c331557b0: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
a36c331557b0: WARNING: /opt/hadoop/logs does not exist. Creating.
Starting Ozone Manager nodes [om]
om: Warning: Permanently added 'om,172.20.0.4' (ECDSA) to the list of known hosts.
om: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
Starting storage container manager nodes [scm]
scm: Warning: Permanently added 'scm,172.20.0.2' (ECDSA) to the list of known hosts.
scm: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
+ sleep 10
+ docker-compose exec -T om /opt/hadoop/bin/ozone om --init
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-07-20 02:19:19,435 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting OzoneManager
STARTUP_MSG:   host = 7821e347e7c8/172.20.0.4
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.61.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.61.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.8.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.5.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.61.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.5.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.5.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.61.Final.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.5.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/joda-time-2.10.6.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/okio-3.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.5.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.5.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.61.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.61.Final.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.8.0.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.5.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.5.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.4.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.61.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.94.Final.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/607b67eeeca4e4f88ae7913fc898a9c22282f758 ; compiled by 'runner' on 2023-07-20T01:36Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=false, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=16KB, dfs.container.ratis.segment.size=1MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.retries=-1, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=9864, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.du.refresh.period=1h, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=5GB, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=64KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.ksm.address=ksm, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.client.rpc.timeout=15m, ozone.om.client.trash.core.pool.size=5, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.group.rights=ALL, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.port=8981, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.ha.raft.server.retrycache.expirytime=300s, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.init.default.layout.version=-1, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.GrpcOmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.finalization.ratis.based.timeout=30s, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.user.rights=ALL, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=10000, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.volume.name=s3v, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=5GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=3, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-07-20 02:19:19,451 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-07-20 02:19:25,137 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
2023-07-20 02:19:27,821 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2023-07-20 02:19:27,999 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.20.0.4:9862
2023-07-20 02:19:27,999 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2023-07-20 02:19:28,008 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
2023-07-20 02:19:28,154 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-07-20 02:19:28,967 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.20.0.2:9863]
OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-7ca7ccad-ae12-430e-9bea-dbf347bdf9b2;layoutVersion=6
2023-07-20 02:19:29,781 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down OzoneManager at 7821e347e7c8/172.20.0.4
************************************************************/
+ docker-compose exec -T scm /opt/hadoop/sbin/start-ozone.sh
Starting datanodes
a36c331557b0: Warning: Permanently added 'a36c331557b0,172.20.0.3' (ECDSA) to the list of known hosts.
a36c331557b0: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
a36c331557b0: datanode is running as process 95.  Stop it first.
Starting Ozone Manager nodes [om]
om: Warning: Permanently added 'om,172.20.0.4' (ECDSA) to the list of known hosts.
om: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
Starting storage container manager nodes [scm]
scm: Warning: Permanently added 'scm,172.20.0.2' (ECDSA) to the list of known hosts.
scm: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm: scm is running as process 709.  Stop it first.
    PID TTY      STAT   TIME COMMAND
      1 ?        Ss     0:00 /usr/local/bin/dumb-init -- entrypoint.sh sudo /usr/sbin/sshd -D
      7 ?        Ss     0:00 sudo /usr/sbin/sshd -D
     13 ?        S      0:00 /usr/sbin/sshd -D
     95 ?        Sl     0:27 /usr/lib/jvm/jre/bin/java -Dproc_datanode -Djava.net.preferIPv4Stack=true -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dlog4j.configurationFile=/etc/hadoop/dn-audit-log4j2.properties,/etc/hadoop/dn-container-log4j2.properties -Dorg.apache.ratis.thirdparty.io.netty.leakDetection.level=disabled -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=ozone-hadoop-datanode-a36c331557b0.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.ozone.HddsDatanodeService
    322 ?        Rs     0:00 ps xa
    PID TTY      STAT   TIME COMMAND
      1 ?        Ss     0:00 /usr/local/bin/dumb-init -- entrypoint.sh sudo /usr/sbin/sshd -D
      8 ?        Ss     0:00 sudo /usr/sbin/sshd -D
     14 ?        S      0:00 /usr/sbin/sshd -D
    325 ?        Sl     0:16 /usr/lib/jvm/jre/bin/java -Dproc_om -Djava.net.preferIPv4Stack=true -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dorg.apache.ratis.thirdparty.io.netty.leakDetection.level=disabled -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false -Dlog4j.configurationFile=/etc/hadoop/om-audit-log4j2.properties -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=ozone-hadoop-om-7821e347e7c8.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.ozone.om.OzoneManagerStarter
    408 ?        Rs     0:00 ps xa
    PID TTY      STAT   TIME COMMAND
      1 ?        Ss     0:00 /usr/local/bin/dumb-init -- entrypoint.sh sudo /usr/sbin/sshd -D
      8 ?        Ss     0:00 sudo /usr/sbin/sshd -D
     14 ?        S      0:00 /usr/sbin/sshd -D
    709 ?        Sl     0:37 /usr/lib/jvm/jre/bin/java -Dproc_scm -Djava.net.preferIPv4Stack=true -Dlog4j2.contextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector -Dorg.apache.ratis.thirdparty.io.netty.leakDetection.level=disabled -Dorg.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads=false -Dlog4j.configurationFile=/etc/hadoop/scm-audit-log4j2.properties -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=ozone-hadoop-scm-a550f9f52914.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter
   1689 ?        Rs     0:00 ps xa
==============================================================================
Single Node :: Smoketest for one datanode                                     
==============================================================================
Basic Freon smoketest for one datanode                                | PASS |
------------------------------------------------------------------------------
Single Node :: Smoketest for one datanode                             | PASS |
1 test, 1 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonescripts/result/robot-ozonescripts-ozonescripts-single_node-scm.xml
==============================================================================
Pipeline :: Test ozone admin pipeline command                                 
==============================================================================
Create pipeline                                                       | PASS |
------------------------------------------------------------------------------
List pipelines                                                        | PASS |
------------------------------------------------------------------------------
List pipelines with explicit host                                     | PASS |
------------------------------------------------------------------------------
Deactivate pipeline                                                   | PASS |
------------------------------------------------------------------------------
Activate pipeline                                                     | PASS |
------------------------------------------------------------------------------
Close pipeline                                                        | PASS |
------------------------------------------------------------------------------
Incomplete command                                                    | PASS |
------------------------------------------------------------------------------
Pipeline :: Test ozone admin pipeline command                         | PASS |
7 tests, 7 passed, 0 failed
==============================================================================
Output:  /tmp/smoketest/ozonescripts/result/robot-ozonescripts-ozonescripts-single_node-scm-1.xml
Stopping datanodes
a36c331557b0: Warning: Permanently added 'a36c331557b0,172.20.0.3' (ECDSA) to the list of known hosts.
a36c331557b0: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
Stopping Ozone Manager nodes [om]
om: Warning: Permanently added 'om,172.20.0.4' (ECDSA) to the list of known hosts.
om: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
Stopping storage container manager nodes [scm]
scm: Warning: Permanently added 'scm,172.20.0.2' (ECDSA) to the list of known hosts.
scm: No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
Stopping ozonescripts_datanode_1 ... 
Stopping ozonescripts_scm_1      ... 
Stopping ozonescripts_om_1       ... 
Stopping ozonescripts_datanode_1 ... done
Stopping ozonescripts_scm_1      ... done
Stopping ozonescripts_om_1       ... done
Removing ozonescripts_datanode_1 ... 
Removing ozonescripts_scm_1      ... 
Removing ozonescripts_om_1       ... 
Removing ozonescripts_om_1       ... done
Removing ozonescripts_datanode_1 ... done
Removing ozonescripts_scm_1      ... done
Removing network ozonescripts_default
Output:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonescripts.xml
removed 'ozonescripts/result/robot-ozonescripts-ozonescripts-single_node-scm-1.xml'
removed 'ozonescripts/result/robot-ozonescripts-ozonescripts-single_node-scm.xml'
renamed 'ozonescripts/result/docker-ozonescripts-ozonescripts-single_node-scm.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonescripts/docker-ozonescripts-ozonescripts-single_node-scm.log'
renamed 'ozonescripts/result/om-audit-7821e347e7c8.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/ozonescripts/om-audit-7821e347e7c8.log'
Executing test restart/test.sh
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data/dn1': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data/dn3': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data/recon': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data/dn2': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data/s3g': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data/om': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data/scm': Operation not permitted
chown: changing ownership of '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/restart/data': Operation not permitted
Removing network restart_net
Network restart_net not found.
Creating network "restart_net" with driver "bridge"
Creating restart_dn1_1 ... 
Creating restart_dn3_1 ... 
Creating restart_scm_1 ... 
Creating restart_om_1  ... 
Creating restart_dn2_1 ... 
Creating restart_recon_1 ... 
Creating restart_s3g_1   ... 
Creating restart_scm_1   ... done
Creating restart_om_1    ... done
Creating restart_s3g_1   ... done
Creating restart_recon_1 ... done
Creating restart_dn1_1   ... done
Creating restart_dn3_1   ... done
Creating restart_dn2_1   ... done
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Port 9860 is not available on scm yet
Timed out waiting on scm 9860 to become available
Stopping restart_s3g_1   ... 
Stopping restart_recon_1 ... 
Stopping restart_om_1    ... 
Stopping restart_dn2_1   ... 
Stopping restart_scm_1   ... 
Stopping restart_dn1_1   ... 
Stopping restart_dn3_1   ... 
Stopping restart_scm_1   ... done
Stopping restart_om_1    ... done
Stopping restart_dn2_1   ... done
Stopping restart_recon_1 ... done
Stopping restart_dn1_1   ... done
Stopping restart_s3g_1   ... done
Stopping restart_dn3_1   ... done
Removing restart_s3g_1   ... 
Removing restart_recon_1 ... 
Removing restart_om_1    ... 
Removing restart_dn2_1   ... 
Removing restart_scm_1   ... 
Removing restart_dn1_1   ... 
Removing restart_dn3_1   ... 
Removing restart_recon_1 ... done
Removing restart_dn1_1   ... done
Removing restart_dn2_1   ... done
Removing restart_s3g_1   ... done
Removing restart_scm_1   ... done
Removing restart_dn3_1   ... done
Removing restart_om_1    ... done
Removing network restart_net
ERROR: Test execution of restart/test.sh is FAILED!!!!
renamed 'restart/result/docker-restart.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/docker-restart.log'
renamed 'restart/result/om-audit-a47b70744e01.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/om-audit-a47b70744e01.log'
renamed 'restart/result/s3g-audit-f2bdf6027e72.log' -> '/home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/restart/s3g-audit-f2bdf6027e72.log'
Executing test upgrade/testlib.sh
find: upgrade/result: No such file or directory
mv: cannot stat 'upgrade/result/*': No such file or directory
Exception in thread "main" java.net.SocketException: Socket closed
	at java.base/java.net.PlainSocketImpl.socketAccept(Native Method)
	at java.base/java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:474)
	at java.base/java.net.ServerSocket.implAccept(ServerSocket.java:565)
	at java.base/java.net.ServerSocket.accept(ServerSocket.java:533)
	at org.apache.hadoop.test.JacocoServer.main(JacocoServer.java:60)
Log:     /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/log.html
Report:  /home/runner/work/ozone/ozone/hadoop-ozone/dist/target/ozone-1.4.0-SNAPSHOT/compose/result/report.html
