No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-07-24 15:57:42,845 [main] INFO recon.ReconServer: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ReconServer
STARTUP_MSG:   host = b5965815bd04/10.9.0.22
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.3.0
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.48.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.3.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.48.1.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.34.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.34.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-core-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.48.1.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.34.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.31.v20200723.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.48.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.48.1.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.3.0.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.34.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.34.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.48.1.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.3.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.53.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.53.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.34.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.48.1.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.34.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.34.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.34.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.2.20.RELEASE.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0.jar
STARTUP_MSG:   build = https://github.com/apache/ozone.git/d0d18a3bff64b90f5f0755edb6003301049ffb32 ; compiled by 'micahzhao' on 2022-12-10T13:24Z
STARTUP_MSG:   java = 11.0.14.1
************************************************************/
2023-07-24 15:57:42,966 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by com.google.inject.internal.cglib.core.$ReflectUtils$2 (file:/opt/hadoop/share/ozone/lib/guice-4.0.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)
WARNING: Please consider reporting this to the maintainers of com.google.inject.internal.cglib.core.$ReflectUtils$2
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2023-07-24 15:57:51,904 [main] INFO reflections.Reflections: Reflections took 886 ms to scan 1 urls, producing 16 keys and 49 values 
2023-07-24 15:58:01,250 [main] INFO recon.ReconServer: Initializing Recon server...
2023-07-24 15:58:05,168 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
2023-07-24 15:58:22,465 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
2023-07-24 15:58:26,936 [main] INFO impl.ReconContainerMetadataManagerImpl: KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
2023-07-24 15:58:26,958 [main] INFO impl.ReconContainerMetadataManagerImpl: It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
2023-07-24 15:58:27,089 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
2023-07-24 15:58:27,763 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
2023-07-24 15:58:27,851 [main] INFO recon.ReconServer: Creating Recon Schema.
2023-07-24 15:58:33,814 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
2023-07-24 15:58:41,008 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
2023-07-24 15:58:41,292 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-07-24 15:58:41,443 [main] INFO util.log: Logging initialized @74000ms to org.eclipse.jetty.util.log.Slf4jLog
2023-07-24 15:58:43,506 [main] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
2023-07-24 15:58:43,699 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
2023-07-24 15:58:43,809 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-07-24 15:58:43,824 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
2023-07-24 15:58:43,850 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-07-24 15:58:43,850 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-07-24 15:58:45,932 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
2023-07-24 15:58:46,981 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
2023-07-24 15:58:47,033 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
2023-07-24 15:58:47,078 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
2023-07-24 15:58:47,174 [main] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2023-07-24 15:58:47,178 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'omservice'.
2023-07-24 15:58:49,340 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-07-24 15:58:49,630 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-07-24 15:58:49,841 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0.jar!/network-topology-default.xml]
2023-07-24 15:58:49,849 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2023-07-24 15:58:50,021 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-07-24 15:58:50,506 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-07-24 15:58:50,842 [main] INFO reflections.Reflections: Reflections took 328 ms to scan 3 urls, producing 112 keys and 252 values 
2023-07-24 15:58:51,265 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2023-07-24 15:58:51,342 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2023-07-24 15:58:51,358 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
2023-07-24 15:58:51,418 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-07-24 15:58:51,603 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-07-24 15:58:51,628 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-07-24 15:58:51,777 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
2023-07-24 15:58:51,824 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2023-07-24 15:58:52,141 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
2023-07-24 15:58:52,141 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
2023-07-24 15:58:52,434 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2023-07-24 15:58:52,451 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-07-24 15:58:52,451 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
2023-07-24 15:58:53,702 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
2023-07-24 15:58:53,704 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
2023-07-24 15:58:53,904 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
2023-07-24 15:58:53,904 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
2023-07-24 15:58:53,906 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
2023-07-24 15:58:53,934 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1b37fbec{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2023-07-24 15:58:53,935 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@357f6391{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0.jar!/webapps/static,AVAILABLE}
2023-07-24 15:59:00,193 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@296949c8{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_3_0_jar-_-any-2931173358790318433/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.3.0.jar!/webapps/recon}
2023-07-24 15:59:00,235 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@1a1f79ce{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
2023-07-24 15:59:00,235 [Listener at 0.0.0.0/9891] INFO server.Server: Started @92792ms
2023-07-24 15:59:00,250 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
2023-07-24 15:59:00,251 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
2023-07-24 15:59:00,253 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
2023-07-24 15:59:00,254 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
2023-07-24 15:59:00,281 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
2023-07-24 15:59:00,297 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
2023-07-24 15:59:00,298 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
2023-07-24 15:59:00,302 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-07-24 15:59:00,303 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
2023-07-24 15:59:00,309 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
2023-07-24 15:59:03,252 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From b5965815bd04/10.9.0.22 to scm2:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=scm2,nodeAddress=scm2/10.9.0.15:9860 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
2023-07-24 15:59:05,254 [Listener at 0.0.0.0/9891] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From b5965815bd04/10.9.0.22 to scm3:9860 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy43.submitRequest over nodeId=scm3,nodeAddress=scm3/10.9.0.16:9860 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
2023-07-24 15:59:10,647 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 7 pipelines from SCM.
2023-07-24 15:59:10,648 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
2023-07-24 15:59:10,649 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=f6313e1a-f4ba-452b-a44d-3a80e24cbd89 from SCM.
2023-07-24 15:59:10,727 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: f6313e1a-f4ba-452b-a44d-3a80e24cbd89, Nodes: 379c119e-3463-4e3a-8678-bdff4eed2546{ip: 10.9.0.21, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-07-24T15:59:05.963Z[UTC]].
2023-07-24 15:59:10,764 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=ffa2234d-c711-4446-93f1-c5a602478cf1 from SCM.
2023-07-24 15:59:10,771 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ffa2234d-c711-4446-93f1-c5a602478cf1, Nodes: 170abe81-33bb-4ece-90da-d3bad37785df{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-07-24T15:59:05.354Z[UTC]].
2023-07-24 15:59:10,772 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=116e024d-06c3-4542-b680-af9c67835557 from SCM.
2023-07-24 15:59:10,788 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 116e024d-06c3-4542-b680-af9c67835557, Nodes: 56e4b329-a334-43cf-91db-05ef258a2a42{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-07-24T15:59:05.669Z[UTC]].
2023-07-24 15:59:10,789 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=d490e9b4-3864-4dbd-a35e-28e5c001140c from SCM.
2023-07-24 15:59:10,807 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d490e9b4-3864-4dbd-a35e-28e5c001140c, Nodes: b7d89b27-8166-464c-8d64-8ae702383e67{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}170abe81-33bb-4ece-90da-d3bad37785df{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}56e4b329-a334-43cf-91db-05ef258a2a42{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-07-24T15:59:05.704Z[UTC]].
2023-07-24 15:59:10,812 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=46245c91-c514-4eff-b13f-9979222a09ec from SCM.
2023-07-24 15:59:10,815 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 46245c91-c514-4eff-b13f-9979222a09ec, Nodes: b7d89b27-8166-464c-8d64-8ae702383e67{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-07-24T15:59:04.720Z[UTC]].
2023-07-24 15:59:10,834 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=b18be1c9-c6e8-4fc0-9918-a81e9da8047a from SCM.
2023-07-24 15:59:10,837 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b18be1c9-c6e8-4fc0-9918-a81e9da8047a, Nodes: b7d89b27-8166-464c-8d64-8ae702383e67{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}56e4b329-a334-43cf-91db-05ef258a2a42{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}170abe81-33bb-4ece-90da-d3bad37785df{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-07-24T15:59:05.740Z[UTC]].
2023-07-24 15:59:10,842 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=c25380df-d883-4e44-96b1-4c2408e44174 from SCM.
2023-07-24 15:59:10,851 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: c25380df-d883-4e44-96b1-4c2408e44174, Nodes: 047357e0-5b48-47e3-931f-dd3e3c91a5b5{ip: 10.9.0.20, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-07-24T15:59:06.268Z[UTC]].
2023-07-24 15:59:10,856 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: SCM DB initialized
2023-07-24 15:59:10,867 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
2023-07-24 15:59:10,869 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-07-24 15:59:11,145 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
2023-07-24 15:59:11,645 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
2023-07-24 15:59:11,645 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
2023-07-24 15:59:11,703 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
2023-07-24 15:59:11,703 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
2023-07-24 15:59:11,881 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 7 pipelines in house.
2023-07-24 15:59:11,949 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 241 milliseconds.
2023-07-24 15:59:13,704 [IPC Server handler 9 on default port 9891] WARN ipc.Server: IPC Server handler 9 on default port 9891, call Call#4 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.19:52688: output error
2023-07-24 15:59:13,748 [IPC Server handler 0 on default port 9891] WARN ipc.Server: IPC Server handler 0 on default port 9891, call Call#3 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.17:46196: output error
2023-07-24 15:59:13,750 [IPC Server handler 5 on default port 9891] WARN ipc.Server: IPC Server handler 5 on default port 9891, call Call#4 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.21:51162: output error
2023-07-24 15:59:13,751 [IPC Server handler 13 on default port 9891] WARN ipc.Server: IPC Server handler 13 on default port 9891, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.19:59974: output error
2023-07-24 15:59:13,746 [IPC Server handler 11 on default port 9891] WARN ipc.Server: IPC Server handler 11 on default port 9891, call Call#4 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.20:36304: output error
2023-07-24 15:59:13,731 [IPC Server handler 8 on default port 9891] WARN ipc.Server: IPC Server handler 8 on default port 9891, call Call#4 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.18:60466: output error
2023-07-24 15:59:13,730 [IPC Server handler 7 on default port 9891] WARN ipc.Server: IPC Server handler 7 on default port 9891, call Call#3 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.20:38316: output error
2023-07-24 15:59:13,730 [IPC Server handler 6 on default port 9891] WARN ipc.Server: IPC Server handler 6 on default port 9891, call Call#10 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.20:42778: output error
2023-07-24 15:59:13,730 [IPC Server handler 10 on default port 9891] WARN ipc.Server: IPC Server handler 10 on default port 9891, call Call#4 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.17:38398: output error
2023-07-24 15:59:13,730 [IPC Server handler 14 on default port 9891] WARN ipc.Server: IPC Server handler 14 on default port 9891, call Call#2 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.21:57816: output error
2023-07-24 15:59:13,730 [IPC Server handler 16 on default port 9891] WARN ipc.Server: IPC Server handler 16 on default port 9891, call Call#8 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.21:51174: output error
2023-07-24 15:59:13,730 [IPC Server handler 24 on default port 9891] WARN ipc.Server: IPC Server handler 24 on default port 9891, call Call#8 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.19:52690: output error
2023-07-24 15:59:13,730 [IPC Server handler 17 on default port 9891] WARN ipc.Server: IPC Server handler 17 on default port 9891, call Call#10 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.17:50068: output error
2023-07-24 15:59:13,730 [IPC Server handler 18 on default port 9891] WARN ipc.Server: IPC Server handler 18 on default port 9891, call Call#11 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.18:59440: output error
2023-07-24 15:59:13,720 [IPC Server handler 12 on default port 9891] WARN ipc.Server: IPC Server handler 12 on default port 9891, call Call#6 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.20:36318: output error
2023-07-24 15:59:13,720 [IPC Server handler 19 on default port 9891] WARN ipc.Server: IPC Server handler 19 on default port 9891, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.18:59730: output error
2023-07-24 15:59:13,720 [IPC Server handler 20 on default port 9891] WARN ipc.Server: IPC Server handler 20 on default port 9891, call Call#8 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.17:38410: output error
2023-07-24 15:59:13,720 [IPC Server handler 21 on default port 9891] WARN ipc.Server: IPC Server handler 21 on default port 9891, call Call#11 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.19:52094: output error
2023-07-24 15:59:13,720 [IPC Server handler 22 on default port 9891] WARN ipc.Server: IPC Server handler 22 on default port 9891, call Call#8 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.18:60482: output error
2023-07-24 15:59:13,704 [IPC Server handler 23 on default port 9891] WARN ipc.Server: IPC Server handler 23 on default port 9891, call Call#10 Retry#0 org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol.submitRequest from 10.9.0.21:35312: output error
2023-07-24 15:59:13,822 [IPC Server handler 18 on default port 9891] INFO ipc.Server: IPC Server handler 18 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,834 [IPC Server handler 12 on default port 9891] INFO ipc.Server: IPC Server handler 12 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,834 [IPC Server handler 19 on default port 9891] INFO ipc.Server: IPC Server handler 19 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,834 [IPC Server handler 20 on default port 9891] INFO ipc.Server: IPC Server handler 20 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,831 [IPC Server handler 0 on default port 9891] INFO ipc.Server: IPC Server handler 0 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,833 [IPC Server handler 21 on default port 9891] INFO ipc.Server: IPC Server handler 21 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,833 [IPC Server handler 22 on default port 9891] INFO ipc.Server: IPC Server handler 22 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,853 [IPC Server handler 8 on default port 9891] INFO ipc.Server: IPC Server handler 8 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,856 [IPC Server handler 13 on default port 9891] INFO ipc.Server: IPC Server handler 13 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,833 [IPC Server handler 23 on default port 9891] INFO ipc.Server: IPC Server handler 23 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,866 [IPC Server handler 5 on default port 9891] INFO ipc.Server: IPC Server handler 5 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,856 [IPC Server handler 11 on default port 9891] INFO ipc.Server: IPC Server handler 11 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,845 [IPC Server handler 7 on default port 9891] INFO ipc.Server: IPC Server handler 7 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,845 [IPC Server handler 6 on default port 9891] INFO ipc.Server: IPC Server handler 6 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,845 [IPC Server handler 10 on default port 9891] INFO ipc.Server: IPC Server handler 10 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,845 [IPC Server handler 14 on default port 9891] INFO ipc.Server: IPC Server handler 14 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,845 [IPC Server handler 16 on default port 9891] INFO ipc.Server: IPC Server handler 16 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,845 [IPC Server handler 24 on default port 9891] INFO ipc.Server: IPC Server handler 24 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,845 [IPC Server handler 17 on default port 9891] INFO ipc.Server: IPC Server handler 17 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:13,893 [IPC Server handler 9 on default port 9891] INFO ipc.Server: IPC Server handler 9 on default port 9891 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2023-07-24 15:59:36,568 [IPC Server handler 62 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/b7d89b27-8166-464c-8d64-8ae702383e67
2023-07-24 15:59:36,580 [IPC Server handler 62 on default port 9891] INFO node.SCMNodeManager: Registered Data node : b7d89b27-8166-464c-8d64-8ae702383e67{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 15:59:36,609 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node b7d89b27-8166-464c-8d64-8ae702383e67 to Node DB.
2023-07-24 15:59:37,187 [IPC Server handler 26 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/170abe81-33bb-4ece-90da-d3bad37785df
2023-07-24 15:59:37,188 [IPC Server handler 26 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 170abe81-33bb-4ece-90da-d3bad37785df{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 15:59:37,189 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 170abe81-33bb-4ece-90da-d3bad37785df to Node DB.
2023-07-24 15:59:37,526 [IPC Server handler 68 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/56e4b329-a334-43cf-91db-05ef258a2a42
2023-07-24 15:59:37,527 [IPC Server handler 68 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 56e4b329-a334-43cf-91db-05ef258a2a42{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 15:59:37,528 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 56e4b329-a334-43cf-91db-05ef258a2a42 to Node DB.
2023-07-24 15:59:37,956 [IPC Server handler 3 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/379c119e-3463-4e3a-8678-bdff4eed2546
2023-07-24 15:59:37,956 [IPC Server handler 3 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 379c119e-3463-4e3a-8678-bdff4eed2546{ip: 10.9.0.21, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 15:59:37,957 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 379c119e-3463-4e3a-8678-bdff4eed2546 to Node DB.
2023-07-24 15:59:38,176 [IPC Server handler 26 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/047357e0-5b48-47e3-931f-dd3e3c91a5b5
2023-07-24 15:59:38,177 [IPC Server handler 26 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 047357e0-5b48-47e3-931f-dd3e3c91a5b5{ip: 10.9.0.20, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 15:59:38,177 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 047357e0-5b48-47e3-931f-dd3e3c91a5b5 to Node DB.
2023-07-24 16:00:00,307 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
2023-07-24 16:00:00,307 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
2023-07-24 16:00:03,244 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1690214400307
2023-07-24 16:00:03,261 [pool-27-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
2023-07-24 16:00:03,263 [pool-27-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
2023-07-24 16:00:03,395 [pool-27-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1690214400307.
2023-07-24 16:00:03,448 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
2023-07-24 16:00:03,481 [pool-49-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a reprocess run of NSSummaryTaskWithFSO
2023-07-24 16:00:03,490 [pool-49-thread-2] INFO tasks.NSSummaryTaskWithLegacy: Completed a reprocess run of NSSummaryTaskWithLegacy
2023-07-24 16:00:04,166 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'reprocess' run of TableCountTask.
2023-07-24 16:00:04,167 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
2023-07-24 16:00:04,168 [pool-28-thread-1] INFO impl.ReconContainerMetadataManagerImpl: KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
2023-07-24 16:00:04,168 [pool-28-thread-1] INFO impl.ReconContainerMetadataManagerImpl: It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
2023-07-24 16:00:04,210 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
2023-07-24 16:00:04,210 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.042 seconds to process 0 keys.
2023-07-24 16:00:04,242 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Deleted 0 records from "FILE_COUNT_BY_SIZE"
2023-07-24 16:00:04,243 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
2023-07-24 16:00:06,593 [IPC Server handler 72 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ha_dn3_1.ha_net
2023-07-24 16:00:07,189 [IPC Server handler 26 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ha_dn2_1.ha_net
2023-07-24 16:00:07,559 [IPC Server handler 64 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ha_dn1_1.ha_net
2023-07-24 16:00:07,809 [IPC Server handler 18 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn3_1.ha_net
2023-07-24 16:00:07,813 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=46245c91-c514-4eff-b13f-9979222a09ec reported by b7d89b27-8166-464c-8d64-8ae702383e67{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:07,814 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 46245c91-c514-4eff-b13f-9979222a09ec, Nodes: b7d89b27-8166-464c-8d64-8ae702383e67{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:b7d89b27-8166-464c-8d64-8ae702383e67, CreationTimestamp2023-07-24T15:59:04.720Z[UTC]] moved to OPEN state
2023-07-24 16:00:07,978 [IPC Server handler 4 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ha_dn5_1.ha_net
2023-07-24 16:00:08,275 [IPC Server handler 32 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ha_dn4_1.ha_net
2023-07-24 16:00:08,495 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d490e9b4-3864-4dbd-a35e-28e5c001140c reported by b7d89b27-8166-464c-8d64-8ae702383e67{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:09,020 [IPC Server handler 26 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn2_1.ha_net
2023-07-24 16:00:09,024 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=ffa2234d-c711-4446-93f1-c5a602478cf1 reported by 170abe81-33bb-4ece-90da-d3bad37785df{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:09,027 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ffa2234d-c711-4446-93f1-c5a602478cf1, Nodes: 170abe81-33bb-4ece-90da-d3bad37785df{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:170abe81-33bb-4ece-90da-d3bad37785df, CreationTimestamp2023-07-24T15:59:05.354Z[UTC]] moved to OPEN state
2023-07-24 16:00:09,561 [IPC Server handler 64 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn1_1.ha_net
2023-07-24 16:00:09,563 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=116e024d-06c3-4542-b680-af9c67835557 reported by 56e4b329-a334-43cf-91db-05ef258a2a42{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:09,578 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 116e024d-06c3-4542-b680-af9c67835557, Nodes: 56e4b329-a334-43cf-91db-05ef258a2a42{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:56e4b329-a334-43cf-91db-05ef258a2a42, CreationTimestamp2023-07-24T15:59:05.669Z[UTC]] moved to OPEN state
2023-07-24 16:00:09,812 [IPC Server handler 18 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn5_1.ha_net
2023-07-24 16:00:09,813 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=f6313e1a-f4ba-452b-a44d-3a80e24cbd89 reported by 379c119e-3463-4e3a-8678-bdff4eed2546{ip: 10.9.0.21, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:09,814 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: f6313e1a-f4ba-452b-a44d-3a80e24cbd89, Nodes: 379c119e-3463-4e3a-8678-bdff4eed2546{ip: 10.9.0.21, host: ha_dn5_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:379c119e-3463-4e3a-8678-bdff4eed2546, CreationTimestamp2023-07-24T15:59:05.963Z[UTC]] moved to OPEN state
2023-07-24 16:00:09,979 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d490e9b4-3864-4dbd-a35e-28e5c001140c reported by 170abe81-33bb-4ece-90da-d3bad37785df{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:10,420 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d490e9b4-3864-4dbd-a35e-28e5c001140c reported by 56e4b329-a334-43cf-91db-05ef258a2a42{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:10,729 [IPC Server handler 99 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ha_dn4_1.ha_net
2023-07-24 16:00:10,734 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=c25380df-d883-4e44-96b1-4c2408e44174 reported by 047357e0-5b48-47e3-931f-dd3e3c91a5b5{ip: 10.9.0.20, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:10,734 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: c25380df-d883-4e44-96b1-4c2408e44174, Nodes: 047357e0-5b48-47e3-931f-dd3e3c91a5b5{ip: 10.9.0.20, host: ha_dn4_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:047357e0-5b48-47e3-931f-dd3e3c91a5b5, CreationTimestamp2023-07-24T15:59:06.268Z[UTC]] moved to OPEN state
2023-07-24 16:00:13,117 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d490e9b4-3864-4dbd-a35e-28e5c001140c reported by 56e4b329-a334-43cf-91db-05ef258a2a42{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:13,118 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=b18be1c9-c6e8-4fc0-9918-a81e9da8047a reported by 56e4b329-a334-43cf-91db-05ef258a2a42{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:13,139 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d490e9b4-3864-4dbd-a35e-28e5c001140c reported by 170abe81-33bb-4ece-90da-d3bad37785df{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:13,139 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=b18be1c9-c6e8-4fc0-9918-a81e9da8047a reported by 170abe81-33bb-4ece-90da-d3bad37785df{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:13,200 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d490e9b4-3864-4dbd-a35e-28e5c001140c reported by b7d89b27-8166-464c-8d64-8ae702383e67{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:13,201 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=b18be1c9-c6e8-4fc0-9918-a81e9da8047a reported by b7d89b27-8166-464c-8d64-8ae702383e67{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:13,386 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d490e9b4-3864-4dbd-a35e-28e5c001140c reported by b7d89b27-8166-464c-8d64-8ae702383e67{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:13,387 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=b18be1c9-c6e8-4fc0-9918-a81e9da8047a reported by b7d89b27-8166-464c-8d64-8ae702383e67{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:14,737 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d490e9b4-3864-4dbd-a35e-28e5c001140c reported by 170abe81-33bb-4ece-90da-d3bad37785df{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:14,744 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=b18be1c9-c6e8-4fc0-9918-a81e9da8047a reported by 170abe81-33bb-4ece-90da-d3bad37785df{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:15,160 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d490e9b4-3864-4dbd-a35e-28e5c001140c reported by 56e4b329-a334-43cf-91db-05ef258a2a42{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:15,160 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=b18be1c9-c6e8-4fc0-9918-a81e9da8047a reported by 56e4b329-a334-43cf-91db-05ef258a2a42{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:23,459 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d490e9b4-3864-4dbd-a35e-28e5c001140c reported by b7d89b27-8166-464c-8d64-8ae702383e67{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:23,459 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=b18be1c9-c6e8-4fc0-9918-a81e9da8047a reported by b7d89b27-8166-464c-8d64-8ae702383e67{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:00:23,460 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b18be1c9-c6e8-4fc0-9918-a81e9da8047a, Nodes: b7d89b27-8166-464c-8d64-8ae702383e67{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}56e4b329-a334-43cf-91db-05ef258a2a42{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}170abe81-33bb-4ece-90da-d3bad37785df{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:b7d89b27-8166-464c-8d64-8ae702383e67, CreationTimestamp2023-07-24T15:59:05.740Z[UTC]] moved to OPEN state
2023-07-24 16:00:45,205 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d490e9b4-3864-4dbd-a35e-28e5c001140c reported by 56e4b329-a334-43cf-91db-05ef258a2a42{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:01:02,514 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
2023-07-24 16:01:04,279 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
2023-07-24 16:01:04,282 [pool-27-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
2023-07-24 16:01:04,282 [pool-27-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
2023-07-24 16:01:04,283 [pool-27-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
2023-07-24 16:01:04,283 [pool-27-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
2023-07-24 16:01:04,283 [pool-27-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
2023-07-24 16:01:04,283 [pool-27-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
2023-07-24 16:01:04,284 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
2023-07-24 16:01:04,284 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 2 
2023-07-24 16:01:04,322 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 3, SequenceNumber diff: 7, SequenceNumber Lag from OM 0.
2023-07-24 16:01:04,322 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 7 records
2023-07-24 16:01:04,331 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
2023-07-24 16:01:04,333 [pool-28-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
2023-07-24 16:01:04,626 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
2023-07-24 16:01:04,626 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
2023-07-24 16:01:04,626 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
2023-07-24 16:01:09,046 [FixedThreadPoolWithAffinityExecutor-9-0] INFO scm.ReconContainerManager: New container #1 got from ha_dn2_1.ha_net.
2023-07-24 16:01:09,199 [FixedThreadPoolWithAffinityExecutor-9-0] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
2023-07-24 16:01:36,049 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=d490e9b4-3864-4dbd-a35e-28e5c001140c reported by 170abe81-33bb-4ece-90da-d3bad37785df{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-07-24 16:01:36,049 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: d490e9b4-3864-4dbd-a35e-28e5c001140c, Nodes: b7d89b27-8166-464c-8d64-8ae702383e67{ip: 10.9.0.19, host: ha_dn3_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}170abe81-33bb-4ece-90da-d3bad37785df{ip: 10.9.0.18, host: ha_dn2_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}56e4b329-a334-43cf-91db-05ef258a2a42{ip: 10.9.0.17, host: ha_dn1_1.ha_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:170abe81-33bb-4ece-90da-d3bad37785df, CreationTimestamp2023-07-24T15:59:05.704Z[UTC]] moved to OPEN state
2023-07-24 16:02:04,652 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
2023-07-24 16:02:04,652 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
2023-07-24 16:02:04,653 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 9 
2023-07-24 16:02:04,665 [pool-27-thread-1] WARN impl.OzoneManagerServiceProviderImpl: Unable to get and apply delta updates from OM.
INTERNAL_ERROR org.apache.hadoop.ozone.om.exceptions.OMException: Invalid transaction log iterator when getting updates since sequence number 9
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.handleError(OzoneManagerProtocolClientSideTranslatorPB.java:701)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getDBUpdates(OzoneManagerProtocolClientSideTranslatorPB.java:1822)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.innerGetAndApplyDeltaUpdatesFromOM(OzoneManagerServiceProviderImpl.java:409)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getAndApplyDeltaUpdatesFromOM(OzoneManagerServiceProviderImpl.java:381)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:458)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$start$0(OzoneManagerServiceProviderImpl.java:248)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
2023-07-24 16:02:04,666 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
2023-07-24 16:02:04,765 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1690214524666
2023-07-24 16:02:04,765 [pool-27-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Cleaning up old OM snapshot db at /data/metadata/om.snapshot.db_1690214400307.
2023-07-24 16:02:04,780 [pool-27-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
2023-07-24 16:02:04,780 [pool-27-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
2023-07-24 16:02:04,853 [pool-27-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1690214524666.
2023-07-24 16:02:04,895 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
2023-07-24 16:02:04,900 [pool-73-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a reprocess run of NSSummaryTaskWithFSO
2023-07-24 16:02:04,937 [pool-73-thread-2] INFO tasks.NSSummaryTaskWithLegacy: Completed a reprocess run of NSSummaryTaskWithLegacy
2023-07-24 16:02:05,425 [pool-28-thread-1] INFO tasks.TableCountTask: Completed a 'reprocess' run of TableCountTask.
2023-07-24 16:02:05,425 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
2023-07-24 16:02:05,426 [pool-28-thread-1] INFO impl.ReconContainerMetadataManagerImpl: KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
2023-07-24 16:02:05,426 [pool-28-thread-1] INFO impl.ReconContainerMetadataManagerImpl: It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
2023-07-24 16:02:05,482 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
2023-07-24 16:02:05,482 [pool-28-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.056 seconds to process 3 keys.
2023-07-24 16:02:05,484 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Deleted 0 records from "FILE_COUNT_BY_SIZE"
2023-07-24 16:02:05,511 [pool-28-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
2023-07-24 16:03:05,523 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
2023-07-24 16:03:05,524 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
2023-07-24 16:03:05,524 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 35 
2023-07-24 16:03:05,541 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0.
2023-07-24 16:03:05,541 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 0 records
2023-07-24 16:04:05,546 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
2023-07-24 16:04:05,547 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
2023-07-24 16:04:05,547 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 35 
2023-07-24 16:04:05,557 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0.
2023-07-24 16:04:05,557 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 0 records
2023-07-24 16:04:11,707 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 32 milliseconds to process 0 existing database records.
2023-07-24 16:04:11,716 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 9 milliseconds for processing 1 containers.
2023-07-24 16:04:12,724 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 7 pipelines in house.
2023-07-24 16:04:12,731 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 15 milliseconds.
2023-07-24 16:04:22,488 [Finalizer] WARN managed.ManagedRocksObjectUtils: RocksIterator is not closed properly
2023-07-24 16:05:05,562 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
2023-07-24 16:05:05,562 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
2023-07-24 16:05:05,562 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 35 
2023-07-24 16:05:05,575 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0.
2023-07-24 16:05:05,575 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 0 records
2023-07-24 16:06:05,581 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
2023-07-24 16:06:05,581 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
2023-07-24 16:06:05,581 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 35 
2023-07-24 16:06:05,589 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0.
2023-07-24 16:06:05,589 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 0 records
2023-07-24 16:07:05,592 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
2023-07-24 16:07:05,592 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
2023-07-24 16:07:05,592 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 35 
2023-07-24 16:07:05,602 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0.
2023-07-24 16:07:05,603 [pool-27-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 0 records
