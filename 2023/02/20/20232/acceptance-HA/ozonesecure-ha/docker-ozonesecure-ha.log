Attaching to ozonesecure-ha_s3g_1, ozonesecure-ha_recon_1, ozonesecure-ha_scm1.org_1, ozonesecure-ha_datanode3_1, ozonesecure-ha_scm2.org_1, ozonesecure-ha_kms_1, ozonesecure-ha_om3_1, ozonesecure-ha_scm3.org_1, ozonesecure-ha_om1_1, ozonesecure-ha_datanode2_1, ozonesecure-ha_datanode1_1, ozonesecure-ha_kdc_1, ozonesecure-ha_om2_1
datanode1_1  | Sleeping for 5 seconds
datanode1_1  | Waiting for the service scm3.org:9894
datanode1_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode1_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode1_1  | 2023-02-20 12:33:41,677 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode1_1  | /************************************************************
datanode1_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode1_1  | STARTUP_MSG:   host = 6b48ece71e49/172.25.0.102
datanode1_1  | STARTUP_MSG:   args = []
datanode1_1  | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
datanode1_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.4.0-SNAPSHOT.jar
datanode1_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
datanode1_1  | STARTUP_MSG:   java = 11.0.14.1
datanode1_1  | ************************************************************/
datanode1_1  | 2023-02-20 12:33:41,855 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode1_1  | 2023-02-20 12:33:42,780 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode1_1  | 2023-02-20 12:33:43,793 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode1_1  | 2023-02-20 12:33:45,361 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode1_1  | 2023-02-20 12:33:45,361 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode1_1  | 2023-02-20 12:33:46,935 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:6b48ece71e49 ip:172.25.0.102
datanode1_1  | 2023-02-20 12:33:54,185 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode1_1  | 2023-02-20 12:33:55,893 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode1_1  | 2023-02-20 12:33:55,901 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode1_1  | 2023-02-20 12:34:00,143 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode1_1  | 2023-02-20 12:34:00,162 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode1_1  | 2023-02-20 12:34:00,172 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode1_1  | 2023-02-20 12:34:00,198 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode1_1  | 2023-02-20 12:34:11,933 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode1_1  | 2023-02-20 12:34:12,350 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.102,host:6b48ece71e49
datanode1_1  | 2023-02-20 12:34:12,358 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode1_1  | 2023-02-20 12:34:12,404 [main] ERROR client.DNCertificateClient: Invalid domain 6b48ece71e49
datanode1_1  | 2023-02-20 12:34:12,414 [main] INFO client.DNCertificateClient: Created csr for DN-> subject:dn@6b48ece71e49
datanode1_1  | 2023-02-20 12:34:21,955 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode1_1  | 2023-02-20 12:34:22,142 [main] INFO client.DNCertificateClient: Added certificate   [0]         Version: 3
datanode1_1  |          SerialNumber: 1
datanode1_1  |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode1_1  |            Start Date: Mon Feb 20 00:00:00 UTC 2023
datanode1_1  |            Final Date: Thu Mar 30 00:00:00 UTC 2028
datanode1_1  |             SubjectDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode1_1  |            Public Key: RSA Public Key [94:7e:a6:1e:66:03:60:cb:31:b6:ba:58:09:e5:6f:61:c6:1f:10:56],[56:66:d1:a4]
datanode1_1  |         modulus: ae4c68b294de9bde416e48f8dd880f73587515c06076bc726de72d7d0efa633c8ab0845ecaa9dfe2be73479c31abedba80a9108027262a3316511997768cdb340fdcb173084f830287356e335877580b2bd5bdc297d7572a3635e6a114294f82bfb68aec57278d80b2e053741f6bd8e43df4c302f807657c2cd83c55edafc9fedddc555b306c6720e2e72e1a403ac6fa6a0b45823767e96cbe34c0ee95838730daf28e939192b29222957ccd58032a49c0446c773bb8ccc080bc6d017e13b3470c1f732b571f7ae50833d9852f4af92799f9b8c5eaec9c998c13768e6e1efd686c4d209f1d79c8d4f12aa2f5821e96eff58d7f8e4bf5877811957c77adb800e7
datanode1_1  | public exponent: 10001
datanode1_1  | 
datanode1_1  |   Signature Algorithm: SHA256WITHRSA
datanode1_1  |             Signature: a7cea6946dc4cec2c98cb07c07498d5444b6300d
datanode1_1  |                        0a6c4e9490adf7093c90271931b5d0417975d9b8
datanode1_1  |                        7a9238465c6f3f4de8400309865e2da81ad21b31
datanode1_1  |                        57de65cb86c13fbef66ec87c8614bd8ad650e11d
datanode1_1  |                        4e49b0e20080ff8a0c3d6a6e6cef0122f38fbedc
datanode1_1  |                        9428a9b69ae6258d8ff4035af00ec4326a833057
datanode1_1  |                        736e2bec20eba55b3e39bd1818d036b10a473b2e
datanode1_1  |                        99f5e8079f4fcaa7750269bdb7680ebf53d8f7bb
datanode1_1  |                        16ddc0ef7ac8c2bd9f938901391f3d9e4f3823e1
datanode1_1  |                        07939f9a9f829615d2d1f339e2f210e795258ac1
datanode1_1  |                        f03a273f30f7cb3110f6d700ded1888ed1dcaa17
datanode1_1  |                        ff9774e9f4d33a5be09b76c57503b7a066668066
datanode1_1  |                        4c46b6c92c5c84d4978c557861c07dba
datanode1_1  |        Extensions: 
datanode1_1  |                        critical(true) BasicConstraints: isCa(true)
datanode1_1  |                        critical(true) KeyUsage: 0x6
datanode1_1  |                        critical(false) 2.5.29.17 value = Sequence
datanode1_1  |     Tagged [7] IMPLICIT 
datanode1_1  |         DER Octet String[4] 
datanode1_1  |     Tagged [2] IMPLICIT 
datanode1_1  |         DER Octet String[8] 
datanode1_1  | 
datanode1_1  |  from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode1_1  | 2023-02-20 12:34:22,194 [main] INFO client.DNCertificateClient: Added certificate   [0]         Version: 3
datanode1_1  |          SerialNumber: 1628842543028
datanode1_1  |              IssuerDN: CN=scm-sub@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode1_1  |            Start Date: Mon Feb 20 00:00:00 UTC 2023
datanode1_1  |            Final Date: Tue Feb 20 00:00:00 UTC 2024
datanode1_1  |             SubjectDN: CN=dn@6b48ece71e49,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode1_1  |            Public Key: RSA Public Key [1a:a5:7f:f7:57:8e:7c:6d:a8:d4:b1:e6:27:40:6b:e6:61:2a:ef:45],[56:66:d1:a4]
datanode1_1  |         modulus: af3ae7f814e7fdfdc84484230e7e2936a558f66824a331a5721eaf7260a9d7c28e609ee6f1f6ec630bf13760ff6f8b0088ab6dacef3a982a66d3b14ca153ccb1425e73bdafd08b5a8676598dbbf688f91e1fc3e16c33e52a3e182eed0ac24e2f1478a95c9f7f6cdff115f461ddb1c375c580cf7eda745a66cb01c235205162bd43a9b0bf74420c4f48c4f914508ff609c627d1cc3f0a92c4088a5709e4b6393f5e1700dbbcf63223ad3374e904babe5e4306d27a32d66539af545c2a5ef394c7f9b8d3267fa852e63e67b35fe5321ff77f5a269fc342870c50d9d61b456dc017c424bd3123bcc053219bd2f5c778fc7f5050fe3700d400d1a59472d609aab403
datanode1_1  | public exponent: 10001
datanode1_1  | 
datanode1_1  |   Signature Algorithm: SHA256WITHRSA
datanode1_1  |             Signature: 0aa59f03a4d6ecadb27b905b9139d6a3b0e27d5a
datanode1_1  |                        7ff292f00ba4b1b03192f4610b5a4c8e1b055fc7
datanode1_1  |                        70b8e3831d992a928d40d1ecac15f9f0cf6bb948
datanode1_1  |                        f08655dfd5a33a9c3cb5722a04e2d820e583aa8e
datanode1_1  |                        15ecfc7ad312b72869712c7ceea825f74702a1c4
datanode1_1  |                        7b1c2a84aadfbe238a3ca16ce26ecdce5c212739
datanode1_1  |                        a7a1e2f33a33d81482d42b4e958025fb52a01a31
datanode1_1  |                        eb5f4cc22edbc122e33d761767a7c2aa762c19c4
datanode2_1  | Sleeping for 5 seconds
datanode2_1  | Waiting for the service scm3.org:9894
datanode2_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode2_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode2_1  | 2023-02-20 12:33:41,514 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode2_1  | /************************************************************
datanode2_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode2_1  | STARTUP_MSG:   host = 2a396b20692f/172.25.0.103
datanode2_1  | STARTUP_MSG:   args = []
datanode2_1  | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
datanode2_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.4.0-SNAPSHOT.jar
datanode2_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
datanode2_1  | STARTUP_MSG:   java = 11.0.14.1
datanode2_1  | ************************************************************/
datanode2_1  | 2023-02-20 12:33:41,657 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode2_1  | 2023-02-20 12:33:42,519 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode2_1  | 2023-02-20 12:33:43,830 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode2_1  | 2023-02-20 12:33:45,645 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode2_1  | 2023-02-20 12:33:45,646 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode2_1  | 2023-02-20 12:33:47,096 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:2a396b20692f ip:172.25.0.103
datanode2_1  | 2023-02-20 12:33:54,305 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode2_1  | 2023-02-20 12:33:55,874 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode2_1  | 2023-02-20 12:33:55,874 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode2_1  | 2023-02-20 12:33:59,954 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode2_1  | 2023-02-20 12:33:59,958 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode2_1  | 2023-02-20 12:33:59,970 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode2_1  | 2023-02-20 12:33:59,981 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode2_1  | 2023-02-20 12:34:08,834 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode2_1  | 2023-02-20 12:34:09,197 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.103,host:2a396b20692f
datanode2_1  | 2023-02-20 12:34:09,199 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode2_1  | 2023-02-20 12:34:09,230 [main] ERROR client.DNCertificateClient: Invalid domain 2a396b20692f
datanode2_1  | 2023-02-20 12:34:09,238 [main] INFO client.DNCertificateClient: Created csr for DN-> subject:dn@2a396b20692f
datanode2_1  | 2023-02-20 12:34:18,234 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode2_1  | 2023-02-20 12:34:18,452 [main] INFO client.DNCertificateClient: Added certificate   [0]         Version: 3
datanode2_1  |          SerialNumber: 1
datanode2_1  |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode2_1  |            Start Date: Mon Feb 20 00:00:00 UTC 2023
datanode2_1  |            Final Date: Thu Mar 30 00:00:00 UTC 2028
datanode2_1  |             SubjectDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode2_1  |            Public Key: RSA Public Key [94:7e:a6:1e:66:03:60:cb:31:b6:ba:58:09:e5:6f:61:c6:1f:10:56],[56:66:d1:a4]
datanode2_1  |         modulus: ae4c68b294de9bde416e48f8dd880f73587515c06076bc726de72d7d0efa633c8ab0845ecaa9dfe2be73479c31abedba80a9108027262a3316511997768cdb340fdcb173084f830287356e335877580b2bd5bdc297d7572a3635e6a114294f82bfb68aec57278d80b2e053741f6bd8e43df4c302f807657c2cd83c55edafc9fedddc555b306c6720e2e72e1a403ac6fa6a0b45823767e96cbe34c0ee95838730daf28e939192b29222957ccd58032a49c0446c773bb8ccc080bc6d017e13b3470c1f732b571f7ae50833d9852f4af92799f9b8c5eaec9c998c13768e6e1efd686c4d209f1d79c8d4f12aa2f5821e96eff58d7f8e4bf5877811957c77adb800e7
datanode2_1  | public exponent: 10001
datanode2_1  | 
datanode2_1  |   Signature Algorithm: SHA256WITHRSA
datanode2_1  |             Signature: a7cea6946dc4cec2c98cb07c07498d5444b6300d
datanode2_1  |                        0a6c4e9490adf7093c90271931b5d0417975d9b8
datanode2_1  |                        7a9238465c6f3f4de8400309865e2da81ad21b31
datanode2_1  |                        57de65cb86c13fbef66ec87c8614bd8ad650e11d
datanode2_1  |                        4e49b0e20080ff8a0c3d6a6e6cef0122f38fbedc
datanode2_1  |                        9428a9b69ae6258d8ff4035af00ec4326a833057
datanode2_1  |                        736e2bec20eba55b3e39bd1818d036b10a473b2e
datanode2_1  |                        99f5e8079f4fcaa7750269bdb7680ebf53d8f7bb
datanode2_1  |                        16ddc0ef7ac8c2bd9f938901391f3d9e4f3823e1
datanode2_1  |                        07939f9a9f829615d2d1f339e2f210e795258ac1
datanode2_1  |                        f03a273f30f7cb3110f6d700ded1888ed1dcaa17
datanode2_1  |                        ff9774e9f4d33a5be09b76c57503b7a066668066
datanode2_1  |                        4c46b6c92c5c84d4978c557861c07dba
datanode2_1  |        Extensions: 
datanode2_1  |                        critical(true) BasicConstraints: isCa(true)
datanode2_1  |                        critical(true) KeyUsage: 0x6
datanode2_1  |                        critical(false) 2.5.29.17 value = Sequence
datanode2_1  |     Tagged [7] IMPLICIT 
datanode2_1  |         DER Octet String[4] 
datanode2_1  |     Tagged [2] IMPLICIT 
datanode2_1  |         DER Octet String[8] 
datanode2_1  | 
datanode2_1  |  from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode2_1  | 2023-02-20 12:34:18,540 [main] INFO client.DNCertificateClient: Added certificate   [0]         Version: 3
datanode2_1  |          SerialNumber: 1624931770966
datanode2_1  |              IssuerDN: CN=scm-sub@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode2_1  |            Start Date: Mon Feb 20 00:00:00 UTC 2023
datanode2_1  |            Final Date: Tue Feb 20 00:00:00 UTC 2024
datanode2_1  |             SubjectDN: CN=dn@2a396b20692f,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode2_1  |            Public Key: RSA Public Key [df:13:03:f9:96:90:1f:82:18:36:ba:9b:a8:f1:a5:59:1b:a6:e3:6b],[56:66:d1:a4]
datanode2_1  |         modulus: c72cf660bd89d7cdd964b303d79c951ff2e059a4170add6d4239b6d82447a087e0861a16496bf7df9eeff52897d72d9962a07ec70d1af07ef62c1d420fd1b01423675c005cf2bd4fb57b0af4bfb951e5bb1a4c00ebcf89e4d76011b25818445fe5ec96d749d7b8a68b5995f9687cfe345d4ab9e3f6a11c488fdabb611b1c5b0e71d695d84a31d30516820c44db880ef5ed153e9fa51986789a02ba3eaac99638a3138d135e6cdfe0ca62d0e44bf5b5739b8fb9002326192c01c12c3e2050f72bdc9e1c6bbf7948a4145d96440f64aded75b967456d4a17439a2b32a0036c77d590c9bfc543b11bac073a58dfd762ded61db5441e6a4b8a349019301f3e269b5f
datanode2_1  | public exponent: 10001
datanode2_1  | 
datanode2_1  |   Signature Algorithm: SHA256WITHRSA
datanode2_1  |             Signature: ac5a79e3b77c41b46e2fdcbdc435ab42187eaf36
datanode2_1  |                        11c6ba18aa0938bf2b1df2ace300a27f908c8811
datanode2_1  |                        888fa69b0abf75e8c8ed3641b82492d1200188f5
datanode2_1  |                        73871ca512796e46e97a4d01ee0ea7ef3d41eecf
datanode2_1  |                        7f6ef110b958aff3b95a805f9bc60cf78144dabc
datanode2_1  |                        881c9b8cb94e55a2750552d34e0ef512b0b77738
datanode2_1  |                        156289d9e525b3881c09116f8a49d7693ef89172
datanode2_1  |                        1b9f2402e61d697663d94089f70948319b14cbe8
datanode2_1  |                        b85f9cba546dbd2f207aad399ff3e97df47d1fa3
datanode2_1  |                        9d7e1f6e99517e8aaecc00e32aac1befae4601dc
datanode2_1  |                        d72ceaa6ded58830215eee3df32bc9ee76d4f49e
datanode2_1  |                        f98aa942c59db1576f6c2843e45b1c13ebde6ca8
datanode2_1  |                        17e323be0898e50bd81ba7d24ddd3db7
datanode2_1  |        Extensions: 
datanode2_1  |                        critical(false) 2.5.29.17 value = Sequence
datanode2_1  |     Tagged [7] IMPLICIT 
datanode2_1  |         DER Octet String[4] 
datanode2_1  | 
datanode2_1  |                        critical(true) KeyUsage: 0xb8
datanode2_1  |  from file:/data/metadata/dn/certs/1624931770966.crt.
datanode2_1  | 2023-02-20 12:34:18,595 [main] INFO client.DNCertificateClient: Added certificate   [0]         Version: 3
datanode2_1  |          SerialNumber: 1490022441527
datanode2_1  |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode2_1  |            Start Date: Mon Feb 20 00:00:00 UTC 2023
datanode2_1  |            Final Date: Thu Mar 30 00:00:00 UTC 2028
datanode2_1  |             SubjectDN: CN=scm-sub@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode2_1  |            Public Key: RSA Public Key [16:2d:b7:a5:b0:1c:7e:50:4b:d3:0c:1e:91:d5:30:6d:12:23:23:1c],[56:66:d1:a4]
datanode2_1  |         modulus: b8881b4dd07c72248c8863bba59686bc7d8a1c0a77f9587da66c7e69fd2912af0eb4b5ab9b5e2cccd38500bee6178abbf02f9c564eb57a3029da82d6fb08538545dd260393eac22764468b808f392fc0555b558cc274360ac207d0b693142fbc5fd801789ecb2aefa0cfb5b7bb92c107c453311fcd9590678300eed8335e7c2887ddadc75dd7fd24d77cdfffb2d01c2817abb555f59cc4ca8c520c785155f682252969d6f60ba724f524b233eba33397229e851534a97c7b9a743d4dd3ed30d92316c44aab2e8741a08ef02fcc96cb516c9e93342ba73692ddd39f254390ff523b588e0710edded5220b5301b85e914019771f8cbd758e861d99222494d387a7
datanode2_1  | public exponent: 10001
datanode2_1  | 
datanode2_1  |   Signature Algorithm: SHA256WITHRSA
datanode2_1  |             Signature: 363d3273c12aa64988005dd16cbf319b130f6b08
datanode2_1  |                        3ec325844d607b1225858823a3b417c8b78f8266
datanode2_1  |                        5338966c887d5ee760050f81da927bac7aafdda0
datanode2_1  |                        203c45d70e75f7f585632db643c276dcfc12d0cf
datanode2_1  |                        31d734300b15141e9c77a37edb550f41a3cc1a14
datanode2_1  |                        5e4b848617279f658ed62ed740017f1b4bd844c2
datanode2_1  |                        cdb757bfdef0058498c0b11f0c59d5c5c4a6fea2
datanode2_1  |                        e44d596ba23e9480406994c2d52d03fb603137d7
datanode2_1  |                        38b028409f31693a2c3fddbd689785b29f009d1f
datanode2_1  |                        b3b815a10f87cee8642a347f5b737ade5d2f2d7f
datanode2_1  |                        3a51aac93500a29b12e04ea17d3d823af05cedd3
datanode2_1  |                        737c196e3d25ee225340482ec1a717bf8f73b126
datanode2_1  |                        32165d626d85896b9c2f99ff029695f3
datanode2_1  |        Extensions: 
datanode2_1  |                        critical(false) 2.5.29.17 value = Sequence
datanode2_1  |     Tagged [7] IMPLICIT 
datanode2_1  |         DER Octet String[4] 
datanode2_1  |     Tagged [2] IMPLICIT 
datanode2_1  |         DER Octet String[8] 
datanode2_1  | 
datanode2_1  |                        critical(true) BasicConstraints: isCa(true)
datanode2_1  |                        critical(true) KeyUsage: 0xbe
datanode2_1  |  from file:/data/metadata/dn/certs/CA-1490022441527.crt.
datanode2_1  | 2023-02-20 12:34:18,659 [main] INFO client.DNCertificateClient: CertificateLifetimeMonitor for dn is started with first delay 29071541388 ms and interval 86400000 ms.
datanode2_1  | 2023-02-20 12:34:18,660 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode2_1  | 2023-02-20 12:34:18,932 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode2_1  | 2023-02-20 12:34:20,639 [main] INFO reflections.Reflections: Reflections took 1309 ms to scan 2 urls, producing 101 keys and 225 values 
datanode2_1  | 2023-02-20 12:34:21,833 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode2_1  | 2023-02-20 12:34:24,138 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode2_1  | 2023-02-20 12:34:24,284 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode2_1  | 2023-02-20 12:34:24,338 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode2_1  | 2023-02-20 12:34:24,362 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode2_1  | 2023-02-20 12:34:24,769 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode2_1  | 2023-02-20 12:34:24,991 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2023-02-20 12:34:24,995 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode2_1  | 2023-02-20 12:34:25,026 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode2_1  | 2023-02-20 12:34:25,029 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode2_1  | 2023-02-20 12:34:25,056 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode2_1  | 2023-02-20 12:34:25,472 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode2_1  | 2023-02-20 12:34:25,491 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode2_1  | 2023-02-20 12:34:34,478 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode1_1  |                        3b97d5f4e7557a41da2e2a8ce208b3afd4569c7d
datanode1_1  |                        48ded38b5fe086262f71825d174177f4392861f5
datanode1_1  |                        0d593e4c96f5035fbc9e33a1a10026d2bc68e412
datanode1_1  |                        d3833d4f06aea214adc553c5eadcc06539d48409
datanode1_1  |                        1707e75ff62f87937f0b3eed4fad2540
datanode1_1  |        Extensions: 
datanode1_1  |                        critical(false) 2.5.29.17 value = Sequence
datanode1_1  |     Tagged [7] IMPLICIT 
datanode1_1  |         DER Octet String[4] 
datanode1_1  | 
datanode1_1  |                        critical(true) KeyUsage: 0xb8
datanode1_1  |  from file:/data/metadata/dn/certs/1628842543028.crt.
datanode1_1  | 2023-02-20 12:34:22,232 [main] INFO client.DNCertificateClient: Added certificate   [0]         Version: 3
datanode1_1  |          SerialNumber: 1490022441527
datanode1_1  |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode1_1  |            Start Date: Mon Feb 20 00:00:00 UTC 2023
datanode1_1  |            Final Date: Thu Mar 30 00:00:00 UTC 2028
datanode1_1  |             SubjectDN: CN=scm-sub@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode1_1  |            Public Key: RSA Public Key [16:2d:b7:a5:b0:1c:7e:50:4b:d3:0c:1e:91:d5:30:6d:12:23:23:1c],[56:66:d1:a4]
datanode1_1  |         modulus: b8881b4dd07c72248c8863bba59686bc7d8a1c0a77f9587da66c7e69fd2912af0eb4b5ab9b5e2cccd38500bee6178abbf02f9c564eb57a3029da82d6fb08538545dd260393eac22764468b808f392fc0555b558cc274360ac207d0b693142fbc5fd801789ecb2aefa0cfb5b7bb92c107c453311fcd9590678300eed8335e7c2887ddadc75dd7fd24d77cdfffb2d01c2817abb555f59cc4ca8c520c785155f682252969d6f60ba724f524b233eba33397229e851534a97c7b9a743d4dd3ed30d92316c44aab2e8741a08ef02fcc96cb516c9e93342ba73692ddd39f254390ff523b588e0710edded5220b5301b85e914019771f8cbd758e861d99222494d387a7
datanode1_1  | public exponent: 10001
datanode1_1  | 
datanode1_1  |   Signature Algorithm: SHA256WITHRSA
datanode1_1  |             Signature: 363d3273c12aa64988005dd16cbf319b130f6b08
datanode1_1  |                        3ec325844d607b1225858823a3b417c8b78f8266
datanode1_1  |                        5338966c887d5ee760050f81da927bac7aafdda0
datanode1_1  |                        203c45d70e75f7f585632db643c276dcfc12d0cf
datanode1_1  |                        31d734300b15141e9c77a37edb550f41a3cc1a14
datanode1_1  |                        5e4b848617279f658ed62ed740017f1b4bd844c2
datanode1_1  |                        cdb757bfdef0058498c0b11f0c59d5c5c4a6fea2
datanode1_1  |                        e44d596ba23e9480406994c2d52d03fb603137d7
datanode1_1  |                        38b028409f31693a2c3fddbd689785b29f009d1f
datanode1_1  |                        b3b815a10f87cee8642a347f5b737ade5d2f2d7f
datanode1_1  |                        3a51aac93500a29b12e04ea17d3d823af05cedd3
datanode1_1  |                        737c196e3d25ee225340482ec1a717bf8f73b126
datanode1_1  |                        32165d626d85896b9c2f99ff029695f3
datanode1_1  |        Extensions: 
datanode1_1  |                        critical(false) 2.5.29.17 value = Sequence
datanode1_1  |     Tagged [7] IMPLICIT 
datanode1_1  |         DER Octet String[4] 
datanode1_1  |     Tagged [2] IMPLICIT 
datanode1_1  |         DER Octet String[8] 
datanode1_1  | 
datanode1_1  |                        critical(true) BasicConstraints: isCa(true)
datanode1_1  |                        critical(true) KeyUsage: 0xbe
datanode1_1  |  from file:/data/metadata/dn/certs/CA-1490022441527.crt.
datanode1_1  | 2023-02-20 12:34:22,334 [main] INFO client.DNCertificateClient: CertificateLifetimeMonitor for dn is started with first delay 29071537730 ms and interval 86400000 ms.
datanode1_1  | 2023-02-20 12:34:22,348 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode1_1  | 2023-02-20 12:34:22,571 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode1_1  | 2023-02-20 12:34:24,420 [main] INFO reflections.Reflections: Reflections took 1427 ms to scan 2 urls, producing 101 keys and 225 values 
datanode1_1  | 2023-02-20 12:34:25,583 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode1_1  | 2023-02-20 12:34:27,958 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode1_1  | 2023-02-20 12:34:28,177 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode1_1  | 2023-02-20 12:34:28,217 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode1_1  | 2023-02-20 12:34:28,257 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode1_1  | 2023-02-20 12:34:28,665 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode1_1  | 2023-02-20 12:34:28,914 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2023-02-20 12:34:28,939 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode1_1  | 2023-02-20 12:34:28,947 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode1_1  | 2023-02-20 12:34:28,947 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode1_1  | 2023-02-20 12:34:28,953 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode1_1  | 2023-02-20 12:34:29,440 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode1_1  | 2023-02-20 12:34:29,443 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode1_1  | 2023-02-20 12:34:38,398 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode1_1  | 2023-02-20 12:34:40,573 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
datanode1_1  | 2023-02-20 12:34:40,897 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig1-
datanode1_1  | 2023-02-20 12:34:41,298 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode1_1  | 2023-02-20 12:34:42,020 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode1_1  | 2023-02-20 12:34:42,981 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode1_1  | 2023-02-20 12:34:42,992 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode1_1  | 2023-02-20 12:34:43,012 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode1_1  | 2023-02-20 12:34:43,021 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode1_1  | 2023-02-20 12:34:43,021 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode1_1  | 2023-02-20 12:34:43,026 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode1_1  | 2023-02-20 12:34:43,034 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode1_1  | 2023-02-20 12:34:43,056 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2023-02-20 12:34:43,076 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode1_1  | 2023-02-20 12:34:43,086 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode1_1  | 2023-02-20 12:34:43,498 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode1_1  | 2023-02-20 12:34:43,643 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode3_1  | Sleeping for 5 seconds
datanode3_1  | Waiting for the service scm3.org:9894
datanode3_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode3_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode3_1  | 2023-02-20 12:33:42,754 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode3_1  | /************************************************************
datanode3_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode3_1  | STARTUP_MSG:   host = 0932752dfb54/172.25.0.104
datanode3_1  | STARTUP_MSG:   args = []
datanode3_1  | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
datanode3_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.4.0-SNAPSHOT.jar
datanode3_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
datanode3_1  | STARTUP_MSG:   java = 11.0.14.1
datanode3_1  | ************************************************************/
datanode3_1  | 2023-02-20 12:33:42,925 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode3_1  | 2023-02-20 12:33:43,723 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode3_1  | 2023-02-20 12:33:44,965 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode3_1  | 2023-02-20 12:33:46,703 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode3_1  | 2023-02-20 12:33:46,711 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode3_1  | 2023-02-20 12:33:48,306 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:0932752dfb54 ip:172.25.0.104
datanode3_1  | 2023-02-20 12:33:54,638 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode3_1  | 2023-02-20 12:33:56,345 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode3_1  | 2023-02-20 12:33:56,345 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode3_1  | 2023-02-20 12:34:00,541 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode3_1  | 2023-02-20 12:34:00,549 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode3_1  | 2023-02-20 12:34:00,553 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode3_1  | 2023-02-20 12:34:00,554 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode3_1  | 2023-02-20 12:34:14,483 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode3_1  | 2023-02-20 12:34:14,873 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.104,host:0932752dfb54
datanode3_1  | 2023-02-20 12:34:14,874 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode3_1  | 2023-02-20 12:34:14,907 [main] ERROR client.DNCertificateClient: Invalid domain 0932752dfb54
datanode3_1  | 2023-02-20 12:34:14,916 [main] INFO client.DNCertificateClient: Created csr for DN-> subject:dn@0932752dfb54
datanode3_1  | 2023-02-20 12:34:25,040 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode3_1  | 2023-02-20 12:34:25,226 [main] INFO client.DNCertificateClient: Added certificate   [0]         Version: 3
datanode3_1  |          SerialNumber: 1
datanode3_1  |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode3_1  |            Start Date: Mon Feb 20 00:00:00 UTC 2023
datanode3_1  |            Final Date: Thu Mar 30 00:00:00 UTC 2028
datanode3_1  |             SubjectDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode3_1  |            Public Key: RSA Public Key [94:7e:a6:1e:66:03:60:cb:31:b6:ba:58:09:e5:6f:61:c6:1f:10:56],[56:66:d1:a4]
datanode3_1  |         modulus: ae4c68b294de9bde416e48f8dd880f73587515c06076bc726de72d7d0efa633c8ab0845ecaa9dfe2be73479c31abedba80a9108027262a3316511997768cdb340fdcb173084f830287356e335877580b2bd5bdc297d7572a3635e6a114294f82bfb68aec57278d80b2e053741f6bd8e43df4c302f807657c2cd83c55edafc9fedddc555b306c6720e2e72e1a403ac6fa6a0b45823767e96cbe34c0ee95838730daf28e939192b29222957ccd58032a49c0446c773bb8ccc080bc6d017e13b3470c1f732b571f7ae50833d9852f4af92799f9b8c5eaec9c998c13768e6e1efd686c4d209f1d79c8d4f12aa2f5821e96eff58d7f8e4bf5877811957c77adb800e7
datanode3_1  | public exponent: 10001
datanode3_1  | 
datanode3_1  |   Signature Algorithm: SHA256WITHRSA
datanode3_1  |             Signature: a7cea6946dc4cec2c98cb07c07498d5444b6300d
datanode3_1  |                        0a6c4e9490adf7093c90271931b5d0417975d9b8
datanode3_1  |                        7a9238465c6f3f4de8400309865e2da81ad21b31
datanode3_1  |                        57de65cb86c13fbef66ec87c8614bd8ad650e11d
datanode3_1  |                        4e49b0e20080ff8a0c3d6a6e6cef0122f38fbedc
datanode3_1  |                        9428a9b69ae6258d8ff4035af00ec4326a833057
datanode3_1  |                        736e2bec20eba55b3e39bd1818d036b10a473b2e
datanode3_1  |                        99f5e8079f4fcaa7750269bdb7680ebf53d8f7bb
datanode3_1  |                        16ddc0ef7ac8c2bd9f938901391f3d9e4f3823e1
datanode3_1  |                        07939f9a9f829615d2d1f339e2f210e795258ac1
datanode3_1  |                        f03a273f30f7cb3110f6d700ded1888ed1dcaa17
datanode3_1  |                        ff9774e9f4d33a5be09b76c57503b7a066668066
datanode3_1  |                        4c46b6c92c5c84d4978c557861c07dba
datanode3_1  |        Extensions: 
datanode3_1  |                        critical(true) BasicConstraints: isCa(true)
datanode3_1  |                        critical(true) KeyUsage: 0x6
datanode3_1  |                        critical(false) 2.5.29.17 value = Sequence
datanode3_1  |     Tagged [7] IMPLICIT 
datanode3_1  |         DER Octet String[4] 
datanode3_1  |     Tagged [2] IMPLICIT 
datanode3_1  |         DER Octet String[8] 
datanode3_1  | 
datanode3_1  |  from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode3_1  | 2023-02-20 12:34:25,302 [main] INFO client.DNCertificateClient: Added certificate   [0]         Version: 3
datanode3_1  |          SerialNumber: 1631425044085
datanode3_1  |              IssuerDN: CN=scm-sub@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode3_1  |            Start Date: Mon Feb 20 00:00:00 UTC 2023
datanode3_1  |            Final Date: Tue Feb 20 00:00:00 UTC 2024
datanode3_1  |             SubjectDN: CN=dn@0932752dfb54,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode3_1  |            Public Key: RSA Public Key [75:1d:c2:42:b9:32:a6:4c:82:f7:ab:15:e3:69:99:c6:2b:00:c0:06],[56:66:d1:a4]
datanode3_1  |         modulus: d67e0911ea9f13455132a29074164f662efe4dd35121c52950368c5dd0787d4235397484cbb1771266d77c005ac4aaed50f60a3f9b150c5492d74cb97ddf3e9255dc03a5a4afc9c1decd3247ea7ffb771aa2ab7cd16ca957776cdadde690a9c3ff5790263339cb498fa18ec0a039d09a9a8fb8e28bd9ced3a54c866a28b42d198852adce4d25e231b49cc03d62d438e7171fed0ce54e0b35b3372d2e9ccd29ea5b7496cfec99873d292afa5b5177724d597108c7ad3c742bf6f9a609252bab8ef4c7fddff2b50988d8def82583403e95bcc566941463948f79f61c86ef2a20072ca4717998d5b57dbab6137e1c7fa7c2ed2cfb92cc8b93c74ad09d9a9af3b513
datanode3_1  | public exponent: 10001
datanode3_1  | 
datanode3_1  |   Signature Algorithm: SHA256WITHRSA
datanode3_1  |             Signature: 3d817acdfa5b9f18ba9914ea6f32b92f5ccf259e
datanode3_1  |                        22a15f888ea3283f2eaaf097281659355d2d29bd
datanode3_1  |                        f721e9a88391341d48c1ce41bee653308e2aa5ed
datanode3_1  |                        1666ead52eb0ed6bf3b911ad8fa49a0ec4a8e440
datanode3_1  |                        e6302be058d1b424acfe445eb55fbbdecc29e6e4
datanode3_1  |                        dc5ea60299eabddc6afccc34f75942c881bec2d5
datanode1_1  | 2023-02-20 12:34:43,653 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode1_1  | 2023-02-20 12:34:54,133 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode1_1  | 2023-02-20 12:34:54,173 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode1_1  | 2023-02-20 12:34:54,191 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode1_1  | 2023-02-20 12:34:54,195 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2023-02-20 12:34:54,196 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2023-02-20 12:34:54,379 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2023-02-20 12:34:54,993 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER KeyStore reloading at 60000 millis.
datanode1_1  | 2023-02-20 12:34:55,078 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER TrustStore reloading at 60000 millis.
datanode1_1  | 2023-02-20 12:34:55,302 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode1_1  | 2023-02-20 12:34:58,548 [main] INFO token.OzoneBlockTokenSecretManager: Updating current master key for generating tokens. Cert id 1628842543028
datanode1_1  | 2023-02-20 12:34:58,594 [main] INFO token.ContainerTokenSecretManager: Updating current master key for generating tokens. Cert id 1628842543028
datanode1_1  | 2023-02-20 12:35:00,018 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode1_1  | 2023-02-20 12:35:00,026 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode1_1  | 2023-02-20 12:35:00,026 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode1_1  | 2023-02-20 12:35:00,605 [main] INFO util.log: Logging initialized @94448ms to org.eclipse.jetty.util.log.Slf4jLog
datanode1_1  | 2023-02-20 12:35:02,137 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode1_1  | 2023-02-20 12:35:02,186 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode1_1  | 2023-02-20 12:35:02,233 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode1_1  | 2023-02-20 12:35:02,235 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode1_1  | 2023-02-20 12:35:02,235 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode1_1  | 2023-02-20 12:35:02,278 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode1_1  | 2023-02-20 12:35:03,137 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode1_1  | 2023-02-20 12:35:03,157 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode1_1  | 2023-02-20 12:35:03,700 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode1_1  | 2023-02-20 12:35:03,711 [main] INFO server.session: No SessionScavenger set, using defaults
datanode1_1  | 2023-02-20 12:35:03,717 [main] INFO server.session: node0 Scavenging every 600000ms
datanode1_1  | 2023-02-20 12:35:04,011 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2023-02-20 12:35:04,060 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2787abe4{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode1_1  | 2023-02-20 12:35:04,098 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2048255a{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode1_1  | 2023-02-20 12:35:05,421 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode1_1  | 2023-02-20 12:35:05,572 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3d8c3d0a{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-1108677389780491612/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode1_1  | 2023-02-20 12:35:05,689 [main] INFO server.AbstractConnector: Started ServerConnector@6ec5c4e2{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode1_1  | 2023-02-20 12:35:05,691 [main] INFO server.Server: Started @99534ms
datanode1_1  | 2023-02-20 12:35:05,732 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode1_1  | 2023-02-20 12:35:05,732 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode1_1  | 2023-02-20 12:35:05,752 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode1_1  | 2023-02-20 12:35:05,795 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode1_1  | 2023-02-20 12:35:06,246 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d5fa7bd] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode1_1  | 2023-02-20 12:35:07,593 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode1_1  | 2023-02-20 12:35:07,735 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode1_1  | 2023-02-20 12:35:10,813 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO utils.DatanodeStoreCache: Added db /data/hdds/hdds/CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/DS-f019c6ae-ab95-472b-a13c-c33f892fb78f/container.db to cache
datanode1_1  | 2023-02-20 12:35:10,818 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/DS-f019c6ae-ab95-472b-a13c-c33f892fb78f/container.db for volume DS-f019c6ae-ab95-472b-a13c-c33f892fb78f
datanode1_1  | 2023-02-20 12:35:10,853 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode1_1  | 2023-02-20 12:35:10,885 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Scheduled background container scanners and the on-demand container scanner have been disabled.
datanode1_1  | 2023-02-20 12:35:12,235 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO replication.ReplicationServer: ReplicationServer is started using port 9886
datanode1_1  | 2023-02-20 12:35:12,290 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 8dd306ed-03df-465a-901a-3b76553ce2f1
datanode1_1  | 2023-02-20 12:35:12,528 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.RaftServer: 8dd306ed-03df-465a-901a-3b76553ce2f1: start RPC server
datanode1_1  | 2023-02-20 12:35:12,605 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 8dd306ed-03df-465a-901a-3b76553ce2f1: GrpcService started, listening on 9858
datanode1_1  | 2023-02-20 12:35:12,615 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 8dd306ed-03df-465a-901a-3b76553ce2f1: GrpcService started, listening on 9856
datanode1_1  | 2023-02-20 12:35:12,617 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: 8dd306ed-03df-465a-901a-3b76553ce2f1: GrpcService started, listening on 9857
datanode1_1  | 2023-02-20 12:35:12,682 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-8dd306ed-03df-465a-901a-3b76553ce2f1: Started
datanode1_1  | 2023-02-20 12:35:12,690 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8dd306ed-03df-465a-901a-3b76553ce2f1 is started using port 9858 for RATIS
datanode1_1  | 2023-02-20 12:35:12,694 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8dd306ed-03df-465a-901a-3b76553ce2f1 is started using port 9857 for RATIS_ADMIN
datanode1_1  | 2023-02-20 12:35:12,694 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 8dd306ed-03df-465a-901a-3b76553ce2f1 is started using port 9856 for RATIS_SERVER
datanode1_1  | 2023-02-20 12:35:12,851 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2023-02-20 12:35:12,855 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode1_1  | 2023-02-20 12:35:17,895 [Command processor thread] INFO server.RaftServer: 8dd306ed-03df-465a-901a-3b76553ce2f1: addNew group-B1BEB74BCBD4:[8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:1|startupRole:FOLLOWER] returns group-B1BEB74BCBD4:java.util.concurrent.CompletableFuture@5ed59ef9[Not completed]
datanode1_1  | 2023-02-20 12:35:18,200 [pool-24-thread-1] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1: new RaftServerImpl for group-B1BEB74BCBD4:[8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode1_1  | 2023-02-20 12:35:18,234 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2023-02-20 12:35:18,236 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2023-02-20 12:35:18,238 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2023-02-20 12:35:18,240 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2023-02-20 12:35:18,242 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2023-02-20 12:35:18,245 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2023-02-20 12:35:18,366 [pool-24-thread-1] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4: ConfigurationManager, init=-1: peers:[8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2023-02-20 12:35:18,372 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2023-02-20 12:35:18,441 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2023-02-20 12:35:18,446 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2023-02-20 12:35:18,544 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2023-02-20 12:35:18,576 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2023-02-20 12:35:18,586 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2023-02-20 12:35:19,116 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2023-02-20 12:35:19,126 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2023-02-20 12:35:19,128 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2023-02-20 12:35:19,131 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2023-02-20 12:35:19,132 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2023-02-20 12:35:19,137 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/fb10096d-83bf-4df3-bd31-b1beb74bcbd4 does not exist. Creating ...
datanode1_1  | 2023-02-20 12:35:19,168 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/fb10096d-83bf-4df3-bd31-b1beb74bcbd4/in_use.lock acquired by nodename 7@6b48ece71e49
datanode1_1  | 2023-02-20 12:35:19,234 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/fb10096d-83bf-4df3-bd31-b1beb74bcbd4 has been successfully formatted.
datanode1_1  | 2023-02-20 12:35:19,316 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-B1BEB74BCBD4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2023-02-20 12:35:19,361 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2023-02-20 12:35:19,445 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2023-02-20 12:35:19,445 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2023-02-20 12:35:19,457 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2023-02-20 12:35:19,473 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode1_1  | 2023-02-20 12:35:19,536 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2023-02-20 12:35:19,607 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2023-02-20 12:35:19,613 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2023-02-20 12:35:19,757 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/fb10096d-83bf-4df3-bd31-b1beb74bcbd4
datanode1_1  | 2023-02-20 12:35:19,771 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2023-02-20 12:35:19,779 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2023-02-20 12:35:19,782 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2023-02-20 12:35:19,790 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2023-02-20 12:35:19,799 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2023-02-20 12:35:19,802 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode2_1  | 2023-02-20 12:34:36,104 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
datanode2_1  | 2023-02-20 12:34:36,215 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig1-
datanode2_1  | 2023-02-20 12:34:36,674 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode2_1  | 2023-02-20 12:34:37,409 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode2_1  | 2023-02-20 12:34:39,229 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode2_1  | 2023-02-20 12:34:39,261 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode2_1  | 2023-02-20 12:34:39,300 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode2_1  | 2023-02-20 12:34:39,308 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode2_1  | 2023-02-20 12:34:39,312 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode2_1  | 2023-02-20 12:34:39,316 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode2_1  | 2023-02-20 12:34:39,389 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode2_1  | 2023-02-20 12:34:39,421 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode2_1  | 2023-02-20 12:34:39,432 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode2_1  | 2023-02-20 12:34:39,439 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode2_1  | 2023-02-20 12:34:39,660 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode2_1  | 2023-02-20 12:34:39,709 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode2_1  | 2023-02-20 12:34:39,717 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode2_1  | 2023-02-20 12:34:48,442 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode2_1  | 2023-02-20 12:34:48,487 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode2_1  | 2023-02-20 12:34:48,489 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode2_1  | 2023-02-20 12:34:48,493 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2023-02-20 12:34:48,497 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2023-02-20 12:34:48,525 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2023-02-20 12:34:48,918 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER KeyStore reloading at 60000 millis.
datanode2_1  | 2023-02-20 12:34:48,972 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER TrustStore reloading at 60000 millis.
datanode2_1  | 2023-02-20 12:34:49,052 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode2_1  | 2023-02-20 12:34:50,639 [main] INFO token.OzoneBlockTokenSecretManager: Updating current master key for generating tokens. Cert id 1624931770966
datanode2_1  | 2023-02-20 12:34:50,698 [main] INFO token.ContainerTokenSecretManager: Updating current master key for generating tokens. Cert id 1624931770966
datanode2_1  | 2023-02-20 12:34:51,322 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode2_1  | 2023-02-20 12:34:51,327 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode2_1  | 2023-02-20 12:34:51,328 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode2_1  | 2023-02-20 12:34:51,581 [main] INFO util.log: Logging initialized @85329ms to org.eclipse.jetty.util.log.Slf4jLog
datanode2_1  | 2023-02-20 12:34:52,798 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode2_1  | 2023-02-20 12:34:52,874 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode2_1  | 2023-02-20 12:34:52,890 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode2_1  | 2023-02-20 12:34:52,890 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode2_1  | 2023-02-20 12:34:52,890 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode2_1  | 2023-02-20 12:34:52,920 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode2_1  | 2023-02-20 12:34:53,337 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode2_1  | 2023-02-20 12:34:53,369 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode2_1  | 2023-02-20 12:34:53,888 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode2_1  | 2023-02-20 12:34:53,889 [main] INFO server.session: No SessionScavenger set, using defaults
datanode2_1  | 2023-02-20 12:34:53,917 [main] INFO server.session: node0 Scavenging every 660000ms
datanode2_1  | 2023-02-20 12:34:54,126 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2023-02-20 12:34:54,146 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2787abe4{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode2_1  | 2023-02-20 12:34:54,156 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2048255a{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode2_1  | 2023-02-20 12:34:55,326 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode2_1  | 2023-02-20 12:34:55,432 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3d8c3d0a{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-3220909629252320106/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode2_1  | 2023-02-20 12:34:55,479 [main] INFO server.AbstractConnector: Started ServerConnector@6ec5c4e2{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode2_1  | 2023-02-20 12:34:55,482 [main] INFO server.Server: Started @89232ms
datanode2_1  | 2023-02-20 12:34:55,548 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode2_1  | 2023-02-20 12:34:55,549 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode2_1  | 2023-02-20 12:34:55,566 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode2_1  | 2023-02-20 12:34:55,599 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode2_1  | 2023-02-20 12:34:56,107 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@e05dd96] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode2_1  | 2023-02-20 12:34:57,288 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode2_1  | 2023-02-20 12:34:57,359 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode2_1  | 2023-02-20 12:35:04,216 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO utils.DatanodeStoreCache: Added db /data/hdds/hdds/CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/DS-6090abc4-afcb-4bf0-9fc8-f53ad79d38d2/container.db to cache
datanode2_1  | 2023-02-20 12:35:04,236 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/DS-6090abc4-afcb-4bf0-9fc8-f53ad79d38d2/container.db for volume DS-6090abc4-afcb-4bf0-9fc8-f53ad79d38d2
datanode2_1  | 2023-02-20 12:35:04,251 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode2_1  | 2023-02-20 12:35:04,299 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Scheduled background container scanners and the on-demand container scanner have been disabled.
datanode2_1  | 2023-02-20 12:35:05,329 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO replication.ReplicationServer: ReplicationServer is started using port 9886
datanode2_1  | 2023-02-20 12:35:05,426 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis f342a5db-4e7d-4274-be79-8b926a9a2f90
datanode2_1  | 2023-02-20 12:35:06,053 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.RaftServer: f342a5db-4e7d-4274-be79-8b926a9a2f90: start RPC server
datanode2_1  | 2023-02-20 12:35:06,133 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: f342a5db-4e7d-4274-be79-8b926a9a2f90: GrpcService started, listening on 9858
datanode2_1  | 2023-02-20 12:35:06,180 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: f342a5db-4e7d-4274-be79-8b926a9a2f90: GrpcService started, listening on 9856
datanode2_1  | 2023-02-20 12:35:06,265 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO server.GrpcService: f342a5db-4e7d-4274-be79-8b926a9a2f90: GrpcService started, listening on 9857
datanode2_1  | 2023-02-20 12:35:06,305 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis f342a5db-4e7d-4274-be79-8b926a9a2f90 is started using port 9858 for RATIS
datanode2_1  | 2023-02-20 12:35:06,314 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis f342a5db-4e7d-4274-be79-8b926a9a2f90 is started using port 9857 for RATIS_ADMIN
datanode2_1  | 2023-02-20 12:35:06,314 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis f342a5db-4e7d-4274-be79-8b926a9a2f90 is started using port 9856 for RATIS_SERVER
datanode2_1  | 2023-02-20 12:35:06,320 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-f342a5db-4e7d-4274-be79-8b926a9a2f90: Started
datanode2_1  | 2023-02-20 12:35:06,460 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2023-02-20 12:35:06,480 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode2_1  | 2023-02-20 12:35:32,899 [grpc-default-executor-0] WARN server.GrpcServerProtocolService: f342a5db-4e7d-4274-be79-8b926a9a2f90: Failed requestVote d23baa5b-5f7e-4a50-8199-73003befd3af->f342a5db-4e7d-4274-be79-8b926a9a2f90#0
datanode2_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: f342a5db-4e7d-4274-be79-8b926a9a2f90: group-B4FB3CA8A87D not found.
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:360)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:355)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:618)
datanode2_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:175)
datanode2_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:382)
kdc_1        | Feb 20 12:31:29 kdc krb5kdc[7](info): Loaded
kdc_1        | Feb 20 12:31:29 kdc krb5kdc[7](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1        | Feb 20 12:31:29 kdc krb5kdc[7](info): setting up network...
kdc_1        | Feb 20 12:31:29 kdc krb5kdc[7](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1        | Feb 20 12:31:29 kdc krb5kdc[7](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1        | Feb 20 12:31:29 kdc krb5kdc[7](info): set up 4 sockets
kdc_1        | Feb 20 12:31:29 kdc krb5kdc[7](info): commencing operation
kdc_1        | krb5kdc: starting...
kdc_1        | Feb 20 12:31:33 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1676896293, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:31:44 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.114: ISSUE: authtime 1676896304, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:31:44 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1676896304, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:31:52 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.115: ISSUE: authtime 1676896312, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:32:06 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1676896326, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:32:12 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.116: ISSUE: authtime 1676896332, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:32:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.115: ISSUE: authtime 1676896312, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:32:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1676896326, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:32:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1676896304, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:32:34 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1676896354, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:32:37 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.117: ISSUE: authtime 1676896357, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:32:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1676896354, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:32:52 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.117: ISSUE: authtime 1676896357, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:32:58 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1676896378, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:32:59 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1676896379, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:33:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1676896379, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:33:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1676896378, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode3_1  |                        dba40e6c258183b94f531d1a7472ab03651e08a8
datanode3_1  |                        c02781bbf77317243fdfe35112b5f28b6e21c3a4
datanode3_1  |                        849bb80b63c14a8dd416da256ebfd50f53b675b9
datanode3_1  |                        aa9b795fdec0276a2f209b6f5c3de03f7da3db8c
datanode3_1  |                        0952fd6b151d3370ed0d2314e2320cc7c586709e
datanode3_1  |                        1b13711ccac8b9196a21e1e292f112814a2aaa90
datanode3_1  |                        e161f862403018c9c841c6ec940d63c6
datanode3_1  |        Extensions: 
datanode3_1  |                        critical(false) 2.5.29.17 value = Sequence
datanode3_1  |     Tagged [7] IMPLICIT 
datanode3_1  |         DER Octet String[4] 
datanode3_1  | 
datanode3_1  |                        critical(true) KeyUsage: 0xb8
datanode3_1  |  from file:/data/metadata/dn/certs/1631425044085.crt.
datanode3_1  | 2023-02-20 12:34:25,347 [main] INFO client.DNCertificateClient: Added certificate   [0]         Version: 3
datanode3_1  |          SerialNumber: 1490022441527
datanode3_1  |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode3_1  |            Start Date: Mon Feb 20 00:00:00 UTC 2023
datanode3_1  |            Final Date: Thu Mar 30 00:00:00 UTC 2028
datanode3_1  |             SubjectDN: CN=scm-sub@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
datanode3_1  |            Public Key: RSA Public Key [16:2d:b7:a5:b0:1c:7e:50:4b:d3:0c:1e:91:d5:30:6d:12:23:23:1c],[56:66:d1:a4]
datanode3_1  |         modulus: b8881b4dd07c72248c8863bba59686bc7d8a1c0a77f9587da66c7e69fd2912af0eb4b5ab9b5e2cccd38500bee6178abbf02f9c564eb57a3029da82d6fb08538545dd260393eac22764468b808f392fc0555b558cc274360ac207d0b693142fbc5fd801789ecb2aefa0cfb5b7bb92c107c453311fcd9590678300eed8335e7c2887ddadc75dd7fd24d77cdfffb2d01c2817abb555f59cc4ca8c520c785155f682252969d6f60ba724f524b233eba33397229e851534a97c7b9a743d4dd3ed30d92316c44aab2e8741a08ef02fcc96cb516c9e93342ba73692ddd39f254390ff523b588e0710edded5220b5301b85e914019771f8cbd758e861d99222494d387a7
datanode3_1  | public exponent: 10001
datanode3_1  | 
datanode3_1  |   Signature Algorithm: SHA256WITHRSA
datanode3_1  |             Signature: 363d3273c12aa64988005dd16cbf319b130f6b08
datanode3_1  |                        3ec325844d607b1225858823a3b417c8b78f8266
datanode3_1  |                        5338966c887d5ee760050f81da927bac7aafdda0
datanode3_1  |                        203c45d70e75f7f585632db643c276dcfc12d0cf
datanode3_1  |                        31d734300b15141e9c77a37edb550f41a3cc1a14
datanode3_1  |                        5e4b848617279f658ed62ed740017f1b4bd844c2
datanode3_1  |                        cdb757bfdef0058498c0b11f0c59d5c5c4a6fea2
datanode3_1  |                        e44d596ba23e9480406994c2d52d03fb603137d7
datanode3_1  |                        38b028409f31693a2c3fddbd689785b29f009d1f
datanode3_1  |                        b3b815a10f87cee8642a347f5b737ade5d2f2d7f
datanode3_1  |                        3a51aac93500a29b12e04ea17d3d823af05cedd3
datanode3_1  |                        737c196e3d25ee225340482ec1a717bf8f73b126
datanode3_1  |                        32165d626d85896b9c2f99ff029695f3
datanode3_1  |        Extensions: 
datanode3_1  |                        critical(false) 2.5.29.17 value = Sequence
datanode3_1  |     Tagged [7] IMPLICIT 
datanode3_1  |         DER Octet String[4] 
datanode3_1  |     Tagged [2] IMPLICIT 
datanode3_1  |         DER Octet String[8] 
datanode3_1  | 
datanode3_1  |                        critical(true) BasicConstraints: isCa(true)
datanode3_1  |                        critical(true) KeyUsage: 0xbe
datanode3_1  |  from file:/data/metadata/dn/certs/CA-1490022441527.crt.
datanode3_1  | 2023-02-20 12:34:25,375 [main] INFO client.DNCertificateClient: CertificateLifetimeMonitor for dn is started with first delay 29071534644 ms and interval 86400000 ms.
datanode3_1  | 2023-02-20 12:34:25,377 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode3_1  | 2023-02-20 12:34:25,580 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode3_1  | 2023-02-20 12:34:27,112 [main] INFO reflections.Reflections: Reflections took 1125 ms to scan 2 urls, producing 101 keys and 225 values 
datanode3_1  | 2023-02-20 12:34:27,991 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 4
datanode3_1  | 2023-02-20 12:34:30,138 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode3_1  | 2023-02-20 12:34:30,298 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode3_1  | 2023-02-20 12:34:30,340 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode3_1  | 2023-02-20 12:34:30,357 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode3_1  | 2023-02-20 12:34:30,651 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode3_1  | 2023-02-20 12:34:30,875 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2023-02-20 12:34:30,893 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode3_1  | 2023-02-20 12:34:30,905 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode3_1  | 2023-02-20 12:34:30,905 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode3_1  | 2023-02-20 12:34:30,905 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode3_1  | 2023-02-20 12:34:31,436 [Thread-8] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode3_1  | 2023-02-20 12:34:31,445 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode3_1  | 2023-02-20 12:34:39,792 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode3_1  | 2023-02-20 12:34:42,266 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
datanode3_1  | 2023-02-20 12:34:42,431 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig1-
datanode3_1  | 2023-02-20 12:34:42,997 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode3_1  | 2023-02-20 12:34:43,791 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode3_1  | 2023-02-20 12:34:45,124 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode3_1  | 2023-02-20 12:34:45,167 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode3_1  | 2023-02-20 12:34:45,183 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode3_1  | 2023-02-20 12:34:45,192 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode3_1  | 2023-02-20 12:34:45,203 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode3_1  | 2023-02-20 12:34:45,209 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode3_1  | 2023-02-20 12:34:45,226 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode3_1  | 2023-02-20 12:34:45,286 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2023-02-20 12:34:45,307 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
datanode3_1  | 2023-02-20 12:34:45,334 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode3_1  | 2023-02-20 12:34:45,666 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
kdc_1        | Feb 20 12:33:14 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.118: ISSUE: authtime 1676896394, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:33:17 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1676896397, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:33:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.118: ISSUE: authtime 1676896394, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:33:55 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.103: ISSUE: authtime 1676896435, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:33:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1676896397, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:33:55 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.102: ISSUE: authtime 1676896435, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:33:56 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.104: ISSUE: authtime 1676896436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:34:02 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1676896442, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:34:02 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1676896442, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:34:03 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1676896443, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:34:06 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.25.0.116: ISSUE: authtime 1676896446, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:34:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1676896442, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:34:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1676896442, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:34:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1676896443, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:34:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1676896435, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:34:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1676896435, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:34:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1676896436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:34:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.103: ISSUE: authtime 1676896435, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Feb 20 12:35:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.102: ISSUE: authtime 1676896435, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Feb 20 12:35:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.104: ISSUE: authtime 1676896436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1        | Feb 20 12:35:13 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.112: ISSUE: authtime 1676896513, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:35:14 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.111: ISSUE: authtime 1676896514, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:35:18 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.25.0.113: ISSUE: authtime 1676896518, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1        | Feb 20 12:35:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.112: ISSUE: authtime 1676896513, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:35:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.111: ISSUE: authtime 1676896514, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:35:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.116: ISSUE: authtime 1676896446, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1        | Feb 20 12:35:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.25.0.113: ISSUE: authtime 1676896518, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:354)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:866)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode2_1  | 2023-02-20 12:35:33,216 [grpc-default-executor-3] WARN server.GrpcServerProtocolService: f342a5db-4e7d-4274-be79-8b926a9a2f90: Failed requestVote d23baa5b-5f7e-4a50-8199-73003befd3af->f342a5db-4e7d-4274-be79-8b926a9a2f90#0
datanode2_1  | org.apache.ratis.protocol.exceptions.GroupMismatchException: f342a5db-4e7d-4274-be79-8b926a9a2f90: group-B4FB3CA8A87D not found.
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:360)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:355)
datanode2_1  | 	at org.apache.ratis.server.impl.RaftServerProxy.requestVote(RaftServerProxy.java:618)
datanode2_1  | 	at org.apache.ratis.grpc.server.GrpcServerProtocolService.requestVote(GrpcServerProtocolService.java:175)
datanode2_1  | 	at org.apache.ratis.proto.grpc.RaftServerProtocolServiceGrpc$MethodHandlers.invoke(RaftServerProtocolServiceGrpc.java:382)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:354)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:866)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
datanode2_1  | 	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode2_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode2_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode2_1  | 2023-02-20 12:35:33,633 [grpc-default-executor-1] INFO server.RaftServer: f342a5db-4e7d-4274-be79-8b926a9a2f90: addNew group-B4FB3CA8A87D:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER] returns group-B4FB3CA8A87D:java.util.concurrent.CompletableFuture@3f025d1e[Not completed]
datanode2_1  | 2023-02-20 12:35:34,225 [pool-24-thread-1] INFO server.RaftServer$Division: f342a5db-4e7d-4274-be79-8b926a9a2f90: new RaftServerImpl for group-B4FB3CA8A87D:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode2_1  | 2023-02-20 12:35:34,244 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode2_1  | 2023-02-20 12:35:34,257 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode2_1  | 2023-02-20 12:35:34,258 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2023-02-20 12:35:19,814 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2023-02-20 12:35:19,816 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2023-02-20 12:35:19,997 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2023-02-20 12:35:20,024 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2023-02-20 12:35:20,283 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2023-02-20 12:35:20,284 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode1_1  | 2023-02-20 12:35:20,288 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2023-02-20 12:35:20,425 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2023-02-20 12:35:20,428 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2023-02-20 12:35:20,484 [pool-24-thread-1] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4: start as a follower, conf=-1: peers:[8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2023-02-20 12:35:20,486 [pool-24-thread-1] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2023-02-20 12:35:20,488 [pool-24-thread-1] INFO impl.RoleInfo: 8dd306ed-03df-465a-901a-3b76553ce2f1: start 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-FollowerState
datanode1_1  | 2023-02-20 12:35:20,532 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B1BEB74BCBD4,id=8dd306ed-03df-465a-901a-3b76553ce2f1
datanode1_1  | 2023-02-20 12:35:20,542 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2023-02-20 12:35:20,542 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2023-02-20 12:35:20,550 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2023-02-20 12:35:20,552 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2023-02-20 12:35:20,554 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2023-02-20 12:35:20,562 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2023-02-20 12:35:20,811 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=fb10096d-83bf-4df3-bd31-b1beb74bcbd4
datanode1_1  | 2023-02-20 12:35:20,851 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=fb10096d-83bf-4df3-bd31-b1beb74bcbd4.
datanode1_1  | 2023-02-20 12:35:20,864 [Command processor thread] INFO server.RaftServer: 8dd306ed-03df-465a-901a-3b76553ce2f1: addNew group-B4FB3CA8A87D:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER] returns group-B4FB3CA8A87D:java.util.concurrent.CompletableFuture@19651fcf[Not completed]
datanode1_1  | 2023-02-20 12:35:20,938 [pool-24-thread-1] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1: new RaftServerImpl for group-B4FB3CA8A87D:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode1_1  | 2023-02-20 12:35:20,942 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode1_1  | 2023-02-20 12:35:20,943 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode1_1  | 2023-02-20 12:35:20,944 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode1_1  | 2023-02-20 12:35:20,945 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode1_1  | 2023-02-20 12:35:20,948 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode1_1  | 2023-02-20 12:35:20,948 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode1_1  | 2023-02-20 12:35:20,949 [pool-24-thread-1] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D: ConfigurationManager, init=-1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode1_1  | 2023-02-20 12:35:20,959 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode1_1  | 2023-02-20 12:35:20,963 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode1_1  | 2023-02-20 12:35:20,963 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode1_1  | 2023-02-20 12:35:20,965 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode1_1  | 2023-02-20 12:35:20,966 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode1_1  | 2023-02-20 12:35:20,967 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode1_1  | 2023-02-20 12:35:20,978 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode1_1  | 2023-02-20 12:35:20,985 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode1_1  | 2023-02-20 12:35:20,985 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode1_1  | 2023-02-20 12:35:20,987 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode1_1  | 2023-02-20 12:35:20,988 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode1_1  | 2023-02-20 12:35:20,989 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d does not exist. Creating ...
datanode1_1  | 2023-02-20 12:35:20,992 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d/in_use.lock acquired by nodename 7@6b48ece71e49
datanode1_1  | 2023-02-20 12:35:20,997 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d has been successfully formatted.
datanode1_1  | 2023-02-20 12:35:21,003 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-B4FB3CA8A87D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode1_1  | 2023-02-20 12:35:21,004 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode1_1  | 2023-02-20 12:35:21,073 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode1_1  | 2023-02-20 12:35:21,076 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2023-02-20 12:35:21,078 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode1_1  | 2023-02-20 12:35:21,079 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode1_1  | 2023-02-20 12:35:21,095 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2023-02-20 12:35:21,101 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode1_1  | 2023-02-20 12:35:21,113 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode1_1  | 2023-02-20 12:35:21,115 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d
datanode1_1  | 2023-02-20 12:35:21,117 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode1_1  | 2023-02-20 12:35:21,117 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode1_1  | 2023-02-20 12:35:21,118 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode1_1  | 2023-02-20 12:35:21,120 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode1_1  | 2023-02-20 12:35:21,121 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode1_1  | 2023-02-20 12:35:21,123 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode1_1  | 2023-02-20 12:35:21,144 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode1_1  | 2023-02-20 12:35:21,144 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode1_1  | 2023-02-20 12:35:21,162 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode1_1  | 2023-02-20 12:35:21,172 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode1_1  | 2023-02-20 12:35:22,426 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-8dd306ed-03df-465a-901a-3b76553ce2f1: Detected pause in JVM or host machine (eg GC): pause of approximately 1056062051ns.
datanode1_1  | GC pool 'ParNew' had collection(s): count=1 time=153ms
datanode1_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=1094ms
datanode1_1  | 2023-02-20 12:35:22,499 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode1_1  | 2023-02-20 12:35:22,500 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode1_1  | 2023-02-20 12:35:22,502 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode1_1  | 2023-02-20 12:35:22,504 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode1_1  | 2023-02-20 12:35:22,504 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode1_1  | 2023-02-20 12:35:22,519 [pool-24-thread-1] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D: start as a follower, conf=-1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2023-02-20 12:35:22,523 [pool-24-thread-1] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode1_1  | 2023-02-20 12:35:22,540 [pool-24-thread-1] INFO impl.RoleInfo: 8dd306ed-03df-465a-901a-3b76553ce2f1: start 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-FollowerState
datanode1_1  | 2023-02-20 12:35:22,547 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2023-02-20 12:35:22,561 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B4FB3CA8A87D,id=8dd306ed-03df-465a-901a-3b76553ce2f1
datanode1_1  | 2023-02-20 12:35:22,561 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2023-02-20 12:35:22,568 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode1_1  | 2023-02-20 12:35:22,568 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode1_1  | 2023-02-20 12:35:22,569 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode1_1  | 2023-02-20 12:35:22,569 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode1_1  | 2023-02-20 12:35:22,582 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d
datanode1_1  | 2023-02-20 12:35:22,635 [Command processor thread] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig2-
datanode2_1  | 2023-02-20 12:35:34,260 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode2_1  | 2023-02-20 12:35:34,262 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode2_1  | 2023-02-20 12:35:34,265 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode2_1  | 2023-02-20 12:35:34,407 [pool-24-thread-1] INFO server.RaftServer$Division: f342a5db-4e7d-4274-be79-8b926a9a2f90@group-B4FB3CA8A87D: ConfigurationManager, init=-1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode2_1  | 2023-02-20 12:35:34,407 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode2_1  | 2023-02-20 12:35:34,581 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode2_1  | 2023-02-20 12:35:34,621 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode2_1  | 2023-02-20 12:35:34,961 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode2_1  | 2023-02-20 12:35:35,072 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode2_1  | 2023-02-20 12:35:35,101 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
kms_1        | Sleeping for 5 seconds
kms_1        | WARNING: /opt/hadoop/temp does not exist. Creating.
om1_1        | Sleeping for 5 seconds
om1_1        | Waiting for the service scm3.org:9894
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2023-02-20 12:33:43,159 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = [--init]
om1_1        | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/joda-time-2.10.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2023-02-20 12:33:43,303 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2023-02-20 12:33:54,729 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2023-02-20 12:33:59,712 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2023-02-20 12:34:00,523 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2023-02-20 12:34:00,528 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2023-02-20 12:34:00,529 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2023-02-20 12:34:03,358 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2023-02-20 12:34:03,362 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2023-02-20 12:34:03,478 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2023-02-20 12:34:05,677 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1;layoutVersion=3
om1_1        | 2023-02-20 12:34:10,325 [main] INFO om.OzoneManager: OM storage initialized. Initializing security
om1_1        | 2023-02-20 12:34:10,325 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om1_1        | 2023-02-20 12:34:17,003 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2023-02-20 12:34:17,088 [main] ERROR security.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om1_1        | 2023-02-20 12:34:17,104 [main] INFO security.OMCertificateClient: Certificate client init case: 0
om1_1        | 2023-02-20 12:34:17,112 [main] INFO security.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om1_1        | 2023-02-20 12:34:26,083 [main] INFO om.OzoneManager: Init response: GETCERT
om1_1        | 2023-02-20 12:34:26,479 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.111,host:om1
om1_1        | 2023-02-20 12:34:26,480 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om1_1        | 2023-02-20 12:34:26,506 [main] ERROR security.OMCertificateClient: Invalid domain om1
om1_1        | 2023-02-20 12:34:26,520 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2023-02-20 12:34:26,543 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2023-02-20 12:34:26,543 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2023-02-20 12:34:26,606 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2023-02-20 12:34:26,659 [main] INFO security.OMCertificateClient: Creating csr for OM->dns:om1,ip:172.25.0.111,scmId:71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,clusterId:CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1,subject:om1
om1_1        | 2023-02-20 12:34:31,782 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om1_1        | 2023-02-20 12:34:31,918 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om1_1        | /************************************************************
om1_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om1/172.25.0.111
om1_1        | ************************************************************/
om1_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om1_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om1_1        | 2023-02-20 12:34:50,179 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om1_1        | /************************************************************
om1_1        | STARTUP_MSG: Starting OzoneManager
om1_1        | STARTUP_MSG:   host = om1/172.25.0.111
om1_1        | STARTUP_MSG:   args = []
om1_1        | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
datanode3_1  | 2023-02-20 12:34:45,700 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode3_1  | 2023-02-20 12:34:45,721 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode3_1  | 2023-02-20 12:34:55,684 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
datanode3_1  | 2023-02-20 12:34:55,707 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode3_1  | 2023-02-20 12:34:55,713 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode3_1  | 2023-02-20 12:34:55,720 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2023-02-20 12:34:55,720 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2023-02-20 12:34:55,756 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2023-02-20 12:34:56,316 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER KeyStore reloading at 60000 millis.
datanode3_1  | 2023-02-20 12:34:56,395 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER TrustStore reloading at 60000 millis.
datanode3_1  | 2023-02-20 12:34:56,504 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode3_1  | 2023-02-20 12:34:58,546 [main] INFO token.OzoneBlockTokenSecretManager: Updating current master key for generating tokens. Cert id 1631425044085
datanode3_1  | 2023-02-20 12:34:58,615 [main] INFO token.ContainerTokenSecretManager: Updating current master key for generating tokens. Cert id 1631425044085
datanode3_1  | 2023-02-20 12:34:59,645 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode3_1  | 2023-02-20 12:34:59,671 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode3_1  | 2023-02-20 12:34:59,671 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode3_1  | 2023-02-20 12:35:00,253 [main] INFO util.log: Logging initialized @93601ms to org.eclipse.jetty.util.log.Slf4jLog
datanode3_1  | 2023-02-20 12:35:02,035 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode3_1  | 2023-02-20 12:35:02,213 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode3_1  | 2023-02-20 12:35:02,251 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode3_1  | 2023-02-20 12:35:02,252 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode3_1  | 2023-02-20 12:35:02,259 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode3_1  | 2023-02-20 12:35:02,262 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode3_1  | 2023-02-20 12:35:03,079 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode3_1  | 2023-02-20 12:35:03,108 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode3_1  | 2023-02-20 12:35:03,595 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode3_1  | 2023-02-20 12:35:03,595 [main] INFO server.session: No SessionScavenger set, using defaults
datanode3_1  | 2023-02-20 12:35:03,647 [main] INFO server.session: node0 Scavenging every 660000ms
datanode3_1  | 2023-02-20 12:35:04,048 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2023-02-20 12:35:04,089 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7ae5f795{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode3_1  | 2023-02-20 12:35:04,107 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@20c7a91d{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode3_1  | 2023-02-20 12:35:05,521 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/db@EXAMPLE.COM
datanode3_1  | 2023-02-20 12:35:05,732 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@28068327{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-6213256586198492563/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode3_1  | 2023-02-20 12:35:05,872 [main] INFO server.AbstractConnector: Started ServerConnector@33c590{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode3_1  | 2023-02-20 12:35:05,874 [main] INFO server.Server: Started @99223ms
datanode3_1  | 2023-02-20 12:35:05,972 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode3_1  | 2023-02-20 12:35:05,973 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode3_1  | 2023-02-20 12:35:05,990 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode3_1  | 2023-02-20 12:35:06,084 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode3_1  | 2023-02-20 12:35:06,583 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c4ba0cd] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode3_1  | 2023-02-20 12:35:08,265 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.25.0.115:9891
datanode3_1  | 2023-02-20 12:35:08,348 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode3_1  | 2023-02-20 12:35:10,895 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO utils.DatanodeStoreCache: Added db /data/hdds/hdds/CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/DS-69e8fb93-1df4-4a0b-99c6-7a59c0f76e20/container.db to cache
datanode3_1  | 2023-02-20 12:35:10,898 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/DS-69e8fb93-1df4-4a0b-99c6-7a59c0f76e20/container.db for volume DS-69e8fb93-1df4-4a0b-99c6-7a59c0f76e20
datanode3_1  | 2023-02-20 12:35:10,928 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode3_1  | 2023-02-20 12:35:10,995 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Scheduled background container scanners and the on-demand container scanner have been disabled.
datanode3_1  | 2023-02-20 12:35:12,448 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO replication.ReplicationServer: ReplicationServer is started using port 9886
datanode3_1  | 2023-02-20 12:35:12,487 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis d23baa5b-5f7e-4a50-8199-73003befd3af
datanode3_1  | 2023-02-20 12:35:12,795 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.RaftServer: d23baa5b-5f7e-4a50-8199-73003befd3af: start RPC server
datanode3_1  | 2023-02-20 12:35:12,814 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: d23baa5b-5f7e-4a50-8199-73003befd3af: GrpcService started, listening on 9858
datanode1_1  | 2023-02-20 12:35:25,682 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-FollowerState] INFO impl.FollowerState: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5193750211ns, electionTimeout:5138ms
datanode1_1  | 2023-02-20 12:35:25,683 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-FollowerState] INFO impl.RoleInfo: 8dd306ed-03df-465a-901a-3b76553ce2f1: shutdown 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-FollowerState
datanode1_1  | 2023-02-20 12:35:25,698 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-FollowerState] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2023-02-20 12:35:25,740 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
datanode1_1  | 2023-02-20 12:35:25,742 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-FollowerState] INFO impl.RoleInfo: 8dd306ed-03df-465a-901a-3b76553ce2f1: start 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1
datanode1_1  | 2023-02-20 12:35:25,785 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO impl.LeaderElection: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2023-02-20 12:35:25,794 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO impl.LeaderElection: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
datanode1_1  | 2023-02-20 12:35:25,819 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO impl.LeaderElection: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2023-02-20 12:35:25,819 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO impl.LeaderElection: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode1_1  | 2023-02-20 12:35:25,826 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO impl.RoleInfo: 8dd306ed-03df-465a-901a-3b76553ce2f1: shutdown 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1
datanode1_1  | 2023-02-20 12:35:25,830 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode1_1  | 2023-02-20 12:35:25,833 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-B1BEB74BCBD4 with new leaderId: 8dd306ed-03df-465a-901a-3b76553ce2f1
datanode1_1  | 2023-02-20 12:35:25,924 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4: change Leader from null to 8dd306ed-03df-465a-901a-3b76553ce2f1 at term 1 for becomeLeader, leader elected after 7293ms
datanode1_1  | 2023-02-20 12:35:26,029 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode1_1  | 2023-02-20 12:35:26,131 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2023-02-20 12:35:26,143 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode1_1  | 2023-02-20 12:35:26,282 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode1_1  | 2023-02-20 12:35:26,285 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode1_1  | 2023-02-20 12:35:26,286 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode1_1  | 2023-02-20 12:35:26,417 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode1_1  | 2023-02-20 12:35:26,475 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode1_1  | 2023-02-20 12:35:26,571 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO impl.RoleInfo: 8dd306ed-03df-465a-901a-3b76553ce2f1: start 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderStateImpl
datanode1_1  | 2023-02-20 12:35:26,999 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-SegmentedRaftLogWorker: Starting segment from index:0
datanode1_1  | 2023-02-20 12:35:27,580 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-FollowerState] INFO impl.FollowerState: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5048020206ns, electionTimeout:5018ms
datanode1_1  | 2023-02-20 12:35:27,581 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-FollowerState] INFO impl.RoleInfo: 8dd306ed-03df-465a-901a-3b76553ce2f1: shutdown 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-FollowerState
datanode1_1  | 2023-02-20 12:35:27,589 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-FollowerState] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode1_1  | 2023-02-20 12:35:27,590 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
datanode1_1  | 2023-02-20 12:35:27,590 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-FollowerState] INFO impl.RoleInfo: 8dd306ed-03df-465a-901a-3b76553ce2f1: start 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-LeaderElection2
datanode1_1  | 2023-02-20 12:35:27,736 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-LeaderElection2] INFO impl.LeaderElection: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-LeaderElection2 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2023-02-20 12:35:27,850 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-LeaderElection1] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4: set configuration 0: peers:[8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2023-02-20 12:35:27,935 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2023-02-20 12:35:27,993 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2023-02-20 12:35:27,999 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-LeaderElection2-1] INFO server.GrpcServerProtocolClient: Build channel for d23baa5b-5f7e-4a50-8199-73003befd3af
datanode1_1  | 2023-02-20 12:35:28,000 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-LeaderElection2-2] INFO server.GrpcServerProtocolClient: Build channel for f342a5db-4e7d-4274-be79-8b926a9a2f90
datanode1_1  | 2023-02-20 12:35:29,736 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-8dd306ed-03df-465a-901a-3b76553ce2f1: Detected pause in JVM or host machine (eg GC): pause of approximately 752401662ns.
datanode1_1  | GC pool 'ParNew' had collection(s): count=1 time=1013ms
datanode1_1  | 2023-02-20 12:35:30,640 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B1BEB74BCBD4-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/fb10096d-83bf-4df3-bd31-b1beb74bcbd4/current/log_inprogress_0
datanode1_1  | 2023-02-20 12:35:33,073 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-LeaderElection2] INFO impl.LeaderElection: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-LeaderElection2: PRE_VOTE TIMEOUT received 0 response(s) and 0 exception(s):
datanode1_1  | 2023-02-20 12:35:33,081 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-LeaderElection2] INFO impl.LeaderElection: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-LeaderElection2 PRE_VOTE round 0: result TIMEOUT
datanode1_1  | 2023-02-20 12:35:33,081 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-LeaderElection2] INFO impl.LeaderElection: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-LeaderElection2 PRE_VOTE round 1: submit vote requests at term 0 for -1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2023-02-20 12:35:33,109 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode1_1  | 2023-02-20 12:35:33,191 [8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode1_1  | 2023-02-20 12:35:34,291 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D: receive requestVote(PRE_VOTE, d23baa5b-5f7e-4a50-8199-73003befd3af, group-B4FB3CA8A87D, 0, (t:0, i:0))
datanode1_1  | 2023-02-20 12:35:34,300 [grpc-default-executor-1] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D: receive requestVote(PRE_VOTE, d23baa5b-5f7e-4a50-8199-73003befd3af, group-B4FB3CA8A87D, 0, (t:0, i:0))
datanode1_1  | 2023-02-20 12:35:34,369 [grpc-default-executor-1] INFO impl.VoteContext: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-CANDIDATE: accept PRE_VOTE from d23baa5b-5f7e-4a50-8199-73003befd3af: our priority 0 <= candidate's priority 0
datanode1_1  | 2023-02-20 12:35:34,776 [grpc-default-executor-1] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D replies to PRE_VOTE vote request: d23baa5b-5f7e-4a50-8199-73003befd3af<-8dd306ed-03df-465a-901a-3b76553ce2f1#0:OK-t0. Peer's state: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D:t0, leader=null, voted=, raftlog=Memoized:8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode1_1  | 2023-02-20 12:35:34,791 [grpc-default-executor-0] INFO impl.VoteContext: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-CANDIDATE: accept PRE_VOTE from d23baa5b-5f7e-4a50-8199-73003befd3af: our priority 0 <= candidate's priority 0
datanode1_1  | 2023-02-20 12:35:34,805 [grpc-default-executor-0] INFO server.RaftServer$Division: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D replies to PRE_VOTE vote request: d23baa5b-5f7e-4a50-8199-73003befd3af<-8dd306ed-03df-465a-901a-3b76553ce2f1#0:OK-t0. Peer's state: 8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D:t0, leader=null, voted=, raftlog=Memoized:8dd306ed-03df-465a-901a-3b76553ce2f1@group-B4FB3CA8A87D-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2023-02-20 12:35:12,829 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: d23baa5b-5f7e-4a50-8199-73003befd3af: GrpcService started, listening on 9856
datanode3_1  | 2023-02-20 12:35:12,839 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO server.GrpcService: d23baa5b-5f7e-4a50-8199-73003befd3af: GrpcService started, listening on 9857
datanode3_1  | 2023-02-20 12:35:12,861 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis d23baa5b-5f7e-4a50-8199-73003befd3af is started using port 9858 for RATIS
datanode3_1  | 2023-02-20 12:35:12,864 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis d23baa5b-5f7e-4a50-8199-73003befd3af is started using port 9857 for RATIS_ADMIN
datanode3_1  | 2023-02-20 12:35:12,864 [EndpointStateMachine task thread for scm2.org/172.25.0.117:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis d23baa5b-5f7e-4a50-8199-73003befd3af is started using port 9856 for RATIS_SERVER
datanode3_1  | 2023-02-20 12:35:12,922 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-d23baa5b-5f7e-4a50-8199-73003befd3af: Started
datanode3_1  | 2023-02-20 12:35:13,106 [EndpointStateMachine task thread for scm1.org/172.25.0.116:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2023-02-20 12:35:13,107 [EndpointStateMachine task thread for scm3.org/172.25.0.118:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Ignore. OzoneContainer already started.
datanode3_1  | 2023-02-20 12:35:18,281 [Command processor thread] INFO server.RaftServer: d23baa5b-5f7e-4a50-8199-73003befd3af: addNew group-2ABA89790566:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:1|startupRole:FOLLOWER] returns group-2ABA89790566:java.util.concurrent.CompletableFuture@343dd734[Not completed]
datanode3_1  | 2023-02-20 12:35:18,485 [pool-24-thread-1] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af: new RaftServerImpl for group-2ABA89790566:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode3_1  | 2023-02-20 12:35:18,508 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2023-02-20 12:35:18,513 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2023-02-20 12:35:18,514 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2023-02-20 12:35:18,517 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2023-02-20 12:35:18,521 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2023-02-20 12:35:18,521 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2023-02-20 12:35:18,618 [pool-24-thread-1] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566: ConfigurationManager, init=-1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2023-02-20 12:35:18,622 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2023-02-20 12:35:18,683 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2023-02-20 12:35:18,688 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2023-02-20 12:35:18,790 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2023-02-20 12:35:18,832 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2023-02-20 12:35:18,844 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2023-02-20 12:35:19,435 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2023-02-20 12:35:19,440 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2023-02-20 12:35:19,443 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2023-02-20 12:35:19,448 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2023-02-20 12:35:19,453 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2023-02-20 12:35:19,458 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4315d5f4-40b0-4520-b2d0-2aba89790566 does not exist. Creating ...
datanode3_1  | 2023-02-20 12:35:19,497 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4315d5f4-40b0-4520-b2d0-2aba89790566/in_use.lock acquired by nodename 7@0932752dfb54
datanode3_1  | 2023-02-20 12:35:19,551 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4315d5f4-40b0-4520-b2d0-2aba89790566 has been successfully formatted.
datanode3_1  | 2023-02-20 12:35:19,669 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-2ABA89790566: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2023-02-20 12:35:19,730 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2023-02-20 12:35:20,008 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2023-02-20 12:35:20,008 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2023-02-20 12:35:20,111 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2023-02-20 12:35:20,122 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode3_1  | 2023-02-20 12:35:20,197 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2023-02-20 12:35:20,255 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2023-02-20 12:35:20,283 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2023-02-20 12:35:20,322 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/4315d5f4-40b0-4520-b2d0-2aba89790566
datanode3_1  | 2023-02-20 12:35:20,343 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2023-02-20 12:35:20,347 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2023-02-20 12:35:20,348 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2023-02-20 12:35:20,372 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2023-02-20 12:35:20,372 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om1_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/joda-time-2.10.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar
om1_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
om1_1        | STARTUP_MSG:   java = 11.0.14.1
om1_1        | ************************************************************/
om1_1        | 2023-02-20 12:34:50,350 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om1_1        | 2023-02-20 12:35:02,277 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om1_1        | 2023-02-20 12:35:07,817 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om1_1        | 2023-02-20 12:35:08,873 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om1, RPC Address: om1:9862 and Ratis port: 9872
om1_1        | 2023-02-20 12:35:08,874 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om1: om1
om1_1        | 2023-02-20 12:35:08,882 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om1: om1
om1_1        | 2023-02-20 12:35:09,081 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2023-02-20 12:35:10,145 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om1_1        | 2023-02-20 12:35:12,933 [main] INFO reflections.Reflections: Reflections took 2096 ms to scan 1 urls, producing 125 keys and 363 values [using 2 cores]
om1_1        | 2023-02-20 12:35:14,918 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om1_1        | 2023-02-20 12:35:14,918 [main] INFO om.OzoneManager: Ozone Manager login successful.
om1_1        | 2023-02-20 12:35:14,919 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2023-02-20 12:35:18,486 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2023-02-20 12:35:19,437 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om1_1        | 2023-02-20 12:35:28,216 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om1_1        | value: 9862
om1_1        | ]
om1_1        | 2023-02-20 12:35:28,287 [main] INFO security.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om1_1        | 2023-02-20 12:35:30,324 [main] INFO security.OMCertificateClient: Added certificate   [0]         Version: 3
om1_1        |          SerialNumber: 1
om1_1        |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
om1_1        |            Start Date: Mon Feb 20 00:00:00 UTC 2023
om1_1        |            Final Date: Thu Mar 30 00:00:00 UTC 2028
om1_1        |             SubjectDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
om1_1        |            Public Key: RSA Public Key [94:7e:a6:1e:66:03:60:cb:31:b6:ba:58:09:e5:6f:61:c6:1f:10:56],[56:66:d1:a4]
om1_1        |         modulus: ae4c68b294de9bde416e48f8dd880f73587515c06076bc726de72d7d0efa633c8ab0845ecaa9dfe2be73479c31abedba80a9108027262a3316511997768cdb340fdcb173084f830287356e335877580b2bd5bdc297d7572a3635e6a114294f82bfb68aec57278d80b2e053741f6bd8e43df4c302f807657c2cd83c55edafc9fedddc555b306c6720e2e72e1a403ac6fa6a0b45823767e96cbe34c0ee95838730daf28e939192b29222957ccd58032a49c0446c773bb8ccc080bc6d017e13b3470c1f732b571f7ae50833d9852f4af92799f9b8c5eaec9c998c13768e6e1efd686c4d209f1d79c8d4f12aa2f5821e96eff58d7f8e4bf5877811957c77adb800e7
om1_1        | public exponent: 10001
om1_1        | 
om1_1        |   Signature Algorithm: SHA256WITHRSA
om1_1        |             Signature: a7cea6946dc4cec2c98cb07c07498d5444b6300d
om1_1        |                        0a6c4e9490adf7093c90271931b5d0417975d9b8
om1_1        |                        7a9238465c6f3f4de8400309865e2da81ad21b31
om1_1        |                        57de65cb86c13fbef66ec87c8614bd8ad650e11d
om1_1        |                        4e49b0e20080ff8a0c3d6a6e6cef0122f38fbedc
om1_1        |                        9428a9b69ae6258d8ff4035af00ec4326a833057
om1_1        |                        736e2bec20eba55b3e39bd1818d036b10a473b2e
om1_1        |                        99f5e8079f4fcaa7750269bdb7680ebf53d8f7bb
om1_1        |                        16ddc0ef7ac8c2bd9f938901391f3d9e4f3823e1
om1_1        |                        07939f9a9f829615d2d1f339e2f210e795258ac1
om1_1        |                        f03a273f30f7cb3110f6d700ded1888ed1dcaa17
om1_1        |                        ff9774e9f4d33a5be09b76c57503b7a066668066
om1_1        |                        4c46b6c92c5c84d4978c557861c07dba
om1_1        |        Extensions: 
om1_1        |                        critical(true) BasicConstraints: isCa(true)
om1_1        |                        critical(true) KeyUsage: 0x6
om1_1        |                        critical(false) 2.5.29.17 value = Sequence
om1_1        |     Tagged [7] IMPLICIT 
om1_1        |         DER Octet String[4] 
om1_1        |     Tagged [2] IMPLICIT 
om1_1        |         DER Octet String[8] 
om1_1        | 
om1_1        |  from file:/data/metadata/om/certs/ROOTCA-1.crt.
om1_1        | 2023-02-20 12:35:30,378 [main] INFO security.OMCertificateClient: Added certificate   [0]         Version: 3
om1_1        |          SerialNumber: 1639667245938
om1_1        |              IssuerDN: CN=scm-sub@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
om1_1        |            Start Date: Mon Feb 20 00:00:00 UTC 2023
om1_1        |            Final Date: Tue Feb 20 00:00:00 UTC 2024
om1_1        |             SubjectDN: CN=om1,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
om1_1        |            Public Key: RSA Public Key [2c:f9:6b:f4:e2:44:28:e8:e1:dc:96:07:3a:b4:1e:2c:08:70:c5:ed],[56:66:d1:a4]
om1_1        |         modulus: aeacfe4bedfe5abfcc36910f9034aaa9ec7c6bf425d774b083eef9959d0849ab7e3a21f57c59d5d31fd96cfbd7a801676ce16b3fa6b1224287a8677b34bd338c6a70467419d1993480dfca55338488b96637b7b01371e436c01481ff88057f515dce9f5adfc87c1601610349ec24816a08f67e35d14b25544bd0432ea1026f8f3b84147f6c324ef1a36a447a3642da288ef683c87ee2aa56dd5490412e2b7cd7ca8ca008ee41e22639cf3250d6a030f4d165c5641b772c19180ec98ec5a28e657333adca579394b07cb3632dac685f97c137b5741cbb66403514ce12870098b4652b186971c4fa58a501fef90e2bd246d001c005e498e36c551f5fada2f4a92d
om1_1        | public exponent: 10001
om1_1        | 
om1_1        |   Signature Algorithm: SHA256WITHRSA
om1_1        |             Signature: 5518e2c0474f4996829b917f3bfd5ff73851dcab
om1_1        |                        2aaa7b868af40226c19552941dbbf1e6e9a9c599
om1_1        |                        da9c7b3b9515cb2145427d5951b88c8326672e5c
om1_1        |                        3a6d86b54fa097e958cb6bba812de0fd40d9ba28
om1_1        |                        42d521ed507ed3ce49805b0f23946b57ced69f3d
om1_1        |                        7572043d0c1c7b14d3a6f85e21e6fd736cfc97c6
om1_1        |                        a9e44dfacc2aef47700948070be8e2a6fec4a652
om1_1        |                        edceb9ff0fe06e39024db4f6a09b6795486dbb40
om1_1        |                        1fa155385fb4d29c06b40d3a3c611b0acae7cd98
om1_1        |                        cf7b96978e151b9e35fbf263893d30726d3fc4f8
om1_1        |                        982f22831d41b3b72c2d78fedc725451886c6e17
om1_1        |                        4bae0c1e5f09eba6123526b007188add0d7c898c
om1_1        |                        c11237033215dd184c46e4ecccf115ae
om1_1        |        Extensions: 
om1_1        |                        critical(false) 2.5.29.17 value = Sequence
om1_1        |     Tagged [7] IMPLICIT 
om1_1        |         DER Octet String[4] 
om1_1        |     Tagged [0] IMPLICIT 
om1_1        |         Sequence
om1_1        |             ObjectIdentifier(2.16.840.1.113730.3.1.34)
om1_1        |             Tagged [0]
om1_1        |                 UTF8String(id1) 
om1_1        | 
om1_1        |                        critical(true) KeyUsage: 0xb8
om1_1        |  from file:/data/metadata/om/certs/1639667245938.crt.
om1_1        | 2023-02-20 12:35:30,414 [main] INFO security.OMCertificateClient: Added certificate   [0]         Version: 3
om1_1        |          SerialNumber: 1490022441527
om1_1        |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
om1_1        |            Start Date: Mon Feb 20 00:00:00 UTC 2023
om1_1        |            Final Date: Thu Mar 30 00:00:00 UTC 2028
om1_1        |             SubjectDN: CN=scm-sub@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
om1_1        |            Public Key: RSA Public Key [16:2d:b7:a5:b0:1c:7e:50:4b:d3:0c:1e:91:d5:30:6d:12:23:23:1c],[56:66:d1:a4]
om1_1        |         modulus: b8881b4dd07c72248c8863bba59686bc7d8a1c0a77f9587da66c7e69fd2912af0eb4b5ab9b5e2cccd38500bee6178abbf02f9c564eb57a3029da82d6fb08538545dd260393eac22764468b808f392fc0555b558cc274360ac207d0b693142fbc5fd801789ecb2aefa0cfb5b7bb92c107c453311fcd9590678300eed8335e7c2887ddadc75dd7fd24d77cdfffb2d01c2817abb555f59cc4ca8c520c785155f682252969d6f60ba724f524b233eba33397229e851534a97c7b9a743d4dd3ed30d92316c44aab2e8741a08ef02fcc96cb516c9e93342ba73692ddd39f254390ff523b588e0710edded5220b5301b85e914019771f8cbd758e861d99222494d387a7
om1_1        | public exponent: 10001
om1_1        | 
om1_1        |   Signature Algorithm: SHA256WITHRSA
om1_1        |             Signature: 363d3273c12aa64988005dd16cbf319b130f6b08
om1_1        |                        3ec325844d607b1225858823a3b417c8b78f8266
om1_1        |                        5338966c887d5ee760050f81da927bac7aafdda0
om1_1        |                        203c45d70e75f7f585632db643c276dcfc12d0cf
om1_1        |                        31d734300b15141e9c77a37edb550f41a3cc1a14
om1_1        |                        5e4b848617279f658ed62ed740017f1b4bd844c2
om1_1        |                        cdb757bfdef0058498c0b11f0c59d5c5c4a6fea2
om1_1        |                        e44d596ba23e9480406994c2d52d03fb603137d7
om1_1        |                        38b028409f31693a2c3fddbd689785b29f009d1f
om1_1        |                        b3b815a10f87cee8642a347f5b737ade5d2f2d7f
om1_1        |                        3a51aac93500a29b12e04ea17d3d823af05cedd3
om1_1        |                        737c196e3d25ee225340482ec1a717bf8f73b126
om1_1        |                        32165d626d85896b9c2f99ff029695f3
om1_1        |        Extensions: 
om1_1        |                        critical(false) 2.5.29.17 value = Sequence
om1_1        |     Tagged [7] IMPLICIT 
om1_1        |         DER Octet String[4] 
om1_1        |     Tagged [2] IMPLICIT 
om1_1        |         DER Octet String[8] 
om1_1        | 
om1_1        |                        critical(true) BasicConstraints: isCa(true)
om1_1        |                        critical(true) KeyUsage: 0xbe
om1_1        |  from file:/data/metadata/om/certs/CA-1490022441527.crt.
om1_1        | 2023-02-20 12:35:30,439 [main] INFO security.OMCertificateClient: CertificateLifetimeMonitor for om is started with first delay 29071469574 ms and interval 86400000 ms.
om1_1        | 2023-02-20 12:35:30,695 [main] INFO om.OzoneManager: OM start with adminUsers: [testuser/scm@EXAMPLE.COM, testuser/s3g@EXAMPLE.COM, recon/recon@EXAMPLE.COM, om/om1@EXAMPLE.COM, om/om2@EXAMPLE.COM, om/om3@EXAMPLE.COM, om]
om1_1        | 2023-02-20 12:35:31,094 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om1_1        | 2023-02-20 12:35:33,140 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om1_1        | 2023-02-20 12:35:33,148 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
datanode3_1  | 2023-02-20 12:35:20,378 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2023-02-20 12:35:20,388 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2023-02-20 12:35:20,389 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2023-02-20 12:35:20,482 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2023-02-20 12:35:20,510 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2023-02-20 12:35:20,649 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2023-02-20 12:35:20,654 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode3_1  | 2023-02-20 12:35:20,656 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2023-02-20 12:35:20,688 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2023-02-20 12:35:20,690 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2023-02-20 12:35:20,696 [pool-24-thread-1] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566: start as a follower, conf=-1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2023-02-20 12:35:20,698 [pool-24-thread-1] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2023-02-20 12:35:20,700 [pool-24-thread-1] INFO impl.RoleInfo: d23baa5b-5f7e-4a50-8199-73003befd3af: start d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-FollowerState
datanode3_1  | 2023-02-20 12:35:20,740 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2ABA89790566,id=d23baa5b-5f7e-4a50-8199-73003befd3af
datanode3_1  | 2023-02-20 12:35:20,743 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2023-02-20 12:35:20,745 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2023-02-20 12:35:20,760 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2023-02-20 12:35:20,765 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2023-02-20 12:35:20,772 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2023-02-20 12:35:20,783 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2023-02-20 12:35:21,014 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=4315d5f4-40b0-4520-b2d0-2aba89790566
datanode3_1  | 2023-02-20 12:35:21,028 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=4315d5f4-40b0-4520-b2d0-2aba89790566.
datanode3_1  | 2023-02-20 12:35:21,041 [Command processor thread] INFO server.RaftServer: d23baa5b-5f7e-4a50-8199-73003befd3af: addNew group-B4FB3CA8A87D:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER] returns group-B4FB3CA8A87D:java.util.concurrent.CompletableFuture@1e637d81[Not completed]
datanode3_1  | 2023-02-20 12:35:21,121 [pool-24-thread-1] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af: new RaftServerImpl for group-B4FB3CA8A87D:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode3_1  | 2023-02-20 12:35:21,124 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode3_1  | 2023-02-20 12:35:21,126 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode3_1  | 2023-02-20 12:35:21,126 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode3_1  | 2023-02-20 12:35:21,130 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode3_1  | 2023-02-20 12:35:21,130 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode3_1  | 2023-02-20 12:35:21,133 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode3_1  | 2023-02-20 12:35:21,134 [pool-24-thread-1] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D: ConfigurationManager, init=-1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode3_1  | 2023-02-20 12:35:21,136 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode3_1  | 2023-02-20 12:35:21,138 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode3_1  | 2023-02-20 12:35:21,139 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode3_1  | 2023-02-20 12:35:21,140 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode3_1  | 2023-02-20 12:35:21,141 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode3_1  | 2023-02-20 12:35:21,144 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode3_1  | 2023-02-20 12:35:21,156 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode3_1  | 2023-02-20 12:35:21,156 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode3_1  | 2023-02-20 12:35:21,156 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode3_1  | 2023-02-20 12:35:21,159 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode3_1  | 2023-02-20 12:35:21,165 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode3_1  | 2023-02-20 12:35:21,165 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d does not exist. Creating ...
datanode3_1  | 2023-02-20 12:35:21,170 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d/in_use.lock acquired by nodename 7@0932752dfb54
datanode3_1  | 2023-02-20 12:35:21,176 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d has been successfully formatted.
datanode3_1  | 2023-02-20 12:35:21,176 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-B4FB3CA8A87D: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode3_1  | 2023-02-20 12:35:21,177 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode3_1  | 2023-02-20 12:35:21,226 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode3_1  | 2023-02-20 12:35:21,226 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2023-02-20 12:35:21,227 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode3_1  | 2023-02-20 12:35:21,227 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode3_1  | 2023-02-20 12:35:21,232 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2023-02-20 12:35:21,235 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode3_1  | 2023-02-20 12:35:21,241 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode3_1  | 2023-02-20 12:35:21,242 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d
datanode3_1  | 2023-02-20 12:35:21,242 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode3_1  | 2023-02-20 12:35:21,244 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode3_1  | 2023-02-20 12:35:21,244 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode3_1  | 2023-02-20 12:35:21,244 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode3_1  | 2023-02-20 12:35:21,245 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode3_1  | 2023-02-20 12:35:21,246 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode3_1  | 2023-02-20 12:35:21,247 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode3_1  | 2023-02-20 12:35:21,284 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode3_1  | 2023-02-20 12:35:21,295 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode3_1  | 2023-02-20 12:35:21,303 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode3_1  | 2023-02-20 12:35:22,415 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-d23baa5b-5f7e-4a50-8199-73003befd3af: Detected pause in JVM or host machine (eg GC): pause of approximately 879441658ns.
datanode3_1  | GC pool 'ParNew' had collection(s): count=1 time=102ms
datanode3_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=1001ms
datanode3_1  | 2023-02-20 12:35:22,437 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c4ba0cd] INFO util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1072ms
datanode3_1  | GC pool 'ParNew' had collection(s): count=1 time=102ms
datanode3_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=1001ms
datanode3_1  | 2023-02-20 12:35:22,477 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode3_1  | 2023-02-20 12:35:22,478 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode3_1  | 2023-02-20 12:35:22,499 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode3_1  | 2023-02-20 12:35:22,503 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode3_1  | 2023-02-20 12:35:22,510 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode3_1  | 2023-02-20 12:35:22,517 [pool-24-thread-1] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D: start as a follower, conf=-1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2023-02-20 12:35:22,517 [pool-24-thread-1] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode3_1  | 2023-02-20 12:35:22,518 [pool-24-thread-1] INFO impl.RoleInfo: d23baa5b-5f7e-4a50-8199-73003befd3af: start d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-FollowerState
datanode3_1  | 2023-02-20 12:35:22,519 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B4FB3CA8A87D,id=d23baa5b-5f7e-4a50-8199-73003befd3af
datanode3_1  | 2023-02-20 12:35:22,520 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode3_1  | 2023-02-20 12:35:22,520 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode3_1  | 2023-02-20 12:35:22,520 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode3_1  | 2023-02-20 12:35:22,520 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode3_1  | 2023-02-20 12:35:22,522 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2023-02-20 12:35:22,535 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2023-02-20 12:35:22,547 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d
datanode3_1  | 2023-02-20 12:35:22,751 [Command processor thread] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig2-
datanode3_1  | 2023-02-20 12:35:25,825 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-FollowerState] INFO impl.FollowerState: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5124674623ns, electionTimeout:5057ms
datanode3_1  | 2023-02-20 12:35:25,833 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-FollowerState] INFO impl.RoleInfo: d23baa5b-5f7e-4a50-8199-73003befd3af: shutdown d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-FollowerState
datanode3_1  | 2023-02-20 12:35:25,856 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-FollowerState] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2023-02-20 12:35:25,935 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
datanode3_1  | 2023-02-20 12:35:25,949 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-FollowerState] INFO impl.RoleInfo: d23baa5b-5f7e-4a50-8199-73003befd3af: start d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1
datanode3_1  | 2023-02-20 12:35:26,032 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO impl.LeaderElection: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2023-02-20 12:35:26,035 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO impl.LeaderElection: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
datanode3_1  | 2023-02-20 12:35:26,057 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO impl.LeaderElection: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2023-02-20 12:35:26,058 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO impl.LeaderElection: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode3_1  | 2023-02-20 12:35:26,060 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO impl.RoleInfo: d23baa5b-5f7e-4a50-8199-73003befd3af: shutdown d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1
datanode3_1  | 2023-02-20 12:35:26,063 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode3_1  | 2023-02-20 12:35:26,067 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-2ABA89790566 with new leaderId: d23baa5b-5f7e-4a50-8199-73003befd3af
datanode3_1  | 2023-02-20 12:35:26,116 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566: change Leader from null to d23baa5b-5f7e-4a50-8199-73003befd3af at term 1 for becomeLeader, leader elected after 7290ms
datanode3_1  | 2023-02-20 12:35:26,283 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode3_1  | 2023-02-20 12:35:26,407 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2023-02-20 12:35:26,422 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode3_1  | 2023-02-20 12:35:26,598 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode3_1  | 2023-02-20 12:35:26,599 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode3_1  | 2023-02-20 12:35:26,604 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode3_1  | 2023-02-20 12:35:26,795 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode3_1  | 2023-02-20 12:35:26,921 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode3_1  | 2023-02-20 12:35:27,061 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO impl.RoleInfo: d23baa5b-5f7e-4a50-8199-73003befd3af: start d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderStateImpl
datanode3_1  | 2023-02-20 12:35:27,337 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-SegmentedRaftLogWorker: Starting segment from index:0
datanode3_1  | 2023-02-20 12:35:27,616 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-FollowerState] INFO impl.FollowerState: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5098265988ns, electionTimeout:5080ms
datanode3_1  | 2023-02-20 12:35:27,620 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-FollowerState] INFO impl.RoleInfo: d23baa5b-5f7e-4a50-8199-73003befd3af: shutdown d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-FollowerState
datanode3_1  | 2023-02-20 12:35:27,621 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-FollowerState] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode3_1  | 2023-02-20 12:35:27,622 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
datanode3_1  | 2023-02-20 12:35:27,622 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-FollowerState] INFO impl.RoleInfo: d23baa5b-5f7e-4a50-8199-73003befd3af: start d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2
datanode3_1  | 2023-02-20 12:35:27,658 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO impl.LeaderElection: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2023-02-20 12:35:27,855 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2023-02-20 12:35:27,855 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2023-02-20 12:35:27,885 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2-2] INFO server.GrpcServerProtocolClient: Build channel for 8dd306ed-03df-465a-901a-3b76553ce2f1
datanode3_1  | 2023-02-20 12:35:27,893 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2-1] INFO server.GrpcServerProtocolClient: Build channel for f342a5db-4e7d-4274-be79-8b926a9a2f90
datanode3_1  | 2023-02-20 12:35:28,963 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-d23baa5b-5f7e-4a50-8199-73003befd3af: Detected pause in JVM or host machine (eg GC): pause of approximately 498437530ns.
datanode3_1  | GC pool 'ParNew' had collection(s): count=1 time=867ms
datanode3_1  | 2023-02-20 12:35:28,972 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-LeaderElection1] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566: set configuration 0: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2023-02-20 12:35:30,427 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d23baa5b-5f7e-4a50-8199-73003befd3af@group-2ABA89790566-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4315d5f4-40b0-4520-b2d0-2aba89790566/current/log_inprogress_0
datanode3_1  | 2023-02-20 12:35:32,958 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO impl.LeaderElection: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2: PRE_VOTE TIMEOUT received 0 response(s) and 0 exception(s):
datanode3_1  | 2023-02-20 12:35:32,961 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO impl.LeaderElection: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2 PRE_VOTE round 0: result TIMEOUT
datanode3_1  | 2023-02-20 12:35:32,963 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO impl.LeaderElection: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2 PRE_VOTE round 1: submit vote requests at term 0 for -1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2023-02-20 12:35:33,034 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode3_1  | 2023-02-20 12:35:33,104 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode3_1  | 2023-02-20 12:35:33,778 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO impl.LeaderElection: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: f342a5db-4e7d-4274-be79-8b926a9a2f90: group-B4FB3CA8A87D not found.
datanode3_1  | 2023-02-20 12:35:34,929 [grpc-default-executor-1] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D: receive requestVote(PRE_VOTE, 8dd306ed-03df-465a-901a-3b76553ce2f1, group-B4FB3CA8A87D, 0, (t:0, i:0))
datanode3_1  | 2023-02-20 12:35:34,964 [grpc-default-executor-0] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D: receive requestVote(PRE_VOTE, 8dd306ed-03df-465a-901a-3b76553ce2f1, group-B4FB3CA8A87D, 0, (t:0, i:0))
datanode3_1  | 2023-02-20 12:35:35,001 [grpc-default-executor-0] INFO impl.VoteContext: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-CANDIDATE: accept PRE_VOTE from 8dd306ed-03df-465a-901a-3b76553ce2f1: our priority 0 <= candidate's priority 0
datanode3_1  | 2023-02-20 12:35:35,359 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO impl.LeaderElection: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2: PRE_VOTE PASSED received 1 response(s) and 1 exception(s):
datanode3_1  | 2023-02-20 12:35:35,374 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO impl.LeaderElection:   Response 0: d23baa5b-5f7e-4a50-8199-73003befd3af<-8dd306ed-03df-465a-901a-3b76553ce2f1#0:OK-t0
datanode3_1  | 2023-02-20 12:35:35,378 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO impl.LeaderElection:   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: INTERNAL: f342a5db-4e7d-4274-be79-8b926a9a2f90: group-B4FB3CA8A87D not found.
datanode3_1  | 2023-02-20 12:35:35,380 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO impl.LeaderElection: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2 PRE_VOTE round 1: result PASSED
datanode3_1  | 2023-02-20 12:35:35,470 [grpc-default-executor-0] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D replies to PRE_VOTE vote request: 8dd306ed-03df-465a-901a-3b76553ce2f1<-d23baa5b-5f7e-4a50-8199-73003befd3af#0:OK-t0. Peer's state: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D:t0, leader=null, voted=, raftlog=Memoized:d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2023-02-20 12:35:35,514 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO impl.LeaderElection: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2023-02-20 12:35:35,609 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om2_1        | Sleeping for 5 seconds
om2_1        | Waiting for the service scm3.org:9894
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2023-02-20 12:33:44,365 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = [--init]
om2_1        | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/joda-time-2.10.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2023-02-20 12:33:44,494 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2023-02-20 12:33:56,352 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2023-02-20 12:34:00,929 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2023-02-20 12:34:01,748 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2023-02-20 12:34:01,751 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2023-02-20 12:34:01,751 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2023-02-20 12:34:04,293 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2023-02-20 12:34:04,297 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2023-02-20 12:34:04,608 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2023-02-20 12:34:07,364 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1;layoutVersion=3
om2_1        | 2023-02-20 12:34:11,839 [main] INFO om.OzoneManager: OM storage initialized. Initializing security
om2_1        | 2023-02-20 12:34:11,845 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om2_1        | 2023-02-20 12:34:18,157 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2023-02-20 12:34:18,215 [main] ERROR security.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om2_1        | 2023-02-20 12:34:18,231 [main] INFO security.OMCertificateClient: Certificate client init case: 0
om2_1        | 2023-02-20 12:34:18,255 [main] INFO security.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om2_1        | 2023-02-20 12:34:25,932 [main] INFO om.OzoneManager: Init response: GETCERT
om2_1        | 2023-02-20 12:34:26,308 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.112,host:om2
om2_1        | 2023-02-20 12:34:26,310 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om2_1        | 2023-02-20 12:34:26,352 [main] ERROR security.OMCertificateClient: Invalid domain om2
om2_1        | 2023-02-20 12:34:26,357 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2023-02-20 12:34:26,373 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2023-02-20 12:34:26,375 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2023-02-20 12:34:26,376 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2023-02-20 12:34:26,404 [main] INFO security.OMCertificateClient: Creating csr for OM->dns:om2,ip:172.25.0.112,scmId:71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,clusterId:CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1,subject:om2
om2_1        | 2023-02-20 12:34:32,172 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om2_1        | 2023-02-20 12:34:32,302 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om2_1        | /************************************************************
om2_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om2/172.25.0.112
datanode3_1  | 2023-02-20 12:35:35,514 [grpc-default-executor-1] INFO impl.VoteContext: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-CANDIDATE: accept PRE_VOTE from 8dd306ed-03df-465a-901a-3b76553ce2f1: our priority 0 <= candidate's priority 0
datanode3_1  | 2023-02-20 12:35:35,699 [grpc-default-executor-1] INFO server.RaftServer$Division: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D replies to PRE_VOTE vote request: 8dd306ed-03df-465a-901a-3b76553ce2f1<-d23baa5b-5f7e-4a50-8199-73003befd3af#0:OK-t1. Peer's state: d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D:t1, leader=null, voted=d23baa5b-5f7e-4a50-8199-73003befd3af, raftlog=Memoized:d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[d23baa5b-5f7e-4a50-8199-73003befd3af|rpc:172.25.0.104:9856|admin:172.25.0.104:9857|client:172.25.0.104:9858|dataStream:172.25.0.104:9858|priority:0|startupRole:FOLLOWER, f342a5db-4e7d-4274-be79-8b926a9a2f90|rpc:172.25.0.103:9856|admin:172.25.0.103:9857|client:172.25.0.103:9858|dataStream:172.25.0.103:9858|priority:1|startupRole:FOLLOWER, 8dd306ed-03df-465a-901a-3b76553ce2f1|rpc:172.25.0.102:9856|admin:172.25.0.102:9857|client:172.25.0.102:9858|dataStream:172.25.0.102:9858|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode3_1  | 2023-02-20 12:35:35,693 [d23baa5b-5f7e-4a50-8199-73003befd3af@group-B4FB3CA8A87D-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om2_1        | ************************************************************/
om2_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om2_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om2_1        | 2023-02-20 12:34:49,584 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om2_1        | /************************************************************
om2_1        | STARTUP_MSG: Starting OzoneManager
om2_1        | STARTUP_MSG:   host = om2/172.25.0.112
om2_1        | STARTUP_MSG:   args = []
om2_1        | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
om2_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/joda-time-2.10.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar
om2_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
om2_1        | STARTUP_MSG:   java = 11.0.14.1
om2_1        | ************************************************************/
om2_1        | 2023-02-20 12:34:49,726 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om2_1        | 2023-02-20 12:35:01,787 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om2_1        | 2023-02-20 12:35:06,708 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om2_1        | 2023-02-20 12:35:08,344 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om2, RPC Address: om2:9862 and Ratis port: 9872
om2_1        | 2023-02-20 12:35:08,356 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om2: om2
om2_1        | 2023-02-20 12:35:08,362 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om2: om2
om2_1        | 2023-02-20 12:35:08,552 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2023-02-20 12:35:09,705 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om2_1        | 2023-02-20 12:35:12,009 [main] INFO reflections.Reflections: Reflections took 1809 ms to scan 1 urls, producing 125 keys and 363 values [using 2 cores]
om2_1        | 2023-02-20 12:35:14,261 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om2_1        | 2023-02-20 12:35:14,271 [main] INFO om.OzoneManager: Ozone Manager login successful.
om2_1        | 2023-02-20 12:35:14,271 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2023-02-20 12:35:17,361 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2023-02-20 12:35:17,925 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om2_1        | 2023-02-20 12:35:27,821 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om2_1        | value: 9862
om2_1        | ]
om2_1        | 2023-02-20 12:35:27,907 [main] INFO security.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om2_1        | 2023-02-20 12:35:29,309 [main] INFO security.OMCertificateClient: Added certificate   [0]         Version: 3
om2_1        |          SerialNumber: 1
om2_1        |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
om2_1        |            Start Date: Mon Feb 20 00:00:00 UTC 2023
om2_1        |            Final Date: Thu Mar 30 00:00:00 UTC 2028
om2_1        |             SubjectDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
om2_1        |            Public Key: RSA Public Key [94:7e:a6:1e:66:03:60:cb:31:b6:ba:58:09:e5:6f:61:c6:1f:10:56],[56:66:d1:a4]
om2_1        |         modulus: ae4c68b294de9bde416e48f8dd880f73587515c06076bc726de72d7d0efa633c8ab0845ecaa9dfe2be73479c31abedba80a9108027262a3316511997768cdb340fdcb173084f830287356e335877580b2bd5bdc297d7572a3635e6a114294f82bfb68aec57278d80b2e053741f6bd8e43df4c302f807657c2cd83c55edafc9fedddc555b306c6720e2e72e1a403ac6fa6a0b45823767e96cbe34c0ee95838730daf28e939192b29222957ccd58032a49c0446c773bb8ccc080bc6d017e13b3470c1f732b571f7ae50833d9852f4af92799f9b8c5eaec9c998c13768e6e1efd686c4d209f1d79c8d4f12aa2f5821e96eff58d7f8e4bf5877811957c77adb800e7
om2_1        | public exponent: 10001
om2_1        | 
om2_1        |   Signature Algorithm: SHA256WITHRSA
om2_1        |             Signature: a7cea6946dc4cec2c98cb07c07498d5444b6300d
om2_1        |                        0a6c4e9490adf7093c90271931b5d0417975d9b8
om2_1        |                        7a9238465c6f3f4de8400309865e2da81ad21b31
om2_1        |                        57de65cb86c13fbef66ec87c8614bd8ad650e11d
om2_1        |                        4e49b0e20080ff8a0c3d6a6e6cef0122f38fbedc
om2_1        |                        9428a9b69ae6258d8ff4035af00ec4326a833057
om2_1        |                        736e2bec20eba55b3e39bd1818d036b10a473b2e
om2_1        |                        99f5e8079f4fcaa7750269bdb7680ebf53d8f7bb
om2_1        |                        16ddc0ef7ac8c2bd9f938901391f3d9e4f3823e1
om2_1        |                        07939f9a9f829615d2d1f339e2f210e795258ac1
om2_1        |                        f03a273f30f7cb3110f6d700ded1888ed1dcaa17
om2_1        |                        ff9774e9f4d33a5be09b76c57503b7a066668066
om2_1        |                        4c46b6c92c5c84d4978c557861c07dba
om2_1        |        Extensions: 
om2_1        |                        critical(true) BasicConstraints: isCa(true)
om2_1        |                        critical(true) KeyUsage: 0x6
om2_1        |                        critical(false) 2.5.29.17 value = Sequence
om2_1        |     Tagged [7] IMPLICIT 
om2_1        |         DER Octet String[4] 
om2_1        |     Tagged [2] IMPLICIT 
om2_1        |         DER Octet String[8] 
om2_1        | 
om2_1        |  from file:/data/metadata/om/certs/ROOTCA-1.crt.
om2_1        | 2023-02-20 12:35:29,429 [main] INFO security.OMCertificateClient: Added certificate   [0]         Version: 3
om2_1        |          SerialNumber: 1640272501443
om2_1        |              IssuerDN: CN=scm-sub@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
om2_1        |            Start Date: Mon Feb 20 00:00:00 UTC 2023
om2_1        |            Final Date: Tue Feb 20 00:00:00 UTC 2024
om2_1        |             SubjectDN: CN=om2,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
om2_1        |            Public Key: RSA Public Key [1a:b1:d4:24:1e:3b:c9:d3:df:f0:68:c9:4d:8d:8b:c6:a0:6c:d0:c9],[56:66:d1:a4]
om2_1        |         modulus: 996af19f17710ddc65eb25ff204f9cf789ca15b4eb0ed4c89bc1ebc672552fc46e90da822ad571819f4354dd825af4d46514a28e165f7fd7b1de7559ef8d1a1c325b0c1e913db164f77584847e05232ec43b34d6d722a04f323db32a50fc225d4d4db38a0e15fc51dbfd0bc06f106fdd08976d0f98b056c9487da065709d0e57c0ed7e3f59248f7b22c11257766f471de6bdd1812736e8c72d59dba57f87d4a2905d85e1c136b71e0a2469d5772d5807295f00ac1d63a036f8abbe611160492a02c24b67a1137ed23d588d61ee3fd2db65c04f3f05a0048c70699513e533a2f1ea4a05f7496c584b4e47f52f9d229f1ddbc06f94bfab6a9944d06d171e61a873
om2_1        | public exponent: 10001
om2_1        | 
om2_1        |   Signature Algorithm: SHA256WITHRSA
om2_1        |             Signature: 433cdd22c3294e0ce11973e319172e3061850a52
om2_1        |                        26cef0e03628e2c7d9f50004b80f0d2e96ead3f6
om2_1        |                        425d5592350cb58520feabf8efdee42b1d2c0fe0
om2_1        |                        9ac2205929e35a7749b9e849bf1287e33d0abb27
om2_1        |                        eaef500536f892b30af06a6f9659ee9e7f50de49
om2_1        |                        9b371b61d94a8cd30fbaf81144d035bb8410f5b4
om2_1        |                        dc504a29948342709edfdc2ddf8ff48382a5bb5b
om2_1        |                        3d28381360e1325666f6204bbf25b2ce3528085c
om2_1        |                        91ae51eb1ae8fbb730b9bbf0cc7edad3aaf0a12b
om2_1        |                        d4c6bdd5d062d6fe33fae64ce54b4bcf0c66344d
om2_1        |                        42b3824000d11f5c91aea7d8cde8d685d92600b2
om2_1        |                        68b6061ba9a6c972dbf864e78a13769c2eef0a73
om2_1        |                        1a70865ecc6a9664d6c4945e40ddc83c
om2_1        |        Extensions: 
om2_1        |                        critical(false) 2.5.29.17 value = Sequence
om2_1        |     Tagged [7] IMPLICIT 
om2_1        |         DER Octet String[4] 
om2_1        |     Tagged [0] IMPLICIT 
om2_1        |         Sequence
om2_1        |             ObjectIdentifier(2.16.840.1.113730.3.1.34)
om2_1        |             Tagged [0]
om2_1        |                 UTF8String(id1) 
om2_1        | 
om2_1        |                        critical(true) KeyUsage: 0xb8
om2_1        |  from file:/data/metadata/om/certs/1640272501443.crt.
om2_1        | 2023-02-20 12:35:29,534 [main] INFO security.OMCertificateClient: Added certificate   [0]         Version: 3
om2_1        |          SerialNumber: 1490022441527
om2_1        |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
om2_1        |            Start Date: Mon Feb 20 00:00:00 UTC 2023
om2_1        |            Final Date: Thu Mar 30 00:00:00 UTC 2028
om2_1        |             SubjectDN: CN=scm-sub@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
om2_1        |            Public Key: RSA Public Key [16:2d:b7:a5:b0:1c:7e:50:4b:d3:0c:1e:91:d5:30:6d:12:23:23:1c],[56:66:d1:a4]
om2_1        |         modulus: b8881b4dd07c72248c8863bba59686bc7d8a1c0a77f9587da66c7e69fd2912af0eb4b5ab9b5e2cccd38500bee6178abbf02f9c564eb57a3029da82d6fb08538545dd260393eac22764468b808f392fc0555b558cc274360ac207d0b693142fbc5fd801789ecb2aefa0cfb5b7bb92c107c453311fcd9590678300eed8335e7c2887ddadc75dd7fd24d77cdfffb2d01c2817abb555f59cc4ca8c520c785155f682252969d6f60ba724f524b233eba33397229e851534a97c7b9a743d4dd3ed30d92316c44aab2e8741a08ef02fcc96cb516c9e93342ba73692ddd39f254390ff523b588e0710edded5220b5301b85e914019771f8cbd758e861d99222494d387a7
om2_1        | public exponent: 10001
om2_1        | 
om2_1        |   Signature Algorithm: SHA256WITHRSA
om2_1        |             Signature: 363d3273c12aa64988005dd16cbf319b130f6b08
om2_1        |                        3ec325844d607b1225858823a3b417c8b78f8266
om2_1        |                        5338966c887d5ee760050f81da927bac7aafdda0
om2_1        |                        203c45d70e75f7f585632db643c276dcfc12d0cf
om2_1        |                        31d734300b15141e9c77a37edb550f41a3cc1a14
om2_1        |                        5e4b848617279f658ed62ed740017f1b4bd844c2
om2_1        |                        cdb757bfdef0058498c0b11f0c59d5c5c4a6fea2
om2_1        |                        e44d596ba23e9480406994c2d52d03fb603137d7
om2_1        |                        38b028409f31693a2c3fddbd689785b29f009d1f
om2_1        |                        b3b815a10f87cee8642a347f5b737ade5d2f2d7f
om2_1        |                        3a51aac93500a29b12e04ea17d3d823af05cedd3
om2_1        |                        737c196e3d25ee225340482ec1a717bf8f73b126
om2_1        |                        32165d626d85896b9c2f99ff029695f3
om2_1        |        Extensions: 
om2_1        |                        critical(false) 2.5.29.17 value = Sequence
om2_1        |     Tagged [7] IMPLICIT 
om2_1        |         DER Octet String[4] 
om2_1        |     Tagged [2] IMPLICIT 
om2_1        |         DER Octet String[8] 
om2_1        | 
om2_1        |                        critical(true) BasicConstraints: isCa(true)
om2_1        |                        critical(true) KeyUsage: 0xbe
om2_1        |  from file:/data/metadata/om/certs/CA-1490022441527.crt.
om2_1        | 2023-02-20 12:35:29,558 [main] INFO security.OMCertificateClient: CertificateLifetimeMonitor for om is started with first delay 29071470453 ms and interval 86400000 ms.
om2_1        | 2023-02-20 12:35:29,757 [main] INFO om.OzoneManager: OM start with adminUsers: [testuser/scm@EXAMPLE.COM, testuser/s3g@EXAMPLE.COM, recon/recon@EXAMPLE.COM, om/om1@EXAMPLE.COM, om/om2@EXAMPLE.COM, om/om3@EXAMPLE.COM, om]
om2_1        | 2023-02-20 12:35:30,346 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om2_1        | 2023-02-20 12:35:31,822 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om2_1        | 2023-02-20 12:35:31,834 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om3_1        | Sleeping for 5 seconds
om3_1        | Waiting for the service scm3.org:9894
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2023-02-20 12:33:44,462 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = [--init]
om3_1        | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/joda-time-2.10.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2023-02-20 12:33:44,632 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2023-02-20 12:33:55,641 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2023-02-20 12:33:59,449 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2023-02-20 12:34:00,436 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2023-02-20 12:34:00,451 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2023-02-20 12:34:00,466 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2023-02-20 12:34:03,696 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2023-02-20 12:34:03,708 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2023-02-20 12:34:03,875 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2023-02-20 12:34:06,652 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1;layoutVersion=3
om3_1        | 2023-02-20 12:34:11,035 [main] INFO om.OzoneManager: OM storage initialized. Initializing security
om3_1        | 2023-02-20 12:34:11,036 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
om3_1        | 2023-02-20 12:34:17,767 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2023-02-20 12:34:17,828 [main] ERROR security.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om3_1        | 2023-02-20 12:34:17,844 [main] INFO security.OMCertificateClient: Certificate client init case: 0
om3_1        | 2023-02-20 12:34:17,859 [main] INFO security.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om3_1        | 2023-02-20 12:34:32,204 [main] INFO om.OzoneManager: Init response: GETCERT
om3_1        | 2023-02-20 12:34:32,687 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.113,host:om3
om3_1        | 2023-02-20 12:34:32,692 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om3_1        | 2023-02-20 12:34:32,722 [main] ERROR security.OMCertificateClient: Invalid domain om3
om3_1        | 2023-02-20 12:34:32,727 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2023-02-20 12:34:32,751 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2023-02-20 12:34:32,757 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2023-02-20 12:34:32,758 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2023-02-20 12:34:32,782 [main] INFO security.OMCertificateClient: Creating csr for OM->dns:om3,ip:172.25.0.113,scmId:71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,clusterId:CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1,subject:om3
om3_1        | 2023-02-20 12:34:36,319 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om3_1        | 2023-02-20 12:34:36,404 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
om3_1        | /************************************************************
om3_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om3/172.25.0.113
om3_1        | ************************************************************/
om3_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om3_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om3_1        | 2023-02-20 12:34:55,453 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om3_1        | /************************************************************
om3_1        | STARTUP_MSG: Starting OzoneManager
om3_1        | STARTUP_MSG:   host = om3/172.25.0.113
om3_1        | STARTUP_MSG:   args = []
om3_1        | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
om3_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/joda-time-2.10.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar
om3_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
om3_1        | STARTUP_MSG:   java = 11.0.14.1
om3_1        | ************************************************************/
om3_1        | 2023-02-20 12:34:55,531 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om3_1        | 2023-02-20 12:35:08,672 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om3_1        | 2023-02-20 12:35:13,286 [main] INFO ha.OMHANodeDetails: ServiceID for OzoneManager is id1
om3_1        | 2023-02-20 12:35:14,346 [main] INFO ha.OMHANodeDetails: Found matching OM address with OMServiceId: id1, OMNodeId: om3, RPC Address: om3:9862 and Ratis port: 9872
om3_1        | 2023-02-20 12:35:14,352 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.http-address with value of key ozone.om.http-address.id1.om3: om3
om3_1        | 2023-02-20 12:35:14,352 [main] INFO ha.OMHANodeDetails: Setting configuration key ozone.om.address with value of key ozone.om.address.id1.om3: om3
om3_1        | 2023-02-20 12:35:14,442 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2023-02-20 12:35:14,950 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om3_1        | 2023-02-20 12:35:17,117 [main] INFO reflections.Reflections: Reflections took 1471 ms to scan 1 urls, producing 125 keys and 363 values [using 2 cores]
om3_1        | 2023-02-20 12:35:18,788 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om3_1        | 2023-02-20 12:35:18,788 [main] INFO om.OzoneManager: Ozone Manager login successful.
om3_1        | 2023-02-20 12:35:18,797 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om3_1        | 2023-02-20 12:35:22,812 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2023-02-20 12:35:23,720 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
om3_1        | 2023-02-20 12:35:34,332 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om3_1        | value: 9862
om3_1        | ]
om3_1        | 2023-02-20 12:35:34,467 [main] INFO security.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
recon_1      | Sleeping for 5 seconds
recon_1      | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1      | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1      | 2023-02-20 12:31:44,460 [main] INFO recon.ReconServer: STARTUP_MSG: 
recon_1      | /************************************************************
recon_1      | STARTUP_MSG: Starting ReconServer
recon_1      | STARTUP_MSG:   host = recon/172.25.0.115
recon_1      | STARTUP_MSG:   args = []
recon_1      | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
recon_1      | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/joda-time-2.10.6.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-core-5.3.23.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.34.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.34.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.3.23.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.3.23.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.34.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.34.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.3.23.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.34.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.13.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.3.23.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.34.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.34.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.34.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.34.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.4.0-SNAPSHOT.jar
recon_1      | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
recon_1      | STARTUP_MSG:   java = 11.0.14.1
recon_1      | ************************************************************/
recon_1      | 2023-02-20 12:31:44,518 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
recon_1      | 2023-02-20 12:31:47,886 [main] INFO reflections.Reflections: Reflections took 499 ms to scan 1 urls, producing 17 keys and 54 values 
recon_1      | 2023-02-20 12:31:51,312 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1      | 2023-02-20 12:31:51,566 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1      | 2023-02-20 12:31:52,319 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file recon.keytab. Keytab auto renewal enabled : false
recon_1      | 2023-02-20 12:31:52,319 [main] INFO recon.ReconServer: Recon login successful.
recon_1      | 2023-02-20 12:31:52,337 [main] INFO recon.ReconServer: ReconStorageConfig initialized.Initializing certificate.
recon_1      | 2023-02-20 12:31:52,337 [main] INFO recon.ReconServer: Initializing secure Recon.
recon_1      | 2023-02-20 12:31:54,304 [main] ERROR client.ReconCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
recon_1      | 2023-02-20 12:31:54,339 [main] INFO client.ReconCertificateClient: Certificate client init case: 0
recon_1      | 2023-02-20 12:31:54,346 [main] INFO client.ReconCertificateClient: Creating keypair for client as keypair and certificate not found.
recon_1      | 2023-02-20 12:31:56,947 [main] INFO recon.ReconServer: Init response: GETCERT
recon_1      | 2023-02-20 12:31:56,959 [main] INFO client.ReconCertificateClient: Creating CSR for Recon.
recon_1      | 2023-02-20 12:31:56,997 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.115,host:recon
recon_1      | 2023-02-20 12:31:56,999 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
recon_1      | 2023-02-20 12:31:57,012 [main] ERROR client.ReconCertificateClient: Invalid domain recon
recon_1      | 2023-02-20 12:32:00,404 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:32:02,407 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:32:04,409 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:32:06,410 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:32:08,413 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:32:10,415 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm1.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:32:12,417 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:32:14,421 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:32:20,204 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa is not the leader. Could not determine the leader node.
recon_1      | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1      | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1      | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
recon_1      | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1      | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1      | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1      | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1      | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1      | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1      | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1      | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1      | , while invoking $Proxy39.submitRequest over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:32:22,220 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm2.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:32:24,222 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to scm3.org:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:32:27,042 [main] INFO client.ReconCertificateClient: Loading certificate from location:/data/metadata/recon/certs.
recon_1      | 2023-02-20 12:32:27,075 [main] INFO client.ReconCertificateClient: Added certificate   [0]         Version: 3
recon_1      |          SerialNumber: 1
recon_1      |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
recon_1      |            Start Date: Mon Feb 20 00:00:00 UTC 2023
recon_1      |            Final Date: Thu Mar 30 00:00:00 UTC 2028
recon_1      |             SubjectDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
recon_1      |            Public Key: RSA Public Key [94:7e:a6:1e:66:03:60:cb:31:b6:ba:58:09:e5:6f:61:c6:1f:10:56],[56:66:d1:a4]
recon_1      |         modulus: ae4c68b294de9bde416e48f8dd880f73587515c06076bc726de72d7d0efa633c8ab0845ecaa9dfe2be73479c31abedba80a9108027262a3316511997768cdb340fdcb173084f830287356e335877580b2bd5bdc297d7572a3635e6a114294f82bfb68aec57278d80b2e053741f6bd8e43df4c302f807657c2cd83c55edafc9fedddc555b306c6720e2e72e1a403ac6fa6a0b45823767e96cbe34c0ee95838730daf28e939192b29222957ccd58032a49c0446c773bb8ccc080bc6d017e13b3470c1f732b571f7ae50833d9852f4af92799f9b8c5eaec9c998c13768e6e1efd686c4d209f1d79c8d4f12aa2f5821e96eff58d7f8e4bf5877811957c77adb800e7
recon_1      | public exponent: 10001
recon_1      | 
recon_1      |   Signature Algorithm: SHA256WITHRSA
recon_1      |             Signature: a7cea6946dc4cec2c98cb07c07498d5444b6300d
recon_1      |                        0a6c4e9490adf7093c90271931b5d0417975d9b8
recon_1      |                        7a9238465c6f3f4de8400309865e2da81ad21b31
recon_1      |                        57de65cb86c13fbef66ec87c8614bd8ad650e11d
recon_1      |                        4e49b0e20080ff8a0c3d6a6e6cef0122f38fbedc
recon_1      |                        9428a9b69ae6258d8ff4035af00ec4326a833057
recon_1      |                        736e2bec20eba55b3e39bd1818d036b10a473b2e
recon_1      |                        99f5e8079f4fcaa7750269bdb7680ebf53d8f7bb
recon_1      |                        16ddc0ef7ac8c2bd9f938901391f3d9e4f3823e1
recon_1      |                        07939f9a9f829615d2d1f339e2f210e795258ac1
recon_1      |                        f03a273f30f7cb3110f6d700ded1888ed1dcaa17
recon_1      |                        ff9774e9f4d33a5be09b76c57503b7a066668066
recon_1      |                        4c46b6c92c5c84d4978c557861c07dba
recon_1      |        Extensions: 
recon_1      |                        critical(true) BasicConstraints: isCa(true)
recon_1      |                        critical(true) KeyUsage: 0x6
recon_1      |                        critical(false) 2.5.29.17 value = Sequence
recon_1      |     Tagged [7] IMPLICIT 
recon_1      |         DER Octet String[4] 
recon_1      |     Tagged [2] IMPLICIT 
recon_1      |         DER Octet String[8] 
recon_1      | 
recon_1      |  from file:/data/metadata/recon/certs/ROOTCA-1.crt.
recon_1      | 2023-02-20 12:32:27,091 [main] INFO client.ReconCertificateClient: Added certificate   [0]         Version: 3
recon_1      |          SerialNumber: 1515665651100
recon_1      |              IssuerDN: CN=scm-sub@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
recon_1      |            Start Date: Mon Feb 20 00:00:00 UTC 2023
recon_1      |            Final Date: Tue Feb 20 00:00:00 UTC 2024
recon_1      |             SubjectDN: CN=recon@recon,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
s3g_1        | Sleeping for 5 seconds
s3g_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
s3g_1        | 2023-02-20 12:31:44,825 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
s3g_1        | 2023-02-20 12:31:44,839 [main] INFO s3.Gateway: S3Gateway login successful.
s3g_1        | 2023-02-20 12:31:45,271 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1        | 2023-02-20 12:31:45,279 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
s3g_1        | 2023-02-20 12:31:45,281 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1        | 2023-02-20 12:31:45,545 [main] INFO util.log: Logging initialized @8452ms to org.eclipse.jetty.util.log.Slf4jLog
s3g_1        | 2023-02-20 12:31:46,343 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1        | 2023-02-20 12:31:46,430 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
s3g_1        | 2023-02-20 12:31:46,452 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
s3g_1        | 2023-02-20 12:31:46,452 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1        | 2023-02-20 12:31:46,453 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
s3g_1        | 2023-02-20 12:31:46,467 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
s3g_1        | 2023-02-20 12:31:47,011 [main] INFO s3.Gateway: STARTUP_MSG: 
s3g_1        | /************************************************************
s3g_1        | STARTUP_MSG: Starting Gateway
s3g_1        | STARTUP_MSG:   host = s3g/172.25.0.114
s3g_1        | STARTUP_MSG:   args = []
s3g_1        | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
s3g_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.34.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.34.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.34.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.34.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.4.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.34.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.34.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.34.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.4.0-SNAPSHOT.jar
s3g_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
s3g_1        | STARTUP_MSG:   java = 11.0.14.1
s3g_1        | ************************************************************/
s3g_1        | 2023-02-20 12:31:47,041 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1        | 2023-02-20 12:31:47,126 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1        | 2023-02-20 12:31:47,416 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1        | 2023-02-20 12:31:48,178 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
s3g_1        | 2023-02-20 12:31:48,179 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1        | 2023-02-20 12:31:48,396 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1        | 2023-02-20 12:31:48,405 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
s3g_1        | 2023-02-20 12:31:48,666 [main] INFO server.session: DefaultSessionIdManager workerName=node0
s3g_1        | 2023-02-20 12:31:48,686 [main] INFO server.session: No SessionScavenger set, using defaults
s3g_1        | 2023-02-20 12:31:48,689 [main] INFO server.session: node0 Scavenging every 660000ms
s3g_1        | 2023-02-20 12:31:48,820 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | 2023-02-20 12:31:48,910 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@77307458{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1        | 2023-02-20 12:31:48,916 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@f9b7332{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
s3g_1        | WARNING: An illegal reflective access operation has occurred
s3g_1        | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
s3g_1        | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1        | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
s3g_1        | WARNING: All illegal access operations will be denied in a future release
s3g_1        | 2023-02-20 12:31:57,225 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/s3g@EXAMPLE.COM
s3g_1        | Feb 20, 2023 12:32:00 PM org.glassfish.jersey.internal.Errors logErrors
scm1.org_1   | Sleeping for 5 seconds
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2023-02-20 12:31:47,674 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = [--init]
scm1.org_1   | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2023-02-20 12:31:47,774 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2023-02-20 12:31:48,454 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2023-02-20 12:31:48,999 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2023-02-20 12:31:49,144 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2023-02-20 12:31:49,568 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2023-02-20 12:31:49,593 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2023-02-20 12:31:49,705 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm1.org_1   | 2023-02-20 12:31:54,062 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm1.org_1   | 2023-02-20 12:31:54,083 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm1.org_1   | 2023-02-20 12:31:54,084 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2023-02-20 12:31:56,869 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm1.org_1   | 2023-02-20 12:31:59,907 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2023-02-20 12:31:59,919 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2023-02-20 12:32:00,270 [main] INFO utils.SelfSignedCertificate: Certificate 1 is issued by CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1 to CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1, valid from Mon Feb 20 00:00:00 UTC 2023 to Thu Mar 30 00:00:00 UTC 2028
scm1.org_1   | 2023-02-20 12:32:00,417 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.116,host:scm1.org
scm1.org_1   | 2023-02-20 12:32:00,423 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm1.org_1   | 2023-02-20 12:32:00,425 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm1.org,scmId:71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,clusterId:CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1,subject:scm-sub@scm1.org
scm1.org_1   | 2023-02-20 12:32:00,817 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm1.org_1   | 2023-02-20 12:32:01,227 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2023-02-20 12:32:01,463 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
scm1.org_1   | 2023-02-20 12:32:01,472 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
scm1.org_1   | 2023-02-20 12:32:01,473 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
scm1.org_1   | 2023-02-20 12:32:01,473 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
scm1.org_1   | 2023-02-20 12:32:01,473 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
scm1.org_1   | 2023-02-20 12:32:01,473 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm1.org_1   | 2023-02-20 12:32:01,474 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2023-02-20 12:32:01,476 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2023-02-20 12:32:01,477 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2023-02-20 12:32:01,477 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2023-02-20 12:32:01,512 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm1.org_1   | 2023-02-20 12:32:01,523 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2023-02-20 12:32:01,524 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2023-02-20 12:32:01,844 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2023-02-20 12:32:01,895 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm1.org_1   | 2023-02-20 12:32:01,896 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2023-02-20 12:32:01,896 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2023-02-20 12:32:01,898 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2023-02-20 12:32:01,921 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2023-02-20 12:32:01,986 [main] INFO server.RaftServer: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: addNew group-F5FD3C6D31B1:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER] returns group-F5FD3C6D31B1:java.util.concurrent.CompletableFuture@119b0892[Not completed]
scm1.org_1   | 2023-02-20 12:32:02,041 [pool-2-thread-1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: new RaftServerImpl for group-F5FD3C6D31B1:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER] with SCMStateMachine:uninitialized
scm1.org_1   | 2023-02-20 12:32:02,046 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2023-02-20 12:32:02,047 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2023-02-20 12:32:02,047 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2023-02-20 12:32:02,047 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2023-02-20 12:32:02,047 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2023-02-20 12:32:02,047 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2023-02-20 12:32:02,067 [pool-2-thread-1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: ConfigurationManager, init=-1: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
s3g_1        | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
s3g_1        | 
s3g_1        | 2023-02-20 12:32:00,388 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@428eb3d5{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_4_0-SNAPSHOT_jar-_-any-2621764942838003211/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.4.0-SNAPSHOT.jar!/webapps/s3gateway}
s3g_1        | 2023-02-20 12:32:00,431 [main] INFO server.AbstractConnector: Started ServerConnector@2c4ca0f9{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1        | 2023-02-20 12:32:00,432 [main] INFO server.Server: Started @23340ms
s3g_1        | 2023-02-20 12:32:00,448 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1        | 2023-02-20 12:32:00,455 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1        | 2023-02-20 12:32:00,460 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
recon_1      |            Public Key: RSA Public Key [f2:76:09:c5:79:bd:2e:d8:a9:c3:19:3b:9d:34:ec:40:d3:85:ed:34],[56:66:d1:a4]
recon_1      |         modulus: d45613bcadf80fd06a960668f0b429703f8bdeedf714a8c6c71ba5d42fd22d9dd29597ca796c227c6747c6b71a6a08212ada7be8f8eb8820dc33280e6e9b763b714ed1ba195df3ba7f1325d1ab0c99dbfaa9d740b678d9dff96f3546be2999f2f8d0244bfc1b7000f849b415c41f8c6b92630c6125f4828373de902610092ffbac912e8b39464c95214596ed70f6977715ee60399b5d9995750dfd09696d72661c71b390f9ed01d270a26c5000d0148893ff404e23bf3a1845df0f3a12904adcf4adc1738b2eda23d0afa4538de74428b05c6ec42a5e00bebe7b4fa3470a7a9f00d603eb24180860e1887aa7d0af73a61c48415d7f30d6dd4e1eb3ae1e74339b
recon_1      | public exponent: 10001
recon_1      | 
recon_1      |   Signature Algorithm: SHA256WITHRSA
recon_1      |             Signature: 935dbdb5fb18e7896a51a75810b3d079284a3e7b
recon_1      |                        b7b526ad39152726b10b76ecf2eef2ba8fd7cc63
recon_1      |                        5d0d49d717b9a453c8bdfd2bb3c7d27dc949ebaa
recon_1      |                        1e5f8cba472df1759c5fc4ffb948223045c30de2
recon_1      |                        63c4e97527542692d2265bf5b36336f7c0b55a3e
recon_1      |                        1f77074db670044b4bff92065a13e3af5cb8a0b8
recon_1      |                        836b012da351b9484b859011e6c3640b13ac6420
recon_1      |                        d10eef46713d8669e9862bc0d293dcbab5285fa9
recon_1      |                        f91390d64b24f0288bc630f0754185db315f4f90
recon_1      |                        b49e08472796e5efcebdf720f986f0223c06e651
recon_1      |                        98e24a4d751b9b13209722b6916ffea91533304a
recon_1      |                        edba3a3695b24e5c81c297bbcf53bcdbdbf91d75
recon_1      |                        62a595d384b62f110b1cf8b258bfff8b
recon_1      |        Extensions: 
recon_1      |                        critical(false) 2.5.29.17 value = Sequence
recon_1      |     Tagged [7] IMPLICIT 
recon_1      |         DER Octet String[4] 
recon_1      | 
recon_1      |                        critical(true) KeyUsage: 0xb8
recon_1      |  from file:/data/metadata/recon/certs/1515665651100.crt.
recon_1      | 2023-02-20 12:32:27,094 [main] INFO client.ReconCertificateClient: Added certificate   [0]         Version: 3
recon_1      |          SerialNumber: 1490022441527
recon_1      |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
recon_1      |            Start Date: Mon Feb 20 00:00:00 UTC 2023
recon_1      |            Final Date: Thu Mar 30 00:00:00 UTC 2028
recon_1      |             SubjectDN: CN=scm-sub@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
recon_1      |            Public Key: RSA Public Key [16:2d:b7:a5:b0:1c:7e:50:4b:d3:0c:1e:91:d5:30:6d:12:23:23:1c],[56:66:d1:a4]
recon_1      |         modulus: b8881b4dd07c72248c8863bba59686bc7d8a1c0a77f9587da66c7e69fd2912af0eb4b5ab9b5e2cccd38500bee6178abbf02f9c564eb57a3029da82d6fb08538545dd260393eac22764468b808f392fc0555b558cc274360ac207d0b693142fbc5fd801789ecb2aefa0cfb5b7bb92c107c453311fcd9590678300eed8335e7c2887ddadc75dd7fd24d77cdfffb2d01c2817abb555f59cc4ca8c520c785155f682252969d6f60ba724f524b233eba33397229e851534a97c7b9a743d4dd3ed30d92316c44aab2e8741a08ef02fcc96cb516c9e93342ba73692ddd39f254390ff523b588e0710edded5220b5301b85e914019771f8cbd758e861d99222494d387a7
recon_1      | public exponent: 10001
recon_1      | 
recon_1      |   Signature Algorithm: SHA256WITHRSA
recon_1      |             Signature: 363d3273c12aa64988005dd16cbf319b130f6b08
recon_1      |                        3ec325844d607b1225858823a3b417c8b78f8266
recon_1      |                        5338966c887d5ee760050f81da927bac7aafdda0
recon_1      |                        203c45d70e75f7f585632db643c276dcfc12d0cf
recon_1      |                        31d734300b15141e9c77a37edb550f41a3cc1a14
recon_1      |                        5e4b848617279f658ed62ed740017f1b4bd844c2
recon_1      |                        cdb757bfdef0058498c0b11f0c59d5c5c4a6fea2
recon_1      |                        e44d596ba23e9480406994c2d52d03fb603137d7
recon_1      |                        38b028409f31693a2c3fddbd689785b29f009d1f
recon_1      |                        b3b815a10f87cee8642a347f5b737ade5d2f2d7f
recon_1      |                        3a51aac93500a29b12e04ea17d3d823af05cedd3
recon_1      |                        737c196e3d25ee225340482ec1a717bf8f73b126
recon_1      |                        32165d626d85896b9c2f99ff029695f3
recon_1      |        Extensions: 
recon_1      |                        critical(false) 2.5.29.17 value = Sequence
recon_1      |     Tagged [7] IMPLICIT 
recon_1      |         DER Octet String[4] 
recon_1      |     Tagged [2] IMPLICIT 
recon_1      |         DER Octet String[8] 
recon_1      | 
recon_1      |                        critical(true) BasicConstraints: isCa(true)
recon_1      |                        critical(true) KeyUsage: 0xbe
recon_1      |  from file:/data/metadata/recon/certs/CA-1490022441527.crt.
recon_1      | 2023-02-20 12:32:27,110 [main] INFO client.ReconCertificateClient: CertificateLifetimeMonitor for recon is started with first delay 29071652898 ms and interval 86400000 ms.
recon_1      | 2023-02-20 12:32:27,110 [main] INFO recon.ReconServer: Successfully stored SCM signed certificate, case:GETCERT.
recon_1      | 2023-02-20 12:32:27,889 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2023-02-20 12:32:31,210 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | WARNING: An illegal reflective access operation has occurred
recon_1      | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
recon_1      | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1      | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1      | WARNING: All illegal access operations will be denied in a future release
scm1.org_1   | 2023-02-20 12:32:02,076 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2023-02-20 12:32:02,098 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2023-02-20 12:32:02,098 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2023-02-20 12:32:02,125 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2023-02-20 12:32:02,131 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2023-02-20 12:32:02,132 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2023-02-20 12:32:02,172 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2023-02-20 12:32:02,465 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2023-02-20 12:32:02,468 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2023-02-20 12:32:02,468 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm1.org_1   | 2023-02-20 12:32:02,476 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2023-02-20 12:32:02,476 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2023-02-20 12:32:02,478 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1 does not exist. Creating ...
scm1.org_1   | 2023-02-20 12:32:02,488 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/in_use.lock acquired by nodename 87@scm1.org
scm1.org_1   | 2023-02-20 12:32:02,495 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1 has been successfully formatted.
scm1.org_1   | 2023-02-20 12:32:02,505 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2023-02-20 12:32:02,530 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2023-02-20 12:32:02,534 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2023-02-20 12:32:02,540 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2023-02-20 12:32:02,541 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
scm1.org_1   | 2023-02-20 12:32:02,551 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2023-02-20 12:32:02,566 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2023-02-20 12:32:02,570 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2023-02-20 12:32:02,587 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm1.org_1   | 2023-02-20 12:32:02,588 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2023-02-20 12:32:02,588 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2023-02-20 12:32:02,590 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2023-02-20 12:32:02,591 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2023-02-20 12:32:02,592 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2023-02-20 12:32:02,593 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2023-02-20 12:32:02,594 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2023-02-20 12:32:02,596 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2023-02-20 12:32:02,618 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2023-02-20 12:32:02,618 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2023-02-20 12:32:02,641 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2023-02-20 12:32:02,646 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
scm1.org_1   | 2023-02-20 12:32:02,652 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2023-02-20 12:32:02,665 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2023-02-20 12:32:02,666 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2023-02-20 12:32:02,681 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: start as a follower, conf=-1: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2023-02-20 12:32:02,682 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm1.org_1   | 2023-02-20 12:32:02,684 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO impl.RoleInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: start 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState
scm1.org_1   | 2023-02-20 12:32:02,700 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
recon_1      | 2023-02-20 12:32:32,031 [main] INFO impl.ReconContainerMetadataManagerImpl: KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
recon_1      | 2023-02-20 12:32:32,034 [main] INFO impl.ReconContainerMetadataManagerImpl: It took 0.001 seconds to initialized 0 records to KEY_CONTAINER table
recon_1      | 2023-02-20 12:32:32,045 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1      | 2023-02-20 12:32:32,083 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1      | 2023-02-20 12:32:32,085 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1      | 2023-02-20 12:32:35,516 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
recon_1      | 2023-02-20 12:32:35,516 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1      | 2023-02-20 12:32:35,516 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
recon_1      | 2023-02-20 12:32:35,550 [main] INFO util.log: Logging initialized @58214ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1      | 2023-02-20 12:32:35,968 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1      | 2023-02-20 12:32:36,002 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1      | 2023-02-20 12:32:36,004 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
recon_1      | 2023-02-20 12:32:36,017 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1      | 2023-02-20 12:32:36,017 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1      | 2023-02-20 12:32:36,054 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
recon_1      | 2023-02-20 12:32:36,307 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1      | 2023-02-20 12:32:37,120 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1      | 2023-02-20 12:32:37,156 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1      | 2023-02-20 12:32:37,182 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
recon_1      | 2023-02-20 12:32:37,251 [main] INFO ozone.OmUtils: Using OzoneManager ServiceID 'id1'.
recon_1      | 2023-02-20 12:32:39,600 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2023-02-20 12:32:40,377 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2023-02-20 12:32:40,658 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
recon_1      | 2023-02-20 12:32:40,658 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1      | 2023-02-20 12:32:40,925 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2023-02-20 12:32:41,353 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
recon_1      | 2023-02-20 12:32:41,567 [main] INFO reflections.Reflections: Reflections took 190 ms to scan 3 urls, producing 125 keys and 280 values 
recon_1      | 2023-02-20 12:32:42,014 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
recon_1      | 2023-02-20 12:32:42,221 [main] INFO node.SCMNodeManager: Entering startup safe mode.
recon_1      | 2023-02-20 12:32:42,244 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
recon_1      | 2023-02-20 12:32:42,263 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
recon_1      | 2023-02-20 12:32:42,395 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1      | 2023-02-20 12:32:42,488 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2023-02-20 12:32:42,528 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
recon_1      | 2023-02-20 12:32:42,764 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 2023-02-20 12:32:43,179 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
recon_1      | 2023-02-20 12:32:43,182 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
recon_1      | 2023-02-20 12:32:43,516 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
recon_1      | 2023-02-20 12:32:43,592 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1      | 2023-02-20 12:32:43,592 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1      | 2023-02-20 12:32:44,689 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
recon_1      | 2023-02-20 12:32:44,700 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
recon_1      | 2023-02-20 12:32:44,981 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1      | 2023-02-20 12:32:44,981 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
recon_1      | 2023-02-20 12:32:44,991 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 600000ms
recon_1      | 2023-02-20 12:32:45,102 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2023-02-20 12:32:45,123 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7322013f{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1      | 2023-02-20 12:32:45,126 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2e10f765{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1      | 2023-02-20 12:32:46,647 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2023-02-20 12:32:46,676 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1      | 2023-02-20 12:32:53,077 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@27a705e8{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_4_0-SNAPSHOT_jar-_-any-971165709416116308/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.4.0-SNAPSHOT.jar!/webapps/recon}
recon_1      | 2023-02-20 12:32:53,117 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@5a0f5567{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
recon_1      | 2023-02-20 12:32:53,117 [Listener at 0.0.0.0/9891] INFO server.Server: Started @75781ms
recon_1      | 2023-02-20 12:32:53,123 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1      | 2023-02-20 12:32:53,124 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1      | 2023-02-20 12:32:53,129 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1      | 2023-02-20 12:32:53,129 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1      | 2023-02-20 12:32:53,145 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
recon_1      | 2023-02-20 12:32:53,156 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1      | 2023-02-20 12:32:53,156 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1      | 2023-02-20 12:32:53,156 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1      | 2023-02-20 12:32:53,156 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
recon_1      | 2023-02-20 12:32:53,160 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
recon_1      | 2023-02-20 12:32:54,743 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 0 pipelines from SCM.
recon_1      | 2023-02-20 12:32:54,744 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1      | 2023-02-20 12:32:54,744 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: SCM DB initialized
recon_1      | 2023-02-20 12:32:54,758 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1      | 2023-02-20 12:32:54,761 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1      | 2023-02-20 12:32:54,806 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1      | 2023-02-20 12:33:13,159 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1      | 2023-02-20 12:33:13,160 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1      | 2023-02-20 12:33:13,316 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 1 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:13,327 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:15,329 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 3 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:15,336 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 4 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:15,337 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:17,343 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 6 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:17,344 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 7 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:17,345 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:19,347 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 9 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:19,348 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 10 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:19,350 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | Sleeping for 5 seconds
scm2.org_1   | Waiting for the service scm1.org:9894
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2023-02-20 12:32:05,761 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm2.org_1   | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2023-02-20 12:32:05,780 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2023-02-20 12:32:05,900 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2023-02-20 12:32:05,997 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2023-02-20 12:32:05,998 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2023-02-20 12:32:06,064 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2023-02-20 12:32:06,064 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2023-02-20 12:32:06,326 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2023-02-20 12:32:06,326 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2023-02-20 12:32:06,420 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2023-02-20 12:32:08,677 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2023-02-20 12:32:10,680 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2023-02-20 12:32:12,683 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2023-02-20 12:32:14,688 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm1.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2023-02-20 12:32:16,701 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2023-02-20 12:32:20,188 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa is not the leader. Could not determine the leader node.
scm2.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm2.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
scm2.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14220)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
scm2.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
scm2.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
scm2.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm2.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm2.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm2.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
scm2.org_1   | , while invoking $Proxy15.send over nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2023-02-20 12:32:22,190 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From scm2.org/172.25.0.117 to scm3.org:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy15.send over nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2023-02-20 12:32:24,369 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm2.org_1   | 2023-02-20 12:32:25,065 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm2.org_1   | 2023-02-20 12:32:25,067 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm2.org_1   | 2023-02-20 12:32:25,070 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm1.org_1   | 2023-02-20 12:32:02,700 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm1.org_1   | 2023-02-20 12:32:02,700 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F5FD3C6D31B1,id=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa
scm1.org_1   | 2023-02-20 12:32:02,704 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2023-02-20 12:32:02,705 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2023-02-20 12:32:02,706 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2023-02-20 12:32:02,712 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2023-02-20 12:32:02,729 [main] INFO server.RaftServer: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: start RPC server
scm1.org_1   | 2023-02-20 12:32:02,848 [main] INFO server.GrpcService: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: GrpcService started, listening on 9894
scm1.org_1   | 2023-02-20 12:32:02,866 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: Started
scm1.org_1   | 2023-02-20 12:32:07,775 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState] INFO impl.FollowerState: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5091856596ns, electionTimeout:5072ms
scm1.org_1   | 2023-02-20 12:32:07,777 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState] INFO impl.RoleInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: shutdown 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState
scm1.org_1   | 2023-02-20 12:32:07,777 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm1.org_1   | 2023-02-20 12:32:07,781 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
scm1.org_1   | 2023-02-20 12:32:07,781 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState] INFO impl.RoleInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: start 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1
scm1.org_1   | 2023-02-20 12:32:07,784 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO impl.LeaderElection: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2023-02-20 12:32:07,785 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO impl.LeaderElection: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
scm1.org_1   | 2023-02-20 12:32:07,788 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO impl.LeaderElection: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2023-02-20 12:32:07,788 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO impl.LeaderElection: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm1.org_1   | 2023-02-20 12:32:07,788 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO impl.RoleInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: shutdown 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1
scm1.org_1   | 2023-02-20 12:32:07,788 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm1.org_1   | 2023-02-20 12:32:07,788 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: change Leader from null to 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa at term 1 for becomeLeader, leader elected after 5664ms
scm1.org_1   | 2023-02-20 12:32:07,795 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2023-02-20 12:32:07,801 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2023-02-20 12:32:07,801 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2023-02-20 12:32:07,808 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2023-02-20 12:32:07,808 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2023-02-20 12:32:07,809 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2023-02-20 12:32:07,814 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2023-02-20 12:32:07,816 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2023-02-20 12:32:07,818 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO impl.RoleInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: start 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderStateImpl
scm1.org_1   | 2023-02-20 12:32:07,840 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker: Starting segment from index:0
scm1.org_1   | 2023-02-20 12:32:07,864 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: set configuration 0: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2023-02-20 12:32:07,930 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/current/log_inprogress_0
scm1.org_1   | 2023-02-20 12:32:08,870 [main] INFO server.RaftServer: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: close
scm1.org_1   | 2023-02-20 12:32:08,870 [main] INFO server.GrpcService: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: shutdown server GrpcServerProtocolService now
scm1.org_1   | 2023-02-20 12:32:08,871 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: shutdown
scm1.org_1   | 2023-02-20 12:32:08,871 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F5FD3C6D31B1,id=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa
scm1.org_1   | 2023-02-20 12:32:08,872 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO impl.RoleInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: shutdown 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderStateImpl
scm1.org_1   | 2023-02-20 12:32:08,878 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO impl.PendingRequests: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-PendingRequests: sendNotLeaderResponses
scm1.org_1   | 2023-02-20 12:32:08,887 [main] INFO server.GrpcService: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: shutdown server GrpcServerProtocolService successfully
scm1.org_1   | 2023-02-20 12:32:08,888 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO impl.StateMachineUpdater: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater: set stopIndex = 0
scm1.org_1   | 2023-02-20 12:32:08,889 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO impl.StateMachineUpdater: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater: Took a snapshot at index 0
scm1.org_1   | 2023-02-20 12:32:08,889 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO impl.StateMachineUpdater: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm1.org_1   | 2023-02-20 12:32:08,894 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: closes. applyIndex: 0
scm1.org_1   | 2023-02-20 12:32:08,895 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm1.org_1   | 2023-02-20 12:32:08,897 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker close()
scm1.org_1   | 2023-02-20 12:32:08,899 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: Stopped
scm1.org_1   | 2023-02-20 12:32:08,899 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2023-02-20 12:32:08,903 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1; layoutVersion=4; scmId=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa
scm1.org_1   | 2023-02-20 12:32:08,908 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm1.org/172.25.0.116
scm1.org_1   | ************************************************************/
scm1.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm1.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm1.org_1   | 2023-02-20 12:32:10,897 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm1.org_1   | /************************************************************
scm1.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm1.org_1   | STARTUP_MSG:   host = scm1.org/172.25.0.116
scm1.org_1   | STARTUP_MSG:   args = []
scm1.org_1   | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
scm1.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
scm1.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
scm1.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm1.org_1   | ************************************************************/
scm1.org_1   | 2023-02-20 12:32:10,918 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm1.org_1   | 2023-02-20 12:32:10,999 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2023-02-20 12:32:11,066 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm1.org_1   | 2023-02-20 12:32:11,092 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm1.org_1   | 2023-02-20 12:32:11,188 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm1, RPC Address: scm1.org:9894 and Ratis port: 9894
scm1.org_1   | 2023-02-20 12:32:11,189 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm1: scm1.org
scm1.org_1   | 2023-02-20 12:32:11,986 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm1.org_1   | 2023-02-20 12:32:12,251 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
scm1.org_1   |          SerialNumber: 1490022441527
scm1.org_1   |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm1.org_1   |            Start Date: Mon Feb 20 00:00:00 UTC 2023
scm1.org_1   |            Final Date: Thu Mar 30 00:00:00 UTC 2028
scm1.org_1   |             SubjectDN: CN=scm-sub@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm1.org_1   |            Public Key: RSA Public Key [16:2d:b7:a5:b0:1c:7e:50:4b:d3:0c:1e:91:d5:30:6d:12:23:23:1c],[56:66:d1:a4]
scm1.org_1   |         modulus: b8881b4dd07c72248c8863bba59686bc7d8a1c0a77f9587da66c7e69fd2912af0eb4b5ab9b5e2cccd38500bee6178abbf02f9c564eb57a3029da82d6fb08538545dd260393eac22764468b808f392fc0555b558cc274360ac207d0b693142fbc5fd801789ecb2aefa0cfb5b7bb92c107c453311fcd9590678300eed8335e7c2887ddadc75dd7fd24d77cdfffb2d01c2817abb555f59cc4ca8c520c785155f682252969d6f60ba724f524b233eba33397229e851534a97c7b9a743d4dd3ed30d92316c44aab2e8741a08ef02fcc96cb516c9e93342ba73692ddd39f254390ff523b588e0710edded5220b5301b85e914019771f8cbd758e861d99222494d387a7
scm1.org_1   | public exponent: 10001
scm1.org_1   | 
scm1.org_1   |   Signature Algorithm: SHA256WITHRSA
scm1.org_1   |             Signature: 363d3273c12aa64988005dd16cbf319b130f6b08
scm1.org_1   |                        3ec325844d607b1225858823a3b417c8b78f8266
scm1.org_1   |                        5338966c887d5ee760050f81da927bac7aafdda0
scm1.org_1   |                        203c45d70e75f7f585632db643c276dcfc12d0cf
scm1.org_1   |                        31d734300b15141e9c77a37edb550f41a3cc1a14
scm1.org_1   |                        5e4b848617279f658ed62ed740017f1b4bd844c2
scm1.org_1   |                        cdb757bfdef0058498c0b11f0c59d5c5c4a6fea2
scm1.org_1   |                        e44d596ba23e9480406994c2d52d03fb603137d7
scm1.org_1   |                        38b028409f31693a2c3fddbd689785b29f009d1f
scm1.org_1   |                        b3b815a10f87cee8642a347f5b737ade5d2f2d7f
scm1.org_1   |                        3a51aac93500a29b12e04ea17d3d823af05cedd3
scm1.org_1   |                        737c196e3d25ee225340482ec1a717bf8f73b126
scm1.org_1   |                        32165d626d85896b9c2f99ff029695f3
scm1.org_1   |        Extensions: 
scm1.org_1   |                        critical(false) 2.5.29.17 value = Sequence
scm1.org_1   |     Tagged [7] IMPLICIT 
scm1.org_1   |         DER Octet String[4] 
scm1.org_1   |     Tagged [2] IMPLICIT 
scm1.org_1   |         DER Octet String[8] 
scm1.org_1   | 
scm1.org_1   |                        critical(true) BasicConstraints: isCa(true)
scm1.org_1   |                        critical(true) KeyUsage: 0xbe
scm1.org_1   |  from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm1.org_1   | 2023-02-20 12:32:12,261 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
scm2.org_1   | 2023-02-20 12:32:25,647 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm2.org_1   | 2023-02-20 12:32:25,695 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.117,host:scm2.org
scm2.org_1   | 2023-02-20 12:32:25,695 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm2.org_1   | 2023-02-20 12:32:25,700 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm2.org,scmId:1cc6fd6e-f210-4c0e-a8e6-009be253683e,clusterId:CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1,subject:scm-sub@scm2.org
scm2.org_1   | 2023-02-20 12:32:28,559 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm2.org_1   | 2023-02-20 12:32:28,625 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1, SCMID 1cc6fd6e-f210-4c0e-a8e6-009be253683e
scm2.org_1   | 2023-02-20 12:32:28,625 [main] INFO server.StorageContainerManager: Primary SCM Node ID 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa
scm2.org_1   | 2023-02-20 12:32:28,652 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm2.org/172.25.0.117
scm2.org_1   | ************************************************************/
scm2.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm2.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm2.org_1   | 2023-02-20 12:32:33,015 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm2.org_1   | /************************************************************
scm2.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm2.org_1   | STARTUP_MSG:   host = scm2.org/172.25.0.117
scm2.org_1   | STARTUP_MSG:   args = []
scm2.org_1   | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
scm2.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
scm2.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
scm2.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm2.org_1   | ************************************************************/
scm2.org_1   | 2023-02-20 12:32:33,096 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm2.org_1   | 2023-02-20 12:32:33,595 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2023-02-20 12:32:33,859 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm2.org_1   | 2023-02-20 12:32:33,932 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm2.org_1   | 2023-02-20 12:32:34,165 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm2, RPC Address: scm2.org:9894 and Ratis port: 9894
scm2.org_1   | 2023-02-20 12:32:34,174 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm2: scm2.org
scm2.org_1   | 2023-02-20 12:32:36,046 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm2.org_1   | 2023-02-20 12:32:36,896 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
scm2.org_1   |          SerialNumber: 1515662102178
scm2.org_1   |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm2.org_1   |            Start Date: Mon Feb 20 00:00:00 UTC 2023
scm2.org_1   |            Final Date: Thu Mar 30 00:00:00 UTC 2028
scm2.org_1   |             SubjectDN: CN=scm-sub@scm2.org,OU=1cc6fd6e-f210-4c0e-a8e6-009be253683e,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm2.org_1   |            Public Key: RSA Public Key [6d:24:6c:bc:21:93:c9:91:8f:5c:5a:2a:80:1d:b8:f1:65:38:7b:1b],[56:66:d1:a4]
scm2.org_1   |         modulus: d2d5fb01a3e2287943e3e39f5d947bab5504b6c5056f6b2b1301a2de36561f245adad7dffe43485b216a94f4cd3b9306190110a341a4979813aee116012bb8baa7d8437c44fe53e5e015752b3c0da0a478d91f29be647d1b0fa204c37484b824d76257896a0bf5d0eca3320e04ba8ddefba931dc55fd37657c79b3dfa62d7f6dbb4f4e38aaea5cf7714feee186fa0458fb848b1e2e2af5fee223115ee6e278a5d99417950c2742b77f7b7595d076c161bf3a53861590cb2cffe16f679abaa458f206623a46f8ad8ce5b44ffd9bbc88bdea619baa0494ce4e66d497b30e753c316832e7415cc2af185c826a4534ee9ecf8de6b94ab4da6870619e1cf2bece586f
scm2.org_1   | public exponent: 10001
scm2.org_1   | 
scm2.org_1   |   Signature Algorithm: SHA256WITHRSA
scm2.org_1   |             Signature: 8b43ab26776861c4d0f7881bfeb3a2dfa0b1eadc
scm2.org_1   |                        6414d83c2f34084983c19fdff74b676c93f4a9eb
scm2.org_1   |                        25782241ac102ffda9db203e97790232c83424f6
scm2.org_1   |                        f74719da2cc56b6f9d8098020d6f4c64fe0a1eac
scm2.org_1   |                        564fb28760cae34522d27b2649657fb3f663e23f
scm2.org_1   |                        61fa605965fc8776320d7579d23a200cc7e4d425
scm2.org_1   |                        bbde92e60f85a085d7249a943a302cd7d1de05fc
scm2.org_1   |                        ed6a4c266d39a56b774113896d15b55e92933828
scm2.org_1   |                        c8c12d2dc6d7ba66bd3adcb00643d8ff335b68da
scm2.org_1   |                        dc7d96cf66585a0e2c28df54638a4cf3754f95d7
scm2.org_1   |                        24fe8d9e6aaec8c8f08cbf53bf304ad8eed98e89
scm2.org_1   |                        27aca11e2e45049e23c29ab0898c541106eb8d1d
scm2.org_1   |                        fff9fbe9a6e8e6943bfdc1078fa4b394
scm2.org_1   |        Extensions: 
scm2.org_1   |                        critical(false) 2.5.29.17 value = Sequence
scm2.org_1   |     Tagged [7] IMPLICIT 
scm2.org_1   |         DER Octet String[4] 
scm2.org_1   |     Tagged [2] IMPLICIT 
scm2.org_1   |         DER Octet String[8] 
scm2.org_1   | 
scm2.org_1   |                        critical(true) BasicConstraints: isCa(true)
scm2.org_1   |                        critical(true) KeyUsage: 0xbe
scm2.org_1   |  from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm2.org_1   | 2023-02-20 12:32:36,943 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
scm2.org_1   |          SerialNumber: 1
scm2.org_1   |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm2.org_1   |            Start Date: Mon Feb 20 00:00:00 UTC 2023
scm2.org_1   |            Final Date: Thu Mar 30 00:00:00 UTC 2028
scm2.org_1   |             SubjectDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm2.org_1   |            Public Key: RSA Public Key [94:7e:a6:1e:66:03:60:cb:31:b6:ba:58:09:e5:6f:61:c6:1f:10:56],[56:66:d1:a4]
scm2.org_1   |         modulus: ae4c68b294de9bde416e48f8dd880f73587515c06076bc726de72d7d0efa633c8ab0845ecaa9dfe2be73479c31abedba80a9108027262a3316511997768cdb340fdcb173084f830287356e335877580b2bd5bdc297d7572a3635e6a114294f82bfb68aec57278d80b2e053741f6bd8e43df4c302f807657c2cd83c55edafc9fedddc555b306c6720e2e72e1a403ac6fa6a0b45823767e96cbe34c0ee95838730daf28e939192b29222957ccd58032a49c0446c773bb8ccc080bc6d017e13b3470c1f732b571f7ae50833d9852f4af92799f9b8c5eaec9c998c13768e6e1efd686c4d209f1d79c8d4f12aa2f5821e96eff58d7f8e4bf5877811957c77adb800e7
scm2.org_1   | public exponent: 10001
scm2.org_1   | 
scm2.org_1   |   Signature Algorithm: SHA256WITHRSA
scm2.org_1   |             Signature: a7cea6946dc4cec2c98cb07c07498d5444b6300d
scm2.org_1   |                        0a6c4e9490adf7093c90271931b5d0417975d9b8
scm2.org_1   |                        7a9238465c6f3f4de8400309865e2da81ad21b31
scm2.org_1   |                        57de65cb86c13fbef66ec87c8614bd8ad650e11d
scm2.org_1   |                        4e49b0e20080ff8a0c3d6a6e6cef0122f38fbedc
scm2.org_1   |                        9428a9b69ae6258d8ff4035af00ec4326a833057
scm2.org_1   |                        736e2bec20eba55b3e39bd1818d036b10a473b2e
scm2.org_1   |                        99f5e8079f4fcaa7750269bdb7680ebf53d8f7bb
scm2.org_1   |                        16ddc0ef7ac8c2bd9f938901391f3d9e4f3823e1
scm3.org_1   | Sleeping for 5 seconds
scm3.org_1   | Waiting for the service scm2.org:9894
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2023-02-20 12:32:58,319 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = [--bootstrap]
scm3.org_1   | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
recon_1      | 2023-02-20 12:33:21,352 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 12 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:21,353 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 13 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:21,355 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:23,357 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 15 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:23,359 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 16 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:23,360 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 17 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:25,362 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 18 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:25,363 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 19 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:25,365 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 20 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:27,368 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 21 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:27,369 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 22 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:27,371 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 23 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:29,375 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 24 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:29,380 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 25 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:29,401 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 26 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:31,403 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 27 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:31,407 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 28 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:31,415 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 29 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:33,417 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 30 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:33,418 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 31 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:33,418 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 32 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:35,421 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 33 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:35,423 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 34 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:35,424 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 35 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:37,427 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 36 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:37,430 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 37 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:37,436 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 38 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:39,438 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 39 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:39,439 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 40 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:39,440 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 41 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:41,442 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 42 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:41,443 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 43 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:41,444 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 44 failover attempts. Trying to failover after sleeping for 2000ms.
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2023-02-20 12:32:58,397 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2023-02-20 12:32:58,760 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2023-02-20 12:32:58,938 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2023-02-20 12:32:58,943 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2023-02-20 12:32:59,100 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2023-02-20 12:32:59,102 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2023-02-20 12:32:59,731 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2023-02-20 12:32:59,733 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2023-02-20 12:32:59,947 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm3.org_1   | 2023-02-20 12:33:01,415 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm3.org_1   | 2023-02-20 12:33:03,092 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm3.org_1   | 2023-02-20 12:33:03,096 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
scm3.org_1   | 2023-02-20 12:33:03,097 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm3.org_1   | 2023-02-20 12:33:05,664 [main] INFO ha.HASecurityUtils: Init response: GETCERT
scm3.org_1   | 2023-02-20 12:33:05,712 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.118,host:scm3.org
scm3.org_1   | 2023-02-20 12:33:05,713 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm3.org_1   | 2023-02-20 12:33:05,718 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm3.org,scmId:d10edad7-6b47-4462-af85-11e38864983b,clusterId:CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1,subject:scm-sub@scm3.org
scm3.org_1   | 2023-02-20 12:33:06,909 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm3.org_1   | 2023-02-20 12:33:06,933 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1, SCMID d10edad7-6b47-4462-af85-11e38864983b
scm3.org_1   | 2023-02-20 12:33:06,933 [main] INFO server.StorageContainerManager: Primary SCM Node ID 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa
scm3.org_1   | 2023-02-20 12:33:06,946 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm3.org/172.25.0.118
scm3.org_1   | ************************************************************/
scm3.org_1   | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm3.org_1   | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm3.org_1   | 2023-02-20 12:33:11,489 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm3.org_1   | /************************************************************
scm3.org_1   | STARTUP_MSG: Starting StorageContainerManager
scm3.org_1   | STARTUP_MSG:   host = scm3.org/172.25.0.118
scm3.org_1   | STARTUP_MSG:   args = []
scm3.org_1   | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
recon_1      | 2023-02-20 12:33:43,448 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 45 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:43,450 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 46 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:43,451 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 47 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:45,453 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 48 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:45,454 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 49 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:45,455 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 50 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:47,457 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 51 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:47,458 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 52 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:47,460 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 53 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:49,461 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 54 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:49,462 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 55 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:49,464 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 56 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:51,465 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 57 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:51,466 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 58 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:51,468 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 59 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:53,470 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 60 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:53,471 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 61 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:53,473 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 62 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:55,474 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 63 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:55,475 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 64 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:55,477 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 65 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:57,478 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 66 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:57,479 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 67 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:57,480 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 68 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:33:59,482 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 69 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:59,483 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 70 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:33:59,484 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 71 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:01,485 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 72 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:01,486 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 73 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:01,491 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 74 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:03,502 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 75 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:03,503 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 76 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:03,504 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 77 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:05,510 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 78 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:05,548 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 79 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:05,574 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 80 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:07,577 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 81 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:07,579 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 82 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:07,580 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 83 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:09,582 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 84 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:09,583 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 85 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:09,585 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 86 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:11,589 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 87 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:11,593 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 88 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:11,596 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 89 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:13,600 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 90 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:13,622 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 91 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:13,651 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 92 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:15,686 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 93 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:15,688 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 94 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:15,692 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 95 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:17,698 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 96 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:17,700 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 97 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:17,703 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 98 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:19,705 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 99 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:19,707 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 100 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:19,708 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 101 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:21,709 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 102 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:21,712 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 103 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:21,714 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 104 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:23,722 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 105 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:23,733 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 106 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:23,738 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 107 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:25,740 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 108 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:25,745 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 109 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:25,758 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 110 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:27,761 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 111 failover attempts. Trying to failover immediately.
scm1.org_1   |          SerialNumber: 1490022441527
scm1.org_1   |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm1.org_1   |            Start Date: Mon Feb 20 00:00:00 UTC 2023
scm1.org_1   |            Final Date: Thu Mar 30 00:00:00 UTC 2028
scm1.org_1   |             SubjectDN: CN=scm-sub@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm1.org_1   |            Public Key: RSA Public Key [16:2d:b7:a5:b0:1c:7e:50:4b:d3:0c:1e:91:d5:30:6d:12:23:23:1c],[56:66:d1:a4]
scm1.org_1   |         modulus: b8881b4dd07c72248c8863bba59686bc7d8a1c0a77f9587da66c7e69fd2912af0eb4b5ab9b5e2cccd38500bee6178abbf02f9c564eb57a3029da82d6fb08538545dd260393eac22764468b808f392fc0555b558cc274360ac207d0b693142fbc5fd801789ecb2aefa0cfb5b7bb92c107c453311fcd9590678300eed8335e7c2887ddadc75dd7fd24d77cdfffb2d01c2817abb555f59cc4ca8c520c785155f682252969d6f60ba724f524b233eba33397229e851534a97c7b9a743d4dd3ed30d92316c44aab2e8741a08ef02fcc96cb516c9e93342ba73692ddd39f254390ff523b588e0710edded5220b5301b85e914019771f8cbd758e861d99222494d387a7
scm1.org_1   | public exponent: 10001
scm1.org_1   | 
scm1.org_1   |   Signature Algorithm: SHA256WITHRSA
scm1.org_1   |             Signature: 363d3273c12aa64988005dd16cbf319b130f6b08
scm1.org_1   |                        3ec325844d607b1225858823a3b417c8b78f8266
scm1.org_1   |                        5338966c887d5ee760050f81da927bac7aafdda0
scm1.org_1   |                        203c45d70e75f7f585632db643c276dcfc12d0cf
scm1.org_1   |                        31d734300b15141e9c77a37edb550f41a3cc1a14
scm1.org_1   |                        5e4b848617279f658ed62ed740017f1b4bd844c2
scm1.org_1   |                        cdb757bfdef0058498c0b11f0c59d5c5c4a6fea2
scm1.org_1   |                        e44d596ba23e9480406994c2d52d03fb603137d7
scm1.org_1   |                        38b028409f31693a2c3fddbd689785b29f009d1f
scm1.org_1   |                        b3b815a10f87cee8642a347f5b737ade5d2f2d7f
scm1.org_1   |                        3a51aac93500a29b12e04ea17d3d823af05cedd3
scm1.org_1   |                        737c196e3d25ee225340482ec1a717bf8f73b126
scm1.org_1   |                        32165d626d85896b9c2f99ff029695f3
scm1.org_1   |        Extensions: 
scm1.org_1   |                        critical(false) 2.5.29.17 value = Sequence
scm1.org_1   |     Tagged [7] IMPLICIT 
scm1.org_1   |         DER Octet String[4] 
scm1.org_1   |     Tagged [2] IMPLICIT 
scm1.org_1   |         DER Octet String[8] 
scm1.org_1   | 
scm1.org_1   |                        critical(true) BasicConstraints: isCa(true)
scm1.org_1   |                        critical(true) KeyUsage: 0xbe
scm1.org_1   |  from file:/data/metadata/scm/sub-ca/certs/1490022441527.crt.
scm1.org_1   | 2023-02-20 12:32:12,274 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
scm1.org_1   |          SerialNumber: 1
scm1.org_1   |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm1.org_1   |            Start Date: Mon Feb 20 00:00:00 UTC 2023
scm1.org_1   |            Final Date: Thu Mar 30 00:00:00 UTC 2028
scm1.org_1   |             SubjectDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm1.org_1   |            Public Key: RSA Public Key [94:7e:a6:1e:66:03:60:cb:31:b6:ba:58:09:e5:6f:61:c6:1f:10:56],[56:66:d1:a4]
scm1.org_1   |         modulus: ae4c68b294de9bde416e48f8dd880f73587515c06076bc726de72d7d0efa633c8ab0845ecaa9dfe2be73479c31abedba80a9108027262a3316511997768cdb340fdcb173084f830287356e335877580b2bd5bdc297d7572a3635e6a114294f82bfb68aec57278d80b2e053741f6bd8e43df4c302f807657c2cd83c55edafc9fedddc555b306c6720e2e72e1a403ac6fa6a0b45823767e96cbe34c0ee95838730daf28e939192b29222957ccd58032a49c0446c773bb8ccc080bc6d017e13b3470c1f732b571f7ae50833d9852f4af92799f9b8c5eaec9c998c13768e6e1efd686c4d209f1d79c8d4f12aa2f5821e96eff58d7f8e4bf5877811957c77adb800e7
scm1.org_1   | public exponent: 10001
scm1.org_1   | 
scm1.org_1   |   Signature Algorithm: SHA256WITHRSA
scm1.org_1   |             Signature: a7cea6946dc4cec2c98cb07c07498d5444b6300d
scm1.org_1   |                        0a6c4e9490adf7093c90271931b5d0417975d9b8
scm1.org_1   |                        7a9238465c6f3f4de8400309865e2da81ad21b31
scm1.org_1   |                        57de65cb86c13fbef66ec87c8614bd8ad650e11d
scm1.org_1   |                        4e49b0e20080ff8a0c3d6a6e6cef0122f38fbedc
scm1.org_1   |                        9428a9b69ae6258d8ff4035af00ec4326a833057
scm1.org_1   |                        736e2bec20eba55b3e39bd1818d036b10a473b2e
scm1.org_1   |                        99f5e8079f4fcaa7750269bdb7680ebf53d8f7bb
scm1.org_1   |                        16ddc0ef7ac8c2bd9f938901391f3d9e4f3823e1
scm1.org_1   |                        07939f9a9f829615d2d1f339e2f210e795258ac1
scm1.org_1   |                        f03a273f30f7cb3110f6d700ded1888ed1dcaa17
scm1.org_1   |                        ff9774e9f4d33a5be09b76c57503b7a066668066
scm1.org_1   |                        4c46b6c92c5c84d4978c557861c07dba
scm1.org_1   |        Extensions: 
scm1.org_1   |                        critical(true) BasicConstraints: isCa(true)
scm1.org_1   |                        critical(true) KeyUsage: 0x6
scm1.org_1   |                        critical(false) 2.5.29.17 value = Sequence
scm1.org_1   |     Tagged [7] IMPLICIT 
scm1.org_1   |         DER Octet String[4] 
scm1.org_1   |     Tagged [2] IMPLICIT 
scm1.org_1   |         DER Octet String[8] 
scm1.org_1   | 
scm1.org_1   |  from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm1.org_1   | 2023-02-20 12:32:12,288 [main] INFO client.SCMCertificateClient: CertificateLifetimeMonitor for scm/sub-ca is started with first delay 158671667719 ms and interval 86400000 ms.
scm1.org_1   | 2023-02-20 12:32:12,533 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm1.org_1   | 2023-02-20 12:32:12,534 [main] INFO server.StorageContainerManager: SCM login successful.
scm1.org_1   | 2023-02-20 12:32:12,594 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2023-02-20 12:32:12,820 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm1.org_1   | 2023-02-20 12:32:13,289 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
scm1.org_1   | 2023-02-20 12:32:13,290 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm1.org_1   | 2023-02-20 12:32:13,366 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm1.org_1   | 2023-02-20 12:32:13,400 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa
scm1.org_1   | 2023-02-20 12:32:13,458 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
scm1.org_1   | 2023-02-20 12:32:13,474 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
scm1.org_1   | 2023-02-20 12:32:13,545 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm1.org_1   | 2023-02-20 12:32:13,639 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
scm1.org_1   | 2023-02-20 12:32:13,643 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
scm1.org_1   | 2023-02-20 12:32:13,644 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
scm1.org_1   | 2023-02-20 12:32:13,645 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
scm1.org_1   | 2023-02-20 12:32:13,646 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
scm1.org_1   | 2023-02-20 12:32:13,646 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
scm3.org_1   | STARTUP_MSG:   build = https://github.com/apache/ozone/4be2122922b84c45cee6e845f182b0dbf4a06805 ; compiled by 'runner' on 2023-02-20T11:55Z
scm3.org_1   | STARTUP_MSG:   java = 11.0.14.1
scm3.org_1   | ************************************************************/
scm3.org_1   | 2023-02-20 12:33:11,520 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm3.org_1   | 2023-02-20 12:33:11,776 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2023-02-20 12:33:11,913 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm3.org_1   | 2023-02-20 12:33:11,949 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm3.org_1   | 2023-02-20 12:33:12,117 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm3, RPC Address: scm3.org:9894 and Ratis port: 9894
scm3.org_1   | 2023-02-20 12:33:12,120 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm3: scm3.org
scm3.org_1   | 2023-02-20 12:33:13,655 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
scm3.org_1   | 2023-02-20 12:33:14,008 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
scm3.org_1   |          SerialNumber: 1555569389665
scm3.org_1   |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm3.org_1   |            Start Date: Mon Feb 20 00:00:00 UTC 2023
scm3.org_1   |            Final Date: Thu Mar 30 00:00:00 UTC 2028
scm3.org_1   |             SubjectDN: CN=scm-sub@scm3.org,OU=d10edad7-6b47-4462-af85-11e38864983b,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm3.org_1   |            Public Key: RSA Public Key [f5:98:87:8f:98:0a:d2:0f:62:c2:35:ee:f8:f5:29:ef:8b:dd:4b:af],[56:66:d1:a4]
scm3.org_1   |         modulus: 9de84facfc7e098f964cd8e67e54b0701740f0e2be7ebfc49b2e3a4c799b34226c8128fcf887bcf9f12fb56e864a56cc41d12f42f22e15d33c47333b5cf23f29eec12d691bf4ba7edc29f92dadbb20b92f80b0c3f759b880cf295e3980128b124f9b4aa63857fc1a5535e05c8cf58d3724b866ac06445b0a6683327895e56730200f74d36cac46e96d0d0ff248b8f833c83411f4787669c579d5ab31ac7bfeae3ffcb32676a3eab648bd47a104d6ce53f80ac4a2383f0bbc0385f64037f711a3dee729fa13f36a8b975176bebf892e5f5ed3a3d23dc78e7576030e18bbc14717ba84519752b8444f250591bde9cb1258d94b70c2d21b35ab3f34e5c0f00b3d91
scm3.org_1   | public exponent: 10001
scm3.org_1   | 
scm3.org_1   |   Signature Algorithm: SHA256WITHRSA
scm3.org_1   |             Signature: 707c9b458751986f8500c00f876d08a540a8adb3
scm3.org_1   |                        3c9bfe0f7571746aaf6ac4986427d26821989773
scm3.org_1   |                        843a90894d72d1dcfb1b16070d91f4ba9c0d3136
scm3.org_1   |                        4da978309e72285f03bafff992355e16a47104d4
scm3.org_1   |                        0e282f68a0b0249a98a0600dda83baef69f3ccab
scm2.org_1   |                        07939f9a9f829615d2d1f339e2f210e795258ac1
scm2.org_1   |                        f03a273f30f7cb3110f6d700ded1888ed1dcaa17
scm2.org_1   |                        ff9774e9f4d33a5be09b76c57503b7a066668066
scm2.org_1   |                        4c46b6c92c5c84d4978c557861c07dba
scm2.org_1   |        Extensions: 
scm2.org_1   |                        critical(true) BasicConstraints: isCa(true)
scm2.org_1   |                        critical(true) KeyUsage: 0x6
scm2.org_1   |                        critical(false) 2.5.29.17 value = Sequence
scm2.org_1   |     Tagged [7] IMPLICIT 
scm2.org_1   |         DER Octet String[4] 
scm2.org_1   |     Tagged [2] IMPLICIT 
scm2.org_1   |         DER Octet String[8] 
scm2.org_1   | 
scm2.org_1   |  from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm2.org_1   | 2023-02-20 12:32:36,974 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
scm2.org_1   |          SerialNumber: 1515662102178
scm2.org_1   |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm2.org_1   |            Start Date: Mon Feb 20 00:00:00 UTC 2023
scm2.org_1   |            Final Date: Thu Mar 30 00:00:00 UTC 2028
scm2.org_1   |             SubjectDN: CN=scm-sub@scm2.org,OU=1cc6fd6e-f210-4c0e-a8e6-009be253683e,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm2.org_1   |            Public Key: RSA Public Key [6d:24:6c:bc:21:93:c9:91:8f:5c:5a:2a:80:1d:b8:f1:65:38:7b:1b],[56:66:d1:a4]
scm2.org_1   |         modulus: d2d5fb01a3e2287943e3e39f5d947bab5504b6c5056f6b2b1301a2de36561f245adad7dffe43485b216a94f4cd3b9306190110a341a4979813aee116012bb8baa7d8437c44fe53e5e015752b3c0da0a478d91f29be647d1b0fa204c37484b824d76257896a0bf5d0eca3320e04ba8ddefba931dc55fd37657c79b3dfa62d7f6dbb4f4e38aaea5cf7714feee186fa0458fb848b1e2e2af5fee223115ee6e278a5d99417950c2742b77f7b7595d076c161bf3a53861590cb2cffe16f679abaa458f206623a46f8ad8ce5b44ffd9bbc88bdea619baa0494ce4e66d497b30e753c316832e7415cc2af185c826a4534ee9ecf8de6b94ab4da6870619e1cf2bece586f
scm2.org_1   | public exponent: 10001
scm2.org_1   | 
scm2.org_1   |   Signature Algorithm: SHA256WITHRSA
scm2.org_1   |             Signature: 8b43ab26776861c4d0f7881bfeb3a2dfa0b1eadc
scm2.org_1   |                        6414d83c2f34084983c19fdff74b676c93f4a9eb
scm2.org_1   |                        25782241ac102ffda9db203e97790232c83424f6
scm2.org_1   |                        f74719da2cc56b6f9d8098020d6f4c64fe0a1eac
scm2.org_1   |                        564fb28760cae34522d27b2649657fb3f663e23f
scm2.org_1   |                        61fa605965fc8776320d7579d23a200cc7e4d425
scm2.org_1   |                        bbde92e60f85a085d7249a943a302cd7d1de05fc
scm2.org_1   |                        ed6a4c266d39a56b774113896d15b55e92933828
scm2.org_1   |                        c8c12d2dc6d7ba66bd3adcb00643d8ff335b68da
scm2.org_1   |                        dc7d96cf66585a0e2c28df54638a4cf3754f95d7
scm2.org_1   |                        24fe8d9e6aaec8c8f08cbf53bf304ad8eed98e89
scm2.org_1   |                        27aca11e2e45049e23c29ab0898c541106eb8d1d
scm2.org_1   |                        fff9fbe9a6e8e6943bfdc1078fa4b394
scm2.org_1   |        Extensions: 
scm2.org_1   |                        critical(false) 2.5.29.17 value = Sequence
scm2.org_1   |     Tagged [7] IMPLICIT 
scm2.org_1   |         DER Octet String[4] 
scm2.org_1   |     Tagged [2] IMPLICIT 
scm2.org_1   |         DER Octet String[8] 
scm2.org_1   | 
scm2.org_1   |                        critical(true) BasicConstraints: isCa(true)
scm2.org_1   |                        critical(true) KeyUsage: 0xbe
scm2.org_1   |  from file:/data/metadata/scm/sub-ca/certs/1515662102178.crt.
scm2.org_1   | 2023-02-20 12:32:36,993 [main] INFO client.SCMCertificateClient: CertificateLifetimeMonitor for scm/sub-ca is started with first delay 158671643019 ms and interval 86400000 ms.
scm2.org_1   | 2023-02-20 12:32:37,459 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm2.org_1   | 2023-02-20 12:32:37,459 [main] INFO server.StorageContainerManager: SCM login successful.
scm2.org_1   | 2023-02-20 12:32:37,546 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2023-02-20 12:32:38,254 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm2.org_1   | 2023-02-20 12:32:39,159 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
scm2.org_1   | 2023-02-20 12:32:39,163 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm2.org_1   | 2023-02-20 12:32:39,427 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm2.org_1   | 2023-02-20 12:32:39,544 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:1cc6fd6e-f210-4c0e-a8e6-009be253683e
scm2.org_1   | 2023-02-20 12:32:39,660 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
scm2.org_1   | 2023-02-20 12:32:39,688 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
scm2.org_1   | 2023-02-20 12:32:39,861 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm2.org_1   | 2023-02-20 12:32:40,101 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
scm2.org_1   | 2023-02-20 12:32:40,106 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
scm2.org_1   | 2023-02-20 12:32:40,110 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
scm2.org_1   | 2023-02-20 12:32:40,112 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
scm2.org_1   | 2023-02-20 12:32:40,112 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
scm2.org_1   | 2023-02-20 12:32:40,113 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm2.org_1   | 2023-02-20 12:32:40,114 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm2.org_1   | 2023-02-20 12:32:40,116 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2023-02-20 12:32:40,125 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm2.org_1   | 2023-02-20 12:32:40,128 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm2.org_1   | 2023-02-20 12:32:40,175 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm2.org_1   | 2023-02-20 12:32:40,191 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm2.org_1   | 2023-02-20 12:32:40,192 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm2.org_1   | 2023-02-20 12:32:42,252 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm2.org_1   | 2023-02-20 12:32:42,256 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm2.org_1   | 2023-02-20 12:32:42,264 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm2.org_1   | 2023-02-20 12:32:42,264 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2023-02-20 12:32:42,268 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2023-02-20 12:32:42,286 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2023-02-20 12:32:42,324 [main] INFO server.RaftServer: 1cc6fd6e-f210-4c0e-a8e6-009be253683e: addNew group-F5FD3C6D31B1:[] returns group-F5FD3C6D31B1:java.util.concurrent.CompletableFuture@3869a6e5[Not completed]
scm2.org_1   | 2023-02-20 12:32:42,526 [pool-17-thread-1] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e: new RaftServerImpl for group-F5FD3C6D31B1:[] with SCMStateMachine:uninitialized
scm2.org_1   | 2023-02-20 12:32:42,545 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm2.org_1   | 2023-02-20 12:32:42,552 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm2.org_1   | 2023-02-20 12:32:42,552 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm2.org_1   | 2023-02-20 12:32:42,552 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm2.org_1   | 2023-02-20 12:32:42,552 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm2.org_1   | 2023-02-20 12:32:42,552 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm2.org_1   | 2023-02-20 12:32:42,577 [pool-17-thread-1] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
scm2.org_1   | 2023-02-20 12:32:42,577 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm2.org_1   | 2023-02-20 12:32:42,604 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm2.org_1   | 2023-02-20 12:32:42,605 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm2.org_1   | 2023-02-20 12:32:42,670 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm2.org_1   | 2023-02-20 12:32:42,681 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm2.org_1   | 2023-02-20 12:32:42,682 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm2.org_1   | 2023-02-20 12:32:43,107 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm2.org_1   | 2023-02-20 12:32:43,107 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm2.org_1   | 2023-02-20 12:32:43,116 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm2.org_1   | 2023-02-20 12:32:43,121 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm2.org_1   | 2023-02-20 12:32:43,121 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm2.org_1   | 2023-02-20 12:32:43,129 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm2.org_1   | 2023-02-20 12:32:43,129 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm2.org_1   | 2023-02-20 12:32:43,130 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm2.org_1   | 2023-02-20 12:32:43,818 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm2.org_1   | 2023-02-20 12:32:44,430 [main] INFO reflections.Reflections: Reflections took 481 ms to scan 3 urls, producing 125 keys and 280 values 
scm2.org_1   | 2023-02-20 12:32:44,754 [main] INFO ha.SequenceIdGenerator: upgrade localId to 111677748019200000
scm2.org_1   | 2023-02-20 12:32:44,756 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm2.org_1   | 2023-02-20 12:32:44,763 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm2.org_1   | 2023-02-20 12:32:44,766 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm2.org_1   | 2023-02-20 12:32:45,006 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm2.org_1   | 2023-02-20 12:32:45,061 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm2.org_1   | 2023-02-20 12:32:45,066 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm2.org_1   | 2023-02-20 12:32:45,094 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm2.org_1   | 2023-02-20 12:32:45,224 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm2.org_1   | 2023-02-20 12:32:45,228 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm2.org_1   | 2023-02-20 12:32:45,251 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm2.org_1   | 2023-02-20 12:32:45,261 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm2.org_1   | 2023-02-20 12:32:45,286 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm2.org_1   | 2023-02-20 12:32:45,293 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm2.org_1   | 2023-02-20 12:32:45,321 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm2.org_1   | 2023-02-20 12:32:45,329 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm2.org_1   | 2023-02-20 12:32:45,477 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm2.org_1   | 2023-02-20 12:32:45,546 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm2.org_1   | 2023-02-20 12:32:45,965 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm2.org_1   | 2023-02-20 12:32:46,050 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm2.org_1   | 2023-02-20 12:32:46,058 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm2.org_1   | 2023-02-20 12:32:46,118 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm2.org_1   | 2023-02-20 12:32:46,184 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:32:46,203 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2023-02-20 12:32:46,381 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm2.org_1   | 2023-02-20 12:32:46,474 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2023-02-20 12:32:46,618 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm2.org_1   | 2023-02-20 12:32:49,033 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2023-02-20 12:32:49,093 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1      | 2023-02-20 12:34:27,764 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 112 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:27,785 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 113 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:29,788 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 114 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:29,793 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 115 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:29,797 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 116 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:31,800 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 117 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:31,804 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 118 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:31,832 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 119 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:33,834 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 120 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:33,835 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 121 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:33,847 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 122 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:35,849 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 123 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:35,852 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 124 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:35,853 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 125 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:37,857 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 126 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:37,858 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 127 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:37,859 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 128 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:39,861 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 129 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:39,863 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 130 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:39,865 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 131 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:41,883 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 132 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:41,884 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 133 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:41,885 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 134 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:43,886 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 135 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:43,888 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 136 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:43,888 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 137 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:45,890 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 138 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:45,891 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 139 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:45,892 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 140 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:47,894 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 141 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:47,895 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 142 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:47,896 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 143 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:49,898 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 144 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:49,899 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 145 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:49,900 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 146 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:51,901 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 147 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:51,903 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 148 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:51,905 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 149 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:53,907 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 150 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:53,908 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 151 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:53,911 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 152 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:55,912 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 153 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:55,913 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 154 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:55,914 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 155 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:57,916 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 156 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:57,921 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 157 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:57,963 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 158 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:34:59,555 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53162
recon_1      | 2023-02-20 12:34:59,653 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2023-02-20 12:34:59,971 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 159 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:34:59,972 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 160 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:00,016 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 161 failover attempts. Trying to failover after sleeping for 2000ms.
scm3.org_1   |                        a812149174e7db587fc97006b9c11d913ed86698
scm3.org_1   |                        6a03f819827d5fd937442fd22a23feee9a9ad0b9
scm3.org_1   |                        dadf344384e7d386b07eb7ca9bfdc17bab2edee4
scm3.org_1   |                        613b5c9945e2a4f119bfe64df5e801c8e9dc2ac0
scm3.org_1   |                        71747587b24a05a382712df7290ef27ff2fc4f77
scm3.org_1   |                        f83cec37053db3ec7ffb46b2f471f56826aee4fd
scm3.org_1   |                        eeb625967d631c936d54667edf9a1604a33392e2
scm3.org_1   |                        9a560da696265038563ceb92770d398a
scm3.org_1   |        Extensions: 
scm3.org_1   |                        critical(false) 2.5.29.17 value = Sequence
scm3.org_1   |     Tagged [7] IMPLICIT 
scm3.org_1   |         DER Octet String[4] 
scm3.org_1   |     Tagged [2] IMPLICIT 
scm3.org_1   |         DER Octet String[8] 
scm3.org_1   | 
scm3.org_1   |                        critical(true) BasicConstraints: isCa(true)
scm3.org_1   |                        critical(true) KeyUsage: 0xbe
scm3.org_1   |  from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm3.org_1   | 2023-02-20 12:33:14,018 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
scm3.org_1   |          SerialNumber: 1555569389665
scm3.org_1   |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm3.org_1   |            Start Date: Mon Feb 20 00:00:00 UTC 2023
scm3.org_1   |            Final Date: Thu Mar 30 00:00:00 UTC 2028
scm3.org_1   |             SubjectDN: CN=scm-sub@scm3.org,OU=d10edad7-6b47-4462-af85-11e38864983b,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm3.org_1   |            Public Key: RSA Public Key [f5:98:87:8f:98:0a:d2:0f:62:c2:35:ee:f8:f5:29:ef:8b:dd:4b:af],[56:66:d1:a4]
scm3.org_1   |         modulus: 9de84facfc7e098f964cd8e67e54b0701740f0e2be7ebfc49b2e3a4c799b34226c8128fcf887bcf9f12fb56e864a56cc41d12f42f22e15d33c47333b5cf23f29eec12d691bf4ba7edc29f92dadbb20b92f80b0c3f759b880cf295e3980128b124f9b4aa63857fc1a5535e05c8cf58d3724b866ac06445b0a6683327895e56730200f74d36cac46e96d0d0ff248b8f833c83411f4787669c579d5ab31ac7bfeae3ffcb32676a3eab648bd47a104d6ce53f80ac4a2383f0bbc0385f64037f711a3dee729fa13f36a8b975176bebf892e5f5ed3a3d23dc78e7576030e18bbc14717ba84519752b8444f250591bde9cb1258d94b70c2d21b35ab3f34e5c0f00b3d91
scm3.org_1   | public exponent: 10001
scm3.org_1   | 
scm3.org_1   |   Signature Algorithm: SHA256WITHRSA
scm3.org_1   |             Signature: 707c9b458751986f8500c00f876d08a540a8adb3
scm3.org_1   |                        3c9bfe0f7571746aaf6ac4986427d26821989773
scm3.org_1   |                        843a90894d72d1dcfb1b16070d91f4ba9c0d3136
scm3.org_1   |                        4da978309e72285f03bafff992355e16a47104d4
scm3.org_1   |                        0e282f68a0b0249a98a0600dda83baef69f3ccab
scm3.org_1   |                        a812149174e7db587fc97006b9c11d913ed86698
scm3.org_1   |                        6a03f819827d5fd937442fd22a23feee9a9ad0b9
scm3.org_1   |                        dadf344384e7d386b07eb7ca9bfdc17bab2edee4
scm3.org_1   |                        613b5c9945e2a4f119bfe64df5e801c8e9dc2ac0
scm3.org_1   |                        71747587b24a05a382712df7290ef27ff2fc4f77
scm3.org_1   |                        f83cec37053db3ec7ffb46b2f471f56826aee4fd
scm3.org_1   |                        eeb625967d631c936d54667edf9a1604a33392e2
scm3.org_1   |                        9a560da696265038563ceb92770d398a
scm3.org_1   |        Extensions: 
scm3.org_1   |                        critical(false) 2.5.29.17 value = Sequence
scm3.org_1   |     Tagged [7] IMPLICIT 
scm3.org_1   |         DER Octet String[4] 
scm3.org_1   |     Tagged [2] IMPLICIT 
scm3.org_1   |         DER Octet String[8] 
scm3.org_1   | 
scm3.org_1   |                        critical(true) BasicConstraints: isCa(true)
scm3.org_1   |                        critical(true) KeyUsage: 0xbe
scm3.org_1   |  from file:/data/metadata/scm/sub-ca/certs/1555569389665.crt.
scm3.org_1   | 2023-02-20 12:33:14,029 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
scm3.org_1   |          SerialNumber: 1
scm3.org_1   |              IssuerDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm3.org_1   |            Start Date: Mon Feb 20 00:00:00 UTC 2023
scm3.org_1   |            Final Date: Thu Mar 30 00:00:00 UTC 2028
scm3.org_1   |             SubjectDN: CN=scm@scm1.org,OU=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa,O=CID-df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm3.org_1   |            Public Key: RSA Public Key [94:7e:a6:1e:66:03:60:cb:31:b6:ba:58:09:e5:6f:61:c6:1f:10:56],[56:66:d1:a4]
scm3.org_1   |         modulus: ae4c68b294de9bde416e48f8dd880f73587515c06076bc726de72d7d0efa633c8ab0845ecaa9dfe2be73479c31abedba80a9108027262a3316511997768cdb340fdcb173084f830287356e335877580b2bd5bdc297d7572a3635e6a114294f82bfb68aec57278d80b2e053741f6bd8e43df4c302f807657c2cd83c55edafc9fedddc555b306c6720e2e72e1a403ac6fa6a0b45823767e96cbe34c0ee95838730daf28e939192b29222957ccd58032a49c0446c773bb8ccc080bc6d017e13b3470c1f732b571f7ae50833d9852f4af92799f9b8c5eaec9c998c13768e6e1efd686c4d209f1d79c8d4f12aa2f5821e96eff58d7f8e4bf5877811957c77adb800e7
scm3.org_1   | public exponent: 10001
scm3.org_1   | 
scm3.org_1   |   Signature Algorithm: SHA256WITHRSA
scm3.org_1   |             Signature: a7cea6946dc4cec2c98cb07c07498d5444b6300d
scm3.org_1   |                        0a6c4e9490adf7093c90271931b5d0417975d9b8
scm3.org_1   |                        7a9238465c6f3f4de8400309865e2da81ad21b31
scm3.org_1   |                        57de65cb86c13fbef66ec87c8614bd8ad650e11d
scm3.org_1   |                        4e49b0e20080ff8a0c3d6a6e6cef0122f38fbedc
scm3.org_1   |                        9428a9b69ae6258d8ff4035af00ec4326a833057
scm3.org_1   |                        736e2bec20eba55b3e39bd1818d036b10a473b2e
scm3.org_1   |                        99f5e8079f4fcaa7750269bdb7680ebf53d8f7bb
scm3.org_1   |                        16ddc0ef7ac8c2bd9f938901391f3d9e4f3823e1
scm3.org_1   |                        07939f9a9f829615d2d1f339e2f210e795258ac1
scm3.org_1   |                        f03a273f30f7cb3110f6d700ded1888ed1dcaa17
scm3.org_1   |                        ff9774e9f4d33a5be09b76c57503b7a066668066
scm3.org_1   |                        4c46b6c92c5c84d4978c557861c07dba
scm3.org_1   |        Extensions: 
scm3.org_1   |                        critical(true) BasicConstraints: isCa(true)
scm3.org_1   |                        critical(true) KeyUsage: 0x6
scm3.org_1   |                        critical(false) 2.5.29.17 value = Sequence
scm3.org_1   |     Tagged [7] IMPLICIT 
scm3.org_1   |         DER Octet String[4] 
scm3.org_1   |     Tagged [2] IMPLICIT 
scm3.org_1   |         DER Octet String[8] 
scm3.org_1   | 
scm3.org_1   |  from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm3.org_1   | 2023-02-20 12:33:14,050 [main] INFO client.SCMCertificateClient: CertificateLifetimeMonitor for scm/sub-ca is started with first delay 158671605967 ms and interval 86400000 ms.
scm3.org_1   | 2023-02-20 12:33:14,261 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
scm3.org_1   | 2023-02-20 12:33:14,261 [main] INFO server.StorageContainerManager: SCM login successful.
scm3.org_1   | 2023-02-20 12:33:14,312 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2023-02-20 12:33:14,586 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm3.org_1   | 2023-02-20 12:33:15,110 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
scm3.org_1   | 2023-02-20 12:33:15,112 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm1.org_1   | 2023-02-20 12:32:13,648 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm1.org_1   | 2023-02-20 12:32:13,651 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2023-02-20 12:32:13,652 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm1.org_1   | 2023-02-20 12:32:13,654 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2023-02-20 12:32:13,692 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm1.org_1   | 2023-02-20 12:32:13,701 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm1.org_1   | 2023-02-20 12:32:13,701 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm1.org_1   | 2023-02-20 12:32:14,429 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm1.org_1   | 2023-02-20 12:32:14,433 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm1.org_1   | 2023-02-20 12:32:14,434 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm1.org_1   | 2023-02-20 12:32:14,434 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2023-02-20 12:32:14,435 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2023-02-20 12:32:14,444 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2023-02-20 12:32:14,448 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServer: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: found a subdirectory /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm1.org_1   | 2023-02-20 12:32:14,455 [main] INFO server.RaftServer: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: addNew group-F5FD3C6D31B1:[] returns group-F5FD3C6D31B1:java.util.concurrent.CompletableFuture@3869a6e5[Not completed]
scm1.org_1   | 2023-02-20 12:32:14,487 [pool-17-thread-1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: new RaftServerImpl for group-F5FD3C6D31B1:[] with SCMStateMachine:uninitialized
scm1.org_1   | 2023-02-20 12:32:14,490 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm1.org_1   | 2023-02-20 12:32:14,490 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm1.org_1   | 2023-02-20 12:32:14,490 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm1.org_1   | 2023-02-20 12:32:14,490 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm1.org_1   | 2023-02-20 12:32:14,491 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm1.org_1   | 2023-02-20 12:32:14,491 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm1.org_1   | 2023-02-20 12:32:14,504 [pool-17-thread-1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
scm1.org_1   | 2023-02-20 12:32:14,505 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm1.org_1   | 2023-02-20 12:32:14,513 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm1.org_1   | 2023-02-20 12:32:14,514 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm1.org_1   | 2023-02-20 12:32:14,536 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm1.org_1   | 2023-02-20 12:32:14,541 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm1.org_1   | 2023-02-20 12:32:14,541 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm1.org_1   | 2023-02-20 12:32:14,739 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2023-02-20 12:32:14,740 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm1.org_1   | 2023-02-20 12:32:14,741 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm1.org_1   | 2023-02-20 12:32:14,742 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm1.org_1   | 2023-02-20 12:32:14,742 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm1.org_1   | 2023-02-20 12:32:14,745 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm1.org_1   | 2023-02-20 12:32:14,745 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm1.org_1   | 2023-02-20 12:32:14,746 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm1.org_1   | 2023-02-20 12:32:15,002 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm1.org_1   | 2023-02-20 12:32:15,275 [main] INFO reflections.Reflections: Reflections took 234 ms to scan 3 urls, producing 125 keys and 280 values 
scm1.org_1   | 2023-02-20 12:32:15,408 [main] INFO ha.SequenceIdGenerator: upgrade localId to 111677748019200000
scm1.org_1   | 2023-02-20 12:32:15,409 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm1.org_1   | 2023-02-20 12:32:15,414 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm1.org_1   | 2023-02-20 12:32:15,417 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm1.org_1   | 2023-02-20 12:32:15,590 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm1.org_1   | 2023-02-20 12:32:15,613 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm1.org_1   | 2023-02-20 12:32:15,616 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm1.org_1   | 2023-02-20 12:32:15,629 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm1.org_1   | 2023-02-20 12:32:15,697 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm1.org_1   | 2023-02-20 12:32:15,699 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm1.org_1   | 2023-02-20 12:32:15,712 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm1.org_1   | 2023-02-20 12:32:15,713 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm1.org_1   | 2023-02-20 12:32:15,718 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm1.org_1   | 2023-02-20 12:32:15,718 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm1.org_1   | 2023-02-20 12:32:15,730 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm1.org_1   | 2023-02-20 12:32:15,732 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm1.org_1   | 2023-02-20 12:32:15,816 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm1.org_1   | 2023-02-20 12:32:15,879 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm1.org_1   | 2023-02-20 12:32:15,971 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm1.org_1   | 2023-02-20 12:32:16,017 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm1.org_1   | 2023-02-20 12:32:16,017 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm1.org_1   | 2023-02-20 12:32:16,041 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm1.org_1   | 2023-02-20 12:32:16,048 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:32:16,052 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2023-02-20 12:32:16,121 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2023-02-20 12:32:16,144 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm1.org_1   | 2023-02-20 12:32:16,145 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 1490022441527 on primary SCM
scm1.org_1   | 2023-02-20 12:32:16,160 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm1.org_1   | 2023-02-20 12:32:16,210 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2023-02-20 12:32:16,268 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm1.org_1   | 2023-02-20 12:32:17,186 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2023-02-20 12:32:17,195 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2023-02-20 12:32:17,196 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm1.org_1   | 2023-02-20 12:32:17,228 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2023-02-20 12:32:17,236 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2023-02-20 12:32:17,237 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm1.org_1   | 2023-02-20 12:32:17,285 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm1.org_1   | 2023-02-20 12:32:17,301 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm1.org_1   | 2023-02-20 12:32:17,302 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm1.org_1   | 2023-02-20 12:32:17,561 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm1.org_1   | 2023-02-20 12:32:17,566 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm1.org_1   | Container Balancer status:
scm1.org_1   | Key                            Value
scm1.org_1   | Running                        true
scm1.org_1   | Container Balancer Configuration values:
scm1.org_1   | Key                                                Value
scm1.org_1   | Threshold                                          10
scm1.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm1.org_1   | Max Size to Move per Iteration                     500GB
scm1.org_1   | Max Size Entering Target per Iteration             26GB
scm1.org_1   | Max Size Leaving Source per Iteration              26GB
scm1.org_1   | 
scm1.org_1   | 2023-02-20 12:32:17,571 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm1.org_1   | 2023-02-20 12:32:17,593 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm1.org_1   | 2023-02-20 12:32:17,607 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm1.org_1   | 2023-02-20 12:32:17,616 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/in_use.lock acquired by nodename 7@scm1.org
scm1.org_1   | 2023-02-20 12:32:17,623 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa} from /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/current/raft-meta
scm1.org_1   | 2023-02-20 12:32:17,681 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: set configuration 0: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2023-02-20 12:32:17,687 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm1.org_1   | 2023-02-20 12:32:17,704 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm1.org_1   | 2023-02-20 12:32:17,704 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2023-02-20 12:32:17,707 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm1.org_1   | 2023-02-20 12:32:17,709 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
scm1.org_1   | 2023-02-20 12:32:17,715 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm1.org_1   | 2023-02-20 12:32:17,729 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm1.org_1   | 2023-02-20 12:32:17,730 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm1.org_1   | 2023-02-20 12:32:17,749 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm1.org_1   | 2023-02-20 12:32:17,750 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2023-02-20 12:32:17,750 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm1.org_1   | 2023-02-20 12:32:17,751 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
recon_1      | 2023-02-20 12:35:02,124 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 162 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:02,125 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 163 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:02,134 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 164 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:35:04,136 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 165 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:04,137 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 166 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:04,138 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 167 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:35:06,139 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 168 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:06,143 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 169 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:06,146 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 170 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:35:06,685 [IPC Server handler 98 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f342a5db-4e7d-4274-be79-8b926a9a2f90
recon_1      | 2023-02-20 12:35:06,784 [IPC Server handler 98 on default port 9891] INFO node.SCMNodeManager: Registered Data node : f342a5db-4e7d-4274-be79-8b926a9a2f90{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886], networkLocation: /default-rack, certSerialId: 1624931770966, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2023-02-20 12:35:07,221 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node f342a5db-4e7d-4274-be79-8b926a9a2f90 to Node DB.
recon_1      | 2023-02-20 12:35:08,147 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 171 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:08,148 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 172 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:08,149 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 173 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:35:08,762 [IPC Server handler 2 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net
recon_1      | 2023-02-20 12:35:09,222 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:49102
recon_1      | 2023-02-20 12:35:09,369 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2023-02-20 12:35:09,600 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:54780
recon_1      | 2023-02-20 12:35:09,691 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1      | 2023-02-20 12:35:10,195 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 174 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:10,203 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 175 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:10,215 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 176 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:35:11,917 [IPC Server handler 10 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8dd306ed-03df-465a-901a-3b76553ce2f1
recon_1      | 2023-02-20 12:35:11,927 [IPC Server handler 10 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 8dd306ed-03df-465a-901a-3b76553ce2f1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [], networkLocation: /default-rack, certSerialId: 1628842543028, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2023-02-20 12:35:11,940 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 8dd306ed-03df-465a-901a-3b76553ce2f1 to Node DB.
recon_1      | 2023-02-20 12:35:12,253 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 177 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:12,266 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 178 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:12,286 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 179 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:35:12,312 [IPC Server handler 2 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/d23baa5b-5f7e-4a50-8199-73003befd3af
recon_1      | 2023-02-20 12:35:12,312 [IPC Server handler 2 on default port 9891] INFO node.SCMNodeManager: Registered Data node : d23baa5b-5f7e-4a50-8199-73003befd3af{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [], networkLocation: /default-rack, certSerialId: 1631425044085, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1      | 2023-02-20 12:35:12,314 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node d23baa5b-5f7e-4a50-8199-73003befd3af to Node DB.
recon_1      | 2023-02-20 12:35:12,806 [IPC Server handler 7 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2023-02-20 12:35:13,256 [IPC Server handler 1 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2023-02-20 12:35:14,290 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 180 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:14,293 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 181 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:14,294 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 182 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:35:14,532 [IPC Server handler 8 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net
recon_1      | 2023-02-20 12:35:14,940 [IPC Server handler 10 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net
recon_1      | 2023-02-20 12:35:16,296 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 183 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:16,298 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 184 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:16,299 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 185 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:35:18,300 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 186 failover attempts. Trying to failover immediately.
scm2.org_1   | 2023-02-20 12:32:49,094 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm2.org_1   | 2023-02-20 12:32:49,272 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2023-02-20 12:32:49,301 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2023-02-20 12:32:49,304 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm2.org_1   | 2023-02-20 12:32:49,498 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm2.org_1   | 2023-02-20 12:32:49,568 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm2.org_1   | 2023-02-20 12:32:49,574 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm2.org_1   | 2023-02-20 12:32:50,001 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm2.org_1   | 2023-02-20 12:32:50,017 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm2.org_1   | Container Balancer status:
scm2.org_1   | Key                            Value
scm2.org_1   | Running                        true
scm2.org_1   | Container Balancer Configuration values:
scm2.org_1   | Key                                                Value
scm2.org_1   | Threshold                                          10
scm2.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm2.org_1   | Max Size to Move per Iteration                     500GB
scm2.org_1   | Max Size Entering Target per Iteration             26GB
scm2.org_1   | Max Size Leaving Source per Iteration              26GB
scm2.org_1   | 
scm2.org_1   | 2023-02-20 12:32:50,018 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm2.org_1   | 2023-02-20 12:32:50,054 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm2.org_1   | 2023-02-20 12:32:50,074 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm2.org_1   | 2023-02-20 12:32:50,084 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1 does not exist. Creating ...
scm2.org_1   | 2023-02-20 12:32:50,115 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/in_use.lock acquired by nodename 6@scm2.org
scm2.org_1   | 2023-02-20 12:32:50,140 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1 has been successfully formatted.
scm2.org_1   | 2023-02-20 12:32:50,151 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm2.org_1   | 2023-02-20 12:32:50,170 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm2.org_1   | 2023-02-20 12:32:50,170 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2023-02-20 12:32:50,179 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm2.org_1   | 2023-02-20 12:32:50,180 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
scm2.org_1   | 2023-02-20 12:32:50,191 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2023-02-20 12:32:50,219 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm2.org_1   | 2023-02-20 12:32:50,221 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm2.org_1   | 2023-02-20 12:32:50,234 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
scm2.org_1   | 2023-02-20 12:32:50,240 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm2.org_1   | 2023-02-20 12:32:50,240 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm2.org_1   | 2023-02-20 12:32:50,257 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm2.org_1   | 2023-02-20 12:32:50,257 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm2.org_1   | 2023-02-20 12:32:50,263 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm2.org_1   | 2023-02-20 12:32:50,264 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm2.org_1   | 2023-02-20 12:32:50,264 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm2.org_1   | 2023-02-20 12:32:50,268 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm2.org_1   | 2023-02-20 12:32:50,350 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm2.org_1   | 2023-02-20 12:32:50,351 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm2.org_1   | 2023-02-20 12:32:50,439 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm2.org_1   | 2023-02-20 12:32:50,441 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
scm2.org_1   | 2023-02-20 12:32:50,441 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm2.org_1   | 2023-02-20 12:32:50,489 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2023-02-20 12:32:50,489 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm2.org_1   | 2023-02-20 12:32:50,503 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: start with initializing state, conf=-1: peers:[]|listeners:[], old=null
scm2.org_1   | 2023-02-20 12:32:50,504 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: changes role from      null to FOLLOWER at term 0 for startInitializing
scm2.org_1   | 2023-02-20 12:32:50,510 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F5FD3C6D31B1,id=1cc6fd6e-f210-4c0e-a8e6-009be253683e
scm2.org_1   | 2023-02-20 12:32:50,515 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm2.org_1   | 2023-02-20 12:32:50,516 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm2.org_1   | 2023-02-20 12:32:50,517 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm2.org_1   | 2023-02-20 12:32:50,517 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm2.org_1   | 2023-02-20 12:32:50,551 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 1cc6fd6e-f210-4c0e-a8e6-009be253683e: start RPC server
scm2.org_1   | 2023-02-20 12:32:50,879 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 1cc6fd6e-f210-4c0e-a8e6-009be253683e: GrpcService started, listening on 9894
scm2.org_1   | 2023-02-20 12:32:50,911 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-1cc6fd6e-f210-4c0e-a8e6-009be253683e: Started
scm2.org_1   | 2023-02-20 12:32:50,990 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
scm2.org_1   | 2023-02-20 12:32:54,999 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: receive installSnapshot: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa->1cc6fd6e-f210-4c0e-a8e6-009be253683e#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2023-02-20 12:32:55,013 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm2.org_1   | 2023-02-20 12:32:55,014 [grpc-default-executor-0] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: change Leader from null to 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa at term 2 for installSnapshot, leader elected after 12341ms
scm2.org_1   | 2023-02-20 12:32:55,031 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: Received notification to install snapshot at index 0
scm2.org_1   | 2023-02-20 12:32:55,033 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm2.org_1   | 2023-02-20 12:32:55,498 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: set new configuration index: 1
scm2.org_1   | configurationEntry {
scm2.org_1   |   peers {
scm2.org_1   |     id: "71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa"
scm2.org_1   |     address: "scm1.org:9894"
scm2.org_1   |     startupRole: FOLLOWER
scm2.org_1   |   }
scm2.org_1   | }
scm2.org_1   |  from snapshot
scm2.org_1   | 2023-02-20 12:32:55,513 [grpc-default-executor-0] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: set configuration 1: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm2.org_1   | 2023-02-20 12:32:55,533 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: reply installSnapshot: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa<-1cc6fd6e-f210-4c0e-a8e6-009be253683e#0:OK-t0,ALREADY_INSTALLED
scm2.org_1   | 2023-02-20 12:32:55,556 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 1cc6fd6e-f210-4c0e-a8e6-009be253683e: Completed INSTALL_SNAPSHOT, lastRequest: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa->1cc6fd6e-f210-4c0e-a8e6-009be253683e#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2023-02-20 12:32:55,827 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-server-thread1] INFO impl.RoleInfo: 1cc6fd6e-f210-4c0e-a8e6-009be253683e: start 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-FollowerState
scm2.org_1   | 2023-02-20 12:32:55,831 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-server-thread1] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2023-02-20 12:32:55,843 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-server-thread1] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: inconsistency entries. Reply:71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa<-1cc6fd6e-f210-4c0e-a8e6-009be253683e#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
scm2.org_1   | 2023-02-20 12:32:55,848 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-server-thread2] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm2.org_1   | 2023-02-20 12:32:55,850 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-server-thread2] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: inconsistency entries. Reply:71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa<-1cc6fd6e-f210-4c0e-a8e6-009be253683e#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
scm2.org_1   | 2023-02-20 12:32:55,909 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-server-thread2] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: set configuration 0: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm2.org_1   | 2023-02-20 12:32:55,909 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-server-thread2] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: set configuration 1: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm2.org_1   | 2023-02-20 12:32:55,926 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-server-thread2] INFO segmented.SegmentedRaftLogWorker: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-SegmentedRaftLogWorker: Starting segment from index:0
scm2.org_1   | 2023-02-20 12:32:56,033 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-server-thread2] INFO segmented.SegmentedRaftLogWorker: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm2.org_1   | 2023-02-20 12:32:56,067 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-server-thread1] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: set configuration 0: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm2.org_1   | 2023-02-20 12:32:56,067 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-server-thread1] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: set configuration 1: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm2.org_1   | 2023-02-20 12:32:56,254 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/current/log_inprogress_0
scm3.org_1   | 2023-02-20 12:33:15,259 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm3.org_1   | 2023-02-20 12:33:15,310 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:d10edad7-6b47-4462-af85-11e38864983b
scm3.org_1   | 2023-02-20 12:33:15,367 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
scm3.org_1   | 2023-02-20 12:33:15,379 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
scm3.org_1   | 2023-02-20 12:33:15,452 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm3.org_1   | 2023-02-20 12:33:15,624 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
scm3.org_1   | 2023-02-20 12:33:15,628 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
scm3.org_1   | 2023-02-20 12:33:15,629 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
scm3.org_1   | 2023-02-20 12:33:15,635 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
scm3.org_1   | 2023-02-20 12:33:15,635 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
scm3.org_1   | 2023-02-20 12:33:15,636 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm3.org_1   | 2023-02-20 12:33:15,637 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm3.org_1   | 2023-02-20 12:33:15,639 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2023-02-20 12:33:15,640 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm3.org_1   | 2023-02-20 12:33:15,643 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm3.org_1   | 2023-02-20 12:33:15,712 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm3.org_1   | 2023-02-20 12:33:15,753 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm3.org_1   | 2023-02-20 12:33:15,755 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm3.org_1   | 2023-02-20 12:33:17,496 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
scm3.org_1   | 2023-02-20 12:33:17,502 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm3.org_1   | 2023-02-20 12:33:17,504 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm3.org_1   | 2023-02-20 12:33:17,505 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2023-02-20 12:33:17,505 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2023-02-20 12:33:17,531 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2023-02-20 12:33:17,544 [main] INFO server.RaftServer: d10edad7-6b47-4462-af85-11e38864983b: addNew group-F5FD3C6D31B1:[] returns group-F5FD3C6D31B1:java.util.concurrent.CompletableFuture@d25e878[Not completed]
scm3.org_1   | 2023-02-20 12:33:17,579 [pool-17-thread-1] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b: new RaftServerImpl for group-F5FD3C6D31B1:[] with SCMStateMachine:uninitialized
scm3.org_1   | 2023-02-20 12:33:17,582 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
scm3.org_1   | 2023-02-20 12:33:17,582 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm3.org_1   | 2023-02-20 12:33:17,582 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
scm3.org_1   | 2023-02-20 12:33:17,582 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm3.org_1   | 2023-02-20 12:33:17,583 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm3.org_1   | 2023-02-20 12:33:17,583 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm3.org_1   | 2023-02-20 12:33:17,604 [pool-17-thread-1] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
scm3.org_1   | 2023-02-20 12:33:17,605 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
scm3.org_1   | 2023-02-20 12:33:17,623 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm3.org_1   | 2023-02-20 12:33:17,623 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm3.org_1   | 2023-02-20 12:33:17,653 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm3.org_1   | 2023-02-20 12:33:17,666 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
scm3.org_1   | 2023-02-20 12:33:17,667 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm3.org_1   | 2023-02-20 12:33:18,163 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm3.org_1   | 2023-02-20 12:33:18,170 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm3.org_1   | 2023-02-20 12:33:18,170 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm3.org_1   | 2023-02-20 12:33:18,212 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm3.org_1   | 2023-02-20 12:33:18,224 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm3.org_1   | 2023-02-20 12:33:18,232 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm3.org_1   | 2023-02-20 12:33:18,232 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm3.org_1   | 2023-02-20 12:33:18,235 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm3.org_1   | 2023-02-20 12:33:18,674 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
scm3.org_1   | 2023-02-20 12:33:19,152 [main] INFO reflections.Reflections: Reflections took 421 ms to scan 3 urls, producing 125 keys and 280 values 
scm3.org_1   | 2023-02-20 12:33:19,461 [main] INFO ha.SequenceIdGenerator: upgrade localId to 111677748019200000
scm3.org_1   | 2023-02-20 12:33:19,462 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm3.org_1   | 2023-02-20 12:33:19,476 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm3.org_1   | 2023-02-20 12:33:19,486 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm3.org_1   | 2023-02-20 12:33:19,783 [main] INFO node.SCMNodeManager: Entering startup safe mode.
scm3.org_1   | 2023-02-20 12:33:19,898 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm3.org_1   | 2023-02-20 12:33:19,905 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm3.org_1   | 2023-02-20 12:33:19,941 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1      | 2023-02-20 12:35:18,302 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 187 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:18,303 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 188 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:35:19,754 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=fb10096d-83bf-4df3-bd31-b1beb74bcbd4. Trying to get from SCM.
recon_1      | 2023-02-20 12:35:20,306 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 189 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:20,312 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 190 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:20,315 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 191 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:35:20,421 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: fb10096d-83bf-4df3-bd31-b1beb74bcbd4, Nodes: 8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:8dd306ed-03df-465a-901a-3b76553ce2f1, CreationTimestamp2023-02-20T12:35:14.590Z[UTC]] to Recon pipeline metadata.
recon_1      | 2023-02-20 12:35:20,734 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fb10096d-83bf-4df3-bd31-b1beb74bcbd4, Nodes: 8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:8dd306ed-03df-465a-901a-3b76553ce2f1, CreationTimestamp2023-02-20T12:35:14.590Z[UTC]].
recon_1      | 2023-02-20 12:35:20,784 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=4315d5f4-40b0-4520-b2d0-2aba89790566. Trying to get from SCM.
recon_1      | 2023-02-20 12:35:20,816 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: 4315d5f4-40b0-4520-b2d0-2aba89790566, Nodes: d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:d23baa5b-5f7e-4a50-8199-73003befd3af, CreationTimestamp2023-02-20T12:35:15.036Z[UTC]] to Recon pipeline metadata.
recon_1      | 2023-02-20 12:35:20,828 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4315d5f4-40b0-4520-b2d0-2aba89790566, Nodes: d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:d23baa5b-5f7e-4a50-8199-73003befd3af, CreationTimestamp2023-02-20T12:35:15.036Z[UTC]].
recon_1      | 2023-02-20 12:35:21,089 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Unknown pipeline PipelineID=b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d. Trying to get from SCM.
recon_1      | 2023-02-20 12:35:21,122 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Adding new pipeline Pipeline[ Id: b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d, Nodes: f342a5db-4e7d-4274-be79-8b926a9a2f90(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103)8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102)d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:15.359Z[UTC]] to Recon pipeline metadata.
recon_1      | 2023-02-20 12:35:21,158 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d, Nodes: f342a5db-4e7d-4274-be79-8b926a9a2f90(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103)8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102)d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:15.359Z[UTC]].
recon_1      | 2023-02-20 12:35:21,160 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d reported by 8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102)
recon_1      | 2023-02-20 12:35:21,228 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d reported by d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104)
recon_1      | 2023-02-20 12:35:22,316 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 192 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:22,318 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 193 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:22,319 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 194 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:35:24,359 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 195 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:24,374 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 196 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:24,427 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 197 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:35:25,904 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d reported by 8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102)
recon_1      | 2023-02-20 12:35:26,089 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d reported by d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104)
recon_1      | 2023-02-20 12:35:26,429 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 198 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:26,430 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 199 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:26,433 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 200 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:35:28,434 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 201 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:28,437 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 202 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:28,438 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 203 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:35:30,439 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 204 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:30,444 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 205 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:30,445 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 206 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1      | 2023-02-20 12:35:32,446 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 207 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:32,449 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 208 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:32,451 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 209 failover attempts. Trying to failover after sleeping for 2000ms.
scm1.org_1   | 2023-02-20 12:32:17,752 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm1.org_1   | 2023-02-20 12:32:17,756 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm1.org_1   | 2023-02-20 12:32:17,757 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm1.org_1   | 2023-02-20 12:32:17,757 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm1.org_1   | 2023-02-20 12:32:17,757 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm1.org_1   | 2023-02-20 12:32:17,772 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm1.org_1   | 2023-02-20 12:32:17,772 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2023-02-20 12:32:18,004 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm1.org_1   | 2023-02-20 12:32:18,004 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
scm1.org_1   | 2023-02-20 12:32:18,005 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm1.org_1   | 2023-02-20 12:32:18,044 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: set configuration 0: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2023-02-20 12:32:18,046 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/current/log_inprogress_0
scm1.org_1   | 2023-02-20 12:32:18,053 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2023-02-20 12:32:18,053 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm1.org_1   | 2023-02-20 12:32:18,121 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: start as a follower, conf=0: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2023-02-20 12:32:18,122 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm1.org_1   | 2023-02-20 12:32:18,124 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO impl.RoleInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: start 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState
scm1.org_1   | 2023-02-20 12:32:18,127 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F5FD3C6D31B1,id=71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa
scm1.org_1   | 2023-02-20 12:32:18,129 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm1.org_1   | 2023-02-20 12:32:18,130 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm1.org_1   | 2023-02-20 12:32:18,130 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm1.org_1   | 2023-02-20 12:32:18,131 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm1.org_1   | 2023-02-20 12:32:18,133 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
scm1.org_1   | 2023-02-20 12:32:18,133 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm1.org_1   | 2023-02-20 12:32:18,139 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: start RPC server
scm1.org_1   | 2023-02-20 12:32:18,207 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: GrpcService started, listening on 9894
scm1.org_1   | 2023-02-20 12:32:18,218 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: Started
scm1.org_1   | 2023-02-20 12:32:18,233 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]
scm1.org_1   | 2023-02-20 12:32:18,233 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm1.org_1   | 2023-02-20 12:32:18,237 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm1.org_1   | 2023-02-20 12:32:18,238 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating current master key for generating tokens. Cert id 1490022441527
scm1.org_1   | 2023-02-20 12:32:18,444 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm1.org_1   | 2023-02-20 12:32:18,458 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm1.org_1   | 2023-02-20 12:32:18,459 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm1.org_1   | 2023-02-20 12:32:18,862 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm1.org_1   | 2023-02-20 12:32:18,863 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2023-02-20 12:32:18,868 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm1.org_1   | 2023-02-20 12:32:18,896 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm1.org_1   | 2023-02-20 12:32:18,908 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm1.org_1   | 2023-02-20 12:32:18,910 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2023-02-20 12:32:18,910 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm1.org_1   | 2023-02-20 12:32:18,942 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm1.org_1   | 2023-02-20 12:32:18,948 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2023-02-20 12:32:18,958 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2023-02-20 12:33:20,071 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm3.org_1   | 2023-02-20 12:33:20,072 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
scm3.org_1   | 2023-02-20 12:33:20,090 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
scm3.org_1   | 2023-02-20 12:33:20,090 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
scm3.org_1   | 2023-02-20 12:33:20,096 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm3.org_1   | 2023-02-20 12:33:20,097 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
scm3.org_1   | 2023-02-20 12:33:20,108 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm3.org_1   | 2023-02-20 12:33:20,109 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
scm3.org_1   | 2023-02-20 12:33:20,188 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
scm3.org_1   | 2023-02-20 12:33:20,289 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm3.org_1   | 2023-02-20 12:33:20,482 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
scm3.org_1   | 2023-02-20 12:33:20,542 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm3.org_1   | 2023-02-20 12:33:20,547 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm3.org_1   | 2023-02-20 12:33:20,603 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm3.org_1   | 2023-02-20 12:33:20,616 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:33:20,623 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2023-02-20 12:33:20,717 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
scm3.org_1   | 2023-02-20 12:33:20,845 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2023-02-20 12:33:20,983 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm3.org_1   | 2023-02-20 12:33:22,944 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2023-02-20 12:33:22,980 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2023-02-20 12:33:22,985 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm3.org_1   | 2023-02-20 12:33:23,117 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2023-02-20 12:33:23,143 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2023-02-20 12:33:23,150 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm3.org_1   | 2023-02-20 12:33:23,295 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm3.org_1   | 2023-02-20 12:33:23,343 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm3.org_1   | 2023-02-20 12:33:23,345 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
scm3.org_1   | 2023-02-20 12:33:23,625 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm3.org_1   | 2023-02-20 12:33:23,634 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
scm3.org_1   | Container Balancer status:
scm3.org_1   | Key                            Value
scm3.org_1   | Running                        true
scm3.org_1   | Container Balancer Configuration values:
scm3.org_1   | Key                                                Value
scm3.org_1   | Threshold                                          10
scm3.org_1   | Max Datanodes to Involve per Iteration(percent)    20
scm3.org_1   | Max Size to Move per Iteration                     500GB
scm3.org_1   | Max Size Entering Target per Iteration             26GB
scm3.org_1   | Max Size Leaving Source per Iteration              26GB
scm3.org_1   | 
scm3.org_1   | 2023-02-20 12:33:23,637 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm3.org_1   | 2023-02-20 12:33:23,692 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm3.org_1   | 2023-02-20 12:33:23,715 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
scm3.org_1   | 2023-02-20 12:33:23,722 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1 does not exist. Creating ...
scm3.org_1   | 2023-02-20 12:33:23,742 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/in_use.lock acquired by nodename 6@scm3.org
scm3.org_1   | 2023-02-20 12:33:23,835 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1 has been successfully formatted.
scm3.org_1   | 2023-02-20 12:33:23,854 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm3.org_1   | 2023-02-20 12:33:23,905 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm3.org_1   | 2023-02-20 12:33:23,905 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2023-02-20 12:33:23,909 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm3.org_1   | 2023-02-20 12:33:23,915 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
scm3.org_1   | 2023-02-20 12:33:23,926 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2023-02-20 12:33:23,958 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm3.org_1   | 2023-02-20 12:33:23,959 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm3.org_1   | 2023-02-20 12:33:23,982 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1
recon_1      | 2023-02-20 12:35:34,468 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om1:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om1,nodeAddress=om1:9862 after 210 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:34,495 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om2:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om2,nodeAddress=om2:9862 after 211 failover attempts. Trying to failover immediately.
recon_1      | 2023-02-20 12:35:34,523 [pool-30-thread-1] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.25.0.115 to om3:9862 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy44.submitRequest over nodeId=om3,nodeAddress=om3:9862 after 212 failover attempts. Trying to failover after sleeping for 2000ms.
scm2.org_1   | 2023-02-20 12:32:56,266 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/current/log_inprogress_0 to /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/current/log_0-0
scm2.org_1   | 2023-02-20 12:32:56,370 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/current/log_inprogress_1
scm2.org_1   | 2023-02-20 12:32:56,410 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:32:56,415 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm2.org_1   | 2023-02-20 12:32:56,433 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm2.org_1   | 2023-02-20 12:32:56,434 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm2.org_1   | 2023-02-20 12:32:56,484 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm2.org_1   | 2023-02-20 12:32:56,509 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2023-02-20 12:32:56,584 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-server-thread3] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: set configuration 7: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
scm2.org_1   | 2023-02-20 12:32:56,813 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-server-thread3] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: set configuration 9: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm2.org_1   | 2023-02-20 12:32:57,191 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm2 to group group-F5FD3C6D31B1:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]
scm2.org_1   | 2023-02-20 12:32:57,217 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm2.org_1   | 2023-02-20 12:32:57,221 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm2.org_1   | 2023-02-20 12:32:57,222 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating current master key for generating tokens. Cert id 1515662102178
scm2.org_1   | 2023-02-20 12:32:57,395 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:32:57,400 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm2.org_1   | 2023-02-20 12:32:57,402 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm2.org_1   | 2023-02-20 12:32:57,613 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:32:58,006 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm2.org_1   | 2023-02-20 12:32:58,067 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm2.org_1   | 2023-02-20 12:32:58,071 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm2.org_1   | 2023-02-20 12:32:59,136 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm2.org_1   | 2023-02-20 12:32:59,149 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2023-02-20 12:32:59,246 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm2.org_1   | 2023-02-20 12:32:59,444 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm2.org_1   | 2023-02-20 12:32:59,456 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm2.org_1   | 2023-02-20 12:32:59,460 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2023-02-20 12:32:59,460 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm2.org_1   | 2023-02-20 12:32:59,603 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm2.org_1   | 2023-02-20 12:32:59,614 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm2.org_1   | 2023-02-20 12:32:59,616 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm2.org_1   | 2023-02-20 12:32:59,616 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm2.org_1   | 2023-02-20 12:32:59,840 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm2.org_1   | 2023-02-20 12:32:59,842 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm2.org_1   | 2023-02-20 12:32:59,842 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm2.org_1   | 2023-02-20 12:33:00,582 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 1cc6fd6e-f210-4c0e-a8e6-009be253683e
scm2.org_1   | 2023-02-20 12:33:00,602 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1490022441527 on Scm Bootstrap Node 1cc6fd6e-f210-4c0e-a8e6-009be253683e
scm2.org_1   | 2023-02-20 12:33:00,737 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7c7caff1] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm2.org_1   | 2023-02-20 12:33:00,818 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm2.org_1   | 2023-02-20 12:33:00,818 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm1.org_1   | 2023-02-20 12:32:18,958 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm1.org_1   | 2023-02-20 12:32:19,138 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@98dc042] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm1.org_1   | 2023-02-20 12:32:19,176 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm1.org_1   | 2023-02-20 12:32:19,178 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm1.org_1   | 2023-02-20 12:32:19,192 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm1.org_1   | 2023-02-20 12:32:19,382 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @9911ms to org.eclipse.jetty.util.log.Slf4jLog
scm1.org_1   | 2023-02-20 12:32:19,627 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:60746
scm1.org_1   | 2023-02-20 12:32:19,632 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38917
scm1.org_1   | 2023-02-20 12:32:19,724 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2023-02-20 12:32:19,740 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2023-02-20 12:32:19,872 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm1.org_1   | 2023-02-20 12:32:19,895 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm1.org_1   | 2023-02-20 12:32:19,896 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm1.org_1   | 2023-02-20 12:32:19,896 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm1.org_1   | 2023-02-20 12:32:19,897 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm1.org_1   | 2023-02-20 12:32:19,900 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm1.org_1   | 2023-02-20 12:32:20,090 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm1.org_1   | 2023-02-20 12:32:20,094 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
scm1.org_1   | 2023-02-20 12:32:20,183 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#9 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.25.0.115:38917
scm1.org_1   | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa is not the leader. Could not determine the leader node.
scm1.org_1   | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm1.org_1   | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
scm1.org_1   | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
scm1.org_1   | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
scm1.org_1   | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
scm1.org_1   | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm1.org_1   | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm1.org_1   | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm1.org_1   | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
scm1.org_1   | 2023-02-20 12:32:20,227 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm1.org_1   | 2023-02-20 12:32:20,227 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm1.org_1   | 2023-02-20 12:32:20,229 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm1.org_1   | 2023-02-20 12:32:20,246 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2023-02-20 12:32:20,249 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@56a3da69{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm1.org_1   | 2023-02-20 12:32:20,250 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@579071ef{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm1.org_1   | 2023-02-20 12:32:20,371 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm1.org_1   | 2023-02-20 12:32:20,385 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7000df03{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_4_0-SNAPSHOT_jar-_-any-5088939374535466744/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/scm}
scm1.org_1   | 2023-02-20 12:32:20,395 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@4b45016d{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm1.org_1   | 2023-02-20 12:32:20,396 [Listener at 0.0.0.0/9860] INFO server.Server: Started @10926ms
scm1.org_1   | 2023-02-20 12:32:20,398 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm1.org_1   | 2023-02-20 12:32:20,399 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm1.org_1   | 2023-02-20 12:32:20,405 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm1.org_1   | 2023-02-20 12:32:21,870 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:58362
scm1.org_1   | 2023-02-20 12:32:21,897 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2023-02-20 12:32:23,271 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState] INFO impl.FollowerState: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5147807359ns, electionTimeout:5136ms
scm3.org_1   | 2023-02-20 12:33:23,984 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm3.org_1   | 2023-02-20 12:33:23,989 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm3.org_1   | 2023-02-20 12:33:23,991 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm3.org_1   | 2023-02-20 12:33:23,994 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
scm3.org_1   | 2023-02-20 12:33:23,996 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm3.org_1   | 2023-02-20 12:33:24,002 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm3.org_1   | 2023-02-20 12:33:24,007 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm3.org_1   | 2023-02-20 12:33:24,008 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm3.org_1   | 2023-02-20 12:33:24,042 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm3.org_1   | 2023-02-20 12:33:24,043 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm3.org_1   | 2023-02-20 12:33:24,408 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm3.org_1   | 2023-02-20 12:33:24,409 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
scm3.org_1   | 2023-02-20 12:33:24,409 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
scm3.org_1   | 2023-02-20 12:33:24,418 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO segmented.SegmentedRaftLogWorker: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2023-02-20 12:33:24,418 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO segmented.SegmentedRaftLogWorker: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm3.org_1   | 2023-02-20 12:33:24,421 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: start with initializing state, conf=-1: peers:[]|listeners:[], old=null
scm3.org_1   | 2023-02-20 12:33:24,421 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: changes role from      null to FOLLOWER at term 0 for startInitializing
scm3.org_1   | 2023-02-20 12:33:24,423 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F5FD3C6D31B1,id=d10edad7-6b47-4462-af85-11e38864983b
scm3.org_1   | 2023-02-20 12:33:24,432 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm3.org_1   | 2023-02-20 12:33:24,433 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
scm3.org_1   | 2023-02-20 12:33:24,434 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm3.org_1   | 2023-02-20 12:33:24,438 [d10edad7-6b47-4462-af85-11e38864983b-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm3.org_1   | 2023-02-20 12:33:24,450 [Listener at 0.0.0.0/9860] INFO server.RaftServer: d10edad7-6b47-4462-af85-11e38864983b: start RPC server
scm3.org_1   | 2023-02-20 12:33:24,600 [Listener at 0.0.0.0/9860] INFO server.GrpcService: d10edad7-6b47-4462-af85-11e38864983b: GrpcService started, listening on 9894
scm3.org_1   | 2023-02-20 12:33:24,610 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-d10edad7-6b47-4462-af85-11e38864983b: Started
scm3.org_1   | 2023-02-20 12:33:24,653 [Listener at 0.0.0.0/9860] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 2 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863]
scm3.org_1   | 2023-02-20 12:33:31,445 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-d10edad7-6b47-4462-af85-11e38864983b: Detected pause in JVM or host machine (eg GC): pause of approximately 284158866ns. No GCs detected.
scm3.org_1   | 2023-02-20 12:33:35,096 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: receive installSnapshot: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa->d10edad7-6b47-4462-af85-11e38864983b#0-t2,notify:(t:1, i:0)
scm3.org_1   | 2023-02-20 12:33:35,120 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
scm3.org_1   | 2023-02-20 12:33:35,120 [grpc-default-executor-0] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: change Leader from null to 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa at term 2 for installSnapshot, leader elected after 17468ms
scm3.org_1   | 2023-02-20 12:33:35,188 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: Received notification to install snapshot at index 0
scm3.org_1   | 2023-02-20 12:33:35,210 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
scm3.org_1   | 2023-02-20 12:33:38,262 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: set new configuration index: 9
scm3.org_1   | configurationEntry {
scm3.org_1   |   peers {
scm3.org_1   |     id: "71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa"
scm3.org_1   |     address: "scm1.org:9894"
scm3.org_1   |     startupRole: FOLLOWER
scm3.org_1   |   }
scm3.org_1   |   peers {
scm3.org_1   |     id: "1cc6fd6e-f210-4c0e-a8e6-009be253683e"
scm3.org_1   |     address: "scm2.org:9894"
scm3.org_1   |     startupRole: FOLLOWER
scm3.org_1   |   }
scm3.org_1   | }
scm3.org_1   |  from snapshot
scm3.org_1   | 2023-02-20 12:33:38,310 [grpc-default-executor-0] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: set configuration 9: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2023-02-20 12:33:38,401 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: reply installSnapshot: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa<-d10edad7-6b47-4462-af85-11e38864983b#0:OK-t0,ALREADY_INSTALLED
scm3.org_1   | 2023-02-20 12:33:38,711 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: d10edad7-6b47-4462-af85-11e38864983b: Completed INSTALL_SNAPSHOT, lastRequest: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa->d10edad7-6b47-4462-af85-11e38864983b#0-t2,notify:(t:1, i:0)
scm2.org_1   | 2023-02-20 12:33:00,825 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm2.org_1   | 2023-02-20 12:33:00,894 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @31504ms to org.eclipse.jetty.util.log.Slf4jLog
scm2.org_1   | 2023-02-20 12:33:01,263 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm2.org_1   | 2023-02-20 12:33:01,283 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm2.org_1   | 2023-02-20 12:33:01,288 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm2.org_1   | 2023-02-20 12:33:01,288 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm2.org_1   | 2023-02-20 12:33:01,288 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm2.org_1   | 2023-02-20 12:33:01,294 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm2.org_1   | 2023-02-20 12:33:01,451 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm2.org_1   | 2023-02-20 12:33:01,459 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
scm2.org_1   | 2023-02-20 12:33:01,666 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm2.org_1   | 2023-02-20 12:33:01,672 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm2.org_1   | 2023-02-20 12:33:01,688 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
scm2.org_1   | 2023-02-20 12:33:01,797 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2023-02-20 12:33:01,823 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1f5797d5{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm2.org_1   | 2023-02-20 12:33:01,827 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5d7d2cb5{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm2.org_1   | 2023-02-20 12:33:02,392 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm2.org_1   | 2023-02-20 12:33:02,437 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4819a11f{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_4_0-SNAPSHOT_jar-_-any-10681807786500797086/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/scm}
scm2.org_1   | 2023-02-20 12:33:02,511 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@19a920d1{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm2.org_1   | 2023-02-20 12:33:02,512 [Listener at 0.0.0.0/9860] INFO server.Server: Started @33123ms
scm2.org_1   | 2023-02-20 12:33:02,527 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm2.org_1   | 2023-02-20 12:33:02,528 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm2.org_1   | 2023-02-20 12:33:02,531 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm2.org_1   | 2023-02-20 12:33:06,577 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:33:42,294 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-server-thread3] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: set configuration 13: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, d10edad7-6b47-4462-af85-11e38864983b|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
scm2.org_1   | 2023-02-20 12:33:42,407 [1cc6fd6e-f210-4c0e-a8e6-009be253683e-server-thread3] INFO server.RaftServer$Division: 1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1: set configuration 15: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, d10edad7-6b47-4462-af85-11e38864983b|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm2.org_1   | 2023-02-20 12:34:16,260 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:34:19,900 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:34:22,588 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:34:30,933 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:34:31,257 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:34:35,248 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:34:59,623 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:55730
scm2.org_1   | 2023-02-20 12:34:59,768 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2023-02-20 12:35:06,991 [IPC Server handler 8 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f342a5db-4e7d-4274-be79-8b926a9a2f90
scm2.org_1   | 2023-02-20 12:35:07,082 [IPC Server handler 8 on default port 9861] INFO node.SCMNodeManager: Registered Data node : f342a5db-4e7d-4274-be79-8b926a9a2f90{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1624931770966, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2023-02-20 12:35:07,181 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm1.org_1   | 2023-02-20 12:32:23,273 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState] INFO impl.RoleInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: shutdown 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState
scm1.org_1   | 2023-02-20 12:32:23,274 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm1.org_1   | 2023-02-20 12:32:23,278 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
scm1.org_1   | 2023-02-20 12:32:23,278 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-FollowerState] INFO impl.RoleInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: start 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1
scm1.org_1   | 2023-02-20 12:32:23,283 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO impl.LeaderElection: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 1 for 0: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2023-02-20 12:32:23,284 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO impl.LeaderElection: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1 PRE_VOTE round 0: result PASSED (term=1)
scm1.org_1   | 2023-02-20 12:32:23,287 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO impl.LeaderElection: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2023-02-20 12:32:23,287 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO impl.LeaderElection: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm1.org_1   | 2023-02-20 12:32:23,288 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO impl.RoleInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: shutdown 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1
scm1.org_1   | 2023-02-20 12:32:23,288 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm1.org_1   | 2023-02-20 12:32:23,288 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm1.org_1   | 2023-02-20 12:32:23,288 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm1.org_1   | 2023-02-20 12:32:23,290 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: change Leader from null to 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa at term 2 for becomeLeader, leader elected after 8752ms
scm1.org_1   | 2023-02-20 12:32:23,297 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm1.org_1   | 2023-02-20 12:32:23,303 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2023-02-20 12:32:23,304 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm1.org_1   | 2023-02-20 12:32:23,310 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm1.org_1   | 2023-02-20 12:32:23,310 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm1.org_1   | 2023-02-20 12:32:23,311 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm1.org_1   | 2023-02-20 12:32:23,316 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm1.org_1   | 2023-02-20 12:32:23,318 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm1.org_1   | 2023-02-20 12:32:23,323 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO impl.RoleInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: start 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderStateImpl
scm1.org_1   | 2023-02-20 12:32:23,329 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm1.org_1   | 2023-02-20 12:32:23,335 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/current/log_inprogress_0 to /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/current/log_0-0
scm1.org_1   | 2023-02-20 12:32:23,352 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderElection1] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: set configuration 1: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2023-02-20 12:32:23,357 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/current/log_inprogress_1
scm1.org_1   | 2023-02-20 12:32:23,370 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm1.org_1   | 2023-02-20 12:32:23,371 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm1.org_1   | 2023-02-20 12:32:23,387 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:32:23,389 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm1.org_1   | 2023-02-20 12:32:23,389 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm1.org_1   | 2023-02-20 12:32:23,390 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm1.org_1   | 2023-02-20 12:32:23,395 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm1.org_1   | 2023-02-20 12:32:23,398 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm1.org_1   | 2023-02-20 12:32:26,014 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:51462
scm1.org_1   | 2023-02-20 12:32:26,017 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2023-02-20 12:32:26,118 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm2.org, nodeId: 1cc6fd6e-f210-4c0e-a8e6-009be253683e
scm1.org_1   | 2023-02-20 12:32:26,224 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: 5d9d3041-134c-474f-a99b-7430b554c453
scm1.org_1   | 2023-02-20 12:32:26,576 [IPC Server handler 0 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
scm1.org_1   | 2023-02-20 12:32:26,813 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:32:26,813 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm1.org_1   | 2023-02-20 12:32:26,813 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm1.org_1   | 2023-02-20 12:32:28,191 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:32:51,429 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:44180
scm1.org_1   | 2023-02-20 12:32:51,475 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2023-02-20 12:32:52,464 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:44828
scm1.org_1   | 2023-02-20 12:32:52,647 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2023-02-20 12:32:52,653 [IPC Server handler 8 on default port 9863] INFO ha.SCMRatisServerImpl: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: Submitting SetConfiguration request to Ratis server with new SCM peers list: [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]
scm1.org_1   | 2023-02-20 12:32:52,704 [IPC Server handler 8 on default port 9863] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: receive setConfiguration SetConfigurationRequest:client-6A608E1BAF38->71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1, cid=1, seq=0, RW, null, SET_UNCONDITIONALLY, servers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER], listeners:[]
scm1.org_1   | 2023-02-20 12:32:52,723 [IPC Server handler 8 on default port 9863] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-6A608E1BAF38->71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1, cid=1, seq=0, RW, null, SET_UNCONDITIONALLY, servers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER], listeners:[]
scm1.org_1   | 2023-02-20 12:32:52,878 [IPC Server handler 8 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2023-02-20 12:32:52,883 [IPC Server handler 8 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2023-02-20 12:32:52,888 [IPC Server handler 8 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2023-02-20 12:32:52,920 [IPC Server handler 8 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2023-02-20 12:32:52,921 [IPC Server handler 8 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2023-02-20 12:32:52,934 [IPC Server handler 8 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2023-02-20 12:32:52,934 [IPC Server handler 8 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm1.org_1   | 2023-02-20 12:32:52,935 [IPC Server handler 8 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
scm1.org_1   | 2023-02-20 12:32:53,048 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->1cc6fd6e-f210-4c0e-a8e6-009be253683e-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->1cc6fd6e-f210-4c0e-a8e6-009be253683e-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2023-02-20 12:32:53,234 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->1cc6fd6e-f210-4c0e-a8e6-009be253683e-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->1cc6fd6e-f210-4c0e-a8e6-009be253683e-GrpcLogAppender: send 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa->1cc6fd6e-f210-4c0e-a8e6-009be253683e#0-t2,notify:(t:1, i:0)
scm1.org_1   | 2023-02-20 12:32:53,421 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->1cc6fd6e-f210-4c0e-a8e6-009be253683e-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcServerProtocolClient: Build channel for 1cc6fd6e-f210-4c0e-a8e6-009be253683e
scm1.org_1   | 2023-02-20 12:32:53,445 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:43745
scm1.org_1   | 2023-02-20 12:32:53,489 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2023-02-20 12:32:55,588 [grpc-default-executor-2] INFO server.GrpcLogAppender: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->1cc6fd6e-f210-4c0e-a8e6-009be253683e-InstallSnapshotResponseHandler: received the first reply 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa<-1cc6fd6e-f210-4c0e-a8e6-009be253683e#0:OK-t0,ALREADY_INSTALLED
scm1.org_1   | 2023-02-20 12:32:55,591 [grpc-default-executor-2] INFO server.GrpcLogAppender: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->1cc6fd6e-f210-4c0e-a8e6-009be253683e-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
scm1.org_1   | 2023-02-20 12:32:55,597 [grpc-default-executor-2] INFO leader.FollowerInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->1cc6fd6e-f210-4c0e-a8e6-009be253683e: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2023-02-20 12:32:55,597 [grpc-default-executor-2] INFO leader.FollowerInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->1cc6fd6e-f210-4c0e-a8e6-009be253683e: matchIndex: setUnconditionally 0 -> 0
scm3.org_1   | 2023-02-20 12:33:39,394 [d10edad7-6b47-4462-af85-11e38864983b-server-thread1] INFO impl.RoleInfo: d10edad7-6b47-4462-af85-11e38864983b: start d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-FollowerState
scm3.org_1   | 2023-02-20 12:33:39,478 [d10edad7-6b47-4462-af85-11e38864983b-server-thread1] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm3.org_1   | 2023-02-20 12:33:39,547 [d10edad7-6b47-4462-af85-11e38864983b-server-thread1] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: inconsistency entries. Reply:71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa<-d10edad7-6b47-4462-af85-11e38864983b#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
scm3.org_1   | 2023-02-20 12:33:39,563 [d10edad7-6b47-4462-af85-11e38864983b-server-thread2] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
scm3.org_1   | 2023-02-20 12:33:39,570 [d10edad7-6b47-4462-af85-11e38864983b-server-thread2] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: inconsistency entries. Reply:71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa<-d10edad7-6b47-4462-af85-11e38864983b#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
scm3.org_1   | 2023-02-20 12:33:39,737 [d10edad7-6b47-4462-af85-11e38864983b-server-thread1] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: set configuration 0: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2023-02-20 12:33:39,754 [d10edad7-6b47-4462-af85-11e38864983b-server-thread1] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: set configuration 1: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2023-02-20 12:33:39,766 [d10edad7-6b47-4462-af85-11e38864983b-server-thread1] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: set configuration 7: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
scm3.org_1   | 2023-02-20 12:33:39,775 [d10edad7-6b47-4462-af85-11e38864983b-server-thread1] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: set configuration 9: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2023-02-20 12:33:39,855 [d10edad7-6b47-4462-af85-11e38864983b-server-thread1] INFO segmented.SegmentedRaftLogWorker: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-SegmentedRaftLogWorker: Starting segment from index:0
scm3.org_1   | 2023-02-20 12:33:40,254 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-d10edad7-6b47-4462-af85-11e38864983b: Detected pause in JVM or host machine (eg GC): pause of approximately 222485390ns. No GCs detected.
scm3.org_1   | 2023-02-20 12:33:40,662 [d10edad7-6b47-4462-af85-11e38864983b-server-thread1] INFO segmented.SegmentedRaftLogWorker: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm3.org_1   | 2023-02-20 12:33:41,242 [d10edad7-6b47-4462-af85-11e38864983b-server-thread2] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: set configuration 0: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2023-02-20 12:33:41,249 [d10edad7-6b47-4462-af85-11e38864983b-server-thread2] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: set configuration 1: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2023-02-20 12:33:41,255 [d10edad7-6b47-4462-af85-11e38864983b-server-thread2] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: set configuration 7: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
scm3.org_1   | 2023-02-20 12:33:41,259 [d10edad7-6b47-4462-af85-11e38864983b-server-thread2] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: set configuration 9: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2023-02-20 12:33:41,292 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/current/log_inprogress_0
scm3.org_1   | 2023-02-20 12:33:41,404 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/current/log_inprogress_0 to /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/current/log_0-0
scm3.org_1   | 2023-02-20 12:33:41,979 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/df603a9d-cb6b-43c6-a944-f5fd3c6d31b1/current/log_inprogress_1
scm3.org_1   | 2023-02-20 12:33:42,114 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:33:42,114 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm3.org_1   | 2023-02-20 12:33:42,121 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm3.org_1   | 2023-02-20 12:33:42,121 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
scm3.org_1   | 2023-02-20 12:33:42,127 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2023-02-20 12:33:42,220 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
scm2.org_1   | 2023-02-20 12:35:07,270 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2023-02-20 12:35:09,749 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:33700
scm2.org_1   | 2023-02-20 12:35:09,785 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:52204
scm2.org_1   | 2023-02-20 12:35:09,851 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2023-02-20 12:35:09,962 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2023-02-20 12:35:10,292 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e15c4d38-f9f2-4e6a-8aa0-5749b8c639a0, Nodes: f342a5db-4e7d-4274-be79-8b926a9a2f90(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:08.300Z[UTC]].
scm2.org_1   | 2023-02-20 12:35:10,318 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:35:14,556 [IPC Server handler 2 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8dd306ed-03df-465a-901a-3b76553ce2f1
scm2.org_1   | 2023-02-20 12:35:14,564 [IPC Server handler 2 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8dd306ed-03df-465a-901a-3b76553ce2f1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1628842543028, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2023-02-20 12:35:14,567 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2023-02-20 12:35:14,592 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm2.org_1   | 2023-02-20 12:35:14,708 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fb10096d-83bf-4df3-bd31-b1beb74bcbd4, Nodes: 8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:14.590Z[UTC]].
scm2.org_1   | 2023-02-20 12:35:14,719 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:35:14,945 [IPC Server handler 34 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/d23baa5b-5f7e-4a50-8199-73003befd3af
scm2.org_1   | 2023-02-20 12:35:14,946 [IPC Server handler 34 on default port 9861] INFO node.SCMNodeManager: Registered Data node : d23baa5b-5f7e-4a50-8199-73003befd3af{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1631425044085, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm2.org_1   | 2023-02-20 12:35:14,946 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2023-02-20 12:35:14,947 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm2.org_1   | 2023-02-20 12:35:14,947 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm2.org_1   | 2023-02-20 12:35:14,947 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm2.org_1   | 2023-02-20 12:35:14,947 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm2.org_1   | 2023-02-20 12:35:14,955 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm2.org_1   | 2023-02-20 12:35:15,219 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4315d5f4-40b0-4520-b2d0-2aba89790566, Nodes: d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:15.036Z[UTC]].
scm2.org_1   | 2023-02-20 12:35:15,222 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:35:15,548 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d, Nodes: f342a5db-4e7d-4274-be79-8b926a9a2f90(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103)8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102)d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:15.359Z[UTC]].
scm2.org_1   | 2023-02-20 12:35:15,551 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:35:15,722 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d7697318-eb22-49ee-a8ab-fcccdde84beb, Nodes: d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104)8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102)f342a5db-4e7d-4274-be79-8b926a9a2f90(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:15.509Z[UTC]].
scm2.org_1   | 2023-02-20 12:35:15,726 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:35:19,685 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: fb10096d-83bf-4df3-bd31-b1beb74bcbd4, Nodes: 8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8dd306ed-03df-465a-901a-3b76553ce2f1, CreationTimestamp2023-02-20T12:35:14.590Z[UTC]] moved to OPEN state
scm3.org_1   | 2023-02-20 12:33:42,530 [d10edad7-6b47-4462-af85-11e38864983b-server-thread3] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: set configuration 13: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, d10edad7-6b47-4462-af85-11e38864983b|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
scm3.org_1   | 2023-02-20 12:33:42,616 [d10edad7-6b47-4462-af85-11e38864983b-server-thread3] INFO server.RaftServer$Division: d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1: set configuration 15: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, d10edad7-6b47-4462-af85-11e38864983b|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm3.org_1   | 2023-02-20 12:33:43,703 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl: Successfully added SCM scm3 to group group-F5FD3C6D31B1:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, d10edad7-6b47-4462-af85-11e38864983b|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]
scm3.org_1   | 2023-02-20 12:33:43,762 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
scm3.org_1   | 2023-02-20 12:33:43,822 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
scm3.org_1   | 2023-02-20 12:33:43,831 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating current master key for generating tokens. Cert id 1555569389665
scm3.org_1   | 2023-02-20 12:33:44,849 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:33:44,860 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
scm3.org_1   | 2023-02-20 12:33:44,861 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm3.org_1   | 2023-02-20 12:33:45,135 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:33:45,233 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:33:45,864 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm3.org_1   | 2023-02-20 12:33:46,155 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
scm3.org_1   | 2023-02-20 12:33:46,156 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
scm3.org_1   | 2023-02-20 12:33:50,165 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm3.org_1   | 2023-02-20 12:33:50,190 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2023-02-20 12:33:50,266 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm3.org_1   | 2023-02-20 12:33:50,507 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
scm3.org_1   | 2023-02-20 12:33:50,510 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm3.org_1   | 2023-02-20 12:33:50,511 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2023-02-20 12:33:50,513 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm3.org_1   | 2023-02-20 12:33:50,732 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
scm3.org_1   | 2023-02-20 12:33:50,735 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
scm3.org_1   | 2023-02-20 12:33:50,736 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm3.org_1   | 2023-02-20 12:33:50,737 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm3.org_1   | 2023-02-20 12:33:51,550 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.client.port appended with serviceId and nodeId
scm3.org_1   | 2023-02-20 12:33:51,552 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.block.client.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.block.client.port appended with serviceId and nodeId
scm3.org_1   | 2023-02-20 12:33:51,559 [Listener at 0.0.0.0/9860] INFO ha.SCMNodeInfo: ConfigKey ozone.scm.datanode.address is deprecated, For configuring different ports for each SCM use PortConfigKey ozone.scm.datanode.port appended with serviceId and nodeId
scm3.org_1   | 2023-02-20 12:33:53,609 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node d10edad7-6b47-4462-af85-11e38864983b
scm3.org_1   | 2023-02-20 12:33:53,643 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Persist certificate serialId 1490022441527 on Scm Bootstrap Node d10edad7-6b47-4462-af85-11e38864983b
scm3.org_1   | 2023-02-20 12:33:53,906 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@26be5ee] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm3.org_1   | 2023-02-20 12:33:54,126 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
scm3.org_1   | 2023-02-20 12:33:54,128 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm3.org_1   | 2023-02-20 12:33:54,147 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm3.org_1   | 2023-02-20 12:33:54,702 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @47176ms to org.eclipse.jetty.util.log.Slf4jLog
scm3.org_1   | 2023-02-20 12:33:56,505 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm3.org_1   | 2023-02-20 12:33:56,677 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm3.org_1   | 2023-02-20 12:33:56,714 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
scm3.org_1   | 2023-02-20 12:33:56,715 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm3.org_1   | 2023-02-20 12:33:56,716 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm3.org_1   | 2023-02-20 12:33:56,762 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
scm1.org_1   | 2023-02-20 12:32:55,597 [grpc-default-executor-2] INFO leader.FollowerInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->1cc6fd6e-f210-4c0e-a8e6-009be253683e: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2023-02-20 12:32:55,607 [grpc-default-executor-2] INFO leader.FollowerInfo: Follower 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->1cc6fd6e-f210-4c0e-a8e6-009be253683e acknowledged installing snapshot
scm1.org_1   | 2023-02-20 12:32:55,608 [grpc-default-executor-2] INFO leader.FollowerInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->1cc6fd6e-f210-4c0e-a8e6-009be253683e: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2023-02-20 12:32:55,891 [grpc-default-executor-1] INFO leader.FollowerInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->1cc6fd6e-f210-4c0e-a8e6-009be253683e: nextIndex: updateUnconditionally 7 -> 0
scm1.org_1   | 2023-02-20 12:32:55,911 [grpc-default-executor-2] INFO leader.FollowerInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->1cc6fd6e-f210-4c0e-a8e6-009be253683e: nextIndex: updateUnconditionally 7 -> 0
scm1.org_1   | 2023-02-20 12:32:56,419 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderStateImpl] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: set configuration 7: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
scm1.org_1   | 2023-02-20 12:32:56,600 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderStateImpl] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: set configuration 9: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2023-02-20 12:32:56,864 [IPC Server handler 8 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: 1cc6fd6e-f210-4c0e-a8e6-009be253683e.
scm1.org_1   | 2023-02-20 12:33:00,262 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.117:49634
scm1.org_1   | 2023-02-20 12:33:00,273 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2023-02-20 12:33:01,172 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:34486
scm1.org_1   | 2023-02-20 12:33:01,225 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2023-02-20 12:33:06,178 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:42206
scm1.org_1   | 2023-02-20 12:33:06,201 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2023-02-20 12:33:06,206 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for scm scm3.org, nodeId: d10edad7-6b47-4462-af85-11e38864983b
scm1.org_1   | 2023-02-20 12:33:06,271 [IPC Server handler 0 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
scm1.org_1   | 2023-02-20 12:33:06,566 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:33:12,374 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:46272
scm1.org_1   | 2023-02-20 12:33:12,429 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2023-02-20 12:33:29,689 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:39270
scm1.org_1   | 2023-02-20 12:33:30,000 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2023-02-20 12:33:30,032 [IPC Server handler 80 on default port 9863] INFO ha.SCMRatisServerImpl: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: Submitting SetConfiguration request to Ratis server with new SCM peers list: [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER, d10edad7-6b47-4462-af85-11e38864983b|rpc:scm3.org:9894|priority:0|startupRole:FOLLOWER]
scm1.org_1   | 2023-02-20 12:33:30,050 [IPC Server handler 80 on default port 9863] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: receive setConfiguration SetConfigurationRequest:client-6A608E1BAF38->71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1, cid=2, seq=0, RW, null, SET_UNCONDITIONALLY, servers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER, d10edad7-6b47-4462-af85-11e38864983b|rpc:scm3.org:9894|priority:0|startupRole:FOLLOWER], listeners:[]
scm1.org_1   | 2023-02-20 12:33:30,050 [IPC Server handler 80 on default port 9863] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderStateImpl: startSetConfiguration SetConfigurationRequest:client-6A608E1BAF38->71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1, cid=2, seq=0, RW, null, SET_UNCONDITIONALLY, servers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER, d10edad7-6b47-4462-af85-11e38864983b|rpc:scm3.org:9894|priority:0|startupRole:FOLLOWER], listeners:[]
scm1.org_1   | 2023-02-20 12:33:30,065 [IPC Server handler 80 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
scm1.org_1   | 2023-02-20 12:33:30,065 [IPC Server handler 80 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm1.org_1   | 2023-02-20 12:33:30,065 [IPC Server handler 80 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
scm1.org_1   | 2023-02-20 12:33:30,094 [IPC Server handler 80 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
scm1.org_1   | 2023-02-20 12:33:30,107 [IPC Server handler 80 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
scm1.org_1   | 2023-02-20 12:33:30,107 [IPC Server handler 80 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm1.org_1   | 2023-02-20 12:33:30,107 [IPC Server handler 80 on default port 9863] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm1.org_1   | 2023-02-20 12:33:30,111 [IPC Server handler 80 on default port 9863] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
scm1.org_1   | 2023-02-20 12:33:30,120 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->d10edad7-6b47-4462-af85-11e38864983b-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->d10edad7-6b47-4462-af85-11e38864983b-GrpcLogAppender: followerNextIndex = 0 but logStartIndex = 0, notify follower to install snapshot-(t:1, i:0)
scm1.org_1   | 2023-02-20 12:33:30,132 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->d10edad7-6b47-4462-af85-11e38864983b-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcLogAppender: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->d10edad7-6b47-4462-af85-11e38864983b-GrpcLogAppender: send 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa->d10edad7-6b47-4462-af85-11e38864983b#0-t2,notify:(t:1, i:0)
scm1.org_1   | 2023-02-20 12:33:30,134 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->d10edad7-6b47-4462-af85-11e38864983b-GrpcLogAppender-LogAppenderDaemon] INFO server.GrpcServerProtocolClient: Build channel for d10edad7-6b47-4462-af85-11e38864983b
scm1.org_1   | 2023-02-20 12:33:38,676 [grpc-default-executor-2] INFO server.GrpcLogAppender: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->d10edad7-6b47-4462-af85-11e38864983b-InstallSnapshotResponseHandler: received the first reply 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa<-d10edad7-6b47-4462-af85-11e38864983b#0:OK-t0,ALREADY_INSTALLED
scm1.org_1   | 2023-02-20 12:33:38,680 [grpc-default-executor-2] INFO server.GrpcLogAppender: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->d10edad7-6b47-4462-af85-11e38864983b-InstallSnapshotResponseHandler: Follower snapshot is already at index 0.
scm1.org_1   | 2023-02-20 12:33:38,684 [grpc-default-executor-2] INFO leader.FollowerInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->d10edad7-6b47-4462-af85-11e38864983b: snapshotIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2023-02-20 12:33:38,686 [grpc-default-executor-2] INFO leader.FollowerInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->d10edad7-6b47-4462-af85-11e38864983b: matchIndex: setUnconditionally 0 -> 0
scm1.org_1   | 2023-02-20 12:33:38,688 [grpc-default-executor-2] INFO leader.FollowerInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->d10edad7-6b47-4462-af85-11e38864983b: nextIndex: setUnconditionally 0 -> 1
scm1.org_1   | 2023-02-20 12:33:38,689 [grpc-default-executor-2] INFO leader.FollowerInfo: Follower 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->d10edad7-6b47-4462-af85-11e38864983b acknowledged installing snapshot
scm1.org_1   | 2023-02-20 12:33:38,695 [grpc-default-executor-2] INFO leader.FollowerInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->d10edad7-6b47-4462-af85-11e38864983b: nextIndex: updateToMax old=1, new=1, updated? false
scm1.org_1   | 2023-02-20 12:33:39,624 [grpc-default-executor-2] INFO leader.FollowerInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->d10edad7-6b47-4462-af85-11e38864983b: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2023-02-20 12:33:39,663 [grpc-default-executor-2] INFO leader.FollowerInfo: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1->d10edad7-6b47-4462-af85-11e38864983b: nextIndex: updateUnconditionally 13 -> 0
scm1.org_1   | 2023-02-20 12:33:42,285 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderStateImpl] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: set configuration 13: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER, d10edad7-6b47-4462-af85-11e38864983b|rpc:scm3.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[]
scm1.org_1   | 2023-02-20 12:33:42,365 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-LeaderStateImpl] INFO server.RaftServer$Division: 71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1: set configuration 15: peers:[71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1cc6fd6e-f210-4c0e-a8e6-009be253683e|rpc:scm2.org:9894|priority:0|startupRole:FOLLOWER, d10edad7-6b47-4462-af85-11e38864983b|rpc:scm3.org:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm1.org_1   | 2023-02-20 12:33:42,476 [IPC Server handler 80 on default port 9863] INFO ha.SCMRatisServerImpl: Successfully added new SCM: d10edad7-6b47-4462-af85-11e38864983b.
scm1.org_1   | 2023-02-20 12:33:53,046 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.118:39074
scm1.org_1   | 2023-02-20 12:33:53,094 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for scm/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2023-02-20 12:33:55,002 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:46531
scm1.org_1   | 2023-02-20 12:33:55,084 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2023-02-20 12:33:56,021 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:40890
scm1.org_1   | 2023-02-20 12:33:56,396 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2023-02-20 12:34:09,422 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:33314
scm1.org_1   | 2023-02-20 12:34:09,652 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2023-02-20 12:34:10,131 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:57128
scm1.org_1   | 2023-02-20 12:34:10,301 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2023-02-20 12:34:11,043 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:37518
scm1.org_1   | 2023-02-20 12:34:11,188 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2023-02-20 12:34:15,162 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:53090
scm1.org_1   | 2023-02-20 12:34:15,407 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2023-02-20 12:34:15,428 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 2a396b20692f, UUID: f342a5db-4e7d-4274-be79-8b926a9a2f90
scm1.org_1   | 2023-02-20 12:34:16,290 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:34:19,254 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:41448
scm1.org_1   | 2023-02-20 12:34:19,408 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2023-02-20 12:34:19,409 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 6b48ece71e49, UUID: 8dd306ed-03df-465a-901a-3b76553ce2f1
scm1.org_1   | 2023-02-20 12:34:19,900 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:34:21,635 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:45768
scm1.org_1   | 2023-02-20 12:34:21,880 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2023-02-20 12:34:21,885 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 0932752dfb54, UUID: d23baa5b-5f7e-4a50-8199-73003befd3af
scm1.org_1   | 2023-02-20 12:34:22,576 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:34:29,779 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:54500
scm1.org_1   | 2023-02-20 12:34:29,840 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:37936
scm1.org_1   | 2023-02-20 12:34:29,869 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2023-02-20 12:34:29,941 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om1, UUID: dcaa61cb-258b-4cc0-b289-3d967aae0619
scm1.org_1   | 2023-02-20 12:34:29,980 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2023-02-20 12:34:29,993 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om2, UUID: cdcdec05-c794-4bc1-a103-6b27aca9b93e
scm1.org_1   | 2023-02-20 12:34:30,842 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:34:31,259 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:34:34,738 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:60914
scm1.org_1   | 2023-02-20 12:34:34,797 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2023-02-20 12:34:34,821 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om3, UUID: 2544d121-9754-4501-afe7-465f730dce71
scm1.org_1   | 2023-02-20 12:34:35,251 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:34:35,657 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:57350
scm1.org_1   | 2023-02-20 12:34:35,671 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2023-02-20 12:34:40,191 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:55288
scm1.org_1   | 2023-02-20 12:34:40,226 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2023-02-20 12:34:41,460 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50586
scm1.org_1   | 2023-02-20 12:34:41,534 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm1.org_1   | 2023-02-20 12:34:59,351 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:39096
scm1.org_1   | 2023-02-20 12:34:59,453 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2023-02-20 12:35:07,300 [IPC Server handler 57 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f342a5db-4e7d-4274-be79-8b926a9a2f90
scm1.org_1   | 2023-02-20 12:35:07,337 [IPC Server handler 57 on default port 9861] INFO node.SCMNodeManager: Registered Data node : f342a5db-4e7d-4274-be79-8b926a9a2f90{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1624931770966, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2023-02-20 12:35:07,624 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2023-02-20 12:35:07,729 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm1.org_1   | 2023-02-20 12:35:08,198 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: Detected pause in JVM or host machine (eg GC): pause of approximately 324726109ns.
scm1.org_1   | GC pool 'ParNew' had collection(s): count=1 time=133ms
scm1.org_1   | 2023-02-20 12:35:08,357 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=e15c4d38-f9f2-4e6a-8aa0-5749b8c639a0 to datanode:f342a5db-4e7d-4274-be79-8b926a9a2f90
scm1.org_1   | 2023-02-20 12:35:09,062 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:60232
scm1.org_1   | 2023-02-20 12:35:09,134 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm2.org_1   | 2023-02-20 12:35:19,993 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:35:20,216 [1cc6fd6e-f210-4c0e-a8e6-009be253683e@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm2.org_1   | 2023-02-20 12:35:20,655 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2023-02-20 12:35:21,082 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2023-02-20 12:35:21,185 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2023-02-20 12:35:25,894 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm2.org_1   | 2023-02-20 12:35:26,096 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2023-02-20 12:33:57,354 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
scm3.org_1   | 2023-02-20 12:33:57,377 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
scm3.org_1   | 2023-02-20 12:33:57,893 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
scm3.org_1   | 2023-02-20 12:33:57,893 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
scm3.org_1   | 2023-02-20 12:33:57,925 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
scm3.org_1   | 2023-02-20 12:33:58,126 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2023-02-20 12:33:58,230 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7e18b9e6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm3.org_1   | 2023-02-20 12:33:58,240 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@52f0b3d8{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm3.org_1   | 2023-02-20 12:33:59,834 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
scm3.org_1   | 2023-02-20 12:34:00,049 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5331be15{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_4_0-SNAPSHOT_jar-_-any-7469113897199581590/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/scm}
scm3.org_1   | 2023-02-20 12:34:00,309 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@698df5e8{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm3.org_1   | 2023-02-20 12:34:00,327 [Listener at 0.0.0.0/9860] INFO server.Server: Started @52801ms
scm3.org_1   | 2023-02-20 12:34:00,356 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm3.org_1   | 2023-02-20 12:34:00,359 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm3.org_1   | 2023-02-20 12:34:00,367 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
scm3.org_1   | 2023-02-20 12:34:16,337 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:34:19,927 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:34:22,598 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:34:30,901 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:34:31,278 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:34:35,264 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:34:59,493 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.103:36198
scm3.org_1   | 2023-02-20 12:34:59,517 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2023-02-20 12:35:06,894 [IPC Server handler 73 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f342a5db-4e7d-4274-be79-8b926a9a2f90
scm3.org_1   | 2023-02-20 12:35:06,952 [IPC Server handler 73 on default port 9861] INFO node.SCMNodeManager: Registered Data node : f342a5db-4e7d-4274-be79-8b926a9a2f90{ip: 172.25.0.103, host: ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1624931770966, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2023-02-20 12:35:07,084 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2023-02-20 12:35:07,029 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm3.org_1   | 2023-02-20 12:35:09,133 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.102:37850
scm3.org_1   | 2023-02-20 12:35:09,188 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2023-02-20 12:35:09,427 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:50632
scm3.org_1   | 2023-02-20 12:35:09,501 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm3.org_1   | 2023-02-20 12:35:10,039 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e15c4d38-f9f2-4e6a-8aa0-5749b8c639a0, Nodes: f342a5db-4e7d-4274-be79-8b926a9a2f90(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:08.300Z[UTC]].
scm3.org_1   | 2023-02-20 12:35:10,061 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:35:14,559 [IPC Server handler 69 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8dd306ed-03df-465a-901a-3b76553ce2f1
scm3.org_1   | 2023-02-20 12:35:14,560 [IPC Server handler 69 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8dd306ed-03df-465a-901a-3b76553ce2f1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1628842543028, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2023-02-20 12:35:14,562 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2023-02-20 12:35:14,566 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm3.org_1   | 2023-02-20 12:35:14,715 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fb10096d-83bf-4df3-bd31-b1beb74bcbd4, Nodes: 8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:14.590Z[UTC]].
scm3.org_1   | 2023-02-20 12:35:14,715 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:35:14,885 [IPC Server handler 93 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/d23baa5b-5f7e-4a50-8199-73003befd3af
scm3.org_1   | 2023-02-20 12:35:14,885 [IPC Server handler 93 on default port 9861] INFO node.SCMNodeManager: Registered Data node : d23baa5b-5f7e-4a50-8199-73003befd3af{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1631425044085, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm3.org_1   | 2023-02-20 12:35:14,886 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2023-02-20 12:35:14,886 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm3.org_1   | 2023-02-20 12:35:14,886 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm3.org_1   | 2023-02-20 12:35:14,886 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm3.org_1   | 2023-02-20 12:35:14,886 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm3.org_1   | 2023-02-20 12:35:14,892 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: ignore, not leader SCM.
scm3.org_1   | 2023-02-20 12:35:15,213 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4315d5f4-40b0-4520-b2d0-2aba89790566, Nodes: d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:15.036Z[UTC]].
scm3.org_1   | 2023-02-20 12:35:15,215 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:35:15,482 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d, Nodes: f342a5db-4e7d-4274-be79-8b926a9a2f90(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103)8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102)d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:15.359Z[UTC]].
scm3.org_1   | 2023-02-20 12:35:15,483 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:35:15,652 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d7697318-eb22-49ee-a8ab-fcccdde84beb, Nodes: d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104)8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102)f342a5db-4e7d-4274-be79-8b926a9a2f90(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:15.509Z[UTC]].
scm3.org_1   | 2023-02-20 12:35:15,656 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:35:19,762 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: fb10096d-83bf-4df3-bd31-b1beb74bcbd4, Nodes: 8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8dd306ed-03df-465a-901a-3b76553ce2f1, CreationTimestamp2023-02-20T12:35:14.590Z[UTC]] moved to OPEN state
scm3.org_1   | 2023-02-20 12:35:20,043 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:35:20,248 [d10edad7-6b47-4462-af85-11e38864983b@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm3.org_1   | 2023-02-20 12:35:20,759 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2023-02-20 12:35:21,025 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2023-02-20 12:35:21,203 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2023-02-20 12:35:25,899 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm3.org_1   | 2023-02-20 12:35:26,103 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2023-02-20 12:35:09,345 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa: Detected pause in JVM or host machine (eg GC): pause of approximately 141608774ns. No GCs detected.
scm1.org_1   | 2023-02-20 12:35:09,634 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: e15c4d38-f9f2-4e6a-8aa0-5749b8c639a0, Nodes: f342a5db-4e7d-4274-be79-8b926a9a2f90(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:08.300Z[UTC]].
scm1.org_1   | 2023-02-20 12:35:09,634 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:35:09,750 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.104:51948
scm1.org_1   | 2023-02-20 12:35:09,806 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm1.org_1   | 2023-02-20 12:35:14,519 [IPC Server handler 57 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/8dd306ed-03df-465a-901a-3b76553ce2f1
scm1.org_1   | 2023-02-20 12:35:14,534 [IPC Server handler 57 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 8dd306ed-03df-465a-901a-3b76553ce2f1{ip: 172.25.0.102, host: ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1628842543028, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2023-02-20 12:35:14,547 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2023-02-20 12:35:14,576 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm1.org_1   | 2023-02-20 12:35:14,590 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fb10096d-83bf-4df3-bd31-b1beb74bcbd4 to datanode:8dd306ed-03df-465a-901a-3b76553ce2f1
scm1.org_1   | 2023-02-20 12:35:14,679 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: fb10096d-83bf-4df3-bd31-b1beb74bcbd4, Nodes: 8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:14.590Z[UTC]].
scm1.org_1   | 2023-02-20 12:35:14,681 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:35:14,984 [IPC Server handler 78 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/d23baa5b-5f7e-4a50-8199-73003befd3af
scm1.org_1   | 2023-02-20 12:35:15,024 [IPC Server handler 78 on default port 9861] INFO node.SCMNodeManager: Registered Data node : d23baa5b-5f7e-4a50-8199-73003befd3af{ip: 172.25.0.104, host: ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 1631425044085, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm1.org_1   | 2023-02-20 12:35:15,029 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2023-02-20 12:35:15,036 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=4315d5f4-40b0-4520-b2d0-2aba89790566 to datanode:d23baa5b-5f7e-4a50-8199-73003befd3af
scm1.org_1   | 2023-02-20 12:35:15,108 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
scm1.org_1   | 2023-02-20 12:35:15,109 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm1.org_1   | 2023-02-20 12:35:15,109 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm1.org_1   | 2023-02-20 12:35:15,109 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm1.org_1   | 2023-02-20 12:35:15,110 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm1.org_1   | 2023-02-20 12:35:15,214 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4315d5f4-40b0-4520-b2d0-2aba89790566, Nodes: d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:15.036Z[UTC]].
scm1.org_1   | 2023-02-20 12:35:15,232 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:35:15,359 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d to datanode:f342a5db-4e7d-4274-be79-8b926a9a2f90
scm1.org_1   | 2023-02-20 12:35:15,361 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d to datanode:8dd306ed-03df-465a-901a-3b76553ce2f1
scm1.org_1   | 2023-02-20 12:35:15,362 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d to datanode:d23baa5b-5f7e-4a50-8199-73003befd3af
scm1.org_1   | 2023-02-20 12:35:15,435 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d, Nodes: f342a5db-4e7d-4274-be79-8b926a9a2f90(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103)8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102)d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:15.359Z[UTC]].
scm1.org_1   | 2023-02-20 12:35:15,439 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:35:15,532 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d7697318-eb22-49ee-a8ab-fcccdde84beb to datanode:d23baa5b-5f7e-4a50-8199-73003befd3af
scm1.org_1   | 2023-02-20 12:35:15,537 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d7697318-eb22-49ee-a8ab-fcccdde84beb to datanode:8dd306ed-03df-465a-901a-3b76553ce2f1
scm1.org_1   | 2023-02-20 12:35:15,539 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=d7697318-eb22-49ee-a8ab-fcccdde84beb to datanode:f342a5db-4e7d-4274-be79-8b926a9a2f90
scm1.org_1   | 2023-02-20 12:35:15,627 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: d7697318-eb22-49ee-a8ab-fcccdde84beb, Nodes: d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104)8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102)f342a5db-4e7d-4274-be79-8b926a9a2f90(ozonesecure-ha_datanode2_1.ozonesecure-ha_ozone_net/172.25.0.103), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-20T12:35:15.509Z[UTC]].
scm1.org_1   | 2023-02-20 12:35:15,634 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:35:15,640 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=d7697318-eb22-49ee-a8ab-fcccdde84beb contains same datanodes as previous pipelines: PipelineID=b6f4373c-2d16-443e-8f8a-b4fb3ca8a87d nodeIds: d23baa5b-5f7e-4a50-8199-73003befd3af, 8dd306ed-03df-465a-901a-3b76553ce2f1, f342a5db-4e7d-4274-be79-8b926a9a2f90
scm1.org_1   | 2023-02-20 12:35:15,673 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm1.org_1   | 2023-02-20 12:35:15,674 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm1.org_1   | 2023-02-20 12:35:19,522 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.112:43794
scm1.org_1   | 2023-02-20 12:35:19,700 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2023-02-20 12:35:19,834 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: fb10096d-83bf-4df3-bd31-b1beb74bcbd4, Nodes: 8dd306ed-03df-465a-901a-3b76553ce2f1(ozonesecure-ha_datanode1_1.ozonesecure-ha_ozone_net/172.25.0.102), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8dd306ed-03df-465a-901a-3b76553ce2f1, CreationTimestamp2023-02-20T12:35:14.590Z[UTC]] moved to OPEN state
scm1.org_1   | 2023-02-20 12:35:19,962 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:35:20,081 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.115:38789
scm1.org_1   | 2023-02-20 12:35:20,109 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 4315d5f4-40b0-4520-b2d0-2aba89790566, Nodes: d23baa5b-5f7e-4a50-8199-73003befd3af(ozonesecure-ha_datanode3_1.ozonesecure-ha_ozone_net/172.25.0.104), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:d23baa5b-5f7e-4a50-8199-73003befd3af, CreationTimestamp2023-02-20T12:35:15.036Z[UTC]] moved to OPEN state
scm1.org_1   | 2023-02-20 12:35:20,162 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2023-02-20 12:35:20,181 [71f5ebbc-385e-4dd4-b11b-8662c2c0f2aa@group-F5FD3C6D31B1-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm1.org_1   | 2023-02-20 12:35:20,202 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2023-02-20 12:35:20,209 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2023-02-20 12:35:21,131 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2023-02-20 12:35:21,202 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2023-02-20 12:35:21,616 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.111:43016
scm1.org_1   | 2023-02-20 12:35:21,726 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2023-02-20 12:35:25,614 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.116:57388
scm1.org_1   | 2023-02-20 12:35:25,815 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.25.0.113:35866
scm1.org_1   | 2023-02-20 12:35:25,855 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm1.org_1   | 2023-02-20 12:35:25,987 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm1.org_1   | 2023-02-20 12:35:26,031 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm1.org_1   | 2023-02-20 12:35:26,111 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
