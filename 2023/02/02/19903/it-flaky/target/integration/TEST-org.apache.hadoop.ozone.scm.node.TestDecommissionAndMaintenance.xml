<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="286.111" tests="7" errors="1" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.4.0-SNAPSHOT/ozone-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.51.1/grpc-netty-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.51.1/grpc-core-1.51.1.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.21/animal-sniffer-annotations-1.21.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.25.0/perfmark-api-0.25.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.86.Final/netty-codec-http2-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.86.Final/netty-common-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.86.Final/netty-buffer-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.86.Final/netty-codec-http-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.86.Final/netty-handler-proxy-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.86.Final/netty-codec-socks-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.54.Final/netty-tcnative-classes-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.4.0-SNAPSHOT/hdds-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.4.0-SNAPSHOT/ozone-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.4.0-SNAPSHOT/hdds-test-utils-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/31.1-jre/guava-31.1-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.12.0/checker-qual-3.12.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.22/reload4j-1.2.22.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.36/slf4j-api-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.4.0-SNAPSHOT/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.49.v20220914/jetty-util-ajax-9.4.49.v20220914.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.4.0-SNAPSHOT/hdds-interface-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.49.v20220914/jetty-servlet-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.49.v20220914/jetty-security-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/runner/.m2/repository/org/awaitility/awaitility/4.2.0/awaitility-4.2.0.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.1/hamcrest-2.1.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.4/hadoop-hdfs-client-3.3.4.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.3/okhttp-4.9.3.jar:/home/runner/.m2/repository/com/squareup/okio/okio/2.8.0/okio-2.8.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.6.21/kotlin-stdlib-common-1.6.21.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.4.0-SNAPSHOT/hdds-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.3/ratis-thirdparty-misc-1.0.3.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.4.0-SNAPSHOT/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/rocksdb-checkpoint-differ/1.4.0-SNAPSHOT/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.49.v20220914/jetty-client-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.6/httpcore-nio-4.4.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.4/hadoop-minikdc-3.3.4.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.4.0-SNAPSHOT/ozone-s3gateway-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.34/jersey-container-servlet-core-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.34/jersey-common-2.34.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.34/jersey-cdi1x-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.34/jersey-hk2-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.34/jersey-media-jaxb-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.13.4/jackson-dataformat-xml-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.13.4/jackson-core-2.13.4.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.13.4/jackson-module-jaxb-annotations-2.13.4.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.51.1/grpc-protobuf-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.51.1/grpc-api-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.51.1/grpc-context-1.51.1.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.9.0/proto-google-common-protos-2.9.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.51.1/grpc-protobuf-lite-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.51.1/grpc-stub-1.51.1.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.86.Final/netty-transport-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.86.Final/netty-resolver-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.4.0-SNAPSHOT/ozone-csi-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.4.0-SNAPSHOT/hdds-config-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.86.Final/netty-transport-native-epoll-4.1.86.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.86.Final/netty-transport-classes-epoll-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.86.Final/netty-transport-native-unix-common-4.1.86.Final.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.4.0-SNAPSHOT/ozone-recon-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.4.0-SNAPSHOT/ozone-reconcodegen-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/runner/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.34/jersey-container-servlet-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.34/jersey-server-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.34/jersey-client-2.34.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.34/jersey-media-json-jackson-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.34/jersey-entity-filtering-2.34.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.23/spring-jdbc-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.23/spring-beans-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.23/spring-core-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-jcl/5.3.23/spring-jcl-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.23/spring-tx-5.3.23.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.4.0-SNAPSHOT/ozone-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.4.0-SNAPSHOT/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.4.0-SNAPSHOT/ozone-filesystem-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.4.0-SNAPSHOT/ozone-filesystem-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.4.0-SNAPSHOT/ozone-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.261/aws-java-sdk-core-1.12.261.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.13.4/jackson-dataformat-cbor-2.13.4.jar:/home/runner/.m2/repository/joda-time/joda-time/2.10.6/joda-time-2.10.6.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.261/aws-java-sdk-s3-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.261/aws-java-sdk-kms-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.261/jmespath-java-1.12.261.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.4.0-SNAPSHOT/hdds-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.4.2-8b8bdda-SNAPSHOT/ratis-tools-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.4.2-8b8bdda-SNAPSHOT/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.4.2-8b8bdda-SNAPSHOT/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.4.0-SNAPSHOT/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.13.4/jackson-annotations-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.13.4/jackson-datatype-jsr310-2.13.4.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-annotation-processing/1.4.0-SNAPSHOT/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.4.2-8b8bdda-SNAPSHOT/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.4.2-8b8bdda-SNAPSHOT/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.4.2-8b8bdda-SNAPSHOT/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.4.2-8b8bdda-SNAPSHOT/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.4.2-8b8bdda-SNAPSHOT/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.4.2-8b8bdda-SNAPSHOT/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.6.21/kotlin-stdlib-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/1.33/snakeyaml-1.33.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.4.0-SNAPSHOT/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.8.2/junit-jupiter-api-5.8.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.8.2/junit-platform-commons-1.8.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.8.2/junit-jupiter-params-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-migrationsupport/5.8.2/junit-jupiter-migrationsupport-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.8.2/junit-jupiter-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.8.2/junit-platform-engine-1.8.2.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.8.2/junit-vintage-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.8.2/junit-platform-launcher-1.8.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/2.28.2/mockito-core-2.28.2.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.9.10/byte-buddy-1.9.10.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.10/byte-buddy-agent-1.9.10.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.4/hadoop-auth-3.3.4.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/home/runner/.m2/repository/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/home/runner/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.49.v20220914/jetty-server-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.49.v20220914/jetty-http-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.49.v20220914/jetty-io-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.49.v20220914/jetty-webapp-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.49.v20220914/jetty-xml-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.9.0/commons-net-3.9.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.49.v20220914/jetty-util-9.4.49.v20220914.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.13.4.2/jackson-databind-2.13.4.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.2-5/zstd-jni-1.5.2-5.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.86.Final/netty-codec-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.86.Final/netty-handler-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.4.0-SNAPSHOT/hdds-hadoop-dependency-test-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.4/hadoop-mapreduce-client-jobclient-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.4/hadoop-mapreduce-client-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.4/hadoop-yarn-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.4/hadoop-yarn-api-3.3.4.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.13.4/jackson-jaxrs-json-provider-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.13.4/jackson-jaxrs-base-2.13.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.4/hadoop-yarn-client-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.43.v20210629/websocket-client-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.43.v20210629/websocket-common-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.43.v20210629/websocket-api-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.4/hadoop-mapreduce-client-core-3.3.4.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.4/hadoop-annotations-3.3.4.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4-tests.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.36/jul-to-slf4j-1.7.36.jar:"/>
    <property name="java.vm.vendor" value="Temurin"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="https://adoptium.net/"/>
    <property name="user.timezone" value="Etc/UTC"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter4560664138288319345.jar /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire 2023-02-02T19-52-36_885-jvmRun1 surefire3523532147303303572tmp surefire_207209912560530279529tmp"/>
    <property name="surefire.test.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.4.0-SNAPSHOT/ozone-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.51.1/grpc-netty-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.51.1/grpc-core-1.51.1.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.21/animal-sniffer-annotations-1.21.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.25.0/perfmark-api-0.25.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.86.Final/netty-codec-http2-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.86.Final/netty-common-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.86.Final/netty-buffer-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.86.Final/netty-codec-http-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.86.Final/netty-handler-proxy-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.86.Final/netty-codec-socks-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.54.Final/netty-tcnative-classes-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.4.0-SNAPSHOT/hdds-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.4.0-SNAPSHOT/ozone-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.4.0-SNAPSHOT/hdds-test-utils-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/31.1-jre/guava-31.1-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.12.0/checker-qual-3.12.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.22/reload4j-1.2.22.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.36/slf4j-api-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.4.0-SNAPSHOT/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.49.v20220914/jetty-util-ajax-9.4.49.v20220914.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.4.0-SNAPSHOT/hdds-interface-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.49.v20220914/jetty-servlet-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.49.v20220914/jetty-security-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/runner/.m2/repository/org/awaitility/awaitility/4.2.0/awaitility-4.2.0.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.1/hamcrest-2.1.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.4/hadoop-hdfs-client-3.3.4.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.3/okhttp-4.9.3.jar:/home/runner/.m2/repository/com/squareup/okio/okio/2.8.0/okio-2.8.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.6.21/kotlin-stdlib-common-1.6.21.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.4.0-SNAPSHOT/hdds-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.3/ratis-thirdparty-misc-1.0.3.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.4.0-SNAPSHOT/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/rocksdb-checkpoint-differ/1.4.0-SNAPSHOT/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.49.v20220914/jetty-client-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.6/httpcore-nio-4.4.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.4/hadoop-minikdc-3.3.4.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.4.0-SNAPSHOT/ozone-s3gateway-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.34/jersey-container-servlet-core-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.34/jersey-common-2.34.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.34/jersey-cdi1x-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.34/jersey-hk2-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.34/jersey-media-jaxb-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.13.4/jackson-dataformat-xml-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.13.4/jackson-core-2.13.4.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.13.4/jackson-module-jaxb-annotations-2.13.4.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.51.1/grpc-protobuf-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.51.1/grpc-api-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.51.1/grpc-context-1.51.1.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.9.0/proto-google-common-protos-2.9.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.51.1/grpc-protobuf-lite-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.51.1/grpc-stub-1.51.1.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.86.Final/netty-transport-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.86.Final/netty-resolver-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.4.0-SNAPSHOT/ozone-csi-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.4.0-SNAPSHOT/hdds-config-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.86.Final/netty-transport-native-epoll-4.1.86.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.86.Final/netty-transport-classes-epoll-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.86.Final/netty-transport-native-unix-common-4.1.86.Final.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.4.0-SNAPSHOT/ozone-recon-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.4.0-SNAPSHOT/ozone-reconcodegen-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/runner/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.34/jersey-container-servlet-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.34/jersey-server-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.34/jersey-client-2.34.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.34/jersey-media-json-jackson-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.34/jersey-entity-filtering-2.34.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.23/spring-jdbc-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.23/spring-beans-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.23/spring-core-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-jcl/5.3.23/spring-jcl-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.23/spring-tx-5.3.23.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.4.0-SNAPSHOT/ozone-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.4.0-SNAPSHOT/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.4.0-SNAPSHOT/ozone-filesystem-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.4.0-SNAPSHOT/ozone-filesystem-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.4.0-SNAPSHOT/ozone-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.261/aws-java-sdk-core-1.12.261.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.13.4/jackson-dataformat-cbor-2.13.4.jar:/home/runner/.m2/repository/joda-time/joda-time/2.10.6/joda-time-2.10.6.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.261/aws-java-sdk-s3-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.261/aws-java-sdk-kms-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.261/jmespath-java-1.12.261.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.4.0-SNAPSHOT/hdds-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.4.2-8b8bdda-SNAPSHOT/ratis-tools-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.4.2-8b8bdda-SNAPSHOT/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.4.2-8b8bdda-SNAPSHOT/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.4.0-SNAPSHOT/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.13.4/jackson-annotations-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.13.4/jackson-datatype-jsr310-2.13.4.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-annotation-processing/1.4.0-SNAPSHOT/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.4.2-8b8bdda-SNAPSHOT/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.4.2-8b8bdda-SNAPSHOT/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.4.2-8b8bdda-SNAPSHOT/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.4.2-8b8bdda-SNAPSHOT/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.4.2-8b8bdda-SNAPSHOT/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.4.2-8b8bdda-SNAPSHOT/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.6.21/kotlin-stdlib-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/1.33/snakeyaml-1.33.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.4.0-SNAPSHOT/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.8.2/junit-jupiter-api-5.8.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.8.2/junit-platform-commons-1.8.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.8.2/junit-jupiter-params-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-migrationsupport/5.8.2/junit-jupiter-migrationsupport-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.8.2/junit-jupiter-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.8.2/junit-platform-engine-1.8.2.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.8.2/junit-vintage-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.8.2/junit-platform-launcher-1.8.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/2.28.2/mockito-core-2.28.2.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.9.10/byte-buddy-1.9.10.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.10/byte-buddy-agent-1.9.10.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.4/hadoop-auth-3.3.4.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/home/runner/.m2/repository/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/home/runner/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.49.v20220914/jetty-server-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.49.v20220914/jetty-http-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.49.v20220914/jetty-io-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.49.v20220914/jetty-webapp-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.49.v20220914/jetty-xml-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.9.0/commons-net-3.9.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.49.v20220914/jetty-util-9.4.49.v20220914.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.13.4.2/jackson-databind-2.13.4.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.2-5/zstd-jni-1.5.2-5.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.86.Final/netty-codec-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.86.Final/netty-handler-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.4.0-SNAPSHOT/hdds-hadoop-dependency-test-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.4/hadoop-mapreduce-client-jobclient-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.4/hadoop-mapreduce-client-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.4/hadoop-yarn-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.4/hadoop-yarn-api-3.3.4.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.13.4/jackson-jaxrs-json-provider-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.13.4/jackson-jaxrs-base-2.13.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.4/hadoop-yarn-client-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.43.v20210629/websocket-client-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.43.v20210629/websocket-common-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.43.v20210629/websocket-api-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.4/hadoop-mapreduce-client-core-3.3.4.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.4/hadoop-annotations-3.3.4.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4-tests.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.36/jul-to-slf4j-1.7.36.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/runner"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/krb5.conf"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="skip.installnpx" value="true"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.fork.timeout" value="3600"/>
    <property name="surefire.real.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter4560664138288319345.jar:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/classes"/>
    <property name="hadoop.log.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_362-b09"/>
    <property name="skip.npx" value="true"/>
    <property name="user.name" value="runner"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="5.15.0-1031-azure"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/runner/.m2/repository"/>
    <property name="jetty.git.hash" value="4231a3b2e4cb8548a412a789936d640a97b1aa0a"/>
    <property name="java.vendor.url.bug" value="https://github.com/adoptium/adoptium-support/issues"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="java.version" value="1.8.0_362"/>
    <property name="surefire.rerunFailingTestsCount" value="5"/>
    <property name="user.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="os.arch" value="amd64"/>
    <property name="test.build.classes" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="org.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads" value="false"/>
    <property name="hadoop.tmp.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/tmp"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vendor" value="Temurin"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.362-b09"/>
    <property name="java.specification.maintenance.version" value="4"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testNodeWithOpenPipelineCanBeDecommissionedAndRecommissioned" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="62.051"/>
  <testcase name="testContainerIsReplicatedWhenAllNodesGotoMaintenance" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="45.33"/>
  <testcase name="testMaintenanceEndsAutomaticallyAtTimeout" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="38.035"/>
  <testcase name="testSingleNodeWithOpenPipelineCanGotoMaintenance" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="38.976"/>
  <testcase name="testSCMHandlesRestartForMaintenanceNode" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="45.644">
    <error type="java.util.concurrent.TimeoutException"><![CDATA[java.util.concurrent.TimeoutException: 
Timed out waiting for condition. Thread diagnostics:
Timestamp: 2023-02-02 08:28:06,899

"Socket Reader #1 for port 0"  prio=5 tid=5421 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"16d82cf4-1422-4a15-9631-5fbf1a57277e@group-1994514B191F-LeaderStateImpl" daemon prio=5 tid=4970 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"pool-2507-thread-1"  prio=5 tid=5521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-SegmentedRaftLogWorker"  prio=5 tid=5748 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 45947" daemon prio=5 tid=5266 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EndpointStateMachine task thread for /0.0.0.0:37573 - 0 "  prio=5 tid=3673 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"964ef1ca-08ae-4b3c-a2ce-6bf03c7bf022@group-3608AD55A432-SegmentedRaftLogWorker"  prio=5 tid=4879 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 42245" daemon prio=5 tid=4172 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1056205779-5557" daemon prio=5 tid=5557 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4376ff23" daemon prio=5 tid=3552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 35129" daemon prio=5 tid=6061 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp33293217-3455" daemon prio=5 tid=3455 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-0"  prio=5 tid=5164 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5904 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderStateImpl" daemon prio=5 tid=6115 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 4 on default port 37573" daemon prio=5 tid=6086 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderStateImpl" daemon prio=5 tid=6223 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"grpc-default-executor-8" daemon prio=5 tid=2136 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"16d82cf4-1422-4a15-9631-5fbf1a57277e-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4663 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4855 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-11" daemon prio=5 tid=5181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5575 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"235120ac-71a1-451e-bf57-c5cd114d9629-impl-thread1"  prio=5 tid=5594 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3510 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4679 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3742 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2023223337-5459" daemon prio=5 tid=5459 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 40643" daemon prio=5 tid=4427 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 5 on default port 42245" daemon prio=5 tid=4166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"b67f1ce3-fbfb-4e89-9cbc-643abd2f2563-server-thread2" daemon prio=5 tid=6227 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5635 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 35129" daemon prio=5 tid=6058 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 13 on default port 41201" daemon prio=5 tid=5309 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 11 on default port 45947" daemon prio=5 tid=5267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@5703a6d7" daemon prio=5 tid=4712 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5647 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4853 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-4deb745-1"  prio=5 tid=4562 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-StateMachineUpdater" daemon prio=5 tid=5946 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp1204808652-4406" daemon prio=5 tid=4406 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"d767bd78-5310-4536-b2f7-e45413a997a1-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5547 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 42189" daemon prio=5 tid=4188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2021 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:42189 - 0 "  prio=5 tid=4755 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 41201" daemon prio=5 tid=5300 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=5539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Timer-4"  prio=5 tid=3449 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854->7153b2e5-6547-4596-92e7-e397d052a5ec-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5972 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/558834684.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 43469" daemon prio=5 tid=5471 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5684 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@218c5b61" daemon prio=5 tid=5317 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3541 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=5420 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"c0917728-87bf-433d-b3f0-4191e0e505db-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4546 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@c9c31cd" daemon prio=5 tid=3692 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5510 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1172302072-3587" daemon prio=5 tid=3587 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"4ec2caad-ead4-478e-ac51-fb863b7de4b5-server-thread2" daemon prio=5 tid=5980 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 34325" daemon prio=5 tid=4142 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-33-thread-1"  prio=5 tid=125 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 37773" daemon prio=5 tid=6076 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1347105255-4726" daemon prio=5 tid=4726 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-6"  prio=5 tid=5373 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5230 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"IPC Server handler 10 on default port 43469" daemon prio=5 tid=5474 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp91775645-5604" daemon prio=5 tid=5604 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-0"  prio=5 tid=5146 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3796 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=6134 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 42189" daemon prio=5 tid=4189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"c2e5a0ee-722e-430e-828a-2d735c45daa1@group-503D6BB962B7-StateMachineUpdater" daemon prio=5 tid=3920 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp1172302072-3588" daemon prio=5 tid=3588 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@7ec7fb61" daemon prio=5 tid=4432 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=2014 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2023223337-5458" daemon prio=5 tid=5458 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-21510986-1"  prio=5 tid=4411 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=4837 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-291b4ece-1"  prio=5 tid=5530 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2461-thread-1"  prio=5 tid=5454 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4682 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp134934515-5625-acceptor-0@6498f9d7-ServerConnector@94d1087{HTTP/1.1, (http/1.1)}{0.0.0.0:36961}" daemon prio=3 tid=5625 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 43469" daemon prio=5 tid=5477 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"d767bd78-5310-4536-b2f7-e45413a997a1-impl-thread1"  prio=5 tid=5548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2132-thread-1" daemon prio=5 tid=4690 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1525410126-3643" daemon prio=5 tid=3643 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 42245" daemon prio=5 tid=4169 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3052 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:37573 - 0 "  prio=5 tid=3695 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 37573" daemon prio=5 tid=6082 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 14 on default port 35129" daemon prio=5 tid=6056 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"SCMBlockDeletingService#0" daemon prio=5 tid=4201 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 43711" daemon prio=5 tid=3481 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 4 on default port 43469" daemon prio=5 tid=5468 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 15 on default port 35129" daemon prio=5 tid=6057 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp143910163-3503" daemon prio=5 tid=3503 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6173 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5509 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Over Replicated Processor" daemon prio=5 tid=4110 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:136)
        at java.lang.Thread.run(Thread.java:750)
"pool-1561-thread-1"  prio=5 tid=3863 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=5885 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Over Replicated Processor" daemon prio=5 tid=5225 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:136)
        at java.lang.Thread.run(Thread.java:750)
"SstFilteringService#0" daemon prio=5 tid=3453 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:188)
"qtp992714005-4673" daemon prio=5 tid=4673 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4813 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3821 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3591 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-StateMachineUpdater" daemon prio=5 tid=5966 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 37773" daemon prio=5 tid=6070 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@7fcb977f" daemon prio=5 tid=3634 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"pool-705-thread-1"  prio=5 tid=1586 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4845 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 43469" daemon prio=5 tid=5480 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp917562781-5671" daemon prio=5 tid=5671 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 42189" daemon prio=5 tid=4199 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 4 on default port 37773" daemon prio=5 tid=6066 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4732 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=2017 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerReplicationThread-0" daemon prio=5 tid=6163 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:549)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"964ef1ca-08ae-4b3c-a2ce-6bf03c7bf022@group-3608AD55A432-FollowerState" daemon prio=5 tid=5037 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3756 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2023223337-5455" daemon prio=5 tid=5455 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-CommandQueueReportForCommandQueueReportHandler" daemon prio=5 tid=5933 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4708 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2123228695-5326" daemon prio=5 tid=5326 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp2123228695-5321" daemon prio=5 tid=5321 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5894 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp305190215-5529" daemon prio=5 tid=5529 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"b67f1ce3-fbfb-4e89-9cbc-643abd2f2563-server-thread1" daemon prio=5 tid=6226 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3693 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5921 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=3444 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"IPC Server handler 3 on default port 43711" daemon prio=5 tid=3467 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5896 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3733 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-18" daemon prio=5 tid=5188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3686 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4715 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1294806619-4700" daemon prio=5 tid=4700 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"a8bd3719-ed86-42e1-a40d-2b4ed0b09d7c-server-thread3" daemon prio=5 tid=5125 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ef8775a4-4a62-450d-ae4d-a3eaa392aaf8-client-thread1" daemon prio=5 tid=5338 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4859 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 35129" daemon prio=5 tid=6055 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29-server-thread1" daemon prio=5 tid=6196 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2459-thread-1"  prio=5 tid=5414 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp938586173-4214" daemon prio=5 tid=4214 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 37573" daemon prio=5 tid=6094 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 2 on default port 37773" daemon prio=5 tid=6064 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"5b8e2765-a6c1-4d85-87a6-bec4168f79ce-server-thread2" daemon prio=5 tid=4002 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2095-thread-1"  prio=5 tid=4878 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1326021788-3533" daemon prio=5 tid=3533 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@26a8f252" daemon prio=5 tid=4639 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3705 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3685 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 34811" daemon prio=5 tid=5285 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 13 on default port 42189" daemon prio=5 tid=4194 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5512 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5906 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1116902535-4624" daemon prio=5 tid=4624 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3794 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4843 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1712205733-5697" daemon prio=5 tid=5697 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 42245" daemon prio=5 tid=4178 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 3 on default port 34811" daemon prio=5 tid=5279 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3689 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-SegmentedRaftLogWorker"  prio=5 tid=5752 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 41201" daemon prio=5 tid=5229 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6174 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1056205779-5552-acceptor-0@5c170c87-ServerConnector@6ae14641{HTTP/1.1, (http/1.1)}{0.0.0.0:40531}" daemon prio=3 tid=5552 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4814 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1901099451-4464" daemon prio=5 tid=4464 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1726962409-4556" daemon prio=5 tid=4556 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 41201" daemon prio=5 tid=5301 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1347105255-4723" daemon prio=5 tid=4723 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 34325" daemon prio=5 tid=4158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1576-thread-1" daemon prio=5 tid=3521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ef8775a4-4a62-450d-ae4d-a3eaa392aaf8@group-9886A1E37655-LeaderStateImpl" daemon prio=5 tid=3962 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=6133 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=6033 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5535 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4608 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 42189" daemon prio=5 tid=4190 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2466-thread-1" daemon prio=5 tid=5488 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@787a9120" daemon prio=5 tid=3484 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 42245" daemon prio=5 tid=4180 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp143910163-3498" daemon prio=5 tid=3498 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 43469" daemon prio=5 tid=5466 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=4829 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5769 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5898 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2499-thread-1"  prio=5 tid=5950 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3823 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-4" daemon prio=5 tid=577 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=5532 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3694 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp917562781-5669" daemon prio=5 tid=5669 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp885186621-6112" daemon prio=5 tid=6112 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"3f7ac4d1-ddb9-474a-8f73-3a04b1780a60-server-thread2" daemon prio=5 tid=4005 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c2e5a0ee-722e-430e-828a-2d735c45daa1@group-503D6BB962B7-SegmentedRaftLogWorker"  prio=5 tid=3918 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3517 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3731 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"235120ac-71a1-451e-bf57-c5cd114d9629-server-thread2" daemon prio=5 tid=6199 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3699 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2618-thread-1" daemon prio=5 tid=5685 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2103-thread-1"  prio=5 tid=4619 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4807 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1172302072-3584" daemon prio=5 tid=3584 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"4ec2caad-ead4-478e-ac51-fb863b7de4b5-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3659 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"78962ee0-dad8-4871-bc4b-e1f0b96bf3d9-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5518 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4811 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-6321339d-1"  prio=5 tid=4731 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 42245" daemon prio=5 tid=4171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=5919 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@c8937da" daemon prio=5 tid=4618 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3651 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2611-thread-1"  prio=5 tid=5663 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1542-thread-1"  prio=5 tid=3420 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1726962409-4558" daemon prio=5 tid=4558 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"3f7ac4d1-ddb9-474a-8f73-3a04b1780a60@group-9D5E22661B84-StateMachineUpdater" daemon prio=5 tid=3870 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3519 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5050 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 37773" daemon prio=5 tid=6062 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 0 on default port 43711" daemon prio=5 tid=3464 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 4 on default port 34811" daemon prio=5 tid=5280 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkReader-ELG-0" daemon prio=5 tid=4857 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"pool-2110-thread-1" daemon prio=5 tid=4661 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-4"  prio=5 tid=5359 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3574 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=5882 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 34325" daemon prio=5 tid=4143 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1726962409-4560" daemon prio=5 tid=4560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5636 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=4386 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"pool-1691-thread-1"  prio=5 tid=3635 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5633 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Mini-Cluster-Provider-Reap"  prio=5 tid=15 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider.lambda$reapClusters$0(MiniOzoneClusterProvider.java:199)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider$$Lambda$341/1878992188.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 43711" daemon prio=5 tid=3474 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 6 on default port 40643" daemon prio=5 tid=4418 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server idle connection scanner for port 45947" daemon prio=5 tid=5237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server idle connection scanner for port 42189" daemon prio=5 tid=4114 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp143910163-3501-acceptor-0@7f96a50b-ServerConnector@4480ef01{HTTP/1.1, (http/1.1)}{0.0.0.0:35947}" daemon prio=3 tid=3501 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor43" daemon prio=5 tid=4765 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-10" daemon prio=5 tid=3718 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 34811" daemon prio=5 tid=5288 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1901099451-4471" daemon prio=5 tid=4471 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1712205733-5698" daemon prio=5 tid=5698 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1172302072-3589" daemon prio=5 tid=3589 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5610 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp134934515-5627" daemon prio=5 tid=5627 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3682 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5589 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp917562781-5667" daemon prio=5 tid=5667 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp992714005-4669" daemon prio=5 tid=4669 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-9FF3442ABBF5-StateMachineUpdater" daemon prio=5 tid=3943 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:41201 - 0 "  prio=5 tid=5643 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor40" daemon prio=5 tid=3818 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp33293217-3456-acceptor-0@29570293-ServerConnector@64469ce3{HTTP/1.1, (http/1.1)}{0.0.0.0:44689}" daemon prio=3 tid=3456 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 37773" daemon prio=5 tid=6080 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-9"  prio=5 tid=5383 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4810 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 34325" daemon prio=5 tid=4157 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5924 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1613-thread-1"  prio=5 tid=3553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4589 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2196-thread-1" daemon prio=5 tid=4784 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3736 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5745 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4520 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5051 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ReplicationMonitor" daemon prio=5 tid=4108 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:667)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$422/1414164286.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5679 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 35129"  prio=5 tid=6027 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"4536c619-fdf7-4443-8da6-b71e8b366fa5-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4457 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"a8bd3719-ed86-42e1-a40d-2b4ed0b09d7c@group-F0F5BE7F53DD-SegmentedRaftLogWorker"  prio=5 tid=4922 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3716 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 45947" daemon prio=5 tid=5261 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 0 on default port 42245" daemon prio=5 tid=4159 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-49f4e54f-1"  prio=5 tid=5699 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=4127 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@42f6000b" daemon prio=5 tid=4550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@424ca251" daemon prio=5 tid=3598 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-SegmentedRaftLogWorker"  prio=5 tid=6001 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1294806619-4703" daemon prio=5 tid=4703 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4594 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DirectoryDeletingService#0" daemon prio=5 tid=4398 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5900 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=4106 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$415/476480949.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"timer4" daemon prio=5 tid=573 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"5b8e2765-a6c1-4d85-87a6-bec4168f79ce@group-1C1BA33CCF34-StateMachineUpdater" daemon prio=5 tid=3902 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-3" daemon prio=5 tid=570 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 42189" daemon prio=5 tid=4193 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1204808652-4407" daemon prio=5 tid=4407 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4850 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5675 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5674 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2123228695-5324" daemon prio=5 tid=5324 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:42189 - 0 "  prio=5 tid=4757 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor55" daemon prio=5 tid=5768 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5620 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ef8775a4-4a62-450d-ae4d-a3eaa392aaf8@group-9D5E22661B84->5b8e2765-a6c1-4d85-87a6-bec4168f79ce-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=3998 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/558834684.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 43711" daemon prio=5 tid=3469 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5638 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:42189 - 0 "  prio=5 tid=4851 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-8"  prio=5 tid=5378 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4536c619-fdf7-4443-8da6-b71e8b366fa5@group-3608AD55A432-LeaderStateImpl" daemon prio=5 tid=5032 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp1525410126-3642" daemon prio=5 tid=3642 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6186 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5611 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 35129" daemon prio=5 tid=6044 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"7153b2e5-6547-4596-92e7-e397d052a5ec-server-thread3" daemon prio=5 tid=5979 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-SegmentedRaftLogWorker"  prio=5 tid=5985 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 34811" daemon prio=5 tid=5294 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 17 on default port 35129" daemon prio=5 tid=6059 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-SegmentedRaftLogWorker"  prio=5 tid=5956 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3566 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 37573" daemon prio=5 tid=6093 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2421-thread-1"  prio=5 tid=5357 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6210 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 37773" daemon prio=5 tid=6022 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"qtp1061117145-3667" daemon prio=5 tid=3667 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5889 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=5245 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4799 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5678 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5541 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@574313de" daemon prio=5 tid=4596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"OMDoubleBufferFlushThread" daemon prio=5 tid=4294 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:615)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:258)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$542/1031077761.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-0"  prio=5 tid=5341 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1603186540-3559" daemon prio=5 tid=3559 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"964ef1ca-08ae-4b3c-a2ce-6bf03c7bf022-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4616 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 42245" daemon prio=5 tid=4176 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderStateImpl" daemon prio=5 tid=6146 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5700 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5606 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ef8775a4-4a62-450d-ae4d-a3eaa392aaf8@group-9D5E22661B84->3f7ac4d1-ddb9-474a-8f73-3a04b1780a60-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=3999 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/558834684.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 37773" daemon prio=5 tid=6079 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@6d940e8e" daemon prio=5 tid=5622 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5078 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 37573" daemon prio=5 tid=6088 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 10 on default port 42189" daemon prio=5 tid=4191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1116902535-4620" daemon prio=5 tid=4620 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3737 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"RatisPipelineUtilsThread - 0"  prio=5 tid=6011 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$412/1285005997.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 43469" daemon prio=5 tid=5465 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1712205733-5691" daemon prio=5 tid=5691 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 34811" daemon prio=5 tid=5292 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=5219 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1635-thread-1"  prio=5 tid=3917 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerReplicationThread-1" daemon prio=5 tid=6162 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:549)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-CommandQueueReportForCommandQueueReportHandler" daemon prio=5 tid=4863 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"null-request--thread1" daemon prio=5 tid=5339 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor54" daemon prio=5 tid=5742 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-5"  prio=5 tid=5369 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29-impl-thread1"  prio=5 tid=5621 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1643-thread-1"  prio=5 tid=3581 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5208 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5656 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4587 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=4072 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3761 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 37573" daemon prio=5 tid=6089 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server idle connection scanner for port 42245" daemon prio=5 tid=4118 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp391956526-4793" daemon prio=5 tid=4793 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4033 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=3445 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d9b3b7a" daemon prio=5 tid=5484 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp1061117145-3664-acceptor-0@133d5a29-ServerConnector@65d5016b{HTTP/1.1, (http/1.1)}{0.0.0.0:44395}" daemon prio=3 tid=3664 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:41201 - 0 "  prio=5 tid=5879 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=5880 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1172302072-3585" daemon prio=5 tid=3585 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=703 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=3508 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp1326021788-3529-acceptor-0@cc65a72-ServerConnector@4eee64f6{HTTP/1.1, (http/1.1)}{0.0.0.0:44405}" daemon prio=3 tid=3529 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4515 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 35129" daemon prio=5 tid=6060 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-StateMachineUpdater" daemon prio=5 tid=5949 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"OM StateMachine ApplyTransaction Thread - 0" daemon prio=5 tid=5049 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2203-thread-1"  prio=5 tid=4933 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"16d82cf4-1422-4a15-9631-5fbf1a57277e@group-F0F5BE7F53DD-StateMachineUpdater" daemon prio=5 tid=4915 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5534 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@1f44280f" daemon prio=5 tid=4752 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"pool-1705-thread-1"  prio=5 tid=3940 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-491764fa-1"  prio=5 tid=3535 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"00fc006e-6b43-4634-bd06-6319b071a59a@group-8BB277A845C3-LeaderStateImpl" daemon prio=5 tid=4981 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-3"  prio=5 tid=5352 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1347105255-4727" daemon prio=5 tid=4727 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6209 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5891 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor46" daemon prio=5 tid=4817 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-CommandQueueReportForCommandQueueReportHandler" daemon prio=5 tid=6150 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer-6"  prio=5 tid=5448 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"4c73a9f1-7904-4197-8af5-de7b9af59d88-impl-thread1"  prio=5 tid=5661 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp305190215-5525" daemon prio=5 tid=5525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4808 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3700 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 34811" daemon prio=5 tid=5287 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 3 on default port 40643" daemon prio=5 tid=4415 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-StateMachineUpdater" daemon prio=5 tid=5996 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"3f3d7b74-b56c-404b-afe2-89147051cf18-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4786 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=4116 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"qtp1204808652-4409" daemon prio=5 tid=4409 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1712205733-5693" daemon prio=5 tid=5693 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-FollowerState" daemon prio=5 tid=5970 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"c2e5a0ee-722e-430e-828a-2d735c45daa1@group-503D6BB962B7-LeaderStateImpl" daemon prio=5 tid=3970 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@2330ae2b" daemon prio=5 tid=3496 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"qtp1204808652-4403" daemon prio=5 tid=4403 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3647 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 41201" daemon prio=5 tid=5299 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 6 on default port 42189" daemon prio=5 tid=4187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5487 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp917562781-5670" daemon prio=5 tid=5670 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-1088-thread-1"  prio=5 tid=2359 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 45947" daemon prio=5 tid=5260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 11 on default port 37773" daemon prio=5 tid=6073 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"KeyDeletingService#0" daemon prio=5 tid=4397 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-1"  prio=5 tid=5166 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-1"  prio=5 tid=5343 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=6032 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6205 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5923 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3676 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 43711" daemon prio=5 tid=3473 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"OMDoubleBufferFlushThread" daemon prio=5 tid=5410 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:615)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:258)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$542/1031077761.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 41201" daemon prio=5 tid=5305 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1603186540-3557" daemon prio=5 tid=3557 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor56" daemon prio=5 tid=5890 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp2023223337-5461" daemon prio=5 tid=5461 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 35129" daemon prio=5 tid=6043 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=4770 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 34811" daemon prio=5 tid=5233 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"JvmPauseMonitor48" daemon prio=5 tid=4856 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4849 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5228 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"qtp1061117145-3663" daemon prio=5 tid=3663 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5905 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp938586173-4215" daemon prio=5 tid=4215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=6130 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3513 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp917562781-5666" daemon prio=5 tid=5666 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2473-thread-1"  prio=5 tid=5942 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5538 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@6f39c42f" daemon prio=5 tid=5511 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@65b6f348" daemon prio=5 tid=3652 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-StateMachineUpdater" daemon prio=5 tid=5991 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp1326021788-3528" daemon prio=5 tid=3528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4775 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=4117 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"qtp134934515-5626" daemon prio=5 tid=5626 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1061117145-3670" daemon prio=5 tid=3670 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 42245" daemon prio=5 tid=4177 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 16 on default port 37773" daemon prio=5 tid=6078 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1347105255-4725" daemon prio=5 tid=4725 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 42189" daemon prio=5 tid=4197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-7a841579-1"  prio=5 tid=5605 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5065 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4809 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5718 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor51" daemon prio=5 tid=5446 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2403-thread-1"  prio=5 tid=5318 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1726962409-4559" daemon prio=5 tid=4559 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA->235120ac-71a1-451e-bf57-c5cd114d9629-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6194 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/558834684.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-57336a6d-1"  prio=5 tid=5502 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c0917728-87bf-433d-b3f0-4191e0e505db@group-EE7CEB6CB5E4-StateMachineUpdater" daemon prio=5 tid=4896 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 43711" daemon prio=5 tid=3478 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=4846 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2525-thread-1"  prio=5 tid=5955 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=5239 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5917 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"78962ee0-dad8-4871-bc4b-e1f0b96bf3d9-impl-thread1"  prio=5 tid=5519 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"7153b2e5-6547-4596-92e7-e397d052a5ec-server-thread2" daemon prio=5 tid=5977 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4806 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState" daemon prio=5 tid=6191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server handler 15 on default port 43469" daemon prio=5 tid=5479 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 14 on default port 40643" daemon prio=5 tid=4426 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=6132 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5082 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1294806619-4701" daemon prio=5 tid=4701 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4593 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 41201" daemon prio=5 tid=5298 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3569 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=6034 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 45947" daemon prio=5 tid=5270 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"OpenKeyCleanupService#0" daemon prio=5 tid=5451 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5702 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2045-thread-1"  prio=5 tid=4551 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5918 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ef8775a4-4a62-450d-ae4d-a3eaa392aaf8@group-9886A1E37655-SegmentedRaftLogWorker"  prio=5 tid=3906 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4591 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 37773"  prio=5 tid=6023 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"Socket Reader #1 for port 0"  prio=5 tid=4113 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"Session-HouseKeeper-6da9990f-1"  prio=5 tid=4798 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4782 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4801 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1204808652-4404" daemon prio=5 tid=4404 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3698 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5077 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@df1b528" daemon prio=5 tid=3516 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"c0917728-87bf-433d-b3f0-4191e0e505db@group-3608AD55A432-FollowerState" daemon prio=5 tid=5028 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4640 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5571 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3572 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5423 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"qtp1061117145-3668" daemon prio=5 tid=3668 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5886 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5878 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 42245" daemon prio=5 tid=4168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1116902535-4627" daemon prio=5 tid=4627 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-SegmentedRaftLogWorker"  prio=5 tid=5998 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3594 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 37573" daemon prio=5 tid=6020 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"BlockDeletingService#0" daemon prio=5 tid=5922 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2533-thread-1"  prio=5 tid=5550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2123228695-5323" daemon prio=5 tid=5323 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:42189 - 0 "  prio=5 tid=4800 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6187 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b8e2765-a6c1-4d85-87a6-bec4168f79ce@group-9D5E22661B84-FollowerState" daemon prio=5 tid=3994 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"ChunkWriter-1-0" daemon prio=5 tid=3797 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCMBlockDeletingService#0" daemon prio=5 tid=5316 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"964ef1ca-08ae-4b3c-a2ce-6bf03c7bf022@group-114CBC1C9326-SegmentedRaftLogWorker"  prio=5 tid=4897 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3645 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor33" daemon prio=5 tid=3448 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 35129" daemon prio=5 tid=6053 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 18 on default port 43469" daemon prio=5 tid=5482 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp2123228695-5320-acceptor-0@79059447-ServerConnector@20247330{HTTP/1.1, (http/1.1)}{0.0.0.0:33261}" daemon prio=3 tid=5320 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@d9e4726" daemon prio=5 tid=5549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor44" daemon prio=5 tid=4771 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1116902535-4623" daemon prio=5 tid=4623 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=10 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:284)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at org.apache.maven.surefire.api.util.internal.Channels$3.readImpl(Channels.java:214)
        at org.apache.maven.surefire.api.util.internal.AbstractNoninterruptibleReadableChannel.read(AbstractNoninterruptibleReadableChannel.java:54)
        at org.apache.maven.surefire.booter.spi.LegacyMasterProcessChannelDecoder.decode(LegacyMasterProcessChannelDecoder.java:80)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:343)
        at java.lang.Thread.run(Thread.java:750)
"Under Replicated Processor" daemon prio=5 tid=4109 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:136)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=5243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 37773" daemon prio=5 tid=6074 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 17 on default port 37573" daemon prio=5 tid=6099 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2154-thread-1" daemon prio=5 tid=4717 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3680 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4518 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=3447 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderStateImpl" daemon prio=5 tid=6148 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"3f7ac4d1-ddb9-474a-8f73-3a04b1780a60@group-62D7DE80C8E2-SegmentedRaftLogWorker"  prio=5 tid=3865 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp134934515-5630" daemon prio=5 tid=5630 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp91775645-5601" daemon prio=5 tid=5601 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 34325" daemon prio=5 tid=4149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=5770 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-SegmentedRaftLogWorker"  prio=5 tid=5751 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 35129" daemon prio=5 tid=6047 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"5b8e2765-a6c1-4d85-87a6-bec4168f79ce-server-thread4"  prio=5 tid=5366 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4778 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 45947" daemon prio=5 tid=5263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6211 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 41201" daemon prio=5 tid=5306 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 8 on default port 45947" daemon prio=5 tid=5264 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#1" daemon prio=5 tid=4860 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-61de4256-1"  prio=5 tid=4704 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5577 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2023223337-5456-acceptor-0@19ce20a4-ServerConnector@e02aea7{HTTP/1.1, (http/1.1)}{0.0.0.0:43861}" daemon prio=3 tid=5456 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 42245" daemon prio=5 tid=4164 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1591-thread-1"  prio=5 tid=3526 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 34811" daemon prio=5 tid=5295 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"c0917728-87bf-433d-b3f0-4191e0e505db@group-EE7CEB6CB5E4-SegmentedRaftLogWorker"  prio=5 tid=4894 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 43469" daemon prio=5 tid=5470 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4034 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer3" daemon prio=5 tid=572 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"EndpointStateMachine task thread for /0.0.0.0:41201 - 0 "  prio=5 tid=5701 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5771 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1963-thread-1"  prio=5 tid=4865 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-9FF3442ABBF5-LeaderStateImpl" daemon prio=5 tid=3988 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@3c3be05b" daemon prio=5 tid=4462 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5572 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5052 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-5db46306-1"  prio=5 tid=3644 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp992714005-4667" daemon prio=5 tid=4667 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4638 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1950-thread-1" daemon prio=5 tid=4449 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"process reaper" daemon prio=10 tid=12 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@abaae5e" daemon prio=5 tid=5540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-SegmentedRaftLogWorker"  prio=5 tid=5964 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4760 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4745 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3514 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2020 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=4836 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3820 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1525410126-3639" daemon prio=5 tid=3639 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4774 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4818 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 40643" daemon prio=5 tid=4414 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3812 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3568 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 34811" daemon prio=5 tid=5293 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1726962409-4561" daemon prio=5 tid=4561 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 37573" daemon prio=5 tid=6084 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=4128 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-StateMachineUpdater" daemon prio=5 tid=5958 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=3442 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5681 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1726962409-4555-acceptor-0@c0cafc5-ServerConnector@2508973c{HTTP/1.1, (http/1.1)}{0.0.0.0:40197}" daemon prio=3 tid=4555 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-3"  prio=5 tid=5353 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3565 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 41201" daemon prio=5 tid=5313 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4753 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4780 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 35129" daemon prio=5 tid=6026 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=4125 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SstFilteringService#0" daemon prio=5 tid=5453 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=5434 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp885186621-6108" daemon prio=5 tid=6108 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-1698-thread-1" daemon prio=5 tid=3657 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 34325" daemon prio=5 tid=4153 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp305190215-5526" daemon prio=5 tid=5526 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-9"  prio=5 tid=5381 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4738 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a8bd3719-ed86-42e1-a40d-2b4ed0b09d7c@group-F0F5BE7F53DD-FollowerState" daemon prio=5 tid=5117 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"Session-HouseKeeper-7442fe30-1"  prio=5 tid=3671 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4093 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Over Replicated Processor" daemon prio=5 tid=6016 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:136)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5646 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2139-thread-1"  prio=5 tid=4921 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 34325" daemon prio=5 tid=4144 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"grpc-default-worker-ELG-3-2" daemon prio=5 tid=475 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:290)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:354)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA->fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/558834684.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2585-thread-1"  prio=5 tid=5623 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-StateMachineUpdater" daemon prio=5 tid=5984 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4815 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@4a376323" daemon prio=5 tid=4522 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp1525410126-3640" daemon prio=5 tid=3640 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=5883 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1683-thread-1"  prio=5 tid=3929 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 35129" daemon prio=5 tid=6052 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1088490717-5497" daemon prio=5 tid=5497 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3539 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4634 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1549-thread-1"  prio=5 tid=3454 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5053 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3f7ac4d1-ddb9-474a-8f73-3a04b1780a60@group-62D7DE80C8E2-StateMachineUpdater" daemon prio=5 tid=3867 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5773 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DatanodeAdminManager-0" daemon prio=5 tid=5226 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 40643" daemon prio=5 tid=4416 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200->b67f1ce3-fbfb-4e89-9cbc-643abd2f2563-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6224 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/558834684.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5713 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3803 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-7"  prio=5 tid=5376 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"IPC Server handler 5 on default port 37773" daemon prio=5 tid=6067 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1061117145-3665" daemon prio=5 tid=3665 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3650 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5895 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=5936 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer-5"  prio=5 tid=4396 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ChunkWriter-3-0" daemon prio=5 tid=4804 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-client-thread1" daemon prio=5 tid=5048 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-2"  prio=5 tid=5148 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 34811" daemon prio=5 tid=5276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1116902535-4621-acceptor-0@2d0f678d-ServerConnector@619aa28d{HTTP/1.1, (http/1.1)}{0.0.0.0:45863}" daemon prio=3 tid=4621 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 34325" daemon prio=5 tid=4147 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2570-thread-1" daemon prio=5 tid=5618 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"16d82cf4-1422-4a15-9631-5fbf1a57277e-server-thread1" daemon prio=5 tid=5121 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp391956526-4791-acceptor-0@32986a0f-ServerConnector@4e9e55ae{HTTP/1.1, (http/1.1)}{0.0.0.0:37873}" daemon prio=3 tid=4791 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-StateMachineUpdater" daemon prio=5 tid=5754 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3678 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5888 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 41201" daemon prio=5 tid=5303 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4828 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 40643" daemon prio=5 tid=4429 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200->78962ee0-dad8-4871-bc4b-e1f0b96bf3d9-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6225 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/558834684.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-6f51b8ff-1"  prio=5 tid=5559 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5508 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"964ef1ca-08ae-4b3c-a2ce-6bf03c7bf022-server-thread2" daemon prio=5 tid=5041 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=5244 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1204808652-4405-acceptor-0@59336701-ServerConnector@4aeedc30{HTTP/1.1, (http/1.1)}{0.0.0.0:38445}" daemon prio=3 tid=4405 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"5b8e2765-a6c1-4d85-87a6-bec4168f79ce-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3523 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5765 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5074 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 40643" daemon prio=5 tid=4428 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=4107 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$415/476480949.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5652 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 35129" daemon prio=5 tid=6051 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2211-thread-1"  prio=5 tid=4789 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-2"  prio=5 tid=5168 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1294806619-4702" daemon prio=5 tid=4702 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"3f7ac4d1-ddb9-474a-8f73-3a04b1780a60-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3494 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5710 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@c14fbc" daemon prio=5 tid=5576 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp91775645-5598-acceptor-0@42dafece-ServerConnector@6615f6cb{HTTP/1.1, (http/1.1)}{0.0.0.0:33385}" daemon prio=3 tid=5598 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4678 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5772 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 34325" daemon prio=5 tid=4141 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6203 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor45" daemon prio=5 tid=4805 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4754 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=4129 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1603186540-3561" daemon prio=5 tid=3561 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3592 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=5242 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor42" daemon prio=5 tid=4739 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 45947" daemon prio=5 tid=5274 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=4130 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 37773" daemon prio=5 tid=6024 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"EndpointStateMachine task thread for /0.0.0.0:37573 - 0 "  prio=5 tid=3813 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor52" daemon prio=5 tid=5649 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=6135 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-7"  prio=5 tid=5375 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp134934515-5629" daemon prio=5 tid=5629 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4035 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4744 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1088490717-5500" daemon prio=5 tid=5500 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1172302072-3583-acceptor-0@4ec2ceb8-ServerConnector@3f9dabe8{HTTP/1.1, (http/1.1)}{0.0.0.0:37871}" daemon prio=3 tid=3583 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4750 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3649 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1088490717-5495-acceptor-0@62eaa60c-ServerConnector@29689844{HTTP/1.1, (http/1.1)}{0.0.0.0:33475}" daemon prio=3 tid=5495 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4688 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4803 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3769 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@5e4cd609" daemon prio=5 tid=5640 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"pool-2743-thread-1"  prio=5 tid=6104 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 37573" daemon prio=5 tid=6083 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5677 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=4115 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3740 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 45947" daemon prio=5 tid=5273 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"7153b2e5-6547-4596-92e7-e397d052a5ec@group-91F2EA8942FC-LeaderStateImpl" daemon prio=5 tid=3986 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ChunkReader-ELG-0" daemon prio=5 tid=5716 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp1294806619-4696" daemon prio=5 tid=4696 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"5b8e2765-a6c1-4d85-87a6-bec4168f79ce@group-9D5E22661B84-SegmentedRaftLogWorker"  prio=5 tid=3873 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"OpenKeyCleanupService#0" daemon prio=5 tid=3452 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@5c248ef8" daemon prio=5 tid=4665 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3546 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=4866 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 34325" daemon prio=5 tid=4150 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3599 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 37773" daemon prio=5 tid=6075 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=5206 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3819 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 43711" daemon prio=5 tid=3468 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"SstFilteringService#0" daemon prio=5 tid=4400 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-2bab5ce5-1"  prio=5 tid=4216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5607 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 34325" daemon prio=5 tid=4151 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 7 on default port 43711" daemon prio=5 tid=3471 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=5712 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer for 'StorageContainerManager' metrics system" daemon prio=5 tid=6040 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5657 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp885186621-6105" daemon prio=5 tid=6105 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1056205779-5556" daemon prio=5 tid=5556 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"3f7ac4d1-ddb9-474a-8f73-3a04b1780a60@group-62D7DE80C8E2-LeaderStateImpl" daemon prio=5 tid=3952 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5673 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 41201" daemon prio=5 tid=5312 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#1" daemon prio=5 tid=5746 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=5227 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"IPC Server handler 4 on default port 42245" daemon prio=5 tid=4165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 11 on default port 42189" daemon prio=5 tid=4192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 8 on default port 43469" daemon prio=5 tid=5472 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=5741 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-StateMachineUpdater" daemon prio=5 tid=6007 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5504 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 37573" daemon prio=5 tid=6100 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@3602ad3f" daemon prio=5 tid=4788 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"3f7ac4d1-ddb9-474a-8f73-3a04b1780a60-server-thread1" daemon prio=5 tid=4004 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp143910163-3499" daemon prio=5 tid=3499 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3683 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Parameter Sending Thread #2" daemon prio=5 tid=3563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5706 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a8bd3719-ed86-42e1-a40d-2b4ed0b09d7c@group-C33017B511CD-LeaderStateImpl" daemon prio=5 tid=4978 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=4833 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5903 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"00fc006e-6b43-4634-bd06-6319b071a59a@group-F0F5BE7F53DD->a8bd3719-ed86-42e1-a40d-2b4ed0b09d7c-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5119 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/558834684.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp391956526-4796" daemon prio=5 tid=4796 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3596 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3051 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 37773" daemon prio=5 tid=6072 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp917562781-5664" daemon prio=5 tid=5664 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"78962ee0-dad8-4871-bc4b-e1f0b96bf3d9-server-thread2" daemon prio=5 tid=6230 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"00fc006e-6b43-4634-bd06-6319b071a59a@group-8BB277A845C3-SegmentedRaftLogWorker"  prio=5 tid=4929 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4831 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=5436 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 43711" daemon prio=5 tid=3470 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 6 on default port 42245" daemon prio=5 tid=4167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1347105255-4724-acceptor-0@3bd0652c-ServerConnector@4cd66417{HTTP/1.1, (http/1.1)}{0.0.0.0:46307}" daemon prio=3 tid=4724 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@5b1f1a68" daemon prio=5 tid=5613 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-2"  prio=5 tid=5347 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1061117145-3666" daemon prio=5 tid=3666 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3646 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=3195 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c0917728-87bf-433d-b3f0-4191e0e505db@group-EE7CEB6CB5E4-LeaderStateImpl" daemon prio=5 tid=4966 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp938586173-4212" daemon prio=5 tid=4212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1056205779-5551" daemon prio=5 tid=5551 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6201 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4447 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DatanodeAdminManager-0" daemon prio=5 tid=6017 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3681 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-8"  prio=5 tid=5380 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-5a6308b4-1"  prio=5 tid=3562 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6207 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-4"  prio=5 tid=5360 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"OpenKeyCleanupService#0" daemon prio=5 tid=4399 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4821 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5574 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3538 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=3200 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 34325" daemon prio=5 tid=4155 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"KeyDeletingService#0" daemon prio=5 tid=3450 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"16d82cf4-1422-4a15-9631-5fbf1a57277e@group-1994514B191F-SegmentedRaftLogWorker"  prio=5 tid=4910 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4854 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3744 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3764 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-16" daemon prio=5 tid=5186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4094 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3f7ac4d1-ddb9-474a-8f73-3a04b1780a60@group-9D5E22661B84-FollowerState" daemon prio=5 tid=4000 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"qtp1204808652-4410" daemon prio=5 tid=4410 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp91775645-5599" daemon prio=5 tid=5599 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp91775645-5597" daemon prio=5 tid=5597 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 37573" daemon prio=5 tid=6087 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1347105255-4729" daemon prio=5 tid=4729 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=5881 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5515 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3544 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=6010 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 43711" daemon prio=5 tid=3465 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"5b8e2765-a6c1-4d85-87a6-bec4168f79ce@group-1C1BA33CCF34-LeaderStateImpl" daemon prio=5 tid=3960 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@386cbca2" daemon prio=5 tid=3661 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4766 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp1603186540-3554" daemon prio=5 tid=3554 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1326021788-3527" daemon prio=5 tid=3527 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4706 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4761 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp91775645-5600" daemon prio=5 tid=5600 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 45947" daemon prio=5 tid=5275 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"4536c619-fdf7-4443-8da6-b71e8b366fa5@group-0E6B1EBA877C-LeaderStateImpl" daemon prio=5 tid=4939 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 8 on default port 35129" daemon prio=5 tid=6050 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"RatisPipelineUtilsThread - 0"  prio=5 tid=5220 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$412/1285005997.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (1807010831) connection to 0.0.0.0/0.0.0.0:42189 from runner" daemon prio=5 tid=4734 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1086)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1133)
"grpc-default-executor-19" daemon prio=5 tid=5197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp33293217-3460" daemon prio=5 tid=3460 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4713 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4630 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=6131 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4747 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1294806619-4699" daemon prio=5 tid=4699 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-1498-thread-1"  prio=5 tid=3373 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3570 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"964ef1ca-08ae-4b3c-a2ce-6bf03c7bf022-server-thread1" daemon prio=5 tid=5038 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor39" daemon prio=5 tid=3800 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"4536c619-fdf7-4443-8da6-b71e8b366fa5@group-0E6B1EBA877C-StateMachineUpdater" daemon prio=5 tid=4869 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3672 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4824 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1931-thread-1"  prio=5 tid=4401 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@3afca8f5" daemon prio=5 tid=3571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3564 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@18134331" daemon prio=5 tid=5595 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"qtp305190215-5528" daemon prio=5 tid=5528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4749 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-7"  prio=5 tid=5374 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState" daemon prio=5 tid=6222 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-3"  prio=5 tid=5348 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2123228695-5325" daemon prio=5 tid=5325 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 41201" daemon prio=5 tid=5304 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2037-thread-1"  prio=5 tid=4873 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1088490717-5498" daemon prio=5 tid=5498 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=4392 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29-server-thread2" daemon prio=5 tid=6198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5892 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 40643" daemon prio=5 tid=4420 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5676 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-4ab558da-1"  prio=5 tid=3506 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 37573" daemon prio=5 tid=6095 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1088490717-5501" daemon prio=5 tid=5501 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 43711" daemon prio=5 tid=3479 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 15 on default port 37773" daemon prio=5 tid=6077 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server Responder" daemon prio=5 tid=5238 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"ChunkWriter-1-0" daemon prio=5 tid=3759 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4825 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 43711" daemon prio=5 tid=3483 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"OMDoubleBufferFlushThread" daemon prio=5 tid=3412 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:615)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:258)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$542/1031077761.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp134934515-5628" daemon prio=5 tid=5628 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1088490717-5499" daemon prio=5 tid=5499 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-FollowerState" daemon prio=5 tid=5975 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"ChunkWriter-1-0" daemon prio=5 tid=4759 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3704 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3697 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DirectoryDeletingService#0" daemon prio=5 tid=5450 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"964ef1ca-08ae-4b3c-a2ce-6bf03c7bf022@group-3608AD55A432-StateMachineUpdater" daemon prio=5 tid=4881 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 40643" daemon prio=5 tid=4421 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 13 on default port 34325" daemon prio=5 tid=4152 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=4684 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4633 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1294806619-4698-acceptor-0@549fd1ab-ServerConnector@685b03c{HTTP/1.1, (http/1.1)}{0.0.0.0:45325}" daemon prio=3 tid=4698 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ef8775a4-4a62-450d-ae4d-a3eaa392aaf8@group-9D5E22661B84-SegmentedRaftLogWorker"  prio=5 tid=3899 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4841 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3053 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3805 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@42fb7aaf" daemon prio=5 tid=5689 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 35129" daemon prio=5 tid=6048 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"b67f1ce3-fbfb-4e89-9cbc-643abd2f2563-impl-thread1"  prio=5 tid=5491 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3732 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-boss-ELG-1-1" daemon prio=5 tid=140 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"qtp1056205779-5558" daemon prio=5 tid=5558 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=4119 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4861 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-6ce10532-1"  prio=5 tid=4675 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2024-thread-1" daemon prio=5 tid=4540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp938586173-4213" daemon prio=5 tid=4213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 40643" daemon prio=5 tid=4419 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#2" daemon prio=5 tid=6202 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:41201 - 0 "  prio=5 tid=5897 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=5247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"235120ac-71a1-451e-bf57-c5cd114d9629-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5593 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=4123 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"IPC Server handler 19 on default port 40643" daemon prio=5 tid=4431 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=5714 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4536c619-fdf7-4443-8da6-b71e8b366fa5@group-3608AD55A432-StateMachineUpdater" daemon prio=5 tid=4872 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"pool-1628-thread-1" daemon prio=5 tid=3576 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4ec2caad-ead4-478e-ac51-fb863b7de4b5-server-thread1" daemon prio=5 tid=5978 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5083 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2117-thread-1"  prio=5 tid=4909 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3687 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3802 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-45f70f68-1"  prio=5 tid=6113 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp938586173-4209-acceptor-0@12e9cec0-ServerConnector@6f0bb{HTTP/1.1, (http/1.1)}{0.0.0.0:34861}" daemon prio=3 tid=4209 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"7153b2e5-6547-4596-92e7-e397d052a5ec-server-thread1" daemon prio=5 tid=5976 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 34811" daemon prio=5 tid=5289 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@11e2e5a" daemon prio=5 tid=4721 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"qtp134934515-5624" daemon prio=5 tid=5624 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-10cbb8a8-1"  prio=5 tid=5463 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c2e5a0ee-722e-430e-828a-2d735c45daa1-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3578 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 40643" daemon prio=5 tid=4424 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 0 on default port 40643" daemon prio=5 tid=4412 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1713-thread-1"  prio=5 tid=3662 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1885-thread-1"  prio=5 tid=4297 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"78962ee0-dad8-4871-bc4b-e1f0b96bf3d9-server-thread1" daemon prio=5 tid=6229 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp391956526-4790" daemon prio=5 tid=4790 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Listener at 0.0.0.0/35129"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1615)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:93)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:79)
        at org.apache.ozone.test.GenericTestUtils.waitFor(GenericTestUtils.java:231)
        at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSCMHandlesRestartForMaintenanceNode(TestDecommissionAndMaintenance.java:585)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
        at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
        at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
        at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
        at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor$$Lambda$164/169663597.apply(Unknown Source)
        at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
        at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall$$Lambda$165/565372776.apply(Unknown Source)
        at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
        at org.junit.jupiter.engine.execution.ExecutableInvoker$$Lambda$322/1062714541.apply(Unknown Source)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
        at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
        at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor$$Lambda$1231/1467740330.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$264/1876682596.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$263/171493374.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$262/1466785259.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$268/627318073.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$264/1876682596.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$263/171493374.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$262/1466785259.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$268/627318073.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$264/1876682596.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$263/171493374.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$262/1466785259.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator$$Lambda$220/1270038388.accept(Unknown Source)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
        at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
        at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
        at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
"qtp1326021788-3532" daemon prio=5 tid=3532 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"prometheus" daemon prio=5 tid=6041 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.metrics2.impl.SinkQueue.waitForData(SinkQueue.java:114)
        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:83)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:135)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:89)
"qtp2023223337-5457" daemon prio=5 tid=5457 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 43711" daemon prio=5 tid=3475 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 1 on default port 34325" daemon prio=5 tid=4140 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-0-0" daemon prio=5 tid=5738 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp143910163-3504" daemon prio=5 tid=3504 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderStateImpl" daemon prio=5 tid=6127 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp1056205779-5553" daemon prio=5 tid=5553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor35" daemon prio=5 tid=3701 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5747 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4767 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderStateImpl" daemon prio=5 tid=6193 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Command processor thread" daemon prio=5 tid=4521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=4389 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"IPC Server handler 2 on default port 43711" daemon prio=5 tid=3466 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3688 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3766 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4819 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=770 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4827 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 45947" daemon prio=5 tid=5258 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"DatanodeAdminManager-0" daemon prio=5 tid=4111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 34811" daemon prio=5 tid=5284 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"00fc006e-6b43-4634-bd06-6319b071a59a@group-8BB277A845C3-StateMachineUpdater" daemon prio=5 tid=4931 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp33293217-3461" daemon prio=5 tid=3461 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-6"  prio=5 tid=5371 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4681 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 42245" daemon prio=5 tid=4162 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=6149 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp33293217-3462" daemon prio=5 tid=3462 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 42189" daemon prio=5 tid=4195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#2" daemon prio=5 tid=5076 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 43469" daemon prio=5 tid=5473 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4517 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6175 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp33293217-3458" daemon prio=5 tid=3458 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 37573" daemon prio=5 tid=6101 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 19 on default port 41201" daemon prio=5 tid=5315 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 13 on default port 43711" daemon prio=5 tid=3477 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=4126 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5703 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 34325" daemon prio=5 tid=4122 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1901099451-4468" daemon prio=5 tid=4468 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ef8775a4-4a62-450d-ae4d-a3eaa392aaf8-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3550 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 45947" daemon prio=5 tid=5265 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 3 on default port 42189" daemon prio=5 tid=4184 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 9 on default port 34325" daemon prio=5 tid=4148 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp885186621-6106-acceptor-0@52b0b778-ServerConnector@ef59aee{HTTP/1.1, (http/1.1)}{0.0.0.0:37403}" daemon prio=3 tid=6106 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5573 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp143910163-3500" daemon prio=5 tid=3500 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp305190215-5523-acceptor-0@1754f39d-ServerConnector@34c1fc1a{HTTP/1.1, (http/1.1)}{0.0.0.0:44731}" daemon prio=3 tid=5523 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=706 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4823 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4711 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1672-thread-1" daemon prio=5 tid=3630 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2548-thread-1" daemon prio=5 tid=5591 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=6035 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4536c619-fdf7-4443-8da6-b71e8b366fa5@group-3608AD55A432->964ef1ca-08ae-4b3c-a2ce-6bf03c7bf022-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5034 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/558834684.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-14" daemon prio=5 tid=5184 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-15" daemon prio=5 tid=5185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5075 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=6151 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-StateMachineUpdater" daemon prio=5 tid=5757 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:42189 - 0 "  prio=5 tid=4733 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1204808652-4408" daemon prio=5 tid=4408 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1901099451-4469" daemon prio=5 tid=4469 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 34811" daemon prio=5 tid=5283 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1583-thread-1"  prio=5 tid=3872 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3815 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"7153b2e5-6547-4596-92e7-e397d052a5ec-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3632 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 43711" daemon prio=5 tid=3482 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5704 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp992714005-4670" daemon prio=5 tid=4670 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-6" daemon prio=5 tid=1368 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5514 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState" daemon prio=5 tid=6221 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server handler 6 on default port 45947" daemon prio=5 tid=5262 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Under Replicated Processor" daemon prio=5 tid=6015 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:136)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 45947" daemon prio=5 tid=5259 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=5740 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1294806619-4697" daemon prio=5 tid=4697 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854->4ec2caad-ead4-478e-ac51-fb863b7de4b5-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5973 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/558834684.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"timer7" daemon prio=5 tid=729 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 1 on default port 45947" daemon prio=5 tid=5256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor37" daemon prio=5 tid=3763 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp91775645-5603" daemon prio=5 tid=5603 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1116902535-4626" daemon prio=5 tid=4626 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6208 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5634 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-SegmentedRaftLogWorker"  prio=5 tid=5989 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=5246 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2123228695-5319" daemon prio=5 tid=5319 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"DirectoryDeletingService#0" daemon prio=5 tid=3451 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3648 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1554-thread-1" daemon prio=5 tid=3492 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1830-thread-1"  prio=5 tid=4206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ef8775a4-4a62-450d-ae4d-a3eaa392aaf8@group-9886A1E37655-StateMachineUpdater" daemon prio=5 tid=3908 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp1326021788-3531" daemon prio=5 tid=3531 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (1807010831) connection to 0.0.0.0/0.0.0.0:37573 from runner" daemon prio=5 tid=6009 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1086)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1133)
"c0917728-87bf-433d-b3f0-4191e0e505db@group-3608AD55A432-StateMachineUpdater" daemon prio=5 tid=4876 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-StateMachineUpdater" daemon prio=5 tid=5953 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"pool-2563-thread-1"  prio=5 tid=5596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4751 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 42189" daemon prio=5 tid=4186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=6039 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3703 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 43711" daemon prio=5 tid=3480 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5537 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3814 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"KeyDeletingService#0" daemon prio=5 tid=5449 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3f3d7b74-b56c-404b-afe2-89147051cf18@group-02A57CE781E4-SegmentedRaftLogWorker"  prio=5 tid=4934 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1603186540-3560" daemon prio=5 tid=3560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2577-thread-1"  prio=5 tid=5988 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=5222 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$415/476480949.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1116902535-4622" daemon prio=5 tid=4622 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 41201" daemon prio=5 tid=5307 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp992714005-4671" daemon prio=5 tid=4671 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1901099451-4466" daemon prio=5 tid=4466 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@60d5c001" daemon prio=5 tid=4202 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp2023223337-5460" daemon prio=5 tid=5460 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 34811" daemon prio=5 tid=5277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp391956526-4797" daemon prio=5 tid=4797 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5925 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderStateImpl" daemon prio=5 tid=6138 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp992714005-4672" daemon prio=5 tid=4672 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"5b8e2765-a6c1-4d85-87a6-bec4168f79ce-server-thread3" daemon prio=5 tid=4003 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1061117145-3669" daemon prio=5 tid=3669 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5708 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=6030 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5645 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 41201" daemon prio=5 tid=5302 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4705 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4802 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-SegmentedRaftLogWorker"  prio=5 tid=5947 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"16d82cf4-1422-4a15-9631-5fbf1a57277e@group-1994514B191F-StateMachineUpdater" daemon prio=5 tid=4912 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5705 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp91775645-5602" daemon prio=5 tid=5602 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5569 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3281 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1172302072-3582" daemon prio=5 tid=3582 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5719 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 42245" daemon prio=5 tid=4175 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"timer5" daemon prio=5 tid=708 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server listener on 0" daemon prio=5 tid=4120 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=4124 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3595 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4743 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4683 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 37773" daemon prio=5 tid=6063 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"b67f1ce3-fbfb-4e89-9cbc-643abd2f2563-server-thread3" daemon prio=5 tid=6228 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3677 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-SegmentedRaftLogWorker"  prio=5 tid=5982 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4707 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 37573" daemon prio=5 tid=6018 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"IPC Client (1807010831) connection to 0.0.0.0/0.0.0.0:41201 from runner" daemon prio=5 tid=5644 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1086)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1133)
"ReplicationMonitor" daemon prio=5 tid=5223 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:667)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$422/1414164286.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 43469" daemon prio=5 tid=5475 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5084 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1525410126-3636" daemon prio=5 tid=3636 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"964ef1ca-08ae-4b3c-a2ce-6bf03c7bf022@group-114CBC1C9326-StateMachineUpdater" daemon prio=5 tid=4899 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4736 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5899 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=5932 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp917562781-5668" daemon prio=5 tid=5668 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3817 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp391956526-4792" daemon prio=5 tid=4792 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderStateImpl" daemon prio=5 tid=6129 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3738 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 37773" daemon prio=5 tid=6065 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"00fc006e-6b43-4634-bd06-6319b071a59a@group-F0F5BE7F53DD-LeaderStateImpl" daemon prio=5 tid=5118 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"pool-2603-thread-1"  prio=5 tid=5993 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2637-thread-1"  prio=5 tid=5690 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp391956526-4795" daemon prio=5 tid=4795 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-1605-thread-1"  prio=5 tid=3889 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5590 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"7153b2e5-6547-4596-92e7-e397d052a5ec@group-91F2EA8942FC-StateMachineUpdater" daemon prio=5 tid=3939 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3770 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-51ff6634-1"  prio=5 tid=3590 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 43469" daemon prio=5 tid=5422 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ChunkWriter-0-0" daemon prio=5 tid=5916 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerReplicationThread-0" daemon prio=5 tid=6161 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:549)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4536c619-fdf7-4443-8da6-b71e8b366fa5@group-3608AD55A432->c0917728-87bf-433d-b3f0-4191e0e505db-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5033 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/558834684.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3211 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3798 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1712205733-5696" daemon prio=5 tid=5696 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1088490717-5496" daemon prio=5 tid=5496 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4852 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 43469" daemon prio=5 tid=5469 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 13 on default port 42245" daemon prio=5 tid=4174 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@3a47aa43" daemon prio=5 tid=3580 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"qtp885186621-6109" daemon prio=5 tid=6109 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5648 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6200 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3758 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp33293217-3457" daemon prio=5 tid=3457 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 34325" daemon prio=5 tid=4154 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 13 on default port 45947" daemon prio=5 tid=5269 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-5a95ae4b-1"  prio=5 tid=5327 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4519 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:37573 - 0 "  prio=5 tid=3757 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3509 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp885186621-6110" daemon prio=5 tid=6110 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-5" daemon prio=5 tid=579 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1603186540-3556" daemon prio=5 tid=3556 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderStateImpl" daemon prio=5 tid=5971 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=4864 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3741 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1525410126-3637-acceptor-0@77a73ed0-ServerConnector@56dfa91{HTTP/1.1, (http/1.1)}{0.0.0.0:46877}" daemon prio=3 tid=3637 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4636 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 41201" daemon prio=5 tid=5314 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server listener on 0" daemon prio=5 tid=5231 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4637 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 37573" daemon prio=5 tid=6091 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=6012 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$415/476480949.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"4536c619-fdf7-4443-8da6-b71e8b366fa5@group-3608AD55A432-SegmentedRaftLogWorker"  prio=5 tid=4870 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 43711" daemon prio=5 tid=3472 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-SegmentedRaftLogWorker"  prio=5 tid=6005 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"3f3d7b74-b56c-404b-afe2-89147051cf18@group-02A57CE781E4-StateMachineUpdater" daemon prio=5 tid=4936 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 42189" daemon prio=5 tid=4198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=5221 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$415/476480949.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"00fc006e-6b43-4634-bd06-6319b071a59a@group-F0F5BE7F53DD-StateMachineUpdater" daemon prio=5 tid=4919 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"pool-2492-thread-1" daemon prio=5 tid=5516 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 34811" daemon prio=5 tid=5290 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5609 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=6025 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"3f7ac4d1-ddb9-474a-8f73-3a04b1780a60@group-9D5E22661B84-SegmentedRaftLogWorker"  prio=5 tid=3868 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 42245" daemon prio=5 tid=4170 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5209 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-38e53c76-1"  prio=5 tid=5632 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 41201" daemon prio=5 tid=5310 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"a8bd3719-ed86-42e1-a40d-2b4ed0b09d7c@group-F0F5BE7F53DD-StateMachineUpdater" daemon prio=5 tid=4924 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 34325" daemon prio=5 tid=4146 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 12 on default port 43469" daemon prio=5 tid=5476 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"3f3d7b74-b56c-404b-afe2-89147051cf18@group-02A57CE781E4-LeaderStateImpl" daemon prio=5 tid=5012 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server listener on 0" daemon prio=5 tid=3441 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"ChunkWriter-1-0" daemon prio=5 tid=5739 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1525410126-3638" daemon prio=5 tid=3638 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@1567574" daemon prio=5 tid=5492 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:41201 - 0 "  prio=5 tid=5737 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3801 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"964ef1ca-08ae-4b3c-a2ce-6bf03c7bf022@group-114CBC1C9326-LeaderStateImpl" daemon prio=5 tid=4968 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp1901099451-4465-acceptor-0@d7fea4c-ServerConnector@70317ffa{HTTP/1.1, (http/1.1)}{0.0.0.0:46527}" daemon prio=3 tid=4465 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:42189 - 0 "  prio=5 tid=4812 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:41201 - 0 "  prio=5 tid=5914 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 41201" daemon prio=5 tid=5297 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3739 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2629-thread-1"  prio=5 tid=6004 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5081 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Parameter Sending Thread #1" daemon prio=5 tid=1033 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c0917728-87bf-433d-b3f0-4191e0e505db@group-3608AD55A432-SegmentedRaftLogWorker"  prio=5 tid=4874 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4735 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 42189" daemon prio=5 tid=4182 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 7 on default port 35129" daemon prio=5 tid=6049 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=3597 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1088490717-5494" daemon prio=5 tid=5494 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1056205779-5555" daemon prio=5 tid=5555 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@3710b8e6" daemon prio=5 tid=5520 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=5240 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3799 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-SegmentedRaftLogWorker"  prio=5 tid=5951 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ReplicationMonitor" daemon prio=5 tid=6014 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:667)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$422/1414164286.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1347105255-4728" daemon prio=5 tid=4728 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5764 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=707 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=6029 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5608 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4737 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=6021 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"BlockDeletingService#0" daemon prio=5 tid=5717 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3212 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a8bd3719-ed86-42e1-a40d-2b4ed0b09d7c-server-thread2" daemon prio=5 tid=5124 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5639 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp391956526-4794" daemon prio=5 tid=4794 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 35129" daemon prio=5 tid=6028 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp917562781-5665-acceptor-0@e129efa-ServerConnector@3a2b8209{HTTP/1.1, (http/1.1)}{0.0.0.0:35139}" daemon prio=3 tid=5665 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-9FF3442ABBF5-SegmentedRaftLogWorker"  prio=5 tid=3941 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1603186540-3555-acceptor-0@28b936cb-ServerConnector@5ce6404b{HTTP/1.1, (http/1.1)}{0.0.0.0:33361}" daemon prio=3 tid=3555 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"pool-2169-thread-1"  prio=5 tid=4722 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor47" daemon prio=5 tid=4844 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3537 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 42189" daemon prio=5 tid=4183 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 12 on default port 45947" daemon prio=5 tid=5268 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"b19954c4-943b-4bda-b8b4-ff98ab071ba2-impl-thread1"  prio=5 tid=5688 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer6" daemon prio=5 tid=709 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"EndpointStateMachine task thread for /0.0.0.0:37573 - 0 "  prio=5 tid=3717 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 40643" daemon prio=5 tid=4388 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 0 on default port 43469" daemon prio=5 tid=5464 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4710 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-9" daemon prio=5 tid=3201 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2161-thread-1"  prio=5 tid=4916 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6206 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 34811" daemon prio=5 tid=5278 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 13 on default port 40643" daemon prio=5 tid=4425 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#1" daemon prio=5 tid=4776 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp143910163-3505" daemon prio=5 tid=3505 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=6013 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$415/476480949.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4772 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5767 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"00fc006e-6b43-4634-bd06-6319b071a59a@group-F0F5BE7F53DD-SegmentedRaftLogWorker"  prio=5 tid=4917 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 43711" daemon prio=5 tid=3476 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Periodic HDDS volume checker" daemon prio=5 tid=5683 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 41201" daemon prio=5 tid=5296 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server listener on 0" daemon prio=5 tid=5235 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"16d82cf4-1422-4a15-9631-5fbf1a57277e@group-F0F5BE7F53DD-FollowerState" daemon prio=5 tid=5116 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server handler 9 on default port 37773" daemon prio=5 tid=6071 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor53" daemon prio=5 tid=5715 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-8"  prio=5 tid=5379 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1326021788-3530" daemon prio=5 tid=3530 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"4c73a9f1-7904-4197-8af5-de7b9af59d88-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5660 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"235120ac-71a1-451e-bf57-c5cd114d9629-server-thread1" daemon prio=5 tid=6197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4536c619-fdf7-4443-8da6-b71e8b366fa5@group-0E6B1EBA877C-SegmentedRaftLogWorker"  prio=5 tid=4867 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@65cf45f" daemon prio=5 tid=4694 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@609da5b6" daemon prio=5 tid=5709 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3684 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-SegmentedRaftLogWorker"  prio=5 tid=5960 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ef8775a4-4a62-450d-ae4d-a3eaa392aaf8@group-9D5E22661B84-StateMachineUpdater" daemon prio=5 tid=3904 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=704 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=6036 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Under Replicated Processor" daemon prio=5 tid=5224 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:136)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5073 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a8bd3719-ed86-42e1-a40d-2b4ed0b09d7c@group-C33017B511CD-StateMachineUpdater" daemon prio=5 tid=4928 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=6031 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 37573" daemon prio=5 tid=6092 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5893 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5614 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-SegmentedRaftLogWorker"  prio=5 tid=5994 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4516 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 43469" daemon prio=5 tid=5478 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=4394 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4748 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-5"  prio=5 tid=5365 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 37773" daemon prio=5 tid=6068 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-0"  prio=5 tid=5340 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 34325" daemon prio=5 tid=4139 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp143910163-3502" daemon prio=5 tid=3502 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"timer1" daemon prio=5 tid=571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"b67f1ce3-fbfb-4e89-9cbc-643abd2f2563-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5490 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3760 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3655 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3515 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"a8bd3719-ed86-42e1-a40d-2b4ed0b09d7c@group-C33017B511CD-SegmentedRaftLogWorker"  prio=5 tid=4926 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 42245" daemon prio=5 tid=4163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp938586173-4208" daemon prio=5 tid=4208 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"RatisPipelineUtilsThread - 0"  prio=5 tid=4105 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$412/1285005997.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=4131 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor34" daemon prio=5 tid=3679 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@564ba93d" daemon prio=5 tid=3525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-StateMachineUpdater" daemon prio=5 tid=6000 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 37573" daemon prio=5 tid=6090 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server Responder" daemon prio=5 tid=5234 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"5b8e2765-a6c1-4d85-87a6-bec4168f79ce-server-thread1" daemon prio=5 tid=4001 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 45947" daemon prio=5 tid=5272 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1603186540-3558" daemon prio=5 tid=3558 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6204 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5711 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp938586173-4210" daemon prio=5 tid=4210 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-2cf3651-1"  prio=5 tid=3463 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-1" daemon prio=5 tid=473 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:290)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:354)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 42189" daemon prio=5 tid=4200 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#1" daemon prio=5 tid=5907 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5232 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"qtp1116902535-4625" daemon prio=5 tid=4625 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"00fc006e-6b43-4634-bd06-6319b071a59a-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4719 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4848 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2518-thread-1" daemon prio=5 tid=5545 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp885186621-6107" daemon prio=5 tid=6107 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp33293217-3459" daemon prio=5 tid=3459 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5720 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=4549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-4"  prio=5 tid=5367 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:42189 - 0 "  prio=5 tid=4839 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-286-thread-1"  prio=5 tid=694 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4842 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=5241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 34811" daemon prio=5 tid=5286 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"7153b2e5-6547-4596-92e7-e397d052a5ec@group-91F2EA8942FC-SegmentedRaftLogWorker"  prio=5 tid=3937 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 34811" daemon prio=5 tid=5291 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-71d7d93f-1"  prio=5 tid=5672 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"null-request--thread1" daemon prio=5 tid=5211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3706 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-impl-thread1"  prio=5 tid=5412 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2481-thread-1"  prio=5 tid=5493 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1847-thread-1"  prio=5 tid=4242 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3628 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4523 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c0917728-87bf-433d-b3f0-4191e0e505db-server-thread3" daemon prio=5 tid=5039 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 37773" daemon prio=5 tid=6081 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp885186621-6111" daemon prio=5 tid=6111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=6038 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3567 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2555-thread-1"  prio=5 tid=5981 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ef8775a4-4a62-450d-ae4d-a3eaa392aaf8@group-9D5E22661B84-LeaderStateImpl" daemon prio=5 tid=3997 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"EndpointStateMachine task thread for /0.0.0.0:37573 - 0 "  prio=5 tid=3795 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=4104 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5887 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1726962409-4557" daemon prio=5 tid=4557 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"timer0" daemon prio=5 tid=736 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 16 on default port 37573" daemon prio=5 tid=6098 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1347105255-4730" daemon prio=5 tid=4730 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5642 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 37773" daemon prio=5 tid=6069 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkReader-ELG-0" daemon prio=5 tid=5650 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 37573" daemon prio=5 tid=6096 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-2"  prio=5 tid=5351 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1901099451-4467" daemon prio=5 tid=4467 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4779 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 43469" daemon prio=5 tid=5483 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-0-0" daemon prio=5 tid=4840 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=5180 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5651 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1901099451-4470" daemon prio=5 tid=4470 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=4112 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"ChunkReader-ELG-0" daemon prio=5 tid=3702 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 35129" daemon prio=5 tid=6054 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2147-thread-1"  prio=5 tid=4695 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp305190215-5522" daemon prio=5 tid=5522 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 43469" daemon prio=5 tid=5467 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp134934515-5631" daemon prio=5 tid=5631 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5506 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp305190215-5527" daemon prio=5 tid=5527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3771 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState" daemon prio=5 tid=6192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server handler 6 on default port 34325" daemon prio=5 tid=4145 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"timer2" daemon prio=5 tid=569 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp2123228695-5322" daemon prio=5 tid=5322 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 40643" daemon prio=5 tid=4413 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4742 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2125-thread-1"  prio=5 tid=4666 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4769 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=5884 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4709 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1172302072-3586" daemon prio=5 tid=3586 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3804 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4847 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1971-thread-1"  prio=5 tid=4463 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 35129" daemon prio=5 tid=6042 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5533 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$815/2099677472.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 41201" daemon prio=5 tid=5308 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Periodic HDDS volume checker" daemon prio=5 tid=4659 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"16d82cf4-1422-4a15-9631-5fbf1a57277e@group-F0F5BE7F53DD-SegmentedRaftLogWorker"  prio=5 tid=4913 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5505 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4816 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5736 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-13" daemon prio=5 tid=5183 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2088-thread-1" daemon prio=5 tid=4610 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Listener at 127.0.0.1/43469"  prio=5 tid=14 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.put(ArrayBlockingQueue.java:353)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider.lambda$createClusters$1(MiniOzoneClusterProvider.java:237)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider$$Lambda$340/1264941544.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2596-thread-1" daemon prio=5 tid=5658 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4838 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3593 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-0"  prio=5 tid=5342 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 37573" daemon prio=5 tid=6097 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4592 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=4862 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-1"  prio=5 tid=5346 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 42189" daemon prio=5 tid=4196 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1056205779-5554" daemon prio=5 tid=5554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp992714005-4668-acceptor-0@26c68fae-ServerConnector@32956dff{HTTP/1.1, (http/1.1)}{0.0.0.0:38915}" daemon prio=3 tid=4668 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 42189" daemon prio=5 tid=4181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=3734 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4595 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=4092 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandForSCMNodeManager" daemon prio=5 tid=6154 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5486 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3511 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5066 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3691 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-StateMachineUpdater" daemon prio=5 tid=5987 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 37573" daemon prio=5 tid=6085 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=4858 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 34811" daemon prio=5 tid=5281 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-StateMachineUpdater" daemon prio=5 tid=6003 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp305190215-5524" daemon prio=5 tid=5524 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1326021788-3534" daemon prio=5 tid=3534 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5641 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=4832 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor58" daemon prio=5 tid=5920 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5570 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3488 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 45947" daemon prio=5 tid=5271 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=4777 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4741 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2023223337-5462" daemon prio=5 tid=5462 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 40643" daemon prio=5 tid=4417 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5654 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4826 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5507 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3822 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b8e2765-a6c1-4d85-87a6-bec4168f79ce@group-9D5E22661B84-StateMachineUpdater" daemon prio=5 tid=3887 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp1712205733-5692-acceptor-0@372b86be-ServerConnector@46eafe6b{HTTP/1.1, (http/1.1)}{0.0.0.0:46375}" daemon prio=3 tid=5692 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=5248 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a8bd3719-ed86-42e1-a40d-2b4ed0b09d7c-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4692 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4032 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"OM StateMachine ApplyTransaction Thread - 0" daemon prio=5 tid=6171 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 41201" daemon prio=5 tid=5311 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=5943 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=6037 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5707 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 40643" daemon prio=5 tid=4422 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-0-0" daemon prio=5 tid=3675 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4680 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@7b0c95f2" daemon prio=5 tid=5662 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=4834 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@4d45b261" daemon prio=5 tid=4685 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5616 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 43469" daemon prio=5 tid=5481 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"grpc-default-executor-17" daemon prio=5 tid=5187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=4121 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"IPC Server handler 6 on default port 34811" daemon prio=5 tid=5282 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Socket Reader #1 for port 37573"  prio=5 tid=6019 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@36b3a49c" daemon prio=5 tid=4830 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-6"  prio=5 tid=5372 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5653 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5617 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-1"  prio=5 tid=5147 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1726962409-4554" daemon prio=5 tid=4554 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/1613032662.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 34325" daemon prio=5 tid=4156 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderStateImpl" daemon prio=5 tid=6153 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"JvmPauseMonitor41" daemon prio=5 tid=4395 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-1"  prio=5 tid=5344 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor57" daemon prio=5 tid=5902 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-StateMachineUpdater" daemon prio=5 tid=5750 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@503aa17f" daemon prio=5 tid=3543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 40643" daemon prio=5 tid=4423 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=3816 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1712205733-5694" daemon prio=5 tid=5694 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-1569-thread-1"  prio=5 tid=3497 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4686 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:41201 - 0 "  prio=5 tid=5763 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-2"  prio=5 tid=5350 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5637 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2050 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4773 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4597 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4768 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 42245" daemon prio=5 tid=4173 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5762 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=4835 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3653 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4758 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5612 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$817/1724018703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5236 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"Session-HouseKeeper-3a3cc412-1"  prio=5 tid=4472 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 42189" daemon prio=5 tid=4185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor36" daemon prio=5 tid=3735 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$748/908327743.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"a8bd3719-ed86-42e1-a40d-2b4ed0b09d7c-server-thread1" daemon prio=5 tid=5122 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=4133 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 35129" daemon prio=5 tid=6045 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4820 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3690 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b8e2765-a6c1-4d85-87a6-bec4168f79ce@group-1C1BA33CCF34-SegmentedRaftLogWorker"  prio=5 tid=3900 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 43711" daemon prio=5 tid=3443 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1525410126-3641" daemon prio=5 tid=3641 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5766 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1712205733-5695" daemon prio=5 tid=5695 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-12" daemon prio=5 tid=5182 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"16d82cf4-1422-4a15-9631-5fbf1a57277e-server-thread2" daemon prio=5 tid=5123 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 42245" daemon prio=5 tid=4179 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4635 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5909 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-StateMachineUpdater" daemon prio=5 tid=5962 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 40643" daemon prio=5 tid=4430 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-SegmentedRaftLogWorker"  prio=5 tid=5944 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$707/1699369497.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp938586173-4211" daemon prio=5 tid=4211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@8243e4a" daemon prio=5 tid=5680 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5744 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4740 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=4387 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"om1-client-thread1" daemon prio=5 tid=6170 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c0917728-87bf-433d-b3f0-4191e0e505db-server-thread4" daemon prio=5 tid=5040 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=4132 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCMBlockDeletingService#0" daemon prio=5 tid=6102 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 45947" daemon prio=5 tid=5255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"00fc006e-6b43-4634-bd06-6319b071a59a@group-F0F5BE7F53DD->16d82cf4-1422-4a15-9631-5fbf1a57277e-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5120 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/558834684.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1598-thread-1" daemon prio=5 tid=3548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4822 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 35129" daemon prio=5 tid=6046 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6172 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3540 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"b19954c4-943b-4bda-b8b4-ff98ab071ba2-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5687 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-9"  prio=5 tid=5382 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5743 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4756 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5901 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-0ad5e6d1-c303-47af-a332-9d5e22661b84-5"  prio=5 tid=5361 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4746 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@408980aa" daemon prio=5 tid=6103 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp992714005-4674" daemon prio=5 tid=4674 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-104fca3a-1"  prio=5 tid=4628 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3512 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)


	at org.apache.ozone.test.GenericTestUtils.waitFor(GenericTestUtils.java:231)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSCMHandlesRestartForMaintenanceNode(TestDecommissionAndMaintenance.java:585)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
]]></error>
    <system-out><![CDATA[2023-02-02 20:27:21,369 [Listener at 127.0.0.1/40643] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-02 20:27:21,371 [Listener at 127.0.0.1/40643] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-02 20:27:21,372 [Listener at 127.0.0.1/40643] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-02-02 20:27:21,372 [Listener at 127.0.0.1/40643] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-02-02 20:27:21,372 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - om1: close
2023-02-02 20:27:21,372 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-02 20:27:21,372 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-02 20:27:21,378 [Listener at 127.0.0.1/40643] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-02 20:27:21,379 [Listener at 127.0.0.1/40643] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-02 20:27:21,378 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - om1@group-C5BA1605619E: shutdown
2023-02-02 20:27:21,378 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - om1: shutdown server GrpcServerProtocolService now
2023-02-02 20:27:21,391 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - om1: shutdown server GrpcServerProtocolService successfully
2023-02-02 20:27:21,392 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2023-02-02 20:27:21,392 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2023-02-02 20:27:21,392 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2023-02-02 20:27:21,405 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 166
2023-02-02 20:27:21,405 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(445)) - Current Snapshot Index (t:1, i:166)
2023-02-02 20:27:21,406 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 166
2023-02-02 20:27:21,406 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 166
2023-02-02 20:27:21,406 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-02-02 20:27:21,406 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(541)) - Stopping OMDoubleBuffer flush thread
2023-02-02 20:27:21,406 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(626)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit.
2023-02-02 20:27:21,408 [om1-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - om1@group-C5BA1605619E: closes. applyIndex: 166
2023-02-02 20:27:21,408 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:21,410 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2023-02-02 20:27:21,413 [JvmPauseMonitor25] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-om1: Stopped
2023-02-02 20:27:21,413 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-02-02 20:27:21,413 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(550)) - OMDoubleBuffer flush thread is not running.
2023-02-02 20:27:21,414 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service KeyDeletingService
2023-02-02 20:27:21,414 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service DirectoryDeletingService
2023-02-02 20:27:21,415 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service OpenKeyCleanupService
2023-02-02 20:27:21,415 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SstFilteringService
2023-02-02 20:27:21,417 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3cd6193a{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-02-02 20:27:21,418 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@7773361d{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-02 20:27:21,418 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-02 20:27:21,420 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@46244fab{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-02-02 20:27:21,423 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@408b166f{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-02 20:27:21,429 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(524)) - Stopping the HddsDatanodes
2023-02-02 20:27:21,439 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(476)) - Creating Volume: vol1, with user90587 as owner and space quota set to -1 bytes, counts quota set to -1
2023-02-02 20:27:21,449 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-02 20:27:21,449 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-02 20:27:21,450 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 7bbfb910-8baa-49a4-be56-632f95348a2c: close
2023-02-02 20:27:21,451 [7bbfb910-8baa-49a4-be56-632f95348a2c-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9: shutdown
2023-02-02 20:27:21,451 [7bbfb910-8baa-49a4-be56-632f95348a2c-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-77EF11360BF9,id=7bbfb910-8baa-49a4-be56-632f95348a2c
2023-02-02 20:27:21,451 [7bbfb910-8baa-49a4-be56-632f95348a2c-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 7bbfb910-8baa-49a4-be56-632f95348a2c: shutdown 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9-LeaderStateImpl
2023-02-02 20:27:21,460 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - da4028ad-c56f-4745-a3af-e0a942311a6d: close
2023-02-02 20:27:21,463 [da4028ad-c56f-4745-a3af-e0a942311a6d-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-D9FCBBBAF01D: shutdown
2023-02-02 20:27:21,463 [da4028ad-c56f-4745-a3af-e0a942311a6d-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D9FCBBBAF01D,id=da4028ad-c56f-4745-a3af-e0a942311a6d
2023-02-02 20:27:21,463 [da4028ad-c56f-4745-a3af-e0a942311a6d-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - da4028ad-c56f-4745-a3af-e0a942311a6d: shutdown da4028ad-c56f-4745-a3af-e0a942311a6d@group-D9FCBBBAF01D-LeaderStateImpl
2023-02-02 20:27:21,463 [da4028ad-c56f-4745-a3af-e0a942311a6d-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-D9FCBBBAF01D-PendingRequests: sendNotLeaderResponses
2023-02-02 20:27:21,464 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - da4028ad-c56f-4745-a3af-e0a942311a6d: shutdown server GrpcServerProtocolService now
2023-02-02 20:27:21,464 [da4028ad-c56f-4745-a3af-e0a942311a6d-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-DC0F517ADBCA: shutdown
2023-02-02 20:27:21,465 [da4028ad-c56f-4745-a3af-e0a942311a6d-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DC0F517ADBCA,id=da4028ad-c56f-4745-a3af-e0a942311a6d
2023-02-02 20:27:21,465 [da4028ad-c56f-4745-a3af-e0a942311a6d-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - da4028ad-c56f-4745-a3af-e0a942311a6d: shutdown da4028ad-c56f-4745-a3af-e0a942311a6d@group-DC0F517ADBCA-FollowerState
2023-02-02 20:27:21,465 [da4028ad-c56f-4745-a3af-e0a942311a6d@group-DC0F517ADBCA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-DC0F517ADBCA-FollowerState was interrupted
2023-02-02 20:27:21,465 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 7d267433-c231-4e32-bff5-417fca1e0c0a Close channels
2023-02-02 20:27:21,466 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253 Close channels
2023-02-02 20:27:21,466 [da4028ad-c56f-4745-a3af-e0a942311a6d@group-DC0F517ADBCA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-DC0F517ADBCA: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-1/data/ratis/df29b2fb-f8d3-453e-beed-dc0f517adbca/sm/snapshot.1_0
2023-02-02 20:27:21,466 [da4028ad-c56f-4745-a3af-e0a942311a6d-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-DC0F517ADBCA-StateMachineUpdater: set stopIndex = 0
2023-02-02 20:27:21,480 [da4028ad-c56f-4745-a3af-e0a942311a6d@group-D9FCBBBAF01D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-D9FCBBBAF01D: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-1/data/ratis/d98a9ae9-8b06-4231-879a-d9fcbbbaf01d/sm/snapshot.1_0
2023-02-02 20:27:21,481 [da4028ad-c56f-4745-a3af-e0a942311a6d@group-DC0F517ADBCA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-DC0F517ADBCA: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-1/data/ratis/df29b2fb-f8d3-453e-beed-dc0f517adbca/sm/snapshot.1_0 took: 15 ms
2023-02-02 20:27:21,481 [da4028ad-c56f-4745-a3af-e0a942311a6d@group-DC0F517ADBCA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-DC0F517ADBCA-StateMachineUpdater: Took a snapshot at index 0
2023-02-02 20:27:21,481 [da4028ad-c56f-4745-a3af-e0a942311a6d@group-DC0F517ADBCA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-DC0F517ADBCA-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-02 20:27:21,481 [da4028ad-c56f-4745-a3af-e0a942311a6d-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-DC0F517ADBCA: closes. applyIndex: 0
2023-02-02 20:27:21,480 [grpc-default-executor-16] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04: Completed APPEND_ENTRIES, lastRequest: 7bbfb910-8baa-49a4-be56-632f95348a2c->7b77c47d-ca18-4352-ae6d-9be789fa6a04#166-t6,previous=(t:6, i:39),leaderCommit=38,initializing? true,entries: size=1, first=(t:6, i:40), METADATAENTRY(c:38)
2023-02-02 20:27:21,480 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - da4028ad-c56f-4745-a3af-e0a942311a6d: shutdown server GrpcServerProtocolService successfully
2023-02-02 20:27:21,479 [7bbfb910-8baa-49a4-be56-632f95348a2c-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9-PendingRequests: sendNotLeaderResponses
2023-02-02 20:27:21,479 [da4028ad-c56f-4745-a3af-e0a942311a6d-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-D9FCBBBAF01D-StateMachineUpdater: set stopIndex = 0
2023-02-02 20:27:21,484 [da4028ad-c56f-4745-a3af-e0a942311a6d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf54a53f8, L:/0:0:0:0:0:0:0:0:43583] CLOSE
2023-02-02 20:27:21,484 [da4028ad-c56f-4745-a3af-e0a942311a6d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf54a53f8, L:/0:0:0:0:0:0:0:0:43583] INACTIVE
2023-02-02 20:27:21,484 [da4028ad-c56f-4745-a3af-e0a942311a6d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf54a53f8, L:/0:0:0:0:0:0:0:0:43583] UNREGISTERED
2023-02-02 20:27:21,484 [grpc-default-executor-17] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - da4028ad-c56f-4745-a3af-e0a942311a6d: installSnapshot onError, lastRequest: f1da6dec-c089-423e-bed5-bf505eacaf1a->da4028ad-c56f-4745-a3af-e0a942311a6d#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "7d267433-c231-4e32-bff5-417fca1e0c0a"
address: "10.1.1.71:43573"
dataStreamAddress: "10.1.1.71:38557"
clientAddress: "10.1.1.71:43573"
adminAddress: "10.1.1.71:43573"
startupRole: FOLLOWER
,id: "f1da6dec-c089-423e-bed5-bf505eacaf1a"
address: "10.1.1.71:32971"
priority: 1
dataStreamAddress: "10.1.1.71:45749"
clientAddress: "10.1.1.71:32971"
adminAddress: "10.1.1.71:32971"
startupRole: FOLLOWER
,id: "da4028ad-c56f-4745-a3af-e0a942311a6d"
address: "10.1.1.71:42641"
dataStreamAddress: "10.1.1.71:43583"
clientAddress: "10.1.1.71:42641"
adminAddress: "10.1.1.71:42641"
startupRole: FOLLOWER
, old:): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-02 20:27:21,485 [grpc-default-executor-18] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04: Completed APPEND_ENTRIES, lastRequest: null
2023-02-02 20:27:21,479 [grpc-default-executor-15] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-7886813F0073->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender is already stopped
2023-02-02 20:27:21,478 [grpc-default-executor-14] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-7886813F0073->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender is already stopped
2023-02-02 20:27:21,478 [grpc-default-executor-12] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-7886813F0073->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender is already stopped
2023-02-02 20:27:21,478 [grpc-default-executor-13] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-7886813F0073->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender is already stopped
2023-02-02 20:27:21,476 [grpc-default-executor-11] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - da4028ad-c56f-4745-a3af-e0a942311a6d: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-02 20:27:21,473 [grpc-default-executor-10] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-7886813F0073->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender is already stopped
2023-02-02 20:27:21,472 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - da4028ad-c56f-4745-a3af-e0a942311a6d: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-02 20:27:21,471 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-02-02 20:27:21,505 [grpc-default-executor-8] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=557, lastRpcResponseTime=557) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:21,471 [grpc-default-executor-9] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - da4028ad-c56f-4745-a3af-e0a942311a6d: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-02 20:27:21,470 [grpc-default-executor-3] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - da4028ad-c56f-4745-a3af-e0a942311a6d: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-02 20:27:21,470 [grpc-default-executor-4] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - da4028ad-c56f-4745-a3af-e0a942311a6d: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-02 20:27:21,470 [7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9->494051a8-4feb-4706-b0a6-36852ae3dccb-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9->494051a8-4feb-4706-b0a6-36852ae3dccb-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-02-02 20:27:21,470 [grpc-default-executor-6] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - da4028ad-c56f-4745-a3af-e0a942311a6d: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-02 20:27:21,470 [7bbfb910-8baa-49a4-be56-632f95348a2c-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-BF581EDFB67C: shutdown
2023-02-02 20:27:21,506 [7bbfb910-8baa-49a4-be56-632f95348a2c-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-BF581EDFB67C,id=7bbfb910-8baa-49a4-be56-632f95348a2c
2023-02-02 20:27:21,506 [7bbfb910-8baa-49a4-be56-632f95348a2c-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 7bbfb910-8baa-49a4-be56-632f95348a2c: shutdown 7bbfb910-8baa-49a4-be56-632f95348a2c@group-BF581EDFB67C-LeaderStateImpl
2023-02-02 20:27:21,507 [7bbfb910-8baa-49a4-be56-632f95348a2c-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-BF581EDFB67C-PendingRequests: sendNotLeaderResponses
2023-02-02 20:27:21,507 [7bbfb910-8baa-49a4-be56-632f95348a2c-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-BF581EDFB67C-StateMachineUpdater: set stopIndex = 0
2023-02-02 20:27:21,470 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 7bbfb910-8baa-49a4-be56-632f95348a2c: shutdown server GrpcServerProtocolService now
2023-02-02 20:27:21,507 [7bbfb910-8baa-49a4-be56-632f95348a2c@group-BF581EDFB67C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-BF581EDFB67C: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-4/data/ratis/3372c4c6-b090-466d-8fa6-bf581edfb67c/sm/snapshot.1_0
2023-02-02 20:27:21,469 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(195)) - created volume:vol1 for user:user90587
2023-02-02 20:27:21,506 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 494051a8-4feb-4706-b0a6-36852ae3dccb: Completed APPEND_ENTRIES, lastRequest: 7bbfb910-8baa-49a4-be56-632f95348a2c->494051a8-4feb-4706-b0a6-36852ae3dccb#176-t6,previous=(t:6, i:39),leaderCommit=38,initializing? true,entries: size=1, first=(t:6, i:40), METADATAENTRY(c:38)
2023-02-02 20:27:21,508 [7bbfb910-8baa-49a4-be56-632f95348a2c@group-BF581EDFB67C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-BF581EDFB67C: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-4/data/ratis/3372c4c6-b090-466d-8fa6-bf581edfb67c/sm/snapshot.1_0 took: 1 ms
2023-02-02 20:27:21,508 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9->494051a8-4feb-4706-b0a6-36852ae3dccb-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-02 20:27:21,508 [7bbfb910-8baa-49a4-be56-632f95348a2c@group-BF581EDFB67C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-BF581EDFB67C-StateMachineUpdater: Took a snapshot at index 0
2023-02-02 20:27:21,508 [7bbfb910-8baa-49a4-be56-632f95348a2c@group-BF581EDFB67C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-BF581EDFB67C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-02 20:27:21,509 [7bbfb910-8baa-49a4-be56-632f95348a2c-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-BF581EDFB67C: closes. applyIndex: 0
2023-02-02 20:27:21,501 [grpc-default-executor-19] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-02-02 20:27:21,501 [grpc-default-executor-17] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9->7b77c47d-ca18-4352-ae6d-9be789fa6a04-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-02 20:27:21,500 [da4028ad-c56f-4745-a3af-e0a942311a6d@group-DC0F517ADBCA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-DC0F517ADBCA-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:21,509 [grpc-default-executor-17] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9->7b77c47d-ca18-4352-ae6d-9be789fa6a04: nextIndex: updateUnconditionally 41 -> 40
2023-02-02 20:27:21,509 [grpc-default-executor-19] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=561, lastRpcResponseTime=561) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:21,481 [da4028ad-c56f-4745-a3af-e0a942311a6d@group-D9FCBBBAF01D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-D9FCBBBAF01D: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-1/data/ratis/d98a9ae9-8b06-4231-879a-d9fcbbbaf01d/sm/snapshot.1_0 took: 0 ms
2023-02-02 20:27:21,509 [da4028ad-c56f-4745-a3af-e0a942311a6d@group-D9FCBBBAF01D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-D9FCBBBAF01D-StateMachineUpdater: Took a snapshot at index 0
2023-02-02 20:27:21,509 [da4028ad-c56f-4745-a3af-e0a942311a6d@group-D9FCBBBAF01D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-D9FCBBBAF01D-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-02 20:27:21,510 [da4028ad-c56f-4745-a3af-e0a942311a6d-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-D9FCBBBAF01D: closes. applyIndex: 0
2023-02-02 20:27:21,509 [da4028ad-c56f-4745-a3af-e0a942311a6d-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-DC0F517ADBCA-SegmentedRaftLogWorker close()
2023-02-02 20:27:21,508 [grpc-default-executor-4] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9->494051a8-4feb-4706-b0a6-36852ae3dccb: nextIndex: updateUnconditionally 41 -> 40
2023-02-02 20:27:21,515 [grpc-default-executor-18] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9->7b77c47d-ca18-4352-ae6d-9be789fa6a04-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-02 20:27:21,515 [grpc-default-executor-18] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9->7b77c47d-ca18-4352-ae6d-9be789fa6a04: nextIndex: updateUnconditionally 40 -> 39
2023-02-02 20:27:21,515 [grpc-default-executor-6] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-02 20:27:21,516 [da4028ad-c56f-4745-a3af-e0a942311a6d@group-D9FCBBBAF01D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-D9FCBBBAF01D-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:21,516 [7bbfb910-8baa-49a4-be56-632f95348a2c@group-BF581EDFB67C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-BF581EDFB67C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:21,531 [grpc-default-executor-19] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-02 20:27:21,531 [grpc-default-executor-18] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 494051a8-4feb-4706-b0a6-36852ae3dccb: Completed APPEND_ENTRIES, lastRequest: null
2023-02-02 20:27:21,532 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 494051a8-4feb-4706-b0a6-36852ae3dccb Close channels
2023-02-02 20:27:21,532 [7bbfb910-8baa-49a4-be56-632f95348a2c-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-BF581EDFB67C-SegmentedRaftLogWorker close()
2023-02-02 20:27:21,533 [da4028ad-c56f-4745-a3af-e0a942311a6d-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - da4028ad-c56f-4745-a3af-e0a942311a6d@group-D9FCBBBAF01D-SegmentedRaftLogWorker close()
2023-02-02 20:27:21,533 [grpc-default-executor-19] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9->494051a8-4feb-4706-b0a6-36852ae3dccb-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-02 20:27:21,533 [grpc-default-executor-19] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(137)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9->494051a8-4feb-4706-b0a6-36852ae3dccb-GrpcLogAppender: Failed to getClient for 494051a8-4feb-4706-b0a6-36852ae3dccb
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 7bbfb910-8baa-49a4-be56-632f95348a2c is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:116)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:121)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:58)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:416)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:468)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:432)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:465)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-02 20:27:21,549 [JvmPauseMonitor27] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-da4028ad-c56f-4745-a3af-e0a942311a6d: Stopped
2023-02-02 20:27:21,549 [7bbfb910-8baa-49a4-be56-632f95348a2c-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9-StateMachineUpdater: set stopIndex = 40
2023-02-02 20:27:21,549 [7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-77EF11360BF9: Taking a snapshot at:(t:6, i:40) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-4/data/ratis/af13c673-fc55-4c7f-bf3e-77ef11360bf9/sm/snapshot.6_40
2023-02-02 20:27:21,555 [7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-77EF11360BF9: Finished taking a snapshot at:(t:6, i:40) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-4/data/ratis/af13c673-fc55-4c7f-bf3e-77ef11360bf9/sm/snapshot.6_40 took: 6 ms
2023-02-02 20:27:21,555 [7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9-StateMachineUpdater: Took a snapshot at index 40
2023-02-02 20:27:21,555 [7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 40
2023-02-02 20:27:21,556 [Listener at 127.0.0.1/40643] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-02-02 20:27:21,556 [Listener at 127.0.0.1/40643] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-02-02 20:27:21,557 [7bbfb910-8baa-49a4-be56-632f95348a2c-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9: closes. applyIndex: 40
2023-02-02 20:27:21,557 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04 Close channels
2023-02-02 20:27:21,558 [7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:21,559 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 7bbfb910-8baa-49a4-be56-632f95348a2c: shutdown server GrpcServerProtocolService successfully
2023-02-02 20:27:21,560 [7bbfb910-8baa-49a4-be56-632f95348a2c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x854b3565, L:/0:0:0:0:0:0:0:0:34999] CLOSE
2023-02-02 20:27:21,560 [7bbfb910-8baa-49a4-be56-632f95348a2c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x854b3565, L:/0:0:0:0:0:0:0:0:34999] INACTIVE
2023-02-02 20:27:21,560 [7bbfb910-8baa-49a4-be56-632f95348a2c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x854b3565, L:/0:0:0:0:0:0:0:0:34999] UNREGISTERED
2023-02-02 20:27:21,561 [Listener at 127.0.0.1/40643] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-02 20:27:21,564 [7bbfb910-8baa-49a4-be56-632f95348a2c-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 7bbfb910-8baa-49a4-be56-632f95348a2c@group-77EF11360BF9-SegmentedRaftLogWorker close()
2023-02-02 20:27:21,608 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(695)) - Creating Bucket: vol1/bucket1, with bucket layout LEGACY, runner as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
2023-02-02 20:27:21,609 [JvmPauseMonitor30] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-7bbfb910-8baa-49a4-be56-632f95348a2c: Stopped
2023-02-02 20:27:21,613 [OM StateMachine ApplyTransaction Thread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(263)) - created bucket: bucket1 of layout LEGACY in volume: vol1
2023-02-02 20:27:21,629 [IPC Server handler 0 on default port 37773] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(128)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2023-02-02 20:27:21,630 [IPC Server handler 0 on default port 37773] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(237)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 111677748019200000.
2023-02-02 20:27:21,630 [IPC Server handler 0 on default port 37773] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(128)) - Allocate a batch for localId, change lastId from 111677748019200000 to 111677748019201000.
2023-02-02 20:27:21,668 [Listener at 127.0.0.1/40643] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 106 ms to scan 7 urls, producing 150 keys and 361 values 
2023-02-02 20:27:21,715 [Listener at 127.0.0.1/40643] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(349)) - upgrade localId to 111677748019200000
2023-02-02 20:27:21,715 [Listener at 127.0.0.1/40643] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(359)) - upgrade delTxnId to 0
2023-02-02 20:27:21,716 [Listener at 127.0.0.1/40643] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(376)) - upgrade containerId to 0
2023-02-02 20:27:21,716 [Listener at 127.0.0.1/40643] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-02-02 20:27:21,737 [Listener at 127.0.0.1/40643] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(149)) - Entering startup safe mode.
2023-02-02 20:27:21,737 [Listener at 127.0.0.1/40643] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-02-02 20:27:21,738 [Listener at 127.0.0.1/40643] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-02-02 20:27:21,738 [Listener at 127.0.0.1/40643] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2023-02-02 20:27:21,738 [Listener at 127.0.0.1/40643] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-02-02 20:27:21,738 [Listener at 127.0.0.1/40643] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-02-02 20:27:21,738 [Listener at 127.0.0.1/40643] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-02-02 20:27:21,738 [Listener at 127.0.0.1/40643] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-02-02 20:27:21,739 [Listener at 127.0.0.1/40643] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-02-02 20:27:21,739 [Listener at 127.0.0.1/40643] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-02-02 20:27:21,739 [Listener at 127.0.0.1/40643] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-02-02 20:27:21,741 [Listener at 127.0.0.1/40643] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-02-02 20:27:21,741 [Listener at 127.0.0.1/40643] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-02-02 20:27:21,742 [Listener at 127.0.0.1/40643] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-02-02 20:27:21,742 [Listener at 127.0.0.1/40643] INFO  replication.ReplicationManager (ReplicationManager.java:start(263)) - Starting Replication Monitor Thread.
2023-02-02 20:27:21,749 [Listener at 127.0.0.1/40643] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-02-02 20:27:21,750 [Listener at 127.0.0.1/40643] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 0
2023-02-02 20:27:21,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:21,767 [Listener at 127.0.0.1/40643] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2023-02-02 20:27:21,767 [Listener at 127.0.0.1/40643] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-02-02 20:27:21,769 [Listener at 127.0.0.1/40643] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-02 20:27:21,773 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-02-02 20:27:21,776 [Listener at 0.0.0.0/41201] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-02 20:27:21,783 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-02-02 20:27:21,788 [Listener at 0.0.0.0/34811] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-02 20:27:21,795 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-02-02 20:27:21,807 [Listener at 0.0.0.0/45947] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-02-02 20:27:21,807 [Listener at 0.0.0.0/45947] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(401)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-02-02 20:27:21,808 [Listener at 0.0.0.0/45947] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-02-02 20:27:21,808 [Listener at 0.0.0.0/45947] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1440)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:45947
2023-02-02 20:27:21,808 [Listener at 0.0.0.0/45947] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2023-02-02 20:27:21,862 [Listener at 0.0.0.0/45947] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(170)) - RPC server for Client  is listening at /0.0.0.0:45947
2023-02-02 20:27:21,876 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-02 20:27:21,911 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-02-02 20:27:21,925 [Listener at 0.0.0.0/45947] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1454)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:34811
2023-02-02 20:27:21,925 [Listener at 0.0.0.0/45947] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:34811
2023-02-02 20:27:21,925 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-02 20:27:21,926 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-02-02 20:27:21,927 [Listener at 0.0.0.0/45947] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:41201
2023-02-02 20:27:21,927 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-02 20:27:21,928 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-02-02 20:27:21,930 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@218c5b61] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-02 20:27:21,931 [Listener at 0.0.0.0/45947] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for scm at: http://0.0.0.0:0
2023-02-02 20:27:21,931 [Listener at 0.0.0.0/45947] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-02 20:27:21,932 [Listener at 0.0.0.0/45947] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-02 20:27:21,933 [Listener at 0.0.0.0/45947] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-02 20:27:21,934 [Listener at 0.0.0.0/45947] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-02 20:27:21,949 [Listener at 0.0.0.0/45947] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-02-02 20:27:21,949 [Listener at 0.0.0.0/45947] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-02 20:27:21,949 [Listener at 0.0.0.0/45947] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-02 20:27:21,950 [Listener at 0.0.0.0/45947] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 33261
2023-02-02 20:27:21,958 [Listener at 0.0.0.0/45947] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-02 20:27:21,980 [Listener at 0.0.0.0/45947] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-02 20:27:21,981 [Listener at 0.0.0.0/45947] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-02 20:27:21,981 [Listener at 0.0.0.0/45947] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-02-02 20:27:21,981 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:22,018 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:22,015 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:21,981 [Listener at 0.0.0.0/45947] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@23434165{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-02 20:27:22,019 [Listener at 0.0.0.0/45947] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2b738a39{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-02-02 20:27:21,981 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:22,029 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 15 milliseconds for processing 3 containers.
2023-02-02 20:27:22,038 [Listener at 0.0.0.0/45947] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@45349f3{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-02-02 20:27:22,033 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedHealthy(1181)) - Container #1 is over replicated. Expected replica count is 3, but found 4.
2023-02-02 20:27:22,041 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1513)) - Sending delete container command for container #1 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:22,042 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedHealthy(1181)) - Container #3 is over replicated. Expected replica count is 3, but found 4.
2023-02-02 20:27:22,042 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1513)) - Sending delete container command for container #3 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:22,042 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedHealthy(1181)) - Container #4 is over replicated. Expected replica count is 3, but found 4.
2023-02-02 20:27:22,042 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1513)) - Sending delete container command for container #4 to datanode 541b5aca-8ce5-47d9-adc3-7e41c6e3e253(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:22,042 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 9 milliseconds for processing 11 containers.
2023-02-02 20:27:22,030 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:22,029 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:22,029 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:22,070 [Listener at 0.0.0.0/45947] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@20247330{HTTP/1.1, (http/1.1)}{0.0.0.0:33261}
2023-02-02 20:27:22,070 [Listener at 0.0.0.0/45947] INFO  server.Server (Server.java:doStart(415)) - Started @186580ms
2023-02-02 20:27:22,070 [Listener at 0.0.0.0/45947] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-02 20:27:22,071 [Listener at 0.0.0.0/45947] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of scm listening at http://0.0.0.0:33261
2023-02-02 20:27:22,071 [Listener at 0.0.0.0/45947] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-02 20:27:22,074 [Listener at 0.0.0.0/45947] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2023-02-02 20:27:22,074 [Listener at 0.0.0.0/45947] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2023-02-02 20:27:22,074 [Listener at 0.0.0.0/45947] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2023-02-02 20:27:22,074 [Listener at 0.0.0.0/45947] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2023-02-02 20:27:22,074 [Listener at 0.0.0.0/45947] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-02 20:27:22,077 [Listener at 0.0.0.0/45947] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
2023-02-02 20:27:22,349 [Listener at 0.0.0.0/45947] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 264 ms to scan 2 urls, producing 157 keys and 445 values [using 2 cores]
2023-02-02 20:27:22,350 [Listener at 0.0.0.0/45947] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2023-02-02 20:27:22,350 [Listener at 0.0.0.0/45947] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-02 20:27:22,350 [Listener at 0.0.0.0/45947] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:34811]
2023-02-02 20:27:22,351 [Listener at 0.0.0.0/45947] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:34811]
2023-02-02 20:27:22,368 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253: addNew group-29A66540D36B:[541b5aca-8ce5-47d9-adc3-7e41c6e3e253|rpc:10.1.1.71:39627|dataStream:10.1.1.71:46073|priority:1|startupRole:FOLLOWER] returns group-29A66540D36B:java.util.concurrent.CompletableFuture@6e2a6d55[Not completed]
2023-02-02 20:27:22,369 [pool-2311-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253: new RaftServerImpl for group-29A66540D36B:[541b5aca-8ce5-47d9-adc3-7e41c6e3e253|rpc:10.1.1.71:39627|dataStream:10.1.1.71:46073|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:22,369 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:22,369 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:22,369 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:22,369 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:22,369 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:22,370 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:22,370 [pool-2311-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B: ConfigurationManager, init=-1: peers:[541b5aca-8ce5-47d9-adc3-7e41c6e3e253|rpc:10.1.1.71:39627|dataStream:10.1.1.71:46073|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:22,370 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-0/data/ratis] (custom)
2023-02-02 20:27:22,370 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:22,370 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:22,370 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:22,370 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:22,370 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:22,371 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:22,371 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:22,371 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:22,371 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:22,372 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:22,372 [pool-2311-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-0/data/ratis/439db6e8-c3e9-465a-9f3a-29a66540d36b does not exist. Creating ...
2023-02-02 20:27:22,373 [pool-2311-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-0/data/ratis/439db6e8-c3e9-465a-9f3a-29a66540d36b/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:22,373 [pool-2311-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-0/data/ratis/439db6e8-c3e9-465a-9f3a-29a66540d36b has been successfully formatted.
2023-02-02 20:27:22,391 [Listener at 0.0.0.0/45947] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-02 20:27:22,391 [Listener at 0.0.0.0/45947] INFO  codec.OmKeyInfoCodec (OmKeyInfoCodec.java:<init>(49)) - OmKeyInfoCodec ignorePipeline = true
2023-02-02 20:27:22,391 [Listener at 0.0.0.0/45947] INFO  codec.RepeatedOmKeyInfoCodec (RepeatedOmKeyInfoCodec.java:<init>(41)) - RepeatedOmKeyInfoCodec ignorePipeline = true
2023-02-02 20:27:22,393 [pool-2311-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-29A66540D36B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:22,393 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:22,393 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:22,394 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:22,394 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:22,394 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:22,394 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:22,396 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 439db6e8-c3e9-465a-9f3a-29a66540d36b, Nodes: 541b5aca-8ce5-47d9-adc3-7e41c6e3e253(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:541b5aca-8ce5-47d9-adc3-7e41c6e3e253, CreationTimestamp2023-02-02T20:27:19.460Z[Etc/UTC]] moved to OPEN state
2023-02-02 20:27:22,398 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:22,402 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:22,402 [pool-2311-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-0/data/ratis/439db6e8-c3e9-465a-9f3a-29a66540d36b
2023-02-02 20:27:22,402 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:22,402 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:22,402 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:22,402 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:22,402 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:22,402 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:22,402 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:22,402 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:22,412 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:22,412 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:22,424 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:22,424 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:22,424 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:22,436 [pool-2311-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:22,436 [pool-2311-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:22,438 [pool-2311-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B: start as a follower, conf=-1: peers:[541b5aca-8ce5-47d9-adc3-7e41c6e3e253|rpc:10.1.1.71:39627|dataStream:10.1.1.71:46073|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:22,438 [pool-2311-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:22,438 [pool-2311-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253: start 541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B-FollowerState
2023-02-02 20:27:22,438 [pool-2311-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-29A66540D36B,id=541b5aca-8ce5-47d9-adc3-7e41c6e3e253
2023-02-02 20:27:22,438 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:22,438 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:22,438 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:22,438 [pool-2311-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:22,439 [541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:22,439 [541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:22,439 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=439db6e8-c3e9-465a-9f3a-29a66540d36b
2023-02-02 20:27:22,439 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=439db6e8-c3e9-465a-9f3a-29a66540d36b.
2023-02-02 20:27:22,763 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:22,969 [Listener at 0.0.0.0/45947] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(721)) - S3 Multi-Tenancy is disabled
2023-02-02 20:27:22,972 [Listener at 0.0.0.0/45947] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4063)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2023-02-02 20:27:22,972 [Listener at 0.0.0.0/45947] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-02-02 20:27:22,972 [Listener at 0.0.0.0/45947] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(436)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2023-02-02 20:27:22,973 [Listener at 0.0.0.0/45947] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-02 20:27:22,973 [Listener at 0.0.0.0/45947] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-02 20:27:22,973 [Listener at 0.0.0.0/45947] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-02-02 20:27:22,978 [Listener at 0.0.0.0/45947] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(160)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:44963
2023-02-02 20:27:22,978 [Listener at 0.0.0.0/45947] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(636)) - LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
2023-02-02 20:27:22,992 [Listener at 0.0.0.0/45947] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-02 20:27:22,992 [Listener at 0.0.0.0/45947] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:22,992 [Listener at 0.0.0.0/45947] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 44963 (fallback to raft.grpc.server.port)
2023-02-02 20:27:22,992 [Listener at 0.0.0.0/45947] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:22,992 [Listener at 0.0.0.0/45947] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 44963 (fallback to raft.grpc.server.port)
2023-02-02 20:27:22,992 [Listener at 0.0.0.0/45947] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-02 20:27:22,992 [Listener at 0.0.0.0/45947] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 44963 (custom)
2023-02-02 20:27:22,992 [Listener at 0.0.0.0/45947] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 33554432 (custom)
2023-02-02 20:27:22,992 [Listener at 0.0.0.0/45947] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:22,993 [Listener at 0.0.0.0/45947] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-02-02 20:27:22,993 [Listener at 0.0.0.0/45947] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2023-02-02 20:27:22,993 [Listener at 0.0.0.0/45947] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-02 20:27:22,993 [Listener at 0.0.0.0/45947] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-02 20:27:22,993 [Listener at 0.0.0.0/45947] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-02 20:27:22,995 [Listener at 0.0.0.0/45947] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2023-02-02 20:27:22,995 [Listener at 0.0.0.0/45947] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-02 20:27:22,995 [Listener at 0.0.0.0/45947] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-02 20:27:22,995 [Listener at 0.0.0.0/45947] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-02-02 20:27:22,995 [Listener at 0.0.0.0/45947] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:22,995 [Listener at 0.0.0.0/45947] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/ozone-meta/ratis] (custom)
2023-02-02 20:27:23,009 [Listener at 0.0.0.0/45947] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - om1: addNew group-C5BA1605619E:[om1|rpc:localhost:44963|priority:0|startupRole:FOLLOWER] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@3739e64f[Not completed]
2023-02-02 20:27:23,010 [Listener at 0.0.0.0/45947] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2038)) - OzoneManager Ratis server initialized at port 44963
2023-02-02 20:27:23,010 [Listener at 0.0.0.0/45947] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1101)) - Creating RPC Server
2023-02-02 20:27:23,017 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:23,018 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:23,018 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:23,022 [pool-2459-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:localhost:44963|priority:0|startupRole:FOLLOWER] with OzoneManagerStateMachine:uninitialized
2023-02-02 20:27:23,023 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2023-02-02 20:27:23,023 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2023-02-02 20:27:23,023 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:23,023 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-02-02 20:27:23,023 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:23,023 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:23,023 [pool-2459-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|rpc:localhost:44963|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:23,023 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/ozone-meta/ratis] (custom)
2023-02-02 20:27:23,023 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:23,023 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:23,023 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2023-02-02 20:27:23,023 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2023-02-02 20:27:23,023 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:23,039 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:23,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-02-02 20:27:23,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:23,043 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:23,043 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(431)) - Sending command [deleteContainerCommand: containerID: 7, replicaIndex: 4, force: true] for container ContainerInfo{id=#7, state=CLOSED, pipelineID=PipelineID=8e6df713-851d-4693-bf7e-016b5e5b1fe3, stateEnterTime=2023-02-02T20:26:44.071Z, owner=om1} to 7d267433-c231-4e32-bff5-417fca1e0c0a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:23,043 [Over Replicated Processor] INFO  replication.ECOverReplicationHandler (ECOverReplicationHandler.java:processAndCreateCommands(111)) - The container 7 with replicas [ContainerReplica{containerID=#7, state=CLOSED, datanodeDetails=f1da6dec-c089-423e-bed5-bf505eacaf1a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), placeOfBirth=f1da6dec-c089-423e-bed5-bf505eacaf1a, sequenceId=0, keyCount=3, bytesUsed=57,replicaIndex=1}, ContainerReplica{containerID=#7, state=CLOSED, datanodeDetails=7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), placeOfBirth=7bbfb910-8baa-49a4-be56-632f95348a2c, sequenceId=0, keyCount=3, bytesUsed=0,replicaIndex=3}, ContainerReplica{containerID=#7, state=CLOSED, datanodeDetails=494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), placeOfBirth=494051a8-4feb-4706-b0a6-36852ae3dccb, sequenceId=0, keyCount=3, bytesUsed=57,replicaIndex=5}, ContainerReplica{containerID=#7, state=CLOSED, datanodeDetails=7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), placeOfBirth=7b77c47d-ca18-4352-ae6d-9be789fa6a04, sequenceId=0, keyCount=3, bytesUsed=0,replicaIndex=2}, ContainerReplica{containerID=#7, state=CLOSED, datanodeDetails=7d267433-c231-4e32-bff5-417fca1e0c0a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), placeOfBirth=7d267433-c231-4e32-bff5-417fca1e0c0a, sequenceId=0, keyCount=3, bytesUsed=57,replicaIndex=4}, ContainerReplica{containerID=#7, state=CLOSED, datanodeDetails=541b5aca-8ce5-47d9-adc3-7e41c6e3e253(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), placeOfBirth=541b5aca-8ce5-47d9-adc3-7e41c6e3e253, sequenceId=0, keyCount=3, bytesUsed=57,replicaIndex=4}] will be corrected by the pending delete
2023-02-02 20:27:23,044 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(431)) - Sending command [deleteContainerCommand: containerID: 8, replicaIndex: 1, force: true] for container ContainerInfo{id=#8, state=CLOSED, pipelineID=PipelineID=299844dc-13b5-44d6-a7e3-ac2d5dfd4aa0, stateEnterTime=2023-02-02T20:26:44.318Z, owner=om1} to 541b5aca-8ce5-47d9-adc3-7e41c6e3e253(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:23,044 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(431)) - Sending command [deleteContainerCommand: containerID: 9, replicaIndex: 2, force: true] for container ContainerInfo{id=#9, state=CLOSED, pipelineID=PipelineID=89c63025-2581-4fd3-b60a-0763d302cec9, stateEnterTime=2023-02-02T20:26:44.509Z, owner=om1} to 7d267433-c231-4e32-bff5-417fca1e0c0a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:23,044 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(431)) - Sending command [deleteContainerCommand: containerID: 10, replicaIndex: 4, force: true] for container ContainerInfo{id=#10, state=CLOSED, pipelineID=PipelineID=3dd5db31-98dd-4ad6-9a0d-f4a0ef71c3c6, stateEnterTime=2023-02-02T20:26:44.669Z, owner=om1} to 7d267433-c231-4e32-bff5-417fca1e0c0a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:23,044 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(431)) - Sending command [deleteContainerCommand: containerID: 11, replicaIndex: 4, force: true] for container ContainerInfo{id=#11, state=CLOSED, pipelineID=PipelineID=1d89e471-cf33-4642-ba8b-8a5e4c494a81, stateEnterTime=2023-02-02T20:26:45.212Z, owner=om1} to 7d267433-c231-4e32-bff5-417fca1e0c0a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:23,044 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 6 containers with health state counts {OVER_REPLICATED=6},failed processing 0
2023-02-02 20:27:23,047 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:23,047 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:23,047 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:23,048 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:23,048 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:23,052 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 13 milliseconds for processing 6 containers.
2023-02-02 20:27:23,074 [IPC Server handler 15 on default port 35129] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(366)) - Starting Maintenance for node 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:23,074 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) moved to HEALTHY state.
2023-02-02 20:27:23,074 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:23,075 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-02-02 20:27:23,450 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:23,451 [grpc-default-executor-19] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:23,452 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=2504, lastRpcResponseTime=2503) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:23,453 [grpc-default-executor-19] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=2505, lastRpcResponseTime=2505) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:23,457 [grpc-default-executor-19] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:23,457 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:23,457 [grpc-default-executor-19] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=2509, lastRpcResponseTime=2509) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:23,458 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=2510, lastRpcResponseTime=2509) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:23,458 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:23,458 [grpc-default-executor-19] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:23,459 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=2511, lastRpcResponseTime=2510) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:23,460 [grpc-default-executor-19] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=2512, lastRpcResponseTime=2511) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:23,461 [grpc-default-executor-19] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:23,461 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:23,461 [grpc-default-executor-19] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=2513, lastRpcResponseTime=2513) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:23,461 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=2513, lastRpcResponseTime=2513) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:23,466 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:23,466 [grpc-default-executor-19] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:23,466 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=2518, lastRpcResponseTime=2518) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:23,467 [grpc-default-executor-19] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=2519, lastRpcResponseTime=2519) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:23,468 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:23,469 [grpc-default-executor-8] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1, lastRpcResponseTime=2521) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:23,469 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:23,469 [grpc-default-executor-8] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1, lastRpcResponseTime=2521) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:23,615 [Listener at 0.0.0.0/45947] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 603 ms to scan 19 urls, producing 67 keys and 4730 values [using 2 cores]
2023-02-02 20:27:23,617 [Listener at 0.0.0.0/45947] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-02 20:27:23,623 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-02-02 20:27:23,637 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-1/data-0/containers/hdds/a7118d63-fcc7-4683-8210-e0c36487c2ca/DS-01439f44-1f54-4245-9005-d311d862e29f/container.db for volume DS-01439f44-1f54-4245-9005-d311d862e29f
2023-02-02 20:27:23,637 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-02 20:27:23,641 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-02 20:27:23,642 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-02 20:27:23,656 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@73b51bf7{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-02 20:27:23,657 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@79a9c99c{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-02 20:27:23,657 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-02 20:27:23,667 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@f995b85{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-02 20:27:23,670 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@50927652{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-02 20:27:23,685 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-02 20:27:23,688 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 7d267433-c231-4e32-bff5-417fca1e0c0a: close
2023-02-02 20:27:23,689 [7d267433-c231-4e32-bff5-417fca1e0c0a-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-DC0F517ADBCA: shutdown
2023-02-02 20:27:23,689 [7d267433-c231-4e32-bff5-417fca1e0c0a-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DC0F517ADBCA,id=7d267433-c231-4e32-bff5-417fca1e0c0a
2023-02-02 20:27:23,689 [7d267433-c231-4e32-bff5-417fca1e0c0a-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 7d267433-c231-4e32-bff5-417fca1e0c0a: shutdown 7d267433-c231-4e32-bff5-417fca1e0c0a@group-DC0F517ADBCA-FollowerState
2023-02-02 20:27:23,689 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 7d267433-c231-4e32-bff5-417fca1e0c0a: shutdown server GrpcServerProtocolService now
2023-02-02 20:27:23,689 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - da4028ad-c56f-4745-a3af-e0a942311a6d Close channels
2023-02-02 20:27:23,689 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253 Close channels
2023-02-02 20:27:23,690 [grpc-default-executor-6] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-02 20:27:23,690 [grpc-default-executor-17] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 7d267433-c231-4e32-bff5-417fca1e0c0a: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-02 20:27:23,691 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 7d267433-c231-4e32-bff5-417fca1e0c0a: shutdown server GrpcServerProtocolService successfully
2023-02-02 20:27:23,691 [grpc-default-executor-19] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 7d267433-c231-4e32-bff5-417fca1e0c0a: installSnapshot onError, lastRequest: f1da6dec-c089-423e-bed5-bf505eacaf1a->7d267433-c231-4e32-bff5-417fca1e0c0a#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "7d267433-c231-4e32-bff5-417fca1e0c0a"
address: "10.1.1.71:43573"
dataStreamAddress: "10.1.1.71:38557"
clientAddress: "10.1.1.71:43573"
adminAddress: "10.1.1.71:43573"
startupRole: FOLLOWER
,id: "f1da6dec-c089-423e-bed5-bf505eacaf1a"
address: "10.1.1.71:32971"
priority: 1
dataStreamAddress: "10.1.1.71:45749"
clientAddress: "10.1.1.71:32971"
adminAddress: "10.1.1.71:32971"
startupRole: FOLLOWER
,id: "da4028ad-c56f-4745-a3af-e0a942311a6d"
address: "10.1.1.71:42641"
dataStreamAddress: "10.1.1.71:43583"
clientAddress: "10.1.1.71:42641"
adminAddress: "10.1.1.71:42641"
startupRole: FOLLOWER
, old:): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-02 20:27:23,691 [7d267433-c231-4e32-bff5-417fca1e0c0a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd45ea6a8, L:/0:0:0:0:0:0:0:0:38557] CLOSE
2023-02-02 20:27:23,691 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-02-02 20:27:23,691 [7d267433-c231-4e32-bff5-417fca1e0c0a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd45ea6a8, L:/0:0:0:0:0:0:0:0:38557] INACTIVE
2023-02-02 20:27:23,691 [7d267433-c231-4e32-bff5-417fca1e0c0a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd45ea6a8, L:/0:0:0:0:0:0:0:0:38557] UNREGISTERED
2023-02-02 20:27:23,691 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a(c0,m0,n1, attendVote=true, lastRpcSendTime=243, lastRpcResponseTime=241) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:23,692 [7d267433-c231-4e32-bff5-417fca1e0c0a-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-68DA2E7F3D41: shutdown
2023-02-02 20:27:23,692 [grpc-default-executor-18] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-02-02 20:27:23,692 [grpc-default-executor-18] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a(c0,m0,n1, attendVote=true, lastRpcSendTime=244, lastRpcResponseTime=243) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:23,692 [7d267433-c231-4e32-bff5-417fca1e0c0a-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-68DA2E7F3D41,id=7d267433-c231-4e32-bff5-417fca1e0c0a
2023-02-02 20:27:23,693 [Listener at 127.0.0.1/43469] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2023-02-02 20:27:23,703 [7d267433-c231-4e32-bff5-417fca1e0c0a-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 7d267433-c231-4e32-bff5-417fca1e0c0a: shutdown 7d267433-c231-4e32-bff5-417fca1e0c0a@group-68DA2E7F3D41-LeaderStateImpl
2023-02-02 20:27:23,704 [7d267433-c231-4e32-bff5-417fca1e0c0a-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-68DA2E7F3D41-PendingRequests: sendNotLeaderResponses
2023-02-02 20:27:23,704 [7d267433-c231-4e32-bff5-417fca1e0c0a@group-68DA2E7F3D41-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-68DA2E7F3D41: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-2/data/ratis/1fc60b6e-672d-47cf-a0e1-68da2e7f3d41/sm/snapshot.1_0
2023-02-02 20:27:23,705 [7d267433-c231-4e32-bff5-417fca1e0c0a-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-68DA2E7F3D41-StateMachineUpdater: set stopIndex = 0
2023-02-02 20:27:23,707 [7d267433-c231-4e32-bff5-417fca1e0c0a@group-68DA2E7F3D41-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-68DA2E7F3D41: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-2/data/ratis/1fc60b6e-672d-47cf-a0e1-68da2e7f3d41/sm/snapshot.1_0 took: 3 ms
2023-02-02 20:27:23,707 [7d267433-c231-4e32-bff5-417fca1e0c0a@group-68DA2E7F3D41-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-68DA2E7F3D41-StateMachineUpdater: Took a snapshot at index 0
2023-02-02 20:27:23,707 [7d267433-c231-4e32-bff5-417fca1e0c0a@group-68DA2E7F3D41-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-68DA2E7F3D41-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-02 20:27:23,707 [7d267433-c231-4e32-bff5-417fca1e0c0a-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-68DA2E7F3D41: closes. applyIndex: 0
2023-02-02 20:27:23,718 [7d267433-c231-4e32-bff5-417fca1e0c0a-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-DC0F517ADBCA-StateMachineUpdater: set stopIndex = 0
2023-02-02 20:27:23,718 [7d267433-c231-4e32-bff5-417fca1e0c0a@group-DC0F517ADBCA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-DC0F517ADBCA-FollowerState was interrupted
2023-02-02 20:27:23,718 [7d267433-c231-4e32-bff5-417fca1e0c0a@group-DC0F517ADBCA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-DC0F517ADBCA: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-2/data/ratis/df29b2fb-f8d3-453e-beed-dc0f517adbca/sm/snapshot.1_0
2023-02-02 20:27:23,719 [7d267433-c231-4e32-bff5-417fca1e0c0a@group-DC0F517ADBCA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-DC0F517ADBCA: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-2/data/ratis/df29b2fb-f8d3-453e-beed-dc0f517adbca/sm/snapshot.1_0 took: 1 ms
2023-02-02 20:27:23,719 [7d267433-c231-4e32-bff5-417fca1e0c0a@group-DC0F517ADBCA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-DC0F517ADBCA-StateMachineUpdater: Took a snapshot at index 0
2023-02-02 20:27:23,719 [7d267433-c231-4e32-bff5-417fca1e0c0a@group-DC0F517ADBCA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-DC0F517ADBCA-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-02 20:27:23,720 [7d267433-c231-4e32-bff5-417fca1e0c0a-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-DC0F517ADBCA: closes. applyIndex: 0
2023-02-02 20:27:23,722 [7d267433-c231-4e32-bff5-417fca1e0c0a@group-68DA2E7F3D41-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-68DA2E7F3D41-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:23,727 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-4/data-0/containers/hdds/a7118d63-fcc7-4683-8210-e0c36487c2ca/DS-c5b676f3-e464-4cce-aaec-d35b52c3753d/container.db for volume DS-c5b676f3-e464-4cce-aaec-d35b52c3753d
2023-02-02 20:27:23,727 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-02 20:27:23,727 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-02 20:27:23,728 [7d267433-c231-4e32-bff5-417fca1e0c0a-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-68DA2E7F3D41-SegmentedRaftLogWorker close()
2023-02-02 20:27:23,729 [7d267433-c231-4e32-bff5-417fca1e0c0a@group-DC0F517ADBCA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-DC0F517ADBCA-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:23,729 [7d267433-c231-4e32-bff5-417fca1e0c0a-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 7d267433-c231-4e32-bff5-417fca1e0c0a@group-DC0F517ADBCA-SegmentedRaftLogWorker close()
2023-02-02 20:27:23,731 [JvmPauseMonitor28] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-7d267433-c231-4e32-bff5-417fca1e0c0a: Stopped
2023-02-02 20:27:23,731 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-02 20:27:23,739 [Listener at 127.0.0.1/43469] INFO  om.OzoneManager (OzoneManager.java:start(1506)) - OzoneManager RPC server is listening at localhost/127.0.0.1:43469
2023-02-02 20:27:23,739 [Listener at 127.0.0.1/43469] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(555)) - Starting OzoneManagerRatisServer om1 at port 44963
2023-02-02 20:27:23,740 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2023-02-02 20:27:23,743 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:23,744 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2023-02-02 20:27:23,744 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:23,744 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:23,745 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:23,745 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:23,745 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:23,745 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-02-02 20:27:23,745 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:23,745 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:23,745 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2023-02-02 20:27:23,745 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-02-02 20:27:23,745 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2023-02-02 20:27:23,745 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-02-02 20:27:23,745 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2023-02-02 20:27:23,746 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:23,746 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:23,746 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:23,746 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:23,747 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2023-02-02 20:27:23,747 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:23,750 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@bc0f996{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-02 20:27:23,752 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@67ed09f8{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-02 20:27:23,753 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-02 20:27:23,757 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@27006aa2{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-02 20:27:23,760 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@36e01a5{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-02 20:27:23,760 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:23,760 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:23,761 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2023-02-02 20:27:23,761 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:23,761 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:23,761 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|rpc:localhost:44963|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:23,761 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:23,761 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2023-02-02 20:27:23,761 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:23,762 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:23,761 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2023-02-02 20:27:23,762 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:23,762 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2023-02-02 20:27:23,770 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-02 20:27:23,764 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:23,783 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2023-02-02 20:27:23,784 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2023-02-02 20:27:23,784 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 494051a8-4feb-4706-b0a6-36852ae3dccb: close
2023-02-02 20:27:23,785 [494051a8-4feb-4706-b0a6-36852ae3dccb-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-77EF11360BF9: shutdown
2023-02-02 20:27:23,785 [494051a8-4feb-4706-b0a6-36852ae3dccb-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-77EF11360BF9,id=494051a8-4feb-4706-b0a6-36852ae3dccb
2023-02-02 20:27:23,785 [494051a8-4feb-4706-b0a6-36852ae3dccb-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 494051a8-4feb-4706-b0a6-36852ae3dccb: shutdown 494051a8-4feb-4706-b0a6-36852ae3dccb@group-77EF11360BF9-FollowerState
2023-02-02 20:27:23,785 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 494051a8-4feb-4706-b0a6-36852ae3dccb: shutdown server GrpcServerProtocolService now
2023-02-02 20:27:23,786 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 7bbfb910-8baa-49a4-be56-632f95348a2c Close channels
2023-02-02 20:27:23,786 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04 Close channels
2023-02-02 20:27:23,787 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 494051a8-4feb-4706-b0a6-36852ae3dccb: shutdown server GrpcServerProtocolService successfully
2023-02-02 20:27:23,787 [494051a8-4feb-4706-b0a6-36852ae3dccb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x4e4dbc54, L:/0:0:0:0:0:0:0:0:46629] CLOSE
2023-02-02 20:27:23,787 [494051a8-4feb-4706-b0a6-36852ae3dccb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x4e4dbc54, L:/0:0:0:0:0:0:0:0:46629] INACTIVE
2023-02-02 20:27:23,787 [494051a8-4feb-4706-b0a6-36852ae3dccb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x4e4dbc54, L:/0:0:0:0:0:0:0:0:46629] UNREGISTERED
2023-02-02 20:27:23,788 [494051a8-4feb-4706-b0a6-36852ae3dccb-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-848A906C6CA1: shutdown
2023-02-02 20:27:23,788 [494051a8-4feb-4706-b0a6-36852ae3dccb-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-848A906C6CA1,id=494051a8-4feb-4706-b0a6-36852ae3dccb
2023-02-02 20:27:23,788 [494051a8-4feb-4706-b0a6-36852ae3dccb-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 494051a8-4feb-4706-b0a6-36852ae3dccb: shutdown 494051a8-4feb-4706-b0a6-36852ae3dccb@group-848A906C6CA1-LeaderStateImpl
2023-02-02 20:27:23,788 [494051a8-4feb-4706-b0a6-36852ae3dccb-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-848A906C6CA1-PendingRequests: sendNotLeaderResponses
2023-02-02 20:27:23,789 [494051a8-4feb-4706-b0a6-36852ae3dccb@group-848A906C6CA1-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-848A906C6CA1: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-3/data/ratis/76a82bb3-0402-4c7b-be7a-848a906c6ca1/sm/snapshot.1_0
2023-02-02 20:27:23,789 [494051a8-4feb-4706-b0a6-36852ae3dccb-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-848A906C6CA1-StateMachineUpdater: set stopIndex = 0
2023-02-02 20:27:23,790 [494051a8-4feb-4706-b0a6-36852ae3dccb@group-848A906C6CA1-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-848A906C6CA1: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-3/data/ratis/76a82bb3-0402-4c7b-be7a-848a906c6ca1/sm/snapshot.1_0 took: 1 ms
2023-02-02 20:27:23,790 [494051a8-4feb-4706-b0a6-36852ae3dccb@group-848A906C6CA1-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-848A906C6CA1-StateMachineUpdater: Took a snapshot at index 0
2023-02-02 20:27:23,790 [494051a8-4feb-4706-b0a6-36852ae3dccb@group-848A906C6CA1-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-848A906C6CA1-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-02 20:27:23,790 [494051a8-4feb-4706-b0a6-36852ae3dccb-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-848A906C6CA1: closes. applyIndex: 0
2023-02-02 20:27:23,814 [Listener at 127.0.0.1/43469] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - om1: start RPC server
2023-02-02 20:27:23,815 [Listener at 127.0.0.1/43469] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - om1: GrpcService started, listening on 44963
2023-02-02 20:27:23,822 [494051a8-4feb-4706-b0a6-36852ae3dccb@group-848A906C6CA1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-848A906C6CA1-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:23,822 [494051a8-4feb-4706-b0a6-36852ae3dccb-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-848A906C6CA1-SegmentedRaftLogWorker close()
2023-02-02 20:27:23,829 [494051a8-4feb-4706-b0a6-36852ae3dccb-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-77EF11360BF9-StateMachineUpdater: set stopIndex = 40
2023-02-02 20:27:23,829 [494051a8-4feb-4706-b0a6-36852ae3dccb@group-77EF11360BF9-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-77EF11360BF9-FollowerState was interrupted
2023-02-02 20:27:23,829 [494051a8-4feb-4706-b0a6-36852ae3dccb@group-77EF11360BF9-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-77EF11360BF9: Taking a snapshot at:(t:6, i:40) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-3/data/ratis/af13c673-fc55-4c7f-bf3e-77ef11360bf9/sm/snapshot.6_40
2023-02-02 20:27:23,833 [494051a8-4feb-4706-b0a6-36852ae3dccb@group-77EF11360BF9-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-77EF11360BF9: Finished taking a snapshot at:(t:6, i:40) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-3/data/ratis/af13c673-fc55-4c7f-bf3e-77ef11360bf9/sm/snapshot.6_40 took: 4 ms
2023-02-02 20:27:23,834 [494051a8-4feb-4706-b0a6-36852ae3dccb@group-77EF11360BF9-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-77EF11360BF9-StateMachineUpdater: Took a snapshot at index 40
2023-02-02 20:27:23,834 [494051a8-4feb-4706-b0a6-36852ae3dccb@group-77EF11360BF9-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-77EF11360BF9-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 40
2023-02-02 20:27:23,841 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(326)) - Waiting for pipelines to close for 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). There are 2 pipelines
2023-02-02 20:27:23,841 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-02 20:27:23,841 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(57)) - Admin start on datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Finalizing its pipelines [PipelineID=d2207948-3c8e-453d-b9ae-f48c343a4530, PipelineID=74626adb-6e97-4dd2-98f3-2c2d94cb32da]
2023-02-02 20:27:23,842 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: d2207948-3c8e-453d-b9ae-f48c343a4530, Nodes: 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:71be8e41-5a57-4368-972a-d639c8cb365f, CreationTimestamp2023-02-02T20:26:13.211Z[Etc/UTC]] moved to CLOSED state
2023-02-02 20:27:23,842 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=d2207948-3c8e-453d-b9ae-f48c343a4530 close command to datanode 71be8e41-5a57-4368-972a-d639c8cb365f
2023-02-02 20:27:23,847 [Listener at 127.0.0.1/43469] INFO  om.OzoneManager (OzoneManager.java:start(1522)) - Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2023-02-02 20:27:23,847 [JvmPauseMonitor51] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-om1: Started
2023-02-02 20:27:23,861 [494051a8-4feb-4706-b0a6-36852ae3dccb-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-77EF11360BF9: closes. applyIndex: 40
2023-02-02 20:27:23,873 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: d2207948-3c8e-453d-b9ae-f48c343a4530, Nodes: 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:71be8e41-5a57-4368-972a-d639c8cb365f, CreationTimestamp2023-02-02T20:26:13.211Z[Etc/UTC]] removed.
2023-02-02 20:27:23,874 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #1 closed for pipeline=PipelineID=74626adb-6e97-4dd2-98f3-2c2d94cb32da
2023-02-02 20:27:23,874 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #2 closed for pipeline=PipelineID=74626adb-6e97-4dd2-98f3-2c2d94cb32da
2023-02-02 20:27:23,874 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #3 closed for pipeline=PipelineID=74626adb-6e97-4dd2-98f3-2c2d94cb32da
2023-02-02 20:27:23,875 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 74626adb-6e97-4dd2-98f3-2c2d94cb32da, Nodes: c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:c2e5a0ee-722e-430e-828a-2d735c45daa1, CreationTimestamp2023-02-02T20:26:13.577Z[Etc/UTC]] moved to CLOSED state
2023-02-02 20:27:23,875 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=74626adb-6e97-4dd2-98f3-2c2d94cb32da close command to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1
2023-02-02 20:27:23,875 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=74626adb-6e97-4dd2-98f3-2c2d94cb32da close command to datanode 71be8e41-5a57-4368-972a-d639c8cb365f
2023-02-02 20:27:23,875 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=74626adb-6e97-4dd2-98f3-2c2d94cb32da close command to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec
2023-02-02 20:27:23,875 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 74626adb-6e97-4dd2-98f3-2c2d94cb32da, Nodes: c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:c2e5a0ee-722e-430e-828a-2d735c45daa1, CreationTimestamp2023-02-02T20:26:13.577Z[Etc/UTC]] removed.
2023-02-02 20:27:23,880 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #1, current state: CLOSING
2023-02-02 20:27:23,880 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #2, current state: CLOSING
2023-02-02 20:27:23,880 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #3, current state: CLOSING
2023-02-02 20:27:23,885 [494051a8-4feb-4706-b0a6-36852ae3dccb@group-77EF11360BF9-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-77EF11360BF9-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:23,885 [494051a8-4feb-4706-b0a6-36852ae3dccb-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 494051a8-4feb-4706-b0a6-36852ae3dccb@group-77EF11360BF9-SegmentedRaftLogWorker close()
2023-02-02 20:27:23,893 [JvmPauseMonitor29] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-494051a8-4feb-4706-b0a6-36852ae3dccb: Stopped
2023-02-02 20:27:23,893 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2023-02-02 20:27:23,893 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-02 20:27:23,894 [Listener at 127.0.0.1/43469] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-02 20:27:23,897 [Listener at 127.0.0.1/43469] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-02 20:27:23,898 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-02 20:27:23,898 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2023-02-02 20:27:23,898 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-02 20:27:23,898 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-02 20:27:23,898 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 43861
2023-02-02 20:27:23,898 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-02 20:27:23,925 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-02 20:27:23,925 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-02 20:27:23,925 [Listener at 127.0.0.1/43469] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-02-02 20:27:23,928 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5c998625{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-02 20:27:23,928 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5bd12709{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-02-02 20:27:23,931 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@4c22eb62{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-02-02 20:27:23,936 [Listener at 127.0.0.1/43469] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@e02aea7{HTTP/1.1, (http/1.1)}{0.0.0.0:43861}
2023-02-02 20:27:23,936 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(415)) - Started @188446ms
2023-02-02 20:27:23,936 [Listener at 127.0.0.1/43469] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-02 20:27:23,937 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of ozoneManager listening at http://0.0.0.0:43861
2023-02-02 20:27:23,937 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-02 20:27:23,944 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-02-02 20:27:23,967 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=74626adb-6e97-4dd2-98f3-2c2d94cb32da is not found
2023-02-02 20:27:24,017 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:24,018 [IPC Server handler 0 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-02-02 20:27:24,018 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:24,018 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:24,036 [Listener at 127.0.0.1/43469] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(1982)) - Trash Interval set to 0. Files deleted won't move to trash
2023-02-02 20:27:24,039 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:24,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 11 containers.
2023-02-02 20:27:24,043 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:24,043 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:24,044 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:24,050 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d9b3b7a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-02 20:27:24,052 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:24,052 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:24,052 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:24,052 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:24,052 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:24,053 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:24,053 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:24,053 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:24,053 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:24,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-02 20:27:24,070 [Listener at 127.0.0.1/43469] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-02 20:27:24,070 [Listener at 127.0.0.1/43469] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-02 20:27:24,070 [Listener at 127.0.0.1/43469] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-02-02 20:27:24,097 [Listener at 127.0.0.1/43469] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(228)) - HddsDatanodeService host:fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net ip:10.1.1.71
2023-02-02 20:27:24,100 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) moved to stale state. Finalizing its pipelines [PipelineID=3372c4c6-b090-466d-8fa6-bf581edfb67c, PipelineID=af13c673-fc55-4c7f-bf3e-77ef11360bf9]
2023-02-02 20:27:24,100 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 3372c4c6-b090-466d-8fa6-bf581edfb67c, Nodes: 7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:7bbfb910-8baa-49a4-be56-632f95348a2c, CreationTimestamp2023-02-02T20:25:37.847Z[Etc/UTC]] moved to CLOSED state
2023-02-02 20:27:24,101 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #2 closed for pipeline=PipelineID=af13c673-fc55-4c7f-bf3e-77ef11360bf9
2023-02-02 20:27:24,101 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #2, current state: CLOSING
2023-02-02 20:27:24,101 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #5 closed for pipeline=PipelineID=af13c673-fc55-4c7f-bf3e-77ef11360bf9
2023-02-02 20:27:24,101 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #5, current state: CLOSING
2023-02-02 20:27:24,101 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #6 closed for pipeline=PipelineID=af13c673-fc55-4c7f-bf3e-77ef11360bf9
2023-02-02 20:27:24,101 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #6, current state: CLOSING
2023-02-02 20:27:24,101 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: af13c673-fc55-4c7f-bf3e-77ef11360bf9, Nodes: 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:7bbfb910-8baa-49a4-be56-632f95348a2c, CreationTimestamp2023-02-02T20:25:38.152Z[Etc/UTC]] moved to CLOSED state
2023-02-02 20:27:24,129 [Listener at 127.0.0.1/43469] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-02 20:27:24,235 [Listener at 127.0.0.1/43469] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 104 ms to scan 7 urls, producing 150 keys and 361 values 
2023-02-02 20:27:24,238 [Listener at 127.0.0.1/43469] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-02-02 20:27:24,245 [Listener at 127.0.0.1/43469] INFO  volume.HddsVolume (HddsVolume.java:<init>(117)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-02-02 20:27:24,246 [Listener at 127.0.0.1/43469] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data-0/containers/hdds to VolumeSet
2023-02-02 20:27:24,246 [Listener at 127.0.0.1/43469] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data-0/containers/hdds
2023-02-02 20:27:24,256 [Listener at 127.0.0.1/43469] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data-0/containers/hdds
2023-02-02 20:27:24,275 [Listener at 127.0.0.1/43469] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis to VolumeSet
2023-02-02 20:27:24,275 [Listener at 127.0.0.1/43469] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis
2023-02-02 20:27:24,275 [Listener at 127.0.0.1/43469] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis
2023-02-02 20:27:24,300 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode da4028ad-c56f-4745-a3af-e0a942311a6d(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) moved to stale state. Finalizing its pipelines [PipelineID=d98a9ae9-8b06-4231-879a-d9fcbbbaf01d, PipelineID=df29b2fb-f8d3-453e-beed-dc0f517adbca]
2023-02-02 20:27:24,301 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: d98a9ae9-8b06-4231-879a-d9fcbbbaf01d, Nodes: da4028ad-c56f-4745-a3af-e0a942311a6d(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:da4028ad-c56f-4745-a3af-e0a942311a6d, CreationTimestamp2023-02-02T20:25:36.718Z[Etc/UTC]] moved to CLOSED state
2023-02-02 20:27:24,301 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: df29b2fb-f8d3-453e-beed-dc0f517adbca, Nodes: da4028ad-c56f-4745-a3af-e0a942311a6d(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)7d267433-c231-4e32-bff5-417fca1e0c0a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)f1da6dec-c089-423e-bed5-bf505eacaf1a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:f1da6dec-c089-423e-bed5-bf505eacaf1a, CreationTimestamp2023-02-02T20:26:51.330Z[Etc/UTC]] moved to CLOSED state
2023-02-02 20:27:24,333 [Thread-3103] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data-0/containers/hdds
2023-02-02 20:27:24,333 [Listener at 127.0.0.1/43469] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(304)) - Build ContainerSet costs 0s
2023-02-02 20:27:24,334 [Listener at 127.0.0.1/43469] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-02 20:27:24,334 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:24,334 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-02-02 20:27:24,335 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:24,335 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-02-02 20:27:24,335 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-02 20:27:24,335 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-02-02 20:27:24,335 [Listener at 127.0.0.1/43469] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-02-02 20:27:24,335 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:24,335 [Listener at 127.0.0.1/43469] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-02-02 20:27:24,335 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-02 20:27:24,335 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-02 20:27:24,335 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-02 20:27:24,335 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-02 20:27:24,336 [Listener at 127.0.0.1/43469] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-02-02 20:27:24,337 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-02-02 20:27:24,337 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-02-02 20:27:24,337 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-02-02 20:27:24,337 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-02-02 20:27:24,337 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-02-02 20:27:24,337 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-02-02 20:27:24,337 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-02-02 20:27:24,338 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-02-02 20:27:24,338 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-02-02 20:27:24,338 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-02-02 20:27:24,338 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-02 20:27:24,338 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-02 20:27:24,338 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:24,338 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:24,338 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis] (custom)
2023-02-02 20:27:24,339 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x8662ce31] REGISTERED
2023-02-02 20:27:24,339 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x8662ce31] BIND: 0.0.0.0/0.0.0.0:0
2023-02-02 20:27:24,339 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x8662ce31, L:/0:0:0:0:0:0:0:0:45911] ACTIVE
2023-02-02 20:27:24,340 [Listener at 127.0.0.1/43469] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-02-02 20:27:24,344 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-02-02 20:27:24,344 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-02 20:27:24,345 [Listener at 127.0.0.1/43469] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-02 20:27:24,346 [Listener at 127.0.0.1/43469] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-02 20:27:24,347 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-02 20:27:24,347 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-02-02 20:27:24,348 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-02 20:27:24,348 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-02 20:27:24,348 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 33475
2023-02-02 20:27:24,348 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-02 20:27:24,349 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-02 20:27:24,349 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-02 20:27:24,349 [Listener at 127.0.0.1/43469] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-02-02 20:27:24,350 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@34951ab9{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-02 20:27:24,350 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1438388f{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-02-02 20:27:24,675 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@62f8f1df{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-33475-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-388754543263931634/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-02 20:27:24,681 [Listener at 127.0.0.1/43469] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@29689844{HTTP/1.1, (http/1.1)}{0.0.0.0:33475}
2023-02-02 20:27:24,681 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(415)) - Started @189191ms
2023-02-02 20:27:24,681 [Listener at 127.0.0.1/43469] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-02 20:27:24,681 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:33475
2023-02-02 20:27:24,682 [Listener at 127.0.0.1/43469] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-02 20:27:24,682 [Listener at 127.0.0.1/43469] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-02 20:27:24,682 [Listener at 127.0.0.1/43469] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-02-02 20:27:24,692 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(516)) - Ozone container server started.
2023-02-02 20:27:24,693 [Listener at 127.0.0.1/43469] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(228)) - HddsDatanodeService host:fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net ip:10.1.1.71
2023-02-02 20:27:24,705 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6f39c42f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-02 20:27:24,717 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/meta/datanode.id
2023-02-02 20:27:24,718 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:24,718 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1250, lastRpcResponseTime=3770) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:24,718 [grpc-default-executor-9] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:24,719 [grpc-default-executor-9] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1251, lastRpcResponseTime=3770) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:24,719 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:24,720 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1252, lastRpcResponseTime=3772) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:24,721 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:24,721 [grpc-default-executor-9] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:24,721 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1253, lastRpcResponseTime=3773) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:24,721 [grpc-default-executor-18] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:24,722 [grpc-default-executor-9] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1255, lastRpcResponseTime=3774) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:24,723 [grpc-default-executor-18] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1255, lastRpcResponseTime=3775) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:24,724 [grpc-default-executor-18] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:24,724 [grpc-default-executor-18] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1256, lastRpcResponseTime=3776) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:24,724 [grpc-default-executor-9] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:24,725 [grpc-default-executor-9] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1257, lastRpcResponseTime=3777) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:24,727 [grpc-default-executor-9] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:24,727 [grpc-default-executor-18] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:24,727 [grpc-default-executor-9] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=0, lastRpcResponseTime=3779) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:24,728 [grpc-default-executor-18] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=0, lastRpcResponseTime=3779) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:24,729 [Listener at 127.0.0.1/43469] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-02 20:27:24,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:24,818 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-02 20:27:24,836 [Listener at 127.0.0.1/43469] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 105 ms to scan 7 urls, producing 150 keys and 361 values 
2023-02-02 20:27:24,843 [Listener at 127.0.0.1/43469] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-02-02 20:27:24,852 [Listener at 127.0.0.1/43469] INFO  volume.HddsVolume (HddsVolume.java:<init>(117)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-02-02 20:27:24,852 [Listener at 127.0.0.1/43469] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data-0/containers/hdds to VolumeSet
2023-02-02 20:27:24,852 [Listener at 127.0.0.1/43469] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data-0/containers/hdds
2023-02-02 20:27:24,863 [Listener at 127.0.0.1/43469] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data-0/containers/hdds
2023-02-02 20:27:24,881 [Listener at 127.0.0.1/43469] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis to VolumeSet
2023-02-02 20:27:24,882 [Listener at 127.0.0.1/43469] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis
2023-02-02 20:27:24,882 [Listener at 127.0.0.1/43469] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis
2023-02-02 20:27:24,903 [Thread-3117] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data-0/containers/hdds
2023-02-02 20:27:24,904 [Listener at 127.0.0.1/43469] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(304)) - Build ContainerSet costs 0s
2023-02-02 20:27:24,905 [Listener at 127.0.0.1/43469] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-02 20:27:24,905 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:24,906 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-02-02 20:27:24,906 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:24,906 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-02-02 20:27:24,906 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-02 20:27:24,906 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-02-02 20:27:24,906 [Listener at 127.0.0.1/43469] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-02-02 20:27:24,906 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:24,906 [Listener at 127.0.0.1/43469] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-02-02 20:27:24,906 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-02 20:27:24,906 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-02 20:27:24,906 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-02 20:27:24,906 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-02 20:27:24,908 [Listener at 127.0.0.1/43469] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-02-02 20:27:24,908 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-02-02 20:27:24,908 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-02-02 20:27:24,908 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-02-02 20:27:24,908 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-02-02 20:27:24,908 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-02-02 20:27:24,909 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-02-02 20:27:24,909 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-02-02 20:27:24,909 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-02-02 20:27:24,910 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-02-02 20:27:24,910 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-02-02 20:27:24,914 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-02 20:27:24,915 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-02 20:27:24,915 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:24,915 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:24,915 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis] (custom)
2023-02-02 20:27:24,915 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x33f86fd8] REGISTERED
2023-02-02 20:27:24,915 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x33f86fd8] BIND: 0.0.0.0/0.0.0.0:0
2023-02-02 20:27:24,915 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x33f86fd8, L:/0:0:0:0:0:0:0:0:45109] ACTIVE
2023-02-02 20:27:24,920 [Listener at 127.0.0.1/43469] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-02-02 20:27:24,927 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-02-02 20:27:24,927 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-02 20:27:24,928 [Listener at 127.0.0.1/43469] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-02 20:27:24,933 [Listener at 127.0.0.1/43469] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-02 20:27:24,934 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-02 20:27:24,934 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-02-02 20:27:24,934 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-02 20:27:24,934 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-02 20:27:24,935 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 44731
2023-02-02 20:27:24,935 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-02 20:27:24,945 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-02 20:27:24,945 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-02 20:27:24,945 [Listener at 127.0.0.1/43469] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-02-02 20:27:24,946 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@74ef90c9{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-02 20:27:24,946 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@747b58c3{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-02-02 20:27:24,981 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1220181596ns, electionTimeout:1189ms
2023-02-02 20:27:24,982 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2023-02-02 20:27:24,982 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-02 20:27:24,982 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:24,982 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection125
2023-02-02 20:27:25,004 [om1@group-C5BA1605619E-LeaderElection125] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection125 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|rpc:localhost:44963|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:25,004 [om1@group-C5BA1605619E-LeaderElection125] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - om1@group-C5BA1605619E-LeaderElection125 ELECTION round 0: result PASSED (term=1)
2023-02-02 20:27:25,004 [om1@group-C5BA1605619E-LeaderElection125] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection125
2023-02-02 20:27:25,004 [om1@group-C5BA1605619E-LeaderElection125] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-02 20:27:25,004 [om1@group-C5BA1605619E-LeaderElection125] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 1981ms
2023-02-02 20:27:25,004 [om1@group-C5BA1605619E-LeaderElection125] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-02 20:27:25,006 [om1@group-C5BA1605619E-LeaderElection125] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-02-02 20:27:25,006 [om1@group-C5BA1605619E-LeaderElection125] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2023-02-02 20:27:25,007 [om1@group-C5BA1605619E-LeaderElection125] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2023-02-02 20:27:25,007 [om1@group-C5BA1605619E-LeaderElection125] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-02 20:27:25,007 [om1@group-C5BA1605619E-LeaderElection125] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-02 20:27:25,007 [om1@group-C5BA1605619E-LeaderElection125] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-02-02 20:27:25,007 [om1@group-C5BA1605619E-LeaderElection125] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-02 20:27:25,007 [om1@group-C5BA1605619E-LeaderElection125] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2023-02-02 20:27:25,010 [om1@group-C5BA1605619E-LeaderElection125] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:25,015 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=74626adb-6e97-4dd2-98f3-2c2d94cb32da is not found
2023-02-02 20:27:25,017 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 71be8e41-5a57-4368-972a-d639c8cb365f: remove    LEADER 71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530:t1, leader=71be8e41-5a57-4368-972a-d639c8cb365f, voted=71be8e41-5a57-4368-972a-d639c8cb365f, raftlog=Memoized:71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530-SegmentedRaftLog:OPENED:c0, conf=0: peers:[71be8e41-5a57-4368-972a-d639c8cb365f|rpc:10.1.1.71:38615|dataStream:10.1.1.71:44305|priority:1|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-02-02 20:27:25,017 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530: shutdown
2023-02-02 20:27:25,017 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F48C343A4530,id=71be8e41-5a57-4368-972a-d639c8cb365f
2023-02-02 20:27:25,017 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 71be8e41-5a57-4368-972a-d639c8cb365f: shutdown 71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530-LeaderStateImpl
2023-02-02 20:27:25,017 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530-PendingRequests: sendNotLeaderResponses
2023-02-02 20:27:25,018 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530-StateMachineUpdater: set stopIndex = 0
2023-02-02 20:27:25,018 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:25,018 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:25,018 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:25,019 [71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-F48C343A4530: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-4/data/ratis/d2207948-3c8e-453d-b9ae-f48c343a4530/sm/snapshot.1_0
2023-02-02 20:27:25,020 [IPC Server handler 15 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-02-02 20:27:25,020 [71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-F48C343A4530: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-4/data/ratis/d2207948-3c8e-453d-b9ae-f48c343a4530/sm/snapshot.1_0 took: 1 ms
2023-02-02 20:27:25,020 [71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530-StateMachineUpdater: Took a snapshot at index 0
2023-02-02 20:27:25,020 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=74626adb-6e97-4dd2-98f3-2c2d94cb32da is not found
2023-02-02 20:27:25,020 [71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-02 20:27:25,021 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=d2207948-3c8e-453d-b9ae-f48c343a4530 is not found
2023-02-02 20:27:25,021 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530: closes. applyIndex: 0
2023-02-02 20:27:25,021 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2023-02-02 20:27:25,022 [71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:25,022 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530-SegmentedRaftLogWorker close()
2023-02-02 20:27:25,026 [om1@group-C5BA1605619E-LeaderElection125] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - om1@group-C5BA1605619E: set configuration 0: peers:[om1|rpc:localhost:44963|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:25,026 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-F48C343A4530: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-4/data/ratis/d2207948-3c8e-453d-b9ae-f48c343a4530
2023-02-02 20:27:25,026 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=d2207948-3c8e-453d-b9ae-f48c343a4530 command on datanode 71be8e41-5a57-4368-972a-d639c8cb365f.
2023-02-02 20:27:25,026 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 71be8e41-5a57-4368-972a-d639c8cb365f: remove  FOLLOWER 71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA:t1, leader=c2e5a0ee-722e-430e-828a-2d735c45daa1, voted=c2e5a0ee-722e-430e-828a-2d735c45daa1, raftlog=Memoized:71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA-SegmentedRaftLog:OPENED:c35, conf=0: peers:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 71be8e41-5a57-4368-972a-d639c8cb365f|rpc:10.1.1.71:38615|dataStream:10.1.1.71:44305|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-02-02 20:27:25,026 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA: shutdown
2023-02-02 20:27:25,027 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2C2D94CB32DA,id=71be8e41-5a57-4368-972a-d639c8cb365f
2023-02-02 20:27:25,027 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 71be8e41-5a57-4368-972a-d639c8cb365f: shutdown 71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA-FollowerState
2023-02-02 20:27:25,027 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA-StateMachineUpdater: set stopIndex = 35
2023-02-02 20:27:25,027 [71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA-FollowerState was interrupted
2023-02-02 20:27:25,027 [71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-2C2D94CB32DA: Taking a snapshot at:(t:1, i:35) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-4/data/ratis/74626adb-6e97-4dd2-98f3-2c2d94cb32da/sm/snapshot.1_35
2023-02-02 20:27:25,027 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(192)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:44963"
startupRole: FOLLOWER
]
2023-02-02 20:27:25,028 [71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-2C2D94CB32DA: Finished taking a snapshot at:(t:1, i:35) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-4/data/ratis/74626adb-6e97-4dd2-98f3-2c2d94cb32da/sm/snapshot.1_35 took: 1 ms
2023-02-02 20:27:25,028 [71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA-StateMachineUpdater: Took a snapshot at index 35
2023-02-02 20:27:25,028 [71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 35
2023-02-02 20:27:25,029 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA: closes. applyIndex: 35
2023-02-02 20:27:25,029 [71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:25,029 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA-SegmentedRaftLogWorker close()
2023-02-02 20:27:25,033 [IPC Server handler 5 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-02-02 20:27:25,039 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:25,044 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,044 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,044 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,044 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #5 to datanode 7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,044 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #5 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,044 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #5 to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,044 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,044 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,044 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-02-02 20:27:25,044 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:25,044 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:25,044 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:25,053 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,053 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,053 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,053 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,053 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,053 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,053 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,053 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,053 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:25,053 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:25,085 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 27.
2023-02-02 20:27:25,085 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 27.
2023-02-02 20:27:25,087 [IPC Server handler 18 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-02-02 20:27:25,087 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #1 to QUASI_CLOSED state, datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) reported QUASI_CLOSED replica.
2023-02-02 20:27:25,088 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 2 is synced with bcsId 31.
2023-02-02 20:27:25,088 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 2 is synced with bcsId 31.
2023-02-02 20:27:25,088 [IPC Server handler 7 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-02-02 20:27:25,090 [IPC Server handler 6 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-02-02 20:27:25,090 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #2 to QUASI_CLOSED state, datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) reported QUASI_CLOSED replica.
2023-02-02 20:27:25,094 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 35.
2023-02-02 20:27:25,094 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 35.
2023-02-02 20:27:25,094 [IPC Server handler 19 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-02-02 20:27:25,098 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 71be8e41-5a57-4368-972a-d639c8cb365f@group-2C2D94CB32DA: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-4/data/ratis/74626adb-6e97-4dd2-98f3-2c2d94cb32da
2023-02-02 20:27:25,098 [IPC Server handler 1 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-02-02 20:27:25,098 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=74626adb-6e97-4dd2-98f3-2c2d94cb32da command on datanode 71be8e41-5a57-4368-972a-d639c8cb365f.
2023-02-02 20:27:25,098 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #3 to QUASI_CLOSED state, datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) reported QUASI_CLOSED replica.
2023-02-02 20:27:25,295 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@1a0b7f1{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-44731-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-4987749008084730469/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-02 20:27:25,301 [Listener at 127.0.0.1/43469] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@34c1fc1a{HTTP/1.1, (http/1.1)}{0.0.0.0:44731}
2023-02-02 20:27:25,301 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(415)) - Started @189811ms
2023-02-02 20:27:25,301 [Listener at 127.0.0.1/43469] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-02 20:27:25,302 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:44731
2023-02-02 20:27:25,307 [Listener at 127.0.0.1/43469] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-02 20:27:25,308 [Listener at 127.0.0.1/43469] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-02 20:27:25,308 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(516)) - Ozone container server started.
2023-02-02 20:27:25,308 [Listener at 127.0.0.1/43469] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-02-02 20:27:25,325 [Listener at 127.0.0.1/43469] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(228)) - HddsDatanodeService host:fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net ip:10.1.1.71
2023-02-02 20:27:25,341 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@abaae5e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-02 20:27:25,346 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/meta/datanode.id
2023-02-02 20:27:25,351 [Listener at 127.0.0.1/43469] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-02 20:27:25,443 [Listener at 127.0.0.1/43469] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 91 ms to scan 7 urls, producing 150 keys and 361 values 
2023-02-02 20:27:25,448 [Listener at 127.0.0.1/43469] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-02-02 20:27:25,454 [Listener at 127.0.0.1/43469] INFO  volume.HddsVolume (HddsVolume.java:<init>(117)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-02-02 20:27:25,454 [Listener at 127.0.0.1/43469] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data-0/containers/hdds to VolumeSet
2023-02-02 20:27:25,454 [Listener at 127.0.0.1/43469] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data-0/containers/hdds
2023-02-02 20:27:25,461 [Listener at 127.0.0.1/43469] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data-0/containers/hdds
2023-02-02 20:27:25,481 [Listener at 127.0.0.1/43469] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis to VolumeSet
2023-02-02 20:27:25,481 [Listener at 127.0.0.1/43469] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis
2023-02-02 20:27:25,482 [Listener at 127.0.0.1/43469] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis
2023-02-02 20:27:25,509 [Thread-3133] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data-0/containers/hdds
2023-02-02 20:27:25,510 [Listener at 127.0.0.1/43469] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(304)) - Build ContainerSet costs 0s
2023-02-02 20:27:25,511 [Listener at 127.0.0.1/43469] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-02 20:27:25,511 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:25,511 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-02-02 20:27:25,511 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:25,511 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-02-02 20:27:25,512 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-02 20:27:25,512 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-02-02 20:27:25,512 [Listener at 127.0.0.1/43469] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-02-02 20:27:25,512 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:25,512 [Listener at 127.0.0.1/43469] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-02-02 20:27:25,512 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-02 20:27:25,512 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-02 20:27:25,512 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-02 20:27:25,512 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-02 20:27:25,513 [Listener at 127.0.0.1/43469] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-02-02 20:27:25,513 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-02-02 20:27:25,514 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-02-02 20:27:25,514 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-02-02 20:27:25,514 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-02-02 20:27:25,514 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-02-02 20:27:25,514 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-02-02 20:27:25,514 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-02-02 20:27:25,515 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-02-02 20:27:25,515 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-02-02 20:27:25,515 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-02-02 20:27:25,520 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-02 20:27:25,520 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-02 20:27:25,520 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:25,520 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:25,521 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis] (custom)
2023-02-02 20:27:25,521 [d767bd78-5310-4536-b2f7-e45413a997a1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0cd87013] REGISTERED
2023-02-02 20:27:25,521 [d767bd78-5310-4536-b2f7-e45413a997a1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0cd87013] BIND: 0.0.0.0/0.0.0.0:0
2023-02-02 20:27:25,521 [d767bd78-5310-4536-b2f7-e45413a997a1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0cd87013, L:/0:0:0:0:0:0:0:0:36701] ACTIVE
2023-02-02 20:27:25,526 [Listener at 127.0.0.1/43469] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-02-02 20:27:25,530 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-02-02 20:27:25,530 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-02 20:27:25,531 [Listener at 127.0.0.1/43469] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-02 20:27:25,534 [Listener at 127.0.0.1/43469] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-02 20:27:25,534 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-02 20:27:25,535 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-02-02 20:27:25,535 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-02 20:27:25,535 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-02 20:27:25,535 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 40531
2023-02-02 20:27:25,535 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-02 20:27:25,564 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-02 20:27:25,564 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-02 20:27:25,565 [Listener at 127.0.0.1/43469] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-02-02 20:27:25,568 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1f1fb445{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-02 20:27:25,568 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@454519a9{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-02-02 20:27:25,758 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-2/data-0/containers/hdds/a7118d63-fcc7-4683-8210-e0c36487c2ca/DS-0e36bebb-a384-40dc-aea0-e433aff663aa/container.db for volume DS-0e36bebb-a384-40dc-aea0-e433aff663aa
2023-02-02 20:27:25,759 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-02 20:27:25,768 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-02 20:27:25,769 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-02 20:27:25,779 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@53db9b7f{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-02 20:27:25,779 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@1b4f0341{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-02 20:27:25,780 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-02 20:27:25,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:25,784 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3916648e{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-02 20:27:25,787 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1458126b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-02 20:27:25,796 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-02 20:27:25,799 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253: close
2023-02-02 20:27:25,799 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253: shutdown server GrpcServerProtocolService now
2023-02-02 20:27:25,799 [541b5aca-8ce5-47d9-adc3-7e41c6e3e253-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B: shutdown
2023-02-02 20:27:25,799 [541b5aca-8ce5-47d9-adc3-7e41c6e3e253-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-29A66540D36B,id=541b5aca-8ce5-47d9-adc3-7e41c6e3e253
2023-02-02 20:27:25,799 [541b5aca-8ce5-47d9-adc3-7e41c6e3e253-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253: shutdown 541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B-FollowerState
2023-02-02 20:27:25,799 [541b5aca-8ce5-47d9-adc3-7e41c6e3e253-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B-StateMachineUpdater: set stopIndex = -1
2023-02-02 20:27:25,800 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253: shutdown server GrpcServerProtocolService successfully
2023-02-02 20:27:25,800 [541b5aca-8ce5-47d9-adc3-7e41c6e3e253-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5b5512f1, L:/0:0:0:0:0:0:0:0:38601] CLOSE
2023-02-02 20:27:25,801 [541b5aca-8ce5-47d9-adc3-7e41c6e3e253-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5b5512f1, L:/0:0:0:0:0:0:0:0:38601] INACTIVE
2023-02-02 20:27:25,801 [541b5aca-8ce5-47d9-adc3-7e41c6e3e253-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5b5512f1, L:/0:0:0:0:0:0:0:0:38601] UNREGISTERED
2023-02-02 20:27:25,801 [541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B-FollowerState was interrupted
2023-02-02 20:27:25,801 [541b5aca-8ce5-47d9-adc3-7e41c6e3e253-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B: closes. applyIndex: -1
2023-02-02 20:27:25,816 [541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:25,816 [541b5aca-8ce5-47d9-adc3-7e41c6e3e253-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 541b5aca-8ce5-47d9-adc3-7e41c6e3e253@group-29A66540D36B-SegmentedRaftLogWorker close()
2023-02-02 20:27:25,818 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-02 20:27:25,836 [JvmPauseMonitor50] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-541b5aca-8ce5-47d9-adc3-7e41c6e3e253: Stopped
2023-02-02 20:27:25,944 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@4983c97a{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-40531-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-77952252165822215/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-02 20:27:25,951 [Listener at 127.0.0.1/43469] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@6ae14641{HTTP/1.1, (http/1.1)}{0.0.0.0:40531}
2023-02-02 20:27:25,951 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(415)) - Started @190461ms
2023-02-02 20:27:25,951 [Listener at 127.0.0.1/43469] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-02 20:27:25,953 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:40531
2023-02-02 20:27:25,954 [grpc-default-executor-9] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:25,954 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-3/data-0/containers/hdds/a7118d63-fcc7-4683-8210-e0c36487c2ca/DS-4ef93ceb-2d58-4bb1-8a17-76eaef80314d/container.db for volume DS-4ef93ceb-2d58-4bb1-8a17-76eaef80314d
2023-02-02 20:27:25,955 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-02 20:27:25,954 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(516)) - Ozone container server started.
2023-02-02 20:27:25,955 [Listener at 127.0.0.1/43469] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-02-02 20:27:25,956 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-02 20:27:25,960 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-02 20:27:25,968 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - c2e5a0ee-722e-430e-828a-2d735c45daa1: remove    LEADER c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA:t1, leader=c2e5a0ee-722e-430e-828a-2d735c45daa1, voted=c2e5a0ee-722e-430e-828a-2d735c45daa1, raftlog=Memoized:c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA-SegmentedRaftLog:OPENED:c36, conf=0: peers:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 71be8e41-5a57-4368-972a-d639c8cb365f|rpc:10.1.1.71:38615|dataStream:10.1.1.71:44305|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-02-02 20:27:25,968 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA: shutdown
2023-02-02 20:27:25,968 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2C2D94CB32DA,id=c2e5a0ee-722e-430e-828a-2d735c45daa1
2023-02-02 20:27:25,968 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - c2e5a0ee-722e-430e-828a-2d735c45daa1: shutdown c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA-LeaderStateImpl
2023-02-02 20:27:25,968 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA-PendingRequests: sendNotLeaderResponses
2023-02-02 20:27:25,968 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA->71be8e41-5a57-4368-972a-d639c8cb365f-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA->71be8e41-5a57-4368-972a-d639c8cb365f-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-02-02 20:27:25,968 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA->7153b2e5-6547-4596-92e7-e397d052a5ec-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA->7153b2e5-6547-4596-92e7-e397d052a5ec-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-02-02 20:27:25,976 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@c14fbc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-02 20:27:25,984 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA-StateMachineUpdater: set stopIndex = 36
2023-02-02 20:27:25,984 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=74626adb-6e97-4dd2-98f3-2c2d94cb32da is not found
2023-02-02 20:27:25,985 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-2C2D94CB32DA: Taking a snapshot at:(t:1, i:36) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-3/data/ratis/74626adb-6e97-4dd2-98f3-2c2d94cb32da/sm/snapshot.1_36
2023-02-02 20:27:25,985 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 7153b2e5-6547-4596-92e7-e397d052a5ec: Completed APPEND_ENTRIES, lastRequest: null
2023-02-02 20:27:25,987 [grpc-default-executor-18] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 7153b2e5-6547-4596-92e7-e397d052a5ec: Completed APPEND_ENTRIES, lastRequest: c2e5a0ee-722e-430e-828a-2d735c45daa1->7153b2e5-6547-4596-92e7-e397d052a5ec#180-t1,previous=(t:1, i:35),leaderCommit=35,initializing? true,entries: size=1, first=(t:1, i:36), METADATAENTRY(c:35)
2023-02-02 20:27:25,987 [grpc-default-executor-19] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA->7153b2e5-6547-4596-92e7-e397d052a5ec-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-02 20:27:25,988 [grpc-default-executor-19] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA->7153b2e5-6547-4596-92e7-e397d052a5ec: nextIndex: updateUnconditionally 37 -> 36
2023-02-02 20:27:25,988 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-2C2D94CB32DA: Finished taking a snapshot at:(t:1, i:36) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-3/data/ratis/74626adb-6e97-4dd2-98f3-2c2d94cb32da/sm/snapshot.1_36 took: 3 ms
2023-02-02 20:27:25,988 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA-StateMachineUpdater: Took a snapshot at index 36
2023-02-02 20:27:25,988 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 36
2023-02-02 20:27:25,988 [grpc-default-executor-17] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA->7153b2e5-6547-4596-92e7-e397d052a5ec-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-02 20:27:25,991 [grpc-default-executor-17] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA->7153b2e5-6547-4596-92e7-e397d052a5ec: nextIndex: updateUnconditionally 36 -> 35
2023-02-02 20:27:25,992 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA: closes. applyIndex: 36
2023-02-02 20:27:25,992 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:25,992 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA-SegmentedRaftLogWorker close()
2023-02-02 20:27:25,994 [grpc-default-executor-17] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 71be8e41-5a57-4368-972a-d639c8cb365f: Completed APPEND_ENTRIES, lastRequest: null
2023-02-02 20:27:25,994 [grpc-default-executor-18] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 71be8e41-5a57-4368-972a-d639c8cb365f: Completed APPEND_ENTRIES, lastRequest: c2e5a0ee-722e-430e-828a-2d735c45daa1->71be8e41-5a57-4368-972a-d639c8cb365f#182-t1,previous=(t:1, i:35),leaderCommit=35,initializing? true,entries: size=1, first=(t:1, i:36), METADATAENTRY(c:35)
2023-02-02 20:27:25,995 [grpc-default-executor-8] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA->71be8e41-5a57-4368-972a-d639c8cb365f-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-02 20:27:25,995 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA->71be8e41-5a57-4368-972a-d639c8cb365f: nextIndex: updateUnconditionally 37 -> 36
2023-02-02 20:27:25,997 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA->71be8e41-5a57-4368-972a-d639c8cb365f-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-02 20:27:25,997 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA->71be8e41-5a57-4368-972a-d639c8cb365f: nextIndex: updateUnconditionally 36 -> 35
2023-02-02 20:27:26,001 [grpc-default-executor-9] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a(c0,m0,n1, attendVote=true, lastRpcSendTime=2552, lastRpcResponseTime=2551) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:26,001 [grpc-default-executor-9] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:26,002 [grpc-default-executor-18] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:26,002 [grpc-default-executor-17] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:26,002 [grpc-default-executor-9] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a(c0,m0,n1, attendVote=true, lastRpcSendTime=0, lastRpcResponseTime=2553) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:26,002 [grpc-default-executor-18] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a(c0,m0,n1, attendVote=true, lastRpcSendTime=1, lastRpcResponseTime=2553) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:26,002 [grpc-default-executor-17] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->7d267433-c231-4e32-bff5-417fca1e0c0a(c0,m0,n1, attendVote=true, lastRpcSendTime=1, lastRpcResponseTime=2553) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:26,003 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@1ea7671d{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-02 20:27:26,004 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@446114a0{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-02 20:27:26,004 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-02 20:27:26,005 [grpc-default-executor-17] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:26,005 [grpc-default-executor-18] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:26,006 [grpc-default-executor-17] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1278, lastRpcResponseTime=5057) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:26,006 [grpc-default-executor-18] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1279, lastRpcResponseTime=5058) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:26,007 [grpc-default-executor-18] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:26,007 [grpc-default-executor-17] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:26,007 [grpc-default-executor-18] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1280, lastRpcResponseTime=5059) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:26,008 [grpc-default-executor-17] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1280, lastRpcResponseTime=5059) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:26,008 [grpc-default-executor-17] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:26,008 [grpc-default-executor-18] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:26,009 [grpc-default-executor-17] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1282, lastRpcResponseTime=5061) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:26,009 [grpc-default-executor-18] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1282, lastRpcResponseTime=5061) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:26,015 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/meta/datanode.id
2023-02-02 20:27:26,016 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 7153b2e5-6547-4596-92e7-e397d052a5ec: remove  FOLLOWER 7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA:t1, leader=c2e5a0ee-722e-430e-828a-2d735c45daa1, voted=c2e5a0ee-722e-430e-828a-2d735c45daa1, raftlog=Memoized:7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA-SegmentedRaftLog:OPENED:c36, conf=0: peers:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 71be8e41-5a57-4368-972a-d639c8cb365f|rpc:10.1.1.71:38615|dataStream:10.1.1.71:44305|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-02-02 20:27:26,016 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA: shutdown
2023-02-02 20:27:26,016 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2C2D94CB32DA,id=7153b2e5-6547-4596-92e7-e397d052a5ec
2023-02-02 20:27:26,016 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 7153b2e5-6547-4596-92e7-e397d052a5ec: shutdown 7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA-FollowerState
2023-02-02 20:27:26,016 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA-StateMachineUpdater: set stopIndex = 36
2023-02-02 20:27:26,016 [7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA-FollowerState was interrupted
2023-02-02 20:27:26,016 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=74626adb-6e97-4dd2-98f3-2c2d94cb32da is not found
2023-02-02 20:27:26,017 [7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-2C2D94CB32DA: Taking a snapshot at:(t:1, i:36) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-5/data/ratis/74626adb-6e97-4dd2-98f3-2c2d94cb32da/sm/snapshot.1_36
2023-02-02 20:27:26,018 [grpc-default-executor-18] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:26,018 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:26,019 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:26,019 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:26,019 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@41f3a0f6{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-02 20:27:26,025 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@12add170{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-02 20:27:26,028 [7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-2C2D94CB32DA: Finished taking a snapshot at:(t:1, i:36) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-5/data/ratis/74626adb-6e97-4dd2-98f3-2c2d94cb32da/sm/snapshot.1_36 took: 11 ms
2023-02-02 20:27:26,029 [7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA-StateMachineUpdater: Took a snapshot at index 36
2023-02-02 20:27:26,029 [7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 36
2023-02-02 20:27:26,030 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA: closes. applyIndex: 36
2023-02-02 20:27:26,030 [7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:26,030 [grpc-default-executor-17] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:26,031 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA-SegmentedRaftLogWorker close()
2023-02-02 20:27:26,031 [grpc-default-executor-18] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=1, lastRpcResponseTime=5083) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:26,033 [grpc-default-executor-17] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d-GrpcLogAppender: Leader has not got in touch with Follower f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA->da4028ad-c56f-4745-a3af-e0a942311a6d(c0,m0,n1, attendVote=true, lastRpcSendTime=2, lastRpcResponseTime=5085) yet, just keep nextIndex unchanged and retry.
2023-02-02 20:27:26,035 [Listener at 127.0.0.1/43469] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(228)) - HddsDatanodeService host:fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net ip:10.1.1.71
2023-02-02 20:27:26,040 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:26,044 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,044 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:26,044 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,045 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,045 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #5 to datanode 7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,045 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #5 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,045 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #5 to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,045 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,045 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,045 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-02-02 20:27:26,045 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:26,045 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:26,049 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-02 20:27:26,050 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - f1da6dec-c089-423e-bed5-bf505eacaf1a: close
2023-02-02 20:27:26,053 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) moved to stale state. Finalizing its pipelines [PipelineID=af13c673-fc55-4c7f-bf3e-77ef11360bf9, PipelineID=76a82bb3-0402-4c7b-be7a-848a906c6ca1]
2023-02-02 20:27:26,060 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,060 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,060 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,060 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,060 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,060 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,060 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,060 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,060 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:26,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 7 milliseconds for processing 6 containers.
2023-02-02 20:27:26,061 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 76a82bb3-0402-4c7b-be7a-848a906c6ca1, Nodes: 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:494051a8-4feb-4706-b0a6-36852ae3dccb, CreationTimestamp2023-02-02T20:25:37.419Z[Etc/UTC]] moved to CLOSED state
2023-02-02 20:27:26,063 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 27.
2023-02-02 20:27:26,063 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 27.
2023-02-02 20:27:26,073 [f1da6dec-c089-423e-bed5-bf505eacaf1a-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-3EF40F351826: shutdown
2023-02-02 20:27:26,073 [f1da6dec-c089-423e-bed5-bf505eacaf1a-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3EF40F351826,id=f1da6dec-c089-423e-bed5-bf505eacaf1a
2023-02-02 20:27:26,073 [f1da6dec-c089-423e-bed5-bf505eacaf1a-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - f1da6dec-c089-423e-bed5-bf505eacaf1a: shutdown f1da6dec-c089-423e-bed5-bf505eacaf1a@group-3EF40F351826-LeaderStateImpl
2023-02-02 20:27:26,073 [f1da6dec-c089-423e-bed5-bf505eacaf1a-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-3EF40F351826-PendingRequests: sendNotLeaderResponses
2023-02-02 20:27:26,079 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - f1da6dec-c089-423e-bed5-bf505eacaf1a: shutdown server GrpcServerProtocolService now
2023-02-02 20:27:26,079 [f1da6dec-c089-423e-bed5-bf505eacaf1a-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA: shutdown
2023-02-02 20:27:26,079 [f1da6dec-c089-423e-bed5-bf505eacaf1a-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DC0F517ADBCA,id=f1da6dec-c089-423e-bed5-bf505eacaf1a
2023-02-02 20:27:26,079 [f1da6dec-c089-423e-bed5-bf505eacaf1a-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - f1da6dec-c089-423e-bed5-bf505eacaf1a: shutdown f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA-LeaderStateImpl
2023-02-02 20:27:26,081 [f1da6dec-c089-423e-bed5-bf505eacaf1a-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA-PendingRequests: sendNotLeaderResponses
2023-02-02 20:27:26,090 [f1da6dec-c089-423e-bed5-bf505eacaf1a-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA-StateMachineUpdater: set stopIndex = 0
2023-02-02 20:27:26,091 [f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-DC0F517ADBCA: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-6/data/ratis/df29b2fb-f8d3-453e-beed-dc0f517adbca/sm/snapshot.1_0
2023-02-02 20:27:26,091 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 2 is synced with bcsId 31.
2023-02-02 20:27:26,091 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 2 is synced with bcsId 31.
2023-02-02 20:27:26,093 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 7d267433-c231-4e32-bff5-417fca1e0c0a Close channels
2023-02-02 20:27:26,094 [f1da6dec-c089-423e-bed5-bf505eacaf1a-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-3EF40F351826-StateMachineUpdater: set stopIndex = 0
2023-02-02 20:27:26,094 [f1da6dec-c089-423e-bed5-bf505eacaf1a@group-3EF40F351826-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-3EF40F351826: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-6/data/ratis/ce8af4f2-acf7-4acc-a9c8-3ef40f351826/sm/snapshot.1_0
2023-02-02 20:27:26,094 [f1da6dec-c089-423e-bed5-bf505eacaf1a@group-3EF40F351826-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-3EF40F351826: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-6/data/ratis/ce8af4f2-acf7-4acc-a9c8-3ef40f351826/sm/snapshot.1_0 took: 0 ms
2023-02-02 20:27:26,095 [f1da6dec-c089-423e-bed5-bf505eacaf1a@group-3EF40F351826-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-3EF40F351826-StateMachineUpdater: Took a snapshot at index 0
2023-02-02 20:27:26,095 [f1da6dec-c089-423e-bed5-bf505eacaf1a@group-3EF40F351826-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-3EF40F351826-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-02 20:27:26,095 [f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-DC0F517ADBCA: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-6/data/ratis/df29b2fb-f8d3-453e-beed-dc0f517adbca/sm/snapshot.1_0 took: 4 ms
2023-02-02 20:27:26,095 [f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA-StateMachineUpdater: Took a snapshot at index 0
2023-02-02 20:27:26,095 [f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-02 20:27:26,096 [f1da6dec-c089-423e-bed5-bf505eacaf1a-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-3EF40F351826: closes. applyIndex: 0
2023-02-02 20:27:26,096 [f1da6dec-c089-423e-bed5-bf505eacaf1a-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA: closes. applyIndex: 0
2023-02-02 20:27:26,096 [f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:26,096 [f1da6dec-c089-423e-bed5-bf505eacaf1a@group-3EF40F351826-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-3EF40F351826-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:26,096 [f1da6dec-c089-423e-bed5-bf505eacaf1a-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-DC0F517ADBCA-SegmentedRaftLogWorker close()
2023-02-02 20:27:26,097 [f1da6dec-c089-423e-bed5-bf505eacaf1a-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - f1da6dec-c089-423e-bed5-bf505eacaf1a@group-3EF40F351826-SegmentedRaftLogWorker close()
2023-02-02 20:27:26,102 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - da4028ad-c56f-4745-a3af-e0a942311a6d Close channels
2023-02-02 20:27:26,102 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - f1da6dec-c089-423e-bed5-bf505eacaf1a: shutdown server GrpcServerProtocolService successfully
2023-02-02 20:27:26,103 [f1da6dec-c089-423e-bed5-bf505eacaf1a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf7855adb, L:/0:0:0:0:0:0:0:0:45749] CLOSE
2023-02-02 20:27:26,103 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 35.
2023-02-02 20:27:26,103 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 35.
2023-02-02 20:27:26,103 [f1da6dec-c089-423e-bed5-bf505eacaf1a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf7855adb, L:/0:0:0:0:0:0:0:0:45749] INACTIVE
2023-02-02 20:27:26,103 [f1da6dec-c089-423e-bed5-bf505eacaf1a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf7855adb, L:/0:0:0:0:0:0:0:0:45749] UNREGISTERED
2023-02-02 20:27:26,106 [Listener at 127.0.0.1/43469] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-02 20:27:26,108 [JvmPauseMonitor32] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-f1da6dec-c089-423e-bed5-bf505eacaf1a: Stopped
2023-02-02 20:27:26,122 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-2C2D94CB32DA: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-3/data/ratis/74626adb-6e97-4dd2-98f3-2c2d94cb32da
2023-02-02 20:27:26,122 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=74626adb-6e97-4dd2-98f3-2c2d94cb32da command on datanode c2e5a0ee-722e-430e-828a-2d735c45daa1.
2023-02-02 20:27:26,124 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 27.
2023-02-02 20:27:26,129 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 27.
2023-02-02 20:27:26,144 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 2 is synced with bcsId 31.
2023-02-02 20:27:26,144 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 2 is synced with bcsId 31.
2023-02-02 20:27:26,148 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 35.
2023-02-02 20:27:26,149 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 35.
2023-02-02 20:27:26,152 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-2C2D94CB32DA: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-5/data/ratis/74626adb-6e97-4dd2-98f3-2c2d94cb32da
2023-02-02 20:27:26,152 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=74626adb-6e97-4dd2-98f3-2c2d94cb32da command on datanode 7153b2e5-6547-4596-92e7-e397d052a5ec.
2023-02-02 20:27:26,189 [Listener at 127.0.0.1/43469] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 60 ms to scan 7 urls, producing 150 keys and 361 values 
2023-02-02 20:27:26,191 [Listener at 127.0.0.1/43469] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-02-02 20:27:26,193 [Listener at 127.0.0.1/43469] INFO  volume.HddsVolume (HddsVolume.java:<init>(117)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-02-02 20:27:26,193 [Listener at 127.0.0.1/43469] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data-0/containers/hdds to VolumeSet
2023-02-02 20:27:26,193 [Listener at 127.0.0.1/43469] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data-0/containers/hdds
2023-02-02 20:27:26,193 [Listener at 127.0.0.1/43469] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data-0/containers/hdds
2023-02-02 20:27:26,204 [Listener at 127.0.0.1/43469] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis to VolumeSet
2023-02-02 20:27:26,204 [Listener at 127.0.0.1/43469] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis
2023-02-02 20:27:26,205 [Listener at 127.0.0.1/43469] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis
2023-02-02 20:27:26,219 [Thread-3164] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data-0/containers/hdds
2023-02-02 20:27:26,219 [Listener at 127.0.0.1/43469] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(304)) - Build ContainerSet costs 0s
2023-02-02 20:27:26,220 [Listener at 127.0.0.1/43469] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-02 20:27:26,221 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:26,221 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-02-02 20:27:26,221 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:26,221 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-02-02 20:27:26,221 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-02 20:27:26,221 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-02-02 20:27:26,221 [Listener at 127.0.0.1/43469] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-02-02 20:27:26,221 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:26,221 [Listener at 127.0.0.1/43469] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-02-02 20:27:26,221 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-02 20:27:26,221 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-02 20:27:26,221 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-02 20:27:26,221 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-02 20:27:26,222 [Listener at 127.0.0.1/43469] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-02-02 20:27:26,222 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-02-02 20:27:26,222 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-02-02 20:27:26,223 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-02-02 20:27:26,223 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-02-02 20:27:26,223 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-02-02 20:27:26,223 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-02-02 20:27:26,223 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-02-02 20:27:26,223 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-02-02 20:27:26,223 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-02-02 20:27:26,223 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-02-02 20:27:26,224 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-02 20:27:26,224 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-02 20:27:26,224 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:26,224 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:26,224 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis] (custom)
2023-02-02 20:27:26,225 [Listener at 127.0.0.1/43469] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-02-02 20:27:26,227 [235120ac-71a1-451e-bf57-c5cd114d9629-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe27fdfca] REGISTERED
2023-02-02 20:27:26,227 [235120ac-71a1-451e-bf57-c5cd114d9629-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe27fdfca] BIND: 0.0.0.0/0.0.0.0:0
2023-02-02 20:27:26,227 [235120ac-71a1-451e-bf57-c5cd114d9629-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe27fdfca, L:/0:0:0:0:0:0:0:0:43003] ACTIVE
2023-02-02 20:27:26,228 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-02-02 20:27:26,228 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-02 20:27:26,229 [Listener at 127.0.0.1/43469] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-02 20:27:26,229 [Listener at 127.0.0.1/43469] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-02 20:27:26,230 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-02 20:27:26,230 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-02-02 20:27:26,231 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-02 20:27:26,231 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-02 20:27:26,231 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 33385
2023-02-02 20:27:26,231 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-02 20:27:26,233 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-02 20:27:26,233 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-02 20:27:26,233 [Listener at 127.0.0.1/43469] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-02-02 20:27:26,233 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6fd42226{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-02 20:27:26,234 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@10335bfa{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-02-02 20:27:26,400 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@11eaf9e4{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-33385-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-4748267115087831141/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-02 20:27:26,404 [Listener at 127.0.0.1/43469] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@6615f6cb{HTTP/1.1, (http/1.1)}{0.0.0.0:33385}
2023-02-02 20:27:26,404 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(415)) - Started @190914ms
2023-02-02 20:27:26,404 [Listener at 127.0.0.1/43469] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-02 20:27:26,405 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:33385
2023-02-02 20:27:26,405 [Listener at 127.0.0.1/43469] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-02 20:27:26,405 [Listener at 127.0.0.1/43469] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-02 20:27:26,406 [Listener at 127.0.0.1/43469] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-02-02 20:27:26,412 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(516)) - Ozone container server started.
2023-02-02 20:27:26,417 [Listener at 127.0.0.1/43469] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(228)) - HddsDatanodeService host:fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net ip:10.1.1.71
2023-02-02 20:27:26,421 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5b1f1a68] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-02 20:27:26,422 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/meta/datanode.id
2023-02-02 20:27:26,434 [Listener at 127.0.0.1/43469] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-02 20:27:26,478 [Listener at 127.0.0.1/43469] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 43 ms to scan 7 urls, producing 150 keys and 361 values 
2023-02-02 20:27:26,479 [Listener at 127.0.0.1/43469] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-02-02 20:27:26,480 [Listener at 127.0.0.1/43469] INFO  volume.HddsVolume (HddsVolume.java:<init>(117)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-02-02 20:27:26,480 [Listener at 127.0.0.1/43469] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data-0/containers/hdds to VolumeSet
2023-02-02 20:27:26,480 [Listener at 127.0.0.1/43469] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data-0/containers/hdds
2023-02-02 20:27:26,481 [Listener at 127.0.0.1/43469] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data-0/containers/hdds
2023-02-02 20:27:26,491 [Listener at 127.0.0.1/43469] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis to VolumeSet
2023-02-02 20:27:26,491 [Listener at 127.0.0.1/43469] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis
2023-02-02 20:27:26,492 [Listener at 127.0.0.1/43469] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis
2023-02-02 20:27:26,502 [Thread-3178] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data-0/containers/hdds
2023-02-02 20:27:26,502 [Listener at 127.0.0.1/43469] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(304)) - Build ContainerSet costs 0s
2023-02-02 20:27:26,503 [Listener at 127.0.0.1/43469] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-02 20:27:26,503 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:26,503 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-02-02 20:27:26,503 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:26,504 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-02-02 20:27:26,504 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-02 20:27:26,504 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-02-02 20:27:26,504 [Listener at 127.0.0.1/43469] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-02-02 20:27:26,504 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:26,504 [Listener at 127.0.0.1/43469] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-02-02 20:27:26,504 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-02 20:27:26,504 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-02 20:27:26,504 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-02 20:27:26,504 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-02 20:27:26,505 [Listener at 127.0.0.1/43469] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-02-02 20:27:26,505 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-02-02 20:27:26,505 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-02-02 20:27:26,505 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-02-02 20:27:26,505 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-02-02 20:27:26,505 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-02-02 20:27:26,505 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-02-02 20:27:26,506 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-02-02 20:27:26,506 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-02-02 20:27:26,506 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-02-02 20:27:26,506 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-02-02 20:27:26,506 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-02 20:27:26,506 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-02 20:27:26,507 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:26,507 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:26,507 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis] (custom)
2023-02-02 20:27:26,507 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x57ea02b7] REGISTERED
2023-02-02 20:27:26,507 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x57ea02b7] BIND: 0.0.0.0/0.0.0.0:0
2023-02-02 20:27:26,507 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x57ea02b7, L:/0:0:0:0:0:0:0:0:40341] ACTIVE
2023-02-02 20:27:26,508 [Listener at 127.0.0.1/43469] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-02-02 20:27:26,510 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-02-02 20:27:26,510 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-02 20:27:26,511 [Listener at 127.0.0.1/43469] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-02 20:27:26,511 [Listener at 127.0.0.1/43469] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-02 20:27:26,512 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-02 20:27:26,512 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-02-02 20:27:26,512 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-02 20:27:26,512 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-02 20:27:26,513 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 36961
2023-02-02 20:27:26,513 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-02 20:27:26,514 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-02 20:27:26,514 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-02 20:27:26,514 [Listener at 127.0.0.1/43469] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-02-02 20:27:26,515 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@68f71eeb{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-02 20:27:26,515 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3e832e3{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-02-02 20:27:26,680 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@66ea2165{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-36961-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-5076269449806500469/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-02 20:27:26,686 [Listener at 127.0.0.1/43469] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@94d1087{HTTP/1.1, (http/1.1)}{0.0.0.0:36961}
2023-02-02 20:27:26,686 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(415)) - Started @191196ms
2023-02-02 20:27:26,686 [Listener at 127.0.0.1/43469] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-02 20:27:26,687 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:36961
2023-02-02 20:27:26,687 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(516)) - Ozone container server started.
2023-02-02 20:27:26,687 [Listener at 127.0.0.1/43469] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-02 20:27:26,687 [Listener at 127.0.0.1/43469] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-02 20:27:26,687 [Listener at 127.0.0.1/43469] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-02-02 20:27:26,698 [Listener at 127.0.0.1/43469] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(228)) - HddsDatanodeService host:fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net ip:10.1.1.71
2023-02-02 20:27:26,704 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5e4cd609] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-02 20:27:26,714 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/meta/datanode.id
2023-02-02 20:27:26,719 [Listener at 127.0.0.1/43469] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-02 20:27:26,751 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data-0/containers/hdds/c5cd579f-3d6e-4979-b5a6-975bd2cf2937/DS-a066fb66-b80f-4db6-8fa6-b979f0fbbfef/container.db to cache
2023-02-02 20:27:26,751 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(307)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data-0/containers/hdds/c5cd579f-3d6e-4979-b5a6-975bd2cf2937/DS-a066fb66-b80f-4db6-8fa6-b979f0fbbfef/container.db for volume DS-a066fb66-b80f-4db6-8fa6-b979f0fbbfef
2023-02-02 20:27:26,751 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(398)) - Attempting to start container services.
2023-02-02 20:27:26,752 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(315)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-02-02 20:27:26,752 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 41407
2023-02-02 20:27:26,756 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis b67f1ce3-fbfb-4e89-9cbc-643abd2f2563
2023-02-02 20:27:26,757 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 7d267433-c231-4e32-bff5-417fca1e0c0a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) moved to stale state. Finalizing its pipelines [PipelineID=df29b2fb-f8d3-453e-beed-dc0f517adbca, PipelineID=1fc60b6e-672d-47cf-a0e1-68da2e7f3d41]
2023-02-02 20:27:26,757 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 1fc60b6e-672d-47cf-a0e1-68da2e7f3d41, Nodes: 7d267433-c231-4e32-bff5-417fca1e0c0a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:7d267433-c231-4e32-bff5-417fca1e0c0a, CreationTimestamp2023-02-02T20:25:37.038Z[Etc/UTC]] moved to CLOSED state
2023-02-02 20:27:26,761 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: start RPC server
2023-02-02 20:27:26,762 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: GrpcService started, listening on 40251
2023-02-02 20:27:26,762 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis b67f1ce3-fbfb-4e89-9cbc-643abd2f2563 is started using port 40251 for RATIS
2023-02-02 20:27:26,762 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis b67f1ce3-fbfb-4e89-9cbc-643abd2f2563 is started using port 40251 for RATIS_ADMIN
2023-02-02 20:27:26,762 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis b67f1ce3-fbfb-4e89-9cbc-643abd2f2563 is started using port 40251 for RATIS_SERVER
2023-02-02 20:27:26,762 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis b67f1ce3-fbfb-4e89-9cbc-643abd2f2563 is started using port 45911 for RATIS_DATASTREAM
2023-02-02 20:27:26,762 [JvmPauseMonitor52] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: Started
2023-02-02 20:27:26,765 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc b67f1ce3-fbfb-4e89-9cbc-643abd2f2563 is started using port 34713
2023-02-02 20:27:26,776 [Listener at 127.0.0.1/43469] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 55 ms to scan 7 urls, producing 150 keys and 361 values 
2023-02-02 20:27:26,777 [Listener at 127.0.0.1/43469] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-02-02 20:27:26,778 [Listener at 127.0.0.1/43469] INFO  volume.HddsVolume (HddsVolume.java:<init>(117)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-02-02 20:27:26,778 [Listener at 127.0.0.1/43469] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data-0/containers/hdds to VolumeSet
2023-02-02 20:27:26,778 [Listener at 127.0.0.1/43469] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data-0/containers/hdds
2023-02-02 20:27:26,779 [Listener at 127.0.0.1/43469] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data-0/containers/hdds
2023-02-02 20:27:26,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:26,790 [Listener at 127.0.0.1/43469] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis to VolumeSet
2023-02-02 20:27:26,790 [Listener at 127.0.0.1/43469] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis
2023-02-02 20:27:26,790 [Listener at 127.0.0.1/43469] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis
2023-02-02 20:27:26,803 [Thread-3198] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data-0/containers/hdds
2023-02-02 20:27:26,803 [Listener at 127.0.0.1/43469] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(304)) - Build ContainerSet costs 0s
2023-02-02 20:27:26,805 [Listener at 127.0.0.1/43469] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-02 20:27:26,805 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:26,805 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-02-02 20:27:26,805 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:26,805 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-02-02 20:27:26,805 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-02 20:27:26,805 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-02-02 20:27:26,805 [Listener at 127.0.0.1/43469] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-02-02 20:27:26,805 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:26,805 [Listener at 127.0.0.1/43469] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-02-02 20:27:26,805 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-02 20:27:26,805 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-02 20:27:26,805 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-02 20:27:26,805 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-02 20:27:26,807 [Listener at 127.0.0.1/43469] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-02-02 20:27:26,807 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-02-02 20:27:26,807 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-02-02 20:27:26,807 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-02-02 20:27:26,807 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-02-02 20:27:26,807 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-02-02 20:27:26,807 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-02-02 20:27:26,807 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-02-02 20:27:26,808 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-02-02 20:27:26,808 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-02-02 20:27:26,808 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-02-02 20:27:26,808 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-02 20:27:26,808 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-02 20:27:26,808 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:26,808 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:26,808 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis] (custom)
2023-02-02 20:27:26,809 [4c73a9f1-7904-4197-8af5-de7b9af59d88-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9460f213] REGISTERED
2023-02-02 20:27:26,809 [4c73a9f1-7904-4197-8af5-de7b9af59d88-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9460f213] BIND: 0.0.0.0/0.0.0.0:0
2023-02-02 20:27:26,810 [Listener at 127.0.0.1/43469] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-02-02 20:27:26,811 [4c73a9f1-7904-4197-8af5-de7b9af59d88-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9460f213, L:/0:0:0:0:0:0:0:0:42537] ACTIVE
2023-02-02 20:27:26,812 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-02-02 20:27:26,812 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-02 20:27:26,813 [Listener at 127.0.0.1/43469] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-02 20:27:26,813 [Listener at 127.0.0.1/43469] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-02 20:27:26,814 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-02 20:27:26,814 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-02-02 20:27:26,814 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-02 20:27:26,814 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-02 20:27:26,815 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 35139
2023-02-02 20:27:26,815 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-02 20:27:26,816 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-02 20:27:26,816 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-02 20:27:26,816 [Listener at 127.0.0.1/43469] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-02-02 20:27:26,817 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7ad997f9{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-02 20:27:26,817 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@70a2376f{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-02-02 20:27:26,820 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) has 3 sufficientlyReplicated, 0 underReplicated and 0 unhealthy containers
2023-02-02 20:27:26,821 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(422)) - Datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) has entered maintenance
2023-02-02 20:27:26,821 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-02 20:27:26,822 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) moved to HEALTHY state.
2023-02-02 20:27:26,822 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:26,822 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=30f6cd70-24a3-46cb-83ea-82e709284854 to datanode:4ec2caad-ead4-478e-ac51-fb863b7de4b5
2023-02-02 20:27:26,822 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=30f6cd70-24a3-46cb-83ea-82e709284854 to datanode:c2e5a0ee-722e-430e-828a-2d735c45daa1
2023-02-02 20:27:26,822 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=30f6cd70-24a3-46cb-83ea-82e709284854 to datanode:7153b2e5-6547-4596-92e7-e397d052a5ec
2023-02-02 20:27:26,823 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 30f6cd70-24a3-46cb-83ea-82e709284854, Nodes: 4ec2caad-ead4-478e-ac51-fb863b7de4b5(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-02T20:27:26.822Z[Etc/UTC]].
2023-02-02 20:27:26,823 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-02-02 20:27:26,988 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@2038ad48{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-35139-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-1396546934226766869/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-02 20:27:26,992 [Listener at 127.0.0.1/43469] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@3a2b8209{HTTP/1.1, (http/1.1)}{0.0.0.0:35139}
2023-02-02 20:27:26,993 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(415)) - Started @191502ms
2023-02-02 20:27:26,993 [Listener at 127.0.0.1/43469] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-02 20:27:26,993 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:35139
2023-02-02 20:27:26,994 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(516)) - Ozone container server started.
2023-02-02 20:27:26,994 [Listener at 127.0.0.1/43469] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-02 20:27:26,994 [Listener at 127.0.0.1/43469] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-02 20:27:26,994 [Listener at 127.0.0.1/43469] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-02-02 20:27:27,002 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@8243e4a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-02 20:27:27,007 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/meta/datanode.id
2023-02-02 20:27:27,008 [Listener at 127.0.0.1/43469] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(228)) - HddsDatanodeService host:fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net ip:10.1.1.71
2023-02-02 20:27:27,019 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:27,019 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:27,019 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:27,027 [Listener at 127.0.0.1/43469] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-02 20:27:27,040 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:27,045 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:27,045 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedHealthy(1181)) - Container #1 is over replicated. Expected replica count is 3, but found 4.
2023-02-02 20:27:27,045 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:deleteExcessWithTopology(2114)) - The container ContainerInfo{id=#1, state=CLOSED, pipelineID=PipelineID=2ef3c4f1-1f5e-43dd-b7b3-7886813f0073, stateEnterTime=2023-02-02T20:26:42.663Z, owner=om1} is over replicated with 1 excess replica. The excess replicas cannot be removed without violating the placement policy
2023-02-02 20:27:27,045 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedHealthy(1181)) - Container #3 is over replicated. Expected replica count is 3, but found 4.
2023-02-02 20:27:27,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:deleteExcessWithTopology(2114)) - The container ContainerInfo{id=#3, state=CLOSED, pipelineID=PipelineID=2ef3c4f1-1f5e-43dd-b7b3-7886813f0073, stateEnterTime=2023-02-02T20:26:43.328Z, owner=om1} is over replicated with 1 excess replica. The excess replicas cannot be removed without violating the placement policy
2023-02-02 20:27:27,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #5 to datanode 7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #5 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #5 to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,046 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-02-02 20:27:27,046 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:27,046 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:27,057 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:27,057 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=3372c4c6-b090-466d-8fa6-bf581edfb67c close command to datanode 7bbfb910-8baa-49a4-be56-632f95348a2c
2023-02-02 20:27:27,057 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 3372c4c6-b090-466d-8fa6-bf581edfb67c, Nodes: 7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:7bbfb910-8baa-49a4-be56-632f95348a2c, CreationTimestamp2023-02-02T20:25:37.847Z[Etc/UTC]] removed.
2023-02-02 20:27:27,057 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=af13c673-fc55-4c7f-bf3e-77ef11360bf9 close command to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04
2023-02-02 20:27:27,058 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=af13c673-fc55-4c7f-bf3e-77ef11360bf9 close command to datanode 7bbfb910-8baa-49a4-be56-632f95348a2c
2023-02-02 20:27:27,058 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=af13c673-fc55-4c7f-bf3e-77ef11360bf9 close command to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb
2023-02-02 20:27:27,058 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: af13c673-fc55-4c7f-bf3e-77ef11360bf9, Nodes: 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)7bbfb910-8baa-49a4-be56-632f95348a2c(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:7bbfb910-8baa-49a4-be56-632f95348a2c, CreationTimestamp2023-02-02T20:25:38.152Z[Etc/UTC]] removed.
2023-02-02 20:27:27,058 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/7bbfb910-8baa-49a4-be56-632f95348a2c
2023-02-02 20:27:27,061 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1113)) - Force closing container #1 with BCSID 27, which is in QUASI_CLOSED state.
2023-02-02 20:27:27,061 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,061 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,061 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,061 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1113)) - Force closing container #2 with BCSID 31, which is in QUASI_CLOSED state.
2023-02-02 20:27:27,061 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,061 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,061 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,061 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1113)) - Force closing container #3 with BCSID 35, which is in QUASI_CLOSED state.
2023-02-02 20:27:27,061 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,061 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,061 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:27,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:27,081 [Listener at 127.0.0.1/43469] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 52 ms to scan 7 urls, producing 150 keys and 361 values 
2023-02-02 20:27:27,082 [Listener at 127.0.0.1/43469] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-02-02 20:27:27,083 [Listener at 127.0.0.1/43469] INFO  volume.HddsVolume (HddsVolume.java:<init>(117)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-02-02 20:27:27,083 [Listener at 127.0.0.1/43469] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data-0/containers/hdds to VolumeSet
2023-02-02 20:27:27,083 [Listener at 127.0.0.1/43469] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data-0/containers/hdds
2023-02-02 20:27:27,084 [Listener at 127.0.0.1/43469] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data-0/containers/hdds
2023-02-02 20:27:27,095 [Listener at 127.0.0.1/43469] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data/ratis to VolumeSet
2023-02-02 20:27:27,095 [Listener at 127.0.0.1/43469] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data/ratis
2023-02-02 20:27:27,095 [Listener at 127.0.0.1/43469] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data/ratis
2023-02-02 20:27:27,098 [IPC Server handler 11 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-02-02 20:27:27,104 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=af13c673-fc55-4c7f-bf3e-77ef11360bf9 is not found
2023-02-02 20:27:27,144 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 27.
2023-02-02 20:27:27,144 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 27.
2023-02-02 20:27:27,157 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 1 is closed with bcsId 27.
2023-02-02 20:27:27,157 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 2 is synced with bcsId 31.
2023-02-02 20:27:27,157 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 2 is synced with bcsId 31.
2023-02-02 20:27:27,158 [IPC Server handler 17 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-02-02 20:27:27,158 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(318)) - Moving container #1 to CLOSED state, datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) reported CLOSED replica.
2023-02-02 20:27:27,160 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 2 is closed with bcsId 31.
2023-02-02 20:27:27,160 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 35.
2023-02-02 20:27:27,160 [IPC Server handler 4 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-02-02 20:27:27,160 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 35.
2023-02-02 20:27:27,161 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(318)) - Moving container #2 to CLOSED state, datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) reported CLOSED replica.
2023-02-02 20:27:27,162 [Thread-3212] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data-0/containers/hdds
2023-02-02 20:27:27,162 [Listener at 127.0.0.1/43469] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(304)) - Build ContainerSet costs 0s
2023-02-02 20:27:27,163 [Listener at 127.0.0.1/43469] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-02 20:27:27,164 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:27,164 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-02-02 20:27:27,164 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-02 20:27:27,164 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-02-02 20:27:27,164 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-02 20:27:27,166 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-02-02 20:27:27,166 [Listener at 127.0.0.1/43469] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-02-02 20:27:27,166 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:27,166 [Listener at 127.0.0.1/43469] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-02-02 20:27:27,166 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-02 20:27:27,166 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-02 20:27:27,166 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-02 20:27:27,166 [Listener at 127.0.0.1/43469] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-02 20:27:27,167 [Listener at 127.0.0.1/43469] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-02-02 20:27:27,168 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-02-02 20:27:27,168 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-02-02 20:27:27,168 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-02-02 20:27:27,168 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-02-02 20:27:27,168 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-02-02 20:27:27,168 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-02-02 20:27:27,168 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-02-02 20:27:27,169 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-02-02 20:27:27,169 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-02-02 20:27:27,169 [Listener at 127.0.0.1/43469] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-02-02 20:27:27,170 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 3 is closed with bcsId 35.
2023-02-02 20:27:27,172 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-02 20:27:27,172 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-02 20:27:27,173 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:27,173 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:27,173 [Listener at 127.0.0.1/43469] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data/ratis] (custom)
2023-02-02 20:27:27,173 [IPC Server handler 8 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-02-02 20:27:27,173 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(318)) - Moving container #3 to CLOSED state, datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) reported CLOSED replica.
2023-02-02 20:27:27,174 [b19954c4-943b-4bda-b8b4-ff98ab071ba2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3b76eaa8] REGISTERED
2023-02-02 20:27:27,175 [b19954c4-943b-4bda-b8b4-ff98ab071ba2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3b76eaa8] BIND: 0.0.0.0/0.0.0.0:0
2023-02-02 20:27:27,175 [b19954c4-943b-4bda-b8b4-ff98ab071ba2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x3b76eaa8, L:/0:0:0:0:0:0:0:0:38999] ACTIVE
2023-02-02 20:27:27,182 [Listener at 127.0.0.1/43469] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-02-02 20:27:27,185 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-02-02 20:27:27,185 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-02 20:27:27,186 [Listener at 127.0.0.1/43469] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-02 20:27:27,187 [Listener at 127.0.0.1/43469] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-02 20:27:27,187 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-02 20:27:27,188 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-02-02 20:27:27,188 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-02 20:27:27,188 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-02 20:27:27,188 [Listener at 127.0.0.1/43469] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 46375
2023-02-02 20:27:27,188 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-02 20:27:27,190 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-02 20:27:27,190 [Listener at 127.0.0.1/43469] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-02 20:27:27,191 [Listener at 127.0.0.1/43469] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-02-02 20:27:27,191 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@615591ad{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-02 20:27:27,191 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6564bafb{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-02-02 20:27:27,257 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. da4028ad-c56f-4745-a3af-e0a942311a6d(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:27,257 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=d98a9ae9-8b06-4231-879a-d9fcbbbaf01d close command to datanode da4028ad-c56f-4745-a3af-e0a942311a6d
2023-02-02 20:27:27,258 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: d98a9ae9-8b06-4231-879a-d9fcbbbaf01d, Nodes: da4028ad-c56f-4745-a3af-e0a942311a6d(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:da4028ad-c56f-4745-a3af-e0a942311a6d, CreationTimestamp2023-02-02T20:25:36.718Z[Etc/UTC]] removed.
2023-02-02 20:27:27,258 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=df29b2fb-f8d3-453e-beed-dc0f517adbca close command to datanode da4028ad-c56f-4745-a3af-e0a942311a6d
2023-02-02 20:27:27,258 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=df29b2fb-f8d3-453e-beed-dc0f517adbca close command to datanode 7d267433-c231-4e32-bff5-417fca1e0c0a
2023-02-02 20:27:27,258 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=df29b2fb-f8d3-453e-beed-dc0f517adbca close command to datanode f1da6dec-c089-423e-bed5-bf505eacaf1a
2023-02-02 20:27:27,258 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: df29b2fb-f8d3-453e-beed-dc0f517adbca, Nodes: da4028ad-c56f-4745-a3af-e0a942311a6d(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)7d267433-c231-4e32-bff5-417fca1e0c0a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)f1da6dec-c089-423e-bed5-bf505eacaf1a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:f1da6dec-c089-423e-bed5-bf505eacaf1a, CreationTimestamp2023-02-02T20:26:51.330Z[Etc/UTC]] removed.
2023-02-02 20:27:27,258 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/da4028ad-c56f-4745-a3af-e0a942311a6d
2023-02-02 20:27:27,367 [Listener at 127.0.0.1/43469] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@2b142ce1{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-46375-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-2669410872309930861/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-02 20:27:27,374 [Listener at 127.0.0.1/43469] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@46eafe6b{HTTP/1.1, (http/1.1)}{0.0.0.0:46375}
2023-02-02 20:27:27,374 [Listener at 127.0.0.1/43469] INFO  server.Server (Server.java:doStart(415)) - Started @191884ms
2023-02-02 20:27:27,374 [Listener at 127.0.0.1/43469] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-02 20:27:27,374 [Listener at 127.0.0.1/43469] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:46375
2023-02-02 20:27:27,375 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-02-02 20:27:27,375 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:27,375 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:27,376 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(516)) - Ozone container server started.
2023-02-02 20:27:27,382 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@609da5b6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-02 20:27:27,386 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data-0/containers/hdds/c5cd579f-3d6e-4979-b5a6-975bd2cf2937/DS-7467c532-8d0e-4459-9004-a67d110b82d9/container.db to cache
2023-02-02 20:27:27,386 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(307)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data-0/containers/hdds/c5cd579f-3d6e-4979-b5a6-975bd2cf2937/DS-7467c532-8d0e-4459-9004-a67d110b82d9/container.db for volume DS-7467c532-8d0e-4459-9004-a67d110b82d9
2023-02-02 20:27:27,386 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(398)) - Attempting to start container services.
2023-02-02 20:27:27,386 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(315)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-02-02 20:27:27,387 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 33693
2023-02-02 20:27:27,391 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9
2023-02-02 20:27:27,392 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/meta/datanode.id
2023-02-02 20:27:27,395 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: start RPC server
2023-02-02 20:27:27,396 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: GrpcService started, listening on 42621
2023-02-02 20:27:27,396 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9 is started using port 42621 for RATIS
2023-02-02 20:27:27,396 [JvmPauseMonitor53] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: Started
2023-02-02 20:27:27,396 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9 is started using port 42621 for RATIS_ADMIN
2023-02-02 20:27:27,396 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9 is started using port 42621 for RATIS_SERVER
2023-02-02 20:27:27,396 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9 is started using port 45109 for RATIS_DATASTREAM
2023-02-02 20:27:27,397 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9 is started using port 42927
2023-02-02 20:27:27,598 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-FollowerState: change to CANDIDATE, lastRpcElapsedTime:8562028882ns, electionTimeout:5006ms
2023-02-02 20:27:27,598 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04: shutdown 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-FollowerState
2023-02-02 20:27:27,598 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9: changes role from  FOLLOWER to CANDIDATE at term 6 for changeToCandidate
2023-02-02 20:27:27,598 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:27,598 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04: start 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126
2023-02-02 20:27:27,601 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9: change Leader from 7bbfb910-8baa-49a4-be56-632f95348a2c to null at term 6 for ELECTION
2023-02-02 20:27:27,602 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126 ELECTION round 0: submit vote requests at term 7 for 0: peers:[7bbfb910-8baa-49a4-be56-632f95348a2c|rpc:10.1.1.71:42895|dataStream:10.1.1.71:34999|priority:1|startupRole:FOLLOWER, 494051a8-4feb-4706-b0a6-36852ae3dccb|rpc:10.1.1.71:37175|dataStream:10.1.1.71:46629|priority:0|startupRole:FOLLOWER, 7b77c47d-ca18-4352-ae6d-9be789fa6a04|rpc:10.1.1.71:34969|dataStream:10.1.1.71:41541|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:27,611 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:27,614 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:27,614 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126: ELECTION REJECTED received 0 response(s) and 2 exception(s):
2023-02-02 20:27:27,614 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:27,614 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-02 20:27:27,614 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126 ELECTION round 0: result REJECTED
2023-02-02 20:27:27,614 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9: changes role from CANDIDATE to FOLLOWER at term 7 for REJECTED
2023-02-02 20:27:27,614 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04: shutdown 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126
2023-02-02 20:27:27,615 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-LeaderElection126] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04: start 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-FollowerState
2023-02-02 20:27:27,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:27,818 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-02 20:27:27,862 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-0/data-0/containers/hdds/a7118d63-fcc7-4683-8210-e0c36487c2ca/DS-27bec211-8d8f-4b71-bb6f-c81dab54b5a1/container.db for volume DS-27bec211-8d8f-4b71-bb6f-c81dab54b5a1
2023-02-02 20:27:27,866 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-02 20:27:27,867 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-02 20:27:27,875 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-02 20:27:27,905 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@6b529d42{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-02 20:27:27,906 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@463a1f47{HTTP/1.1, (http/1.1)}{0.0.0.0:37795}
2023-02-02 20:27:27,906 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-02 20:27:27,916 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@426a4301{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-02 20:27:27,916 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@33bf2602{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-02 20:27:27,919 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-02 20:27:27,920 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04: close
2023-02-02 20:27:27,920 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9: shutdown
2023-02-02 20:27:27,921 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-77EF11360BF9,id=7b77c47d-ca18-4352-ae6d-9be789fa6a04
2023-02-02 20:27:27,921 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04: shutdown 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-FollowerState
2023-02-02 20:27:27,924 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04: shutdown server GrpcServerProtocolService now
2023-02-02 20:27:27,925 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-77EF11360BF9: Taking a snapshot at:(t:6, i:40) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-5/data/ratis/af13c673-fc55-4c7f-bf3e-77ef11360bf9/sm/snapshot.6_40
2023-02-02 20:27:27,924 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-FollowerState was interrupted
2023-02-02 20:27:27,925 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 7bbfb910-8baa-49a4-be56-632f95348a2c Close channels
2023-02-02 20:27:27,926 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 494051a8-4feb-4706-b0a6-36852ae3dccb Close channels
2023-02-02 20:27:27,926 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-StateMachineUpdater: set stopIndex = 40
2023-02-02 20:27:27,926 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04: shutdown server GrpcServerProtocolService successfully
2023-02-02 20:27:27,926 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-B919281D7F33: shutdown
2023-02-02 20:27:27,926 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9159fed1, L:/0:0:0:0:0:0:0:0:41541] CLOSE
2023-02-02 20:27:27,927 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9159fed1, L:/0:0:0:0:0:0:0:0:41541] INACTIVE
2023-02-02 20:27:27,927 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9159fed1, L:/0:0:0:0:0:0:0:0:41541] UNREGISTERED
2023-02-02 20:27:27,927 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-77EF11360BF9: Finished taking a snapshot at:(t:6, i:40) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-5/data/ratis/af13c673-fc55-4c7f-bf3e-77ef11360bf9/sm/snapshot.6_40 took: 2 ms
2023-02-02 20:27:27,928 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-StateMachineUpdater: Took a snapshot at index 40
2023-02-02 20:27:27,928 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 40
2023-02-02 20:27:27,928 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B919281D7F33,id=7b77c47d-ca18-4352-ae6d-9be789fa6a04
2023-02-02 20:27:27,928 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04: shutdown 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-B919281D7F33-LeaderStateImpl
2023-02-02 20:27:27,928 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-B919281D7F33-PendingRequests: sendNotLeaderResponses
2023-02-02 20:27:27,929 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-B919281D7F33-StateMachineUpdater: set stopIndex = 0
2023-02-02 20:27:27,929 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-B919281D7F33-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-B919281D7F33: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-5/data/ratis/27eed19e-2910-4aa1-983e-b919281d7f33/sm/snapshot.1_0
2023-02-02 20:27:27,935 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-B919281D7F33-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-B919281D7F33: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-5/data/ratis/27eed19e-2910-4aa1-983e-b919281d7f33/sm/snapshot.1_0 took: 6 ms
2023-02-02 20:27:27,935 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-B919281D7F33-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-B919281D7F33-StateMachineUpdater: Took a snapshot at index 0
2023-02-02 20:27:27,935 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-B919281D7F33-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-B919281D7F33-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-02 20:27:27,935 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-B919281D7F33: closes. applyIndex: 0
2023-02-02 20:27:27,936 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9: closes. applyIndex: 40
2023-02-02 20:27:27,946 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:27,946 [7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-B919281D7F33-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-B919281D7F33-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:27:27,946 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-77EF11360BF9-SegmentedRaftLogWorker close()
2023-02-02 20:27:27,947 [7b77c47d-ca18-4352-ae6d-9be789fa6a04-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 7b77c47d-ca18-4352-ae6d-9be789fa6a04@group-B919281D7F33-SegmentedRaftLogWorker close()
2023-02-02 20:27:27,948 [JvmPauseMonitor31] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-7b77c47d-ca18-4352-ae6d-9be789fa6a04: Stopped
2023-02-02 20:27:28,014 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data-0/containers/hdds/c5cd579f-3d6e-4979-b5a6-975bd2cf2937/DS-637ec556-a0b8-460c-96b6-2c3cc84aca88/container.db to cache
2023-02-02 20:27:28,014 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(307)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data-0/containers/hdds/c5cd579f-3d6e-4979-b5a6-975bd2cf2937/DS-637ec556-a0b8-460c-96b6-2c3cc84aca88/container.db for volume DS-637ec556-a0b8-460c-96b6-2c3cc84aca88
2023-02-02 20:27:28,015 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(398)) - Attempting to start container services.
2023-02-02 20:27:28,015 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(315)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-02-02 20:27:28,015 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 39543
2023-02-02 20:27:28,019 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:28,019 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:28,019 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:28,019 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis d767bd78-5310-4536-b2f7-e45413a997a1
2023-02-02 20:27:28,029 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - d767bd78-5310-4536-b2f7-e45413a997a1: start RPC server
2023-02-02 20:27:28,029 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - d767bd78-5310-4536-b2f7-e45413a997a1: GrpcService started, listening on 33759
2023-02-02 20:27:28,029 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis d767bd78-5310-4536-b2f7-e45413a997a1 is started using port 33759 for RATIS
2023-02-02 20:27:28,029 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis d767bd78-5310-4536-b2f7-e45413a997a1 is started using port 33759 for RATIS_ADMIN
2023-02-02 20:27:28,029 [JvmPauseMonitor54] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-d767bd78-5310-4536-b2f7-e45413a997a1: Started
2023-02-02 20:27:28,029 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis d767bd78-5310-4536-b2f7-e45413a997a1 is started using port 33759 for RATIS_SERVER
2023-02-02 20:27:28,030 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis d767bd78-5310-4536-b2f7-e45413a997a1 is started using port 36701 for RATIS_DATASTREAM
2023-02-02 20:27:28,031 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc d767bd78-5310-4536-b2f7-e45413a997a1 is started using port 42993
2023-02-02 20:27:28,040 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:28,045 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:28,047 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:28,047 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:28,047 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2249)) - Cannot replicate container #4, no healthy datanodes with replica found.
2023-02-02 20:27:28,047 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #5 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:28,047 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #5 to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:28,047 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:28,047 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:28,047 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-02-02 20:27:28,047 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:28,047 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:28,062 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:28,062 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:28,062 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:28,062 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:28,062 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:28,062 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:28,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:28,121 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - c2e5a0ee-722e-430e-828a-2d735c45daa1: addNew group-82E709284854:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER] returns group-82E709284854:java.util.concurrent.CompletableFuture@6f6733eb[Not completed]
2023-02-02 20:27:28,122 [pool-1635-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - c2e5a0ee-722e-430e-828a-2d735c45daa1: new RaftServerImpl for group-82E709284854:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:28,122 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:28,122 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:28,122 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:28,122 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:28,122 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:28,123 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:28,123 [pool-1635-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854: ConfigurationManager, init=-1: peers:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:28,123 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-3/data/ratis] (custom)
2023-02-02 20:27:28,123 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:28,123 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:28,123 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:28,123 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:28,123 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:28,125 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:28,125 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:28,125 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:28,125 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:28,125 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:28,125 [pool-1635-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-3/data/ratis/30f6cd70-24a3-46cb-83ea-82e709284854 does not exist. Creating ...
2023-02-02 20:27:28,127 [pool-1635-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-3/data/ratis/30f6cd70-24a3-46cb-83ea-82e709284854/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:28,128 [pool-1635-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-3/data/ratis/30f6cd70-24a3-46cb-83ea-82e709284854 has been successfully formatted.
2023-02-02 20:27:28,129 [pool-1635-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-82E709284854: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:28,129 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:28,129 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:28,129 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:28,129 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:28,129 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:28,130 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:28,131 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:28,131 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:28,131 [pool-1635-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-3/data/ratis/30f6cd70-24a3-46cb-83ea-82e709284854
2023-02-02 20:27:28,131 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:28,131 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:28,131 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:28,131 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:28,131 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:28,131 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:28,131 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:28,131 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:28,132 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:28,133 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:28,138 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:28,138 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:28,138 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:28,139 [pool-1635-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:28,139 [pool-1635-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:28,139 [pool-1635-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854: start as a follower, conf=-1: peers:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:28,139 [pool-1635-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:28,139 [pool-1635-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c2e5a0ee-722e-430e-828a-2d735c45daa1: start c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-FollowerState
2023-02-02 20:27:28,139 [pool-1635-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-82E709284854,id=c2e5a0ee-722e-430e-828a-2d735c45daa1
2023-02-02 20:27:28,139 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:28,139 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:28,139 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:28,139 [pool-1635-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:28,140 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:28,140 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:28,140 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=30f6cd70-24a3-46cb-83ea-82e709284854
2023-02-02 20:27:28,145 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-6/data-0/containers/hdds/a7118d63-fcc7-4683-8210-e0c36487c2ca/DS-37c21820-a570-431e-93cb-9c2f5fc11053/container.db for volume DS-37c21820-a570-431e-93cb-9c2f5fc11053
2023-02-02 20:27:28,145 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-02 20:27:28,147 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-02 20:27:28,148 [grpc-default-executor-9] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5: addNew group-82E709284854:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER] returns group-82E709284854:java.util.concurrent.CompletableFuture@41377f19[Not completed]
2023-02-02 20:27:28,151 [pool-1705-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5: new RaftServerImpl for group-82E709284854:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:28,151 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:28,151 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:28,151 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:28,151 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:28,151 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:28,151 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:28,151 [pool-1705-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854: ConfigurationManager, init=-1: peers:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:28,151 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-6/data/ratis] (custom)
2023-02-02 20:27:28,152 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:28,152 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:28,152 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:28,152 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:28,152 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:28,151 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 7153b2e5-6547-4596-92e7-e397d052a5ec: addNew group-82E709284854:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER] returns group-82E709284854:java.util.concurrent.CompletableFuture@6d88336[Not completed]
2023-02-02 20:27:28,153 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-02 20:27:28,152 [pool-1683-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 7153b2e5-6547-4596-92e7-e397d052a5ec: new RaftServerImpl for group-82E709284854:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:28,154 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:28,154 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:28,154 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:28,154 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:28,154 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:28,154 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:28,154 [pool-1683-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854: ConfigurationManager, init=-1: peers:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:28,154 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-5/data/ratis] (custom)
2023-02-02 20:27:28,154 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:28,154 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:28,154 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:28,154 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:28,154 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:28,173 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:28,173 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:28,173 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:28,173 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:28,173 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:28,173 [pool-1705-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-6/data/ratis/30f6cd70-24a3-46cb-83ea-82e709284854 does not exist. Creating ...
2023-02-02 20:27:28,174 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:28,174 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:28,174 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:28,174 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:28,174 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:28,174 [pool-1683-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-5/data/ratis/30f6cd70-24a3-46cb-83ea-82e709284854 does not exist. Creating ...
2023-02-02 20:27:28,175 [pool-1705-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-6/data/ratis/30f6cd70-24a3-46cb-83ea-82e709284854/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:28,176 [pool-1683-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-5/data/ratis/30f6cd70-24a3-46cb-83ea-82e709284854/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:28,176 [pool-1705-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-6/data/ratis/30f6cd70-24a3-46cb-83ea-82e709284854 has been successfully formatted.
2023-02-02 20:27:28,177 [pool-1705-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-82E709284854: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:28,177 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:28,178 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:28,178 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:28,178 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:28,178 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:28,178 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:28,178 [pool-1683-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-5/data/ratis/30f6cd70-24a3-46cb-83ea-82e709284854 has been successfully formatted.
2023-02-02 20:27:28,179 [pool-1683-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-82E709284854: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:28,179 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:28,179 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:28,180 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:28,180 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:28,180 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:28,180 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:28,180 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:28,180 [pool-1705-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-6/data/ratis/30f6cd70-24a3-46cb-83ea-82e709284854
2023-02-02 20:27:28,180 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:28,180 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:28,180 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:28,180 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:28,181 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:28,181 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:28,181 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:28,181 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:28,181 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:28,183 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:28,183 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:28,181 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:28,185 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:28,185 [pool-1683-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-5/data/ratis/30f6cd70-24a3-46cb-83ea-82e709284854
2023-02-02 20:27:28,185 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:28,185 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:28,185 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:28,185 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:28,185 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:28,185 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:28,185 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:28,185 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:28,186 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:28,187 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:28,187 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@194d1b85{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-02 20:27:28,187 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@768cb9b4{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-02 20:27:28,188 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-02 20:27:28,188 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7a51ec7a{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-02 20:27:28,188 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@a2e76b8{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-02 20:27:28,194 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:28,194 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:28,195 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:28,195 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:28,195 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:28,204 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:28,204 [pool-1705-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:28,204 [pool-1705-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:28,204 [pool-1705-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854: start as a follower, conf=-1: peers:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:28,204 [pool-1705-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:28,204 [pool-1705-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5: start 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-FollowerState
2023-02-02 20:27:28,205 [4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:28,205 [pool-1705-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-82E709284854,id=4ec2caad-ead4-478e-ac51-fb863b7de4b5
2023-02-02 20:27:28,205 [4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:28,205 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:28,205 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:28,205 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:28,205 [pool-1705-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:28,211 [pool-1683-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:28,211 [pool-1683-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:28,212 [pool-1683-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854: start as a follower, conf=-1: peers:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:28,212 [pool-1683-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:28,212 [pool-1683-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7153b2e5-6547-4596-92e7-e397d052a5ec: start 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-FollowerState
2023-02-02 20:27:28,212 [pool-1683-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-82E709284854,id=7153b2e5-6547-4596-92e7-e397d052a5ec
2023-02-02 20:27:28,212 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:28,212 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:28,212 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:28,212 [pool-1683-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:28,213 [7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:28,213 [7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:28,213 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=30f6cd70-24a3-46cb-83ea-82e709284854
2023-02-02 20:27:28,237 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=30f6cd70-24a3-46cb-83ea-82e709284854.
2023-02-02 20:27:28,261 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode f1da6dec-c089-423e-bed5-bf505eacaf1a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) moved to stale state. Finalizing its pipelines [PipelineID=ce8af4f2-acf7-4acc-a9c8-3ef40f351826]
2023-02-02 20:27:28,262 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: ce8af4f2-acf7-4acc-a9c8-3ef40f351826, Nodes: f1da6dec-c089-423e-bed5-bf505eacaf1a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:f1da6dec-c089-423e-bed5-bf505eacaf1a, CreationTimestamp2023-02-02T20:25:38.510Z[Etc/UTC]] moved to CLOSED state
2023-02-02 20:27:28,263 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 27.
2023-02-02 20:27:28,263 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 27.
2023-02-02 20:27:28,265 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 1 is closed with bcsId 27.
2023-02-02 20:27:28,265 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 2 is synced with bcsId 31.
2023-02-02 20:27:28,265 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 2 is synced with bcsId 31.
2023-02-02 20:27:28,266 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 2 is closed with bcsId 31.
2023-02-02 20:27:28,267 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 35.
2023-02-02 20:27:28,267 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 35.
2023-02-02 20:27:28,268 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 3 is closed with bcsId 35.
2023-02-02 20:27:28,272 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=30f6cd70-24a3-46cb-83ea-82e709284854.
2023-02-02 20:27:28,287 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:restartStorageContainerManager(351)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneClusterImpl
2023-02-02 20:27:28,287 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1535)) - Container Balancer is not running.
2023-02-02 20:27:28,287 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1542)) - Stopping Replication Manager Service.
2023-02-02 20:27:28,288 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(294)) - Stopping Replication Monitor Thread.
2023-02-02 20:27:28,288 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(142)) - Under Replicated Processor interrupted. Exiting...
2023-02-02 20:27:28,288 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(142)) - Over Replicated Processor interrupted. Exiting...
2023-02-02 20:27:28,293 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1549)) - Stopping the Datanode Admin Monitor.
2023-02-02 20:27:28,293 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1556)) - Stopping datanode service RPC server
2023-02-02 20:27:28,293 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(441)) - Stopping the RPC server for DataNodes
2023-02-02 20:27:28,297 [main] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 37573
2023-02-02 20:27:28,300 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(671)) - Replication Monitor Thread is stopped
2023-02-02 20:27:28,300 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 27.
2023-02-02 20:27:28,300 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 27.
2023-02-02 20:27:28,305 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-02 20:27:28,305 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-02 20:27:28,311 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 1 is closed with bcsId 27.
2023-02-02 20:27:28,311 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 2 is synced with bcsId 31.
2023-02-02 20:27:28,312 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 2 is synced with bcsId 31.
2023-02-02 20:27:28,314 [EndpointStateMachine task thread for /0.0.0.0:37573 - 0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(242)) - Unable to communicate to SCM server at 0.0.0.0:37573 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "fv-az133-962/10.1.1.71"; destination host is: "0.0.0.0":37573; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
	at com.sun.proxy.$Proxy54.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:149)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:185)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:87)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
2023-02-02 20:27:28,324 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 2 is closed with bcsId 31.
2023-02-02 20:27:28,324 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 35.
2023-02-02 20:27:28,325 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 35.
2023-02-02 20:27:28,328 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 3 is closed with bcsId 35.
2023-02-02 20:27:28,361 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-02-02 20:27:28,361 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1564)) - Stopping block service RPC server
2023-02-02 20:27:28,361 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-02-02 20:27:28,365 [main] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 37773
2023-02-02 20:27:28,377 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-02 20:27:28,379 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1571)) - Stopping the StorageContainerLocationProtocol RPC server
2023-02-02 20:27:28,380 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(179)) - Stopping the RPC server for Client Protocol
2023-02-02 20:27:28,380 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-02-02 20:27:28,380 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-02 20:27:28,380 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:28,380 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:28,382 [main] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 35129
2023-02-02 20:27:28,387 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-02 20:27:28,389 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1578)) - Stopping Storage Container Manager HTTP server.
2023-02-02 20:27:28,390 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@46af0e7b{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-02-02 20:27:28,390 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-02 20:27:28,391 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@6bf7f45f{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-02 20:27:28,391 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-02 20:27:28,391 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@9ee9bea{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-02-02 20:27:28,391 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@71db395b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-02 20:27:28,393 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1584)) - Stopping SCM LayoutVersionManager Service.
2023-02-02 20:27:28,393 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1592)) - Stopping Block Manager Service.
2023-02-02 20:27:28,393 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-02 20:27:28,394 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-02 20:27:28,394 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1614)) - Stopping SCM Event Queue.
2023-02-02 20:27:28,397 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1625)) - Stopping SCM HA services.
2023-02-02 20:27:28,397 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-02-02 20:27:28,398 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-02-02 20:27:28,398 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-02-02 20:27:28,398 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-02-02 20:27:28,398 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2023-02-02 20:27:28,410 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2023-02-02 20:27:28,410 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2023-02-02 20:27:28,411 [main] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-02-02 20:27:28,411 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-02-02 20:27:28,411 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-02-02 20:27:28,411 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-02-02 20:27:28,411 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-02 20:27:28,411 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(302)) - Replication Monitor Thread is not running.
2023-02-02 20:27:28,411 [main] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(322)) - Cannot stop Container Balancer because it's not running or stopping
2023-02-02 20:27:28,412 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1643)) - Stopping SCM MetadataStore.
2023-02-02 20:27:28,414 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-02 20:27:28,414 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-02-02 20:27:28,414 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-02-02 20:27:28,415 [main] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-02 20:27:28,415 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-02 20:27:28,458 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data-0/containers/hdds/c5cd579f-3d6e-4979-b5a6-975bd2cf2937/DS-f357abac-a72b-4c43-8496-28cbdcb19d1b/container.db to cache
2023-02-02 20:27:28,458 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(307)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data-0/containers/hdds/c5cd579f-3d6e-4979-b5a6-975bd2cf2937/DS-f357abac-a72b-4c43-8496-28cbdcb19d1b/container.db for volume DS-f357abac-a72b-4c43-8496-28cbdcb19d1b
2023-02-02 20:27:28,458 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(398)) - Attempting to start container services.
2023-02-02 20:27:28,459 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(315)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-02-02 20:27:28,459 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 34893
2023-02-02 20:27:28,463 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 235120ac-71a1-451e-bf57-c5cd114d9629
2023-02-02 20:27:28,463 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 541b5aca-8ce5-47d9-adc3-7e41c6e3e253(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) moved to stale state. Finalizing its pipelines [PipelineID=439db6e8-c3e9-465a-9f3a-29a66540d36b]
2023-02-02 20:27:28,464 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 439db6e8-c3e9-465a-9f3a-29a66540d36b, Nodes: 541b5aca-8ce5-47d9-adc3-7e41c6e3e253(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:541b5aca-8ce5-47d9-adc3-7e41c6e3e253, CreationTimestamp2023-02-02T20:27:19.460Z[Etc/UTC]] moved to CLOSED state
2023-02-02 20:27:28,465 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-02-02 20:27:28,465 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-02-02 20:27:28,468 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-02 20:27:28,484 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 235120ac-71a1-451e-bf57-c5cd114d9629: start RPC server
2023-02-02 20:27:28,486 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 235120ac-71a1-451e-bf57-c5cd114d9629: GrpcService started, listening on 36259
2023-02-02 20:27:28,491 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 235120ac-71a1-451e-bf57-c5cd114d9629 is started using port 36259 for RATIS
2023-02-02 20:27:28,491 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 235120ac-71a1-451e-bf57-c5cd114d9629 is started using port 36259 for RATIS_ADMIN
2023-02-02 20:27:28,492 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 235120ac-71a1-451e-bf57-c5cd114d9629 is started using port 36259 for RATIS_SERVER
2023-02-02 20:27:28,492 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 235120ac-71a1-451e-bf57-c5cd114d9629 is started using port 43003 for RATIS_DATASTREAM
2023-02-02 20:27:28,492 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 235120ac-71a1-451e-bf57-c5cd114d9629 is started using port 46053
2023-02-02 20:27:28,493 [JvmPauseMonitor55] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-235120ac-71a1-451e-bf57-c5cd114d9629: Started
2023-02-02 20:27:28,519 [main] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 50 ms to scan 7 urls, producing 150 keys and 361 values 
2023-02-02 20:27:28,521 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-02-02 20:27:28,522 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(149)) - Entering startup safe mode.
2023-02-02 20:27:28,522 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-02-02 20:27:28,523 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-02-02 20:27:28,524 [main] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-02-02 20:27:28,524 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-02-02 20:27:28,525 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-02-02 20:27:28,525 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-02-02 20:27:28,526 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-02-02 20:27:28,526 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-02-02 20:27:28,526 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-02-02 20:27:28,528 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-02-02 20:27:28,529 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-02-02 20:27:28,530 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-02-02 20:27:28,530 [main] INFO  replication.ReplicationManager (ReplicationManager.java:start(263)) - Starting Replication Monitor Thread.
2023-02-02 20:27:28,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:28,535 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-02-02 20:27:28,536 [main] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 3
2023-02-02 20:27:28,536 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 1, healthy pipeline threshold count is 1
2023-02-02 20:27:28,536 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 1, pipeline's with at least one datanode reported threshold count is 1
2023-02-02 20:27:28,537 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-02 20:27:28,537 [Socket Reader #1 for port 37573] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 37573
2023-02-02 20:27:28,541 [Listener at 0.0.0.0/37573] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-02 20:27:28,542 [Socket Reader #1 for port 37773] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 37773
2023-02-02 20:27:28,544 [Listener at 0.0.0.0/37773] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-02 20:27:28,545 [Socket Reader #1 for port 35129] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 35129
2023-02-02 20:27:28,548 [Listener at 0.0.0.0/35129] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-02-02 20:27:28,564 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(401)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-02-02 20:27:28,564 [Listener at 0.0.0.0/35129] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-02-02 20:27:28,565 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1440)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:35129
2023-02-02 20:27:28,566 [Listener at 0.0.0.0/35129] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2023-02-02 20:27:28,567 [Listener at 0.0.0.0/35129] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2023-02-02 20:27:28,567 [Listener at 0.0.0.0/35129] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2023-02-02 20:27:28,590 [Listener at 0.0.0.0/35129] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2023-02-02 20:27:28,590 [Listener at 0.0.0.0/35129] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2023-02-02 20:27:28,645 [Listener at 0.0.0.0/35129] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(170)) - RPC server for Client  is listening at /0.0.0.0:35129
2023-02-02 20:27:28,645 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-02 20:27:28,645 [IPC Server listener on 35129] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 35129: starting
2023-02-02 20:27:28,660 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1454)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:37773
2023-02-02 20:27:28,661 [Listener at 0.0.0.0/35129] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:37773
2023-02-02 20:27:28,661 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-02 20:27:28,661 [IPC Server listener on 37773] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 37773: starting
2023-02-02 20:27:28,662 [Listener at 0.0.0.0/35129] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:37573
2023-02-02 20:27:28,663 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-02 20:27:28,663 [IPC Server listener on 37573] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 37573: starting
2023-02-02 20:27:28,673 [Listener at 0.0.0.0/35129] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for scm at: http://0.0.0.0:37403
2023-02-02 20:27:28,673 [Listener at 0.0.0.0/35129] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-02 20:27:28,674 [Listener at 0.0.0.0/35129] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-02 20:27:28,675 [Listener at 0.0.0.0/35129] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-02 20:27:28,675 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5354bfce] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-02 20:27:28,676 [Listener at 0.0.0.0/35129] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-02 20:27:28,676 [Listener at 0.0.0.0/35129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-02-02 20:27:28,676 [Listener at 0.0.0.0/35129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-02 20:27:28,676 [Listener at 0.0.0.0/35129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-02 20:27:28,677 [Listener at 0.0.0.0/35129] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 37403
2023-02-02 20:27:28,677 [Listener at 0.0.0.0/35129] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-02 20:27:28,678 [Listener at 0.0.0.0/35129] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-02 20:27:28,678 [Listener at 0.0.0.0/35129] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-02 20:27:28,678 [Listener at 0.0.0.0/35129] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-02-02 20:27:28,679 [Listener at 0.0.0.0/35129] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3df681cc{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-02 20:27:28,679 [Listener at 0.0.0.0/35129] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2fbd47b7{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-02-02 20:27:28,686 [Listener at 0.0.0.0/35129] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@5e94947e{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-02-02 20:27:28,689 [Listener at 0.0.0.0/35129] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@1892865f{HTTP/1.1, (http/1.1)}{0.0.0.0:37403}
2023-02-02 20:27:28,689 [Listener at 0.0.0.0/35129] INFO  server.Server (Server.java:doStart(415)) - Started @193199ms
2023-02-02 20:27:28,690 [Listener at 0.0.0.0/35129] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-02 20:27:28,690 [Listener at 0.0.0.0/35129] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of scm listening at http://0.0.0.0:37403
2023-02-02 20:27:28,690 [Listener at 0.0.0.0/35129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-02-02 20:27:28,690 [Listener at 0.0.0.0/35129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:28,690 [Listener at 0.0.0.0/35129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:28,709 [IPC Server handler 3 on default port 41201] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/b67f1ce3-fbfb-4e89-9cbc-643abd2f2563
2023-02-02 20:27:28,710 [IPC Server handler 3 on default port 41201] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : b67f1ce3-fbfb-4e89-9cbc-643abd2f2563{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=41407, RATIS=40251, RATIS_ADMIN=40251, RATIS_SERVER=40251, RATIS_DATASTREAM=45911, STANDALONE=34713], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:28,723 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-02-02 20:27:28,723 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-02-02 20:27:28,726 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-02-02 20:27:28,729 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:28,729 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=1de3754f-9ce0-45a5-aa58-1016d399c608 to datanode:b67f1ce3-fbfb-4e89-9cbc-643abd2f2563
2023-02-02 20:27:28,730 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 1de3754f-9ce0-45a5-aa58-1016d399c608, Nodes: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-02T20:27:28.729Z[Etc/UTC]].
2023-02-02 20:27:28,761 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data-0/containers/hdds/c5cd579f-3d6e-4979-b5a6-975bd2cf2937/DS-3e0f5b78-9ca0-49fd-849d-8201baa8d79d/container.db to cache
2023-02-02 20:27:28,761 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(307)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data-0/containers/hdds/c5cd579f-3d6e-4979-b5a6-975bd2cf2937/DS-3e0f5b78-9ca0-49fd-849d-8201baa8d79d/container.db for volume DS-3e0f5b78-9ca0-49fd-849d-8201baa8d79d
2023-02-02 20:27:28,761 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(398)) - Attempting to start container services.
2023-02-02 20:27:28,761 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(315)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-02-02 20:27:28,762 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 35859
2023-02-02 20:27:28,765 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29
2023-02-02 20:27:28,779 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: start RPC server
2023-02-02 20:27:28,779 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: GrpcService started, listening on 46223
2023-02-02 20:27:28,779 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29 is started using port 46223 for RATIS
2023-02-02 20:27:28,779 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29 is started using port 46223 for RATIS_ADMIN
2023-02-02 20:27:28,779 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29 is started using port 46223 for RATIS_SERVER
2023-02-02 20:27:28,780 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29 is started using port 40341 for RATIS_DATASTREAM
2023-02-02 20:27:28,780 [JvmPauseMonitor56] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: Started
2023-02-02 20:27:28,780 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29 is started using port 42867
2023-02-02 20:27:28,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:29,019 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(322)) - Cannot proceed for EC container reconstruction for #8, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {5=(ContainerReplica{containerID=#8, state=CLOSED, datanodeDetails=7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), placeOfBirth=7b77c47d-ca18-4352-ae6d-9be789fa6a04, sequenceId=0, keyCount=5, bytesUsed=95,replicaIndex=5},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-02-02 20:27:29,019 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(220)) - Container #8 is under replicated, but no commands were created to correct it
2023-02-02 20:27:29,020 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(322)) - Cannot proceed for EC container reconstruction for #11, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {1=(ContainerReplica{containerID=#11, state=CLOSED, datanodeDetails=7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), placeOfBirth=7b77c47d-ca18-4352-ae6d-9be789fa6a04, sequenceId=0, keyCount=4, bytesUsed=76,replicaIndex=1},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-02-02 20:27:29,020 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(220)) - Container #11 is under replicated, but no commands were created to correct it
2023-02-02 20:27:29,020 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(322)) - Cannot proceed for EC container reconstruction for #10, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 0. Available sources are: {}
2023-02-02 20:27:29,020 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(220)) - Container #10 is under replicated, but no commands were created to correct it
2023-02-02 20:27:29,020 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(322)) - Cannot proceed for EC container reconstruction for #9, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {5=(ContainerReplica{containerID=#9, state=CLOSED, datanodeDetails=7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), placeOfBirth=7b77c47d-ca18-4352-ae6d-9be789fa6a04, sequenceId=0, keyCount=4, bytesUsed=76,replicaIndex=5},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-02-02 20:27:29,020 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(220)) - Container #9 is under replicated, but no commands were created to correct it
2023-02-02 20:27:29,020 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(322)) - Cannot proceed for EC container reconstruction for #7, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {2=(ContainerReplica{containerID=#7, state=CLOSED, datanodeDetails=7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), placeOfBirth=7b77c47d-ca18-4352-ae6d-9be789fa6a04, sequenceId=0, keyCount=3, bytesUsed=0,replicaIndex=2},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-02-02 20:27:29,020 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(220)) - Container #7 is under replicated, but no commands were created to correct it
2023-02-02 20:27:29,020 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 5 containers with health state counts {UNDER_REPLICATED=5},failed processing 0
2023-02-02 20:27:29,020 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:29,034 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data-0/containers/hdds/c5cd579f-3d6e-4979-b5a6-975bd2cf2937/DS-c9e5aa54-243b-4446-8b99-43fc305a2459/container.db to cache
2023-02-02 20:27:29,034 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(307)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data-0/containers/hdds/c5cd579f-3d6e-4979-b5a6-975bd2cf2937/DS-c9e5aa54-243b-4446-8b99-43fc305a2459/container.db for volume DS-c9e5aa54-243b-4446-8b99-43fc305a2459
2023-02-02 20:27:29,035 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(398)) - Attempting to start container services.
2023-02-02 20:27:29,035 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(315)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-02-02 20:27:29,035 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 39337
2023-02-02 20:27:29,039 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 4c73a9f1-7904-4197-8af5-de7b9af59d88
2023-02-02 20:27:29,040 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:29,047 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: start RPC server
2023-02-02 20:27:29,048 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:29,048 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #2 to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:29,048 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2249)) - Cannot replicate container #4, no healthy datanodes with replica found.
2023-02-02 20:27:29,048 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #5 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:29,048 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #5 to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:29,048 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 7b77c47d-ca18-4352-ae6d-9be789fa6a04(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:29,048 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71).
2023-02-02 20:27:29,048 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: GrpcService started, listening on 46827
2023-02-02 20:27:29,049 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-02-02 20:27:29,049 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 4c73a9f1-7904-4197-8af5-de7b9af59d88 is started using port 46827 for RATIS
2023-02-02 20:27:29,049 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 4c73a9f1-7904-4197-8af5-de7b9af59d88 is started using port 46827 for RATIS_ADMIN
2023-02-02 20:27:29,049 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 4c73a9f1-7904-4197-8af5-de7b9af59d88 is started using port 46827 for RATIS_SERVER
2023-02-02 20:27:29,049 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 4c73a9f1-7904-4197-8af5-de7b9af59d88 is started using port 42537 for RATIS_DATASTREAM
2023-02-02 20:27:29,049 [JvmPauseMonitor57] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-4c73a9f1-7904-4197-8af5-de7b9af59d88: Started
2023-02-02 20:27:29,050 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 4c73a9f1-7904-4197-8af5-de7b9af59d88 is started using port 46061
2023-02-02 20:27:29,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-02-02 20:27:29,051 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:29,066 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:29,066 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=76a82bb3-0402-4c7b-be7a-848a906c6ca1 close command to datanode 494051a8-4feb-4706-b0a6-36852ae3dccb
2023-02-02 20:27:29,066 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 76a82bb3-0402-4c7b-be7a-848a906c6ca1, Nodes: 494051a8-4feb-4706-b0a6-36852ae3dccb(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:494051a8-4feb-4706-b0a6-36852ae3dccb, CreationTimestamp2023-02-02T20:25:37.419Z[Etc/UTC]] removed.
2023-02-02 20:27:29,066 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/494051a8-4feb-4706-b0a6-36852ae3dccb
2023-02-02 20:27:29,327 [EndpointStateMachine task thread for /0.0.0.0:37573 - 0 ] INFO  ipc.Client (Client.java:handleConnectionFailure(1010)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37573. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2023-02-02 20:27:29,339 [IPC Server handler 0 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:29,339 [IPC Server handler 1 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:29,340 [IPC Server handler 2 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:29,340 [IPC Server handler 0 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 4ec2caad-ead4-478e-ac51-fb863b7de4b5(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:29,350 [IPC Server handler 3 on default port 41201] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/78962ee0-dad8-4871-bc4b-e1f0b96bf3d9
2023-02-02 20:27:29,350 [IPC Server handler 3 on default port 41201] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=33693, RATIS=42621, RATIS_ADMIN=42621, RATIS_SERVER=42621, RATIS_DATASTREAM=45109, STANDALONE=42927], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:29,350 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:29,351 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=9a11209b-2cb2-422e-bd22-2e6a8faa1ac2 to datanode:78962ee0-dad8-4871-bc4b-e1f0b96bf3d9
2023-02-02 20:27:29,351 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 9a11209b-2cb2-422e-bd22-2e6a8faa1ac2, Nodes: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-02T20:27:29.351Z[Etc/UTC]].
2023-02-02 20:27:29,352 [IPC Server handler 4 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 5b8e2765-a6c1-4d85-87a6-bec4168f79ce(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:29,352 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(207)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:321)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.get(FutureTask.java:205)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2023-02-02 20:27:29,356 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-02-02 20:27:29,357 [IPC Server handler 5 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode ef8775a4-4a62-450d-ae4d-a3eaa392aaf8(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:29,359 [IPC Server handler 6 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 3f7ac4d1-ddb9-474a-8f73-3a04b1780a60(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:29,359 [IPC Server handler 7 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:29,360 [IPC Server handler 8 on default port 37573] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/7153b2e5-6547-4596-92e7-e397d052a5ec
2023-02-02 20:27:29,360 [IPC Server handler 8 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 7153b2e5-6547-4596-92e7-e397d052a5ec{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=33391, RATIS=33067, RATIS_ADMIN=33067, RATIS_SERVER=33067, RATIS_DATASTREAM=41865, STANDALONE=43301], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:29,382 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 2 of 7 DN Heartbeats.
2023-02-02 20:27:29,382 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:29,382 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:29,382 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:29,383 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-02-02 20:27:29,385 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 100.0 % containers have at least one reported replica.
2023-02-02 20:27:29,385 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-02-02 20:27:29,386 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 1
2023-02-02 20:27:29,406 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:29,417 [IPC Server handler 9 on default port 37573] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/ef8775a4-4a62-450d-ae4d-a3eaa392aaf8
2023-02-02 20:27:29,417 [IPC Server handler 9 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : ef8775a4-4a62-450d-ae4d-a3eaa392aaf8{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=45915, RATIS=33485, RATIS_ADMIN=33485, RATIS_SERVER=33485, RATIS_DATASTREAM=39369, STANDALONE=36617], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:29,420 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:29,420 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-02-02 20:27:29,420 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 1
2023-02-02 20:27:29,420 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:29,421 [IPC Server handler 10 on default port 37573] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/3f7ac4d1-ddb9-474a-8f73-3a04b1780a60
2023-02-02 20:27:29,421 [IPC Server handler 10 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 3f7ac4d1-ddb9-474a-8f73-3a04b1780a60{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=33869, RATIS=33907, RATIS_ADMIN=33907, RATIS_SERVER=33907, RATIS_DATASTREAM=40869, STANDALONE=43321], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:29,421 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:29,422 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-02-02 20:27:29,422 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:29,424 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-02-02 20:27:29,424 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-02-02 20:27:29,424 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-02-02 20:27:29,424 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-02-02 20:27:29,424 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:29,430 [IPC Server handler 11 on default port 37573] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/5b8e2765-a6c1-4d85-87a6-bec4168f79ce
2023-02-02 20:27:29,430 [IPC Server handler 11 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 5b8e2765-a6c1-4d85-87a6-bec4168f79ce{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=35361, RATIS=45251, RATIS_ADMIN=45251, RATIS_SERVER=45251, RATIS_DATASTREAM=44061, STANDALONE=42465], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:29,431 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:29,431 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:29,431 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-02-02 20:27:29,431 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-02-02 20:27:29,431 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-02-02 20:27:29,431 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-02-02 20:27:29,431 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-02-02 20:27:29,431 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-02-02 20:27:29,431 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-02-02 20:27:29,431 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-02-02 20:27:29,431 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(937)) - Service ReplicationManager transitions to RUNNING.
2023-02-02 20:27:29,431 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-02-02 20:27:29,437 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data-0/containers/hdds/c5cd579f-3d6e-4979-b5a6-975bd2cf2937/DS-ebf08c2b-a8fb-47b7-a128-1d8ca2b65630/container.db to cache
2023-02-02 20:27:29,438 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(307)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data-0/containers/hdds/c5cd579f-3d6e-4979-b5a6-975bd2cf2937/DS-ebf08c2b-a8fb-47b7-a128-1d8ca2b65630/container.db for volume DS-ebf08c2b-a8fb-47b7-a128-1d8ca2b65630
2023-02-02 20:27:29,438 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(398)) - Attempting to start container services.
2023-02-02 20:27:29,440 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(315)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-02-02 20:27:29,442 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 37879
2023-02-02 20:27:29,444 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis b19954c4-943b-4bda-b8b4-ff98ab071ba2
2023-02-02 20:27:29,449 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2: start RPC server
2023-02-02 20:27:29,449 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2: GrpcService started, listening on 41919
2023-02-02 20:27:29,450 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis b19954c4-943b-4bda-b8b4-ff98ab071ba2 is started using port 41919 for RATIS
2023-02-02 20:27:29,450 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis b19954c4-943b-4bda-b8b4-ff98ab071ba2 is started using port 41919 for RATIS_ADMIN
2023-02-02 20:27:29,450 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis b19954c4-943b-4bda-b8b4-ff98ab071ba2 is started using port 41919 for RATIS_SERVER
2023-02-02 20:27:29,450 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis b19954c4-943b-4bda-b8b4-ff98ab071ba2 is started using port 38999 for RATIS_DATASTREAM
2023-02-02 20:27:29,450 [JvmPauseMonitor58] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-b19954c4-943b-4bda-b8b4-ff98ab071ba2: Started
2023-02-02 20:27:29,451 [EndpointStateMachine task thread for /0.0.0.0:41201 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc b19954c4-943b-4bda-b8b4-ff98ab071ba2 is started using port 45229
2023-02-02 20:27:29,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:29,691 [Listener at 0.0.0.0/35129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 4 of 7 DN Heartbeats.
2023-02-02 20:27:29,691 [Listener at 0.0.0.0/35129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Cluster exits safe mode
2023-02-02 20:27:29,691 [Listener at 0.0.0.0/35129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:29,771 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 7d267433-c231-4e32-bff5-417fca1e0c0a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:29,771 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=1fc60b6e-672d-47cf-a0e1-68da2e7f3d41 close command to datanode 7d267433-c231-4e32-bff5-417fca1e0c0a
2023-02-02 20:27:29,772 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 1fc60b6e-672d-47cf-a0e1-68da2e7f3d41, Nodes: 7d267433-c231-4e32-bff5-417fca1e0c0a(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:7d267433-c231-4e32-bff5-417fca1e0c0a, CreationTimestamp2023-02-02T20:25:37.038Z[Etc/UTC]] removed.
2023-02-02 20:27:29,772 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/7d267433-c231-4e32-bff5-417fca1e0c0a
2023-02-02 20:27:29,784 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:29,976 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-a7118d63-fcc7-4683-8210-e0c36487c2ca/datanode-5/data-0/containers/hdds/a7118d63-fcc7-4683-8210-e0c36487c2ca/DS-30eadb4f-2567-4e2f-9afd-f6191011c545/container.db for volume DS-30eadb4f-2567-4e2f-9afd-f6191011c545
2023-02-02 20:27:29,976 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-02 20:27:29,977 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-02 20:27:29,977 [IPC Server handler 0 on default port 41201] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/d767bd78-5310-4536-b2f7-e45413a997a1
2023-02-02 20:27:29,977 [IPC Server handler 0 on default port 41201] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : d767bd78-5310-4536-b2f7-e45413a997a1{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=39543, RATIS=33759, RATIS_ADMIN=33759, RATIS_SERVER=33759, RATIS_DATASTREAM=36701, STANDALONE=42993], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:29,978 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:29,978 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=648c6b16-b370-4b37-9777-4685184db1b7 to datanode:d767bd78-5310-4536-b2f7-e45413a997a1
2023-02-02 20:27:29,978 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 648c6b16-b370-4b37-9777-4685184db1b7, Nodes: d767bd78-5310-4536-b2f7-e45413a997a1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-02T20:27:29.978Z[Etc/UTC]].
2023-02-02 20:27:29,983 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-02-02 20:27:29,984 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-02-02 20:27:29,984 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-02-02 20:27:29,984 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-02-02 20:27:29,984 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:29,984 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=32d10313-a11a-4058-8165-98c2244bc200 to datanode:78962ee0-dad8-4871-bc4b-e1f0b96bf3d9
2023-02-02 20:27:29,984 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=32d10313-a11a-4058-8165-98c2244bc200 to datanode:b67f1ce3-fbfb-4e89-9cbc-643abd2f2563
2023-02-02 20:27:29,984 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=32d10313-a11a-4058-8165-98c2244bc200 to datanode:d767bd78-5310-4536-b2f7-e45413a997a1
2023-02-02 20:27:29,984 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 32d10313-a11a-4058-8165-98c2244bc200, Nodes: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)b67f1ce3-fbfb-4e89-9cbc-643abd2f2563(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)d767bd78-5310-4536-b2f7-e45413a997a1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-02T20:27:29.984Z[Etc/UTC]].
2023-02-02 20:27:29,985 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-02-02 20:27:29,998 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-02 20:27:30,005 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@1d61320d{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-02 20:27:30,007 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@65e01ba9{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-02 20:27:30,007 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-02 20:27:30,007 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@625cbf12{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-02 20:27:30,007 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@33668e7f{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-02 20:27:30,013 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(539)) - Stopping the StorageContainerManager
2023-02-02 20:27:30,013 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1535)) - Container Balancer is not running.
2023-02-02 20:27:30,013 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1542)) - Stopping Replication Manager Service.
2023-02-02 20:27:30,013 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(294)) - Stopping Replication Monitor Thread.
2023-02-02 20:27:30,013 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(142)) - Under Replicated Processor interrupted. Exiting...
2023-02-02 20:27:30,013 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(142)) - Over Replicated Processor interrupted. Exiting...
2023-02-02 20:27:30,017 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1549)) - Stopping the Datanode Admin Monitor.
2023-02-02 20:27:30,017 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(671)) - Replication Monitor Thread is stopped
2023-02-02 20:27:30,017 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1556)) - Stopping datanode service RPC server
2023-02-02 20:27:30,017 [Mini-Cluster-Provider-Reap] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(441)) - Stopping the RPC server for DataNodes
2023-02-02 20:27:30,020 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 46723
2023-02-02 20:27:30,021 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:30,023 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-02 20:27:30,024 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-02 20:27:30,040 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:30,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:30,072 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-02-02 20:27:30,072 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1564)) - Stopping block service RPC server
2023-02-02 20:27:30,072 [Mini-Cluster-Provider-Reap] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-02-02 20:27:30,076 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 40495
2023-02-02 20:27:30,080 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-02 20:27:30,081 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1571)) - Stopping the StorageContainerLocationProtocol RPC server
2023-02-02 20:27:30,081 [Mini-Cluster-Provider-Reap] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(179)) - Stopping the RPC server for Client Protocol
2023-02-02 20:27:30,083 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 41775
2023-02-02 20:27:30,089 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1578)) - Stopping Storage Container Manager HTTP server.
2023-02-02 20:27:30,090 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-02 20:27:30,090 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2ea587b1{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-02-02 20:27:30,090 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-02 20:27:30,091 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@33f21e58{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-02 20:27:30,091 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-02 20:27:30,091 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-02 20:27:30,091 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@57db4e8c{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-02-02 20:27:30,091 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@16dcdf83{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-02 20:27:30,094 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1584)) - Stopping SCM LayoutVersionManager Service.
2023-02-02 20:27:30,094 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1592)) - Stopping Block Manager Service.
2023-02-02 20:27:30,094 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-02 20:27:30,094 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-02 20:27:30,094 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1614)) - Stopping SCM Event Queue.
2023-02-02 20:27:30,099 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1625)) - Stopping SCM HA services.
2023-02-02 20:27:30,099 [Mini-Cluster-Provider-Reap] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-02-02 20:27:30,099 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-02-02 20:27:30,099 [Mini-Cluster-Provider-Reap] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-02-02 20:27:30,099 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-02-02 20:27:30,100 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping StorageContainerManager metrics system...
2023-02-02 20:27:30,108 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2023-02-02 20:27:30,108 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - StorageContainerManager metrics system stopped.
2023-02-02 20:27:30,109 [Mini-Cluster-Provider-Reap] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-02-02 20:27:30,109 [Mini-Cluster-Provider-Reap] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-02-02 20:27:30,109 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-02-02 20:27:30,109 [Mini-Cluster-Provider-Reap] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-02-02 20:27:30,109 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-02 20:27:30,109 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(302)) - Replication Monitor Thread is not running.
2023-02-02 20:27:30,109 [Mini-Cluster-Provider-Reap] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(322)) - Cannot stop Container Balancer because it's not running or stopping
2023-02-02 20:27:30,109 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1643)) - Stopping SCM MetadataStore.
2023-02-02 20:27:30,172 [IPC Server handler 0 on default port 37573] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/71be8e41-5a57-4368-972a-d639c8cb365f
2023-02-02 20:27:30,173 [IPC Server handler 0 on default port 37573] INFO  node.NodeStateManager (NodeStateManager.java:newNodeStatus(338)) - Updating nodeOperationalState on registration as the datanode has a persisted state of IN_MAINTENANCE and expiry of 0
2023-02-02 20:27:30,173 [IPC Server handler 0 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 71be8e41-5a57-4368-972a-d639c8cb365f{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=36213, RATIS=38615, RATIS_ADMIN=38615, RATIS_SERVER=38615, RATIS_DATASTREAM=44305, STANDALONE=39863], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:30,177 [IPC Server handler 2 on default port 37573] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/4ec2caad-ead4-478e-ac51-fb863b7de4b5
2023-02-02 20:27:30,177 [IPC Server handler 2 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 4ec2caad-ead4-478e-ac51-fb863b7de4b5{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=36373, RATIS=45079, RATIS_ADMIN=45079, RATIS_SERVER=45079, RATIS_DATASTREAM=45141, STANDALONE=42005], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:30,181 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:30,188 [EventQueue-NewNodeForNewNodeHandler] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:continueAdminForNode(267)) - Continue admin for datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:30,188 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:30,269 [IPC Server handler 1 on default port 37573] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/c2e5a0ee-722e-430e-828a-2d735c45daa1
2023-02-02 20:27:30,269 [IPC Server handler 1 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : c2e5a0ee-722e-430e-828a-2d735c45daa1{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=42483, RATIS=46481, RATIS_ADMIN=46481, RATIS_SERVER=46481, RATIS_DATASTREAM=36873, STANDALONE=35925], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:30,269 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:30,270 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-02-02 20:27:30,382 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 3 of 7 DN Heartbeats.
2023-02-02 20:27:30,383 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:30,383 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:30,424 [IPC Server handler 4 on default port 41201] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/235120ac-71a1-451e-bf57-c5cd114d9629
2023-02-02 20:27:30,425 [IPC Server handler 4 on default port 41201] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 235120ac-71a1-451e-bf57-c5cd114d9629{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=34893, RATIS=36259, RATIS_ADMIN=36259, RATIS_SERVER=36259, RATIS_DATASTREAM=43003, STANDALONE=46053], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:30,425 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:30,425 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=24040cbb-e033-4e5f-8298-21297c9fd6bd to datanode:235120ac-71a1-451e-bf57-c5cd114d9629
2023-02-02 20:27:30,425 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 24040cbb-e033-4e5f-8298-21297c9fd6bd, Nodes: 235120ac-71a1-451e-bf57-c5cd114d9629(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-02T20:27:30.425Z[Etc/UTC]].
2023-02-02 20:27:30,426 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-02-02 20:27:30,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:30,537 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-02 20:27:30,537 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(57)) - Admin start on datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Finalizing its pipelines []
2023-02-02 20:27:30,691 [Listener at 0.0.0.0/35129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:30,692 [Listener at 0.0.0.0/35129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Cluster exits safe mode
2023-02-02 20:27:30,692 [Listener at 0.0.0.0/35129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:30,695 [Listener at 0.0.0.0/35129] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-02 20:27:30,696 [Listener at 0.0.0.0/35129] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 71be8e41-5a57-4368-972a-d639c8cb365f: close
2023-02-02 20:27:30,696 [Listener at 0.0.0.0/35129] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 71be8e41-5a57-4368-972a-d639c8cb365f: shutdown server GrpcServerProtocolService now
2023-02-02 20:27:30,702 [Listener at 0.0.0.0/35129] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 71be8e41-5a57-4368-972a-d639c8cb365f: shutdown server GrpcServerProtocolService successfully
2023-02-02 20:27:30,702 [71be8e41-5a57-4368-972a-d639c8cb365f-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa6696b1a, L:/0:0:0:0:0:0:0:0:44305] CLOSE
2023-02-02 20:27:30,702 [71be8e41-5a57-4368-972a-d639c8cb365f-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa6696b1a, L:/0:0:0:0:0:0:0:0:44305] INACTIVE
2023-02-02 20:27:30,703 [71be8e41-5a57-4368-972a-d639c8cb365f-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa6696b1a, L:/0:0:0:0:0:0:0:0:44305] UNREGISTERED
2023-02-02 20:27:30,736 [IPC Server handler 7 on default port 41201] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29
2023-02-02 20:27:30,737 [IPC Server handler 7 on default port 41201] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=35859, RATIS=46223, RATIS_ADMIN=46223, RATIS_SERVER=46223, RATIS_DATASTREAM=40341, STANDALONE=42867], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:30,737 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:30,737 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=6bb9acfe-0937-42a9-8200-947b5bdbd3e4 to datanode:fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29
2023-02-02 20:27:30,738 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 6bb9acfe-0937-42a9-8200-947b5bdbd3e4, Nodes: fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-02T20:27:30.737Z[Etc/UTC]].
2023-02-02 20:27:30,738 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2023-02-02 20:27:30,739 [JvmPauseMonitor38] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-71be8e41-5a57-4368-972a-d639c8cb365f: Stopped
2023-02-02 20:27:30,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:31,006 [IPC Server handler 3 on default port 41201] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/4c73a9f1-7904-4197-8af5-de7b9af59d88
2023-02-02 20:27:31,006 [IPC Server handler 3 on default port 41201] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 4c73a9f1-7904-4197-8af5-de7b9af59d88{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=39337, RATIS=46827, RATIS_ADMIN=46827, RATIS_SERVER=46827, RATIS_DATASTREAM=42537, STANDALONE=46061], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:31,006 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:31,007 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=3664afca-a46f-42af-bb6c-c02d4ae7fd74 to datanode:4c73a9f1-7904-4197-8af5-de7b9af59d88
2023-02-02 20:27:31,007 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 3664afca-a46f-42af-bb6c-c02d4ae7fd74, Nodes: 4c73a9f1-7904-4197-8af5-de7b9af59d88(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-02T20:27:31.007Z[Etc/UTC]].
2023-02-02 20:27:31,007 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=39f90b93-57d1-4e92-9a34-56a09b24dbfa to datanode:fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29
2023-02-02 20:27:31,007 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=39f90b93-57d1-4e92-9a34-56a09b24dbfa to datanode:235120ac-71a1-451e-bf57-c5cd114d9629
2023-02-02 20:27:31,007 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=39f90b93-57d1-4e92-9a34-56a09b24dbfa to datanode:4c73a9f1-7904-4197-8af5-de7b9af59d88
2023-02-02 20:27:31,008 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 39f90b93-57d1-4e92-9a34-56a09b24dbfa, Nodes: fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)235120ac-71a1-451e-bf57-c5cd114d9629(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)4c73a9f1-7904-4197-8af5-de7b9af59d88(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-02T20:27:31.007Z[Etc/UTC]].
2023-02-02 20:27:31,008 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-02-02 20:27:31,021 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:31,040 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:31,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:31,383 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 6 of 7 DN Heartbeats.
2023-02-02 20:27:31,383 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:31,383 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:31,384 [IPC Server handler 4 on default port 41201] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/b19954c4-943b-4bda-b8b4-ff98ab071ba2
2023-02-02 20:27:31,384 [IPC Server handler 4 on default port 41201] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : b19954c4-943b-4bda-b8b4-ff98ab071ba2{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=37879, RATIS=41919, RATIS_ADMIN=41919, RATIS_SERVER=41919, RATIS_DATASTREAM=38999, STANDALONE=45229], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:31,384 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:31,384 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=95432b81-0b2d-4aca-b61b-4776704241ea to datanode:b19954c4-943b-4bda-b8b4-ff98ab071ba2
2023-02-02 20:27:31,385 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 95432b81-0b2d-4aca-b61b-4776704241ea, Nodes: b19954c4-943b-4bda-b8b4-ff98ab071ba2(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-02T20:27:31.384Z[Etc/UTC]].
2023-02-02 20:27:31,385 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-02-02 20:27:31,535 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:31,537 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-02 20:27:31,706 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: addNew group-1016D399C608:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:1|startupRole:FOLLOWER] returns group-1016D399C608:java.util.concurrent.CompletableFuture@42029e1a[Not completed]
2023-02-02 20:27:31,707 [pool-2473-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: new RaftServerImpl for group-1016D399C608:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:31,707 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:31,707 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:31,707 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:31,707 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:31,708 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:31,708 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:31,708 [pool-2473-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608: ConfigurationManager, init=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:31,708 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis] (custom)
2023-02-02 20:27:31,708 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:31,708 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:31,708 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:31,708 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:31,708 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:31,710 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:31,710 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:31,710 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:31,710 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:31,710 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:31,710 [pool-2473-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis/1de3754f-9ce0-45a5-aa58-1016d399c608 does not exist. Creating ...
2023-02-02 20:27:31,713 [pool-2473-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis/1de3754f-9ce0-45a5-aa58-1016d399c608/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:31,714 [pool-2473-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis/1de3754f-9ce0-45a5-aa58-1016d399c608 has been successfully formatted.
2023-02-02 20:27:31,715 [pool-2473-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-1016D399C608: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:31,715 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:31,715 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:31,716 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 1de3754f-9ce0-45a5-aa58-1016d399c608, Nodes: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:b67f1ce3-fbfb-4e89-9cbc-643abd2f2563, CreationTimestamp2023-02-02T20:27:28.729Z[Etc/UTC]] moved to OPEN state
2023-02-02 20:27:31,724 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:31,724 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:31,724 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:31,724 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:31,724 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:31,725 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:31,725 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:31,725 [pool-2473-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis/1de3754f-9ce0-45a5-aa58-1016d399c608
2023-02-02 20:27:31,725 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:31,725 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:31,725 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:31,725 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:31,725 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:31,725 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:31,725 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:31,725 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:31,727 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:31,727 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:31,732 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:31,732 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:31,732 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:31,732 [pool-2473-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:31,732 [pool-2473-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:31,732 [pool-2473-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608: start as a follower, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:31,733 [pool-2473-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:31,733 [pool-2473-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: start b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-FollowerState
2023-02-02 20:27:31,733 [pool-2473-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1016D399C608,id=b67f1ce3-fbfb-4e89-9cbc-643abd2f2563
2023-02-02 20:27:31,733 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:31,733 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:31,733 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:31,733 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:31,733 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:31,733 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:31,734 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=1de3754f-9ce0-45a5-aa58-1016d399c608
2023-02-02 20:27:31,734 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=1de3754f-9ce0-45a5-aa58-1016d399c608.
2023-02-02 20:27:31,734 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: addNew group-98C2244BC200:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER] returns group-98C2244BC200:java.util.concurrent.CompletableFuture@463d1282[Not completed]
2023-02-02 20:27:31,735 [pool-2473-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: new RaftServerImpl for group-98C2244BC200:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:31,735 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:31,735 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:31,735 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:31,735 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:31,735 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:31,735 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:31,735 [pool-2473-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: ConfigurationManager, init=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:31,735 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis] (custom)
2023-02-02 20:27:31,735 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:31,735 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:31,736 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:31,736 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:31,736 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:31,737 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:31,737 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:31,737 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:31,737 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:31,737 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:31,737 [pool-2473-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis/32d10313-a11a-4058-8165-98c2244bc200 does not exist. Creating ...
2023-02-02 20:27:31,738 [pool-2473-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis/32d10313-a11a-4058-8165-98c2244bc200/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:31,739 [pool-2473-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis/32d10313-a11a-4058-8165-98c2244bc200 has been successfully formatted.
2023-02-02 20:27:31,740 [pool-2473-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-98C2244BC200: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:31,740 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:31,740 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:31,740 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:31,740 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:31,740 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:31,741 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:31,741 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:31,741 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:31,741 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:31,742 [pool-2473-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis/32d10313-a11a-4058-8165-98c2244bc200
2023-02-02 20:27:31,742 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:31,742 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:31,742 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:31,742 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:31,742 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:31,742 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:31,742 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:31,742 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:31,743 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:31,743 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:31,748 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:31,748 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:31,748 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:31,749 [pool-2473-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:31,749 [pool-2473-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:31,749 [pool-2473-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: start as a follower, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:31,749 [pool-2473-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:31,749 [pool-2473-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: start b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState
2023-02-02 20:27:31,749 [pool-2473-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-98C2244BC200,id=b67f1ce3-fbfb-4e89-9cbc-643abd2f2563
2023-02-02 20:27:31,749 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:31,749 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:31,749 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:31,749 [pool-2473-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:31,750 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=32d10313-a11a-4058-8165-98c2244bc200
2023-02-02 20:27:31,750 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:31,750 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:31,760 [grpc-default-executor-18] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: addNew group-98C2244BC200:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER] returns group-98C2244BC200:java.util.concurrent.CompletableFuture@55e5bc84[Not completed]
2023-02-02 20:27:31,761 [pool-2499-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: new RaftServerImpl for group-98C2244BC200:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:31,761 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:31,761 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:31,761 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:31,761 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:31,761 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:31,761 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:31,761 [pool-2499-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: ConfigurationManager, init=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:31,761 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis] (custom)
2023-02-02 20:27:31,761 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:31,761 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:31,761 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:31,761 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:31,761 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:31,763 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:31,763 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:31,763 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:31,763 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:31,763 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:31,763 [pool-2499-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis/32d10313-a11a-4058-8165-98c2244bc200 does not exist. Creating ...
2023-02-02 20:27:31,764 [pool-2499-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis/32d10313-a11a-4058-8165-98c2244bc200/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:31,765 [pool-2499-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis/32d10313-a11a-4058-8165-98c2244bc200 has been successfully formatted.
2023-02-02 20:27:31,766 [pool-2499-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-98C2244BC200: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:31,766 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:31,766 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:31,766 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:31,767 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:31,767 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:31,767 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:31,767 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:31,767 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:31,767 [pool-2499-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis/32d10313-a11a-4058-8165-98c2244bc200
2023-02-02 20:27:31,767 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:31,767 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:31,767 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:31,767 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:31,767 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:31,768 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:31,768 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:31,768 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:31,769 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:31,769 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:31,774 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:31,774 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:31,774 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:31,774 [pool-2499-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:31,774 [pool-2499-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:31,775 [pool-2499-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: start as a follower, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:31,775 [pool-2499-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:31,775 [pool-2499-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: start 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState
2023-02-02 20:27:31,775 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:31,775 [pool-2499-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-98C2244BC200,id=78962ee0-dad8-4871-bc4b-e1f0b96bf3d9
2023-02-02 20:27:31,775 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:31,775 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:31,775 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:31,775 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:31,775 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:31,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:31,788 [grpc-default-executor-18] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - d767bd78-5310-4536-b2f7-e45413a997a1: addNew group-98C2244BC200:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER] returns group-98C2244BC200:java.util.concurrent.CompletableFuture@7f88848a[Not completed]
2023-02-02 20:27:31,789 [pool-2525-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - d767bd78-5310-4536-b2f7-e45413a997a1: new RaftServerImpl for group-98C2244BC200:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:31,789 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:31,789 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:31,789 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:31,789 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:31,789 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:31,789 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:31,789 [pool-2525-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: ConfigurationManager, init=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:31,790 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis] (custom)
2023-02-02 20:27:31,790 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:31,790 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:31,790 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:31,790 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:31,790 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:31,791 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:31,791 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:31,791 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:31,792 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:31,792 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:31,792 [pool-2525-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis/32d10313-a11a-4058-8165-98c2244bc200 does not exist. Creating ...
2023-02-02 20:27:31,794 [pool-2525-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis/32d10313-a11a-4058-8165-98c2244bc200/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:31,795 [pool-2525-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis/32d10313-a11a-4058-8165-98c2244bc200 has been successfully formatted.
2023-02-02 20:27:31,800 [pool-2525-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-98C2244BC200: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:31,801 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:31,801 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:31,801 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:31,801 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:31,801 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:31,802 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:31,802 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:31,802 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:31,802 [pool-2525-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis/32d10313-a11a-4058-8165-98c2244bc200
2023-02-02 20:27:31,802 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:31,802 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:31,802 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:31,802 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:31,802 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:31,802 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:31,802 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:31,803 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:31,804 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:31,804 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:31,809 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:31,809 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:31,809 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:31,810 [pool-2525-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:31,810 [pool-2525-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:31,810 [pool-2525-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: start as a follower, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:31,810 [pool-2525-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:31,810 [pool-2525-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d767bd78-5310-4536-b2f7-e45413a997a1: start d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState
2023-02-02 20:27:31,810 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:31,810 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:31,810 [pool-2525-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-98C2244BC200,id=d767bd78-5310-4536-b2f7-e45413a997a1
2023-02-02 20:27:31,810 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:31,811 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:31,811 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:31,811 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:31,813 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=32d10313-a11a-4058-8165-98c2244bc200.
2023-02-02 20:27:32,021 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:32,041 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:32,051 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:32,349 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: addNew group-2E6A8FAA1AC2:[78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:1|startupRole:FOLLOWER] returns group-2E6A8FAA1AC2:java.util.concurrent.CompletableFuture@3c6533e1[Not completed]
2023-02-02 20:27:32,350 [pool-2499-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: new RaftServerImpl for group-2E6A8FAA1AC2:[78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:32,350 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:32,350 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:32,350 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:32,350 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:32,350 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:32,350 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:32,350 [pool-2499-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2: ConfigurationManager, init=-1: peers:[78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:32,350 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis] (custom)
2023-02-02 20:27:32,350 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:32,351 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:32,351 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:32,351 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:32,351 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:32,352 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:32,352 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:32,352 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:32,352 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:32,352 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:32,353 [pool-2499-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis/9a11209b-2cb2-422e-bd22-2e6a8faa1ac2 does not exist. Creating ...
2023-02-02 20:27:32,354 [pool-2499-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis/9a11209b-2cb2-422e-bd22-2e6a8faa1ac2/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:32,355 [pool-2499-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis/9a11209b-2cb2-422e-bd22-2e6a8faa1ac2 has been successfully formatted.
2023-02-02 20:27:32,355 [pool-2499-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-2E6A8FAA1AC2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:32,355 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:32,355 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:32,355 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:32,355 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:32,356 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 9a11209b-2cb2-422e-bd22-2e6a8faa1ac2, Nodes: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:78962ee0-dad8-4871-bc4b-e1f0b96bf3d9, CreationTimestamp2023-02-02T20:27:29.351Z[Etc/UTC]] moved to OPEN state
2023-02-02 20:27:32,356 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:32,356 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:32,356 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:32,357 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:32,357 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:32,357 [pool-2499-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis/9a11209b-2cb2-422e-bd22-2e6a8faa1ac2
2023-02-02 20:27:32,357 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:32,357 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:32,357 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:32,357 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:32,357 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:32,357 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:32,357 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:32,357 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:32,358 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:32,359 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:32,364 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:32,364 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:32,364 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:32,364 [pool-2499-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:32,364 [pool-2499-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:32,365 [pool-2499-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2: start as a follower, conf=-1: peers:[78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:32,365 [pool-2499-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:32,365 [pool-2499-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: start 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-FollowerState
2023-02-02 20:27:32,365 [pool-2499-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2E6A8FAA1AC2,id=78962ee0-dad8-4871-bc4b-e1f0b96bf3d9
2023-02-02 20:27:32,365 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:32,365 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:32,365 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:32,365 [pool-2499-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:32,365 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:32,366 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:32,366 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=9a11209b-2cb2-422e-bd22-2e6a8faa1ac2
2023-02-02 20:27:32,366 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=9a11209b-2cb2-422e-bd22-2e6a8faa1ac2.
2023-02-02 20:27:32,384 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:32,384 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:32,384 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:32,535 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:32,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-02 20:27:32,537 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-02 20:27:32,537 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:32,741 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:32,743 [Listener at 0.0.0.0/35129] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-4/data-0/containers/hdds/1ca5169e-081d-4c84-b198-688caf4e4cd2/DS-51074578-8e79-45b0-81a0-e46993d537cd/container.db for volume DS-51074578-8e79-45b0-81a0-e46993d537cd
2023-02-02 20:27:32,743 [Listener at 0.0.0.0/35129] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-02 20:27:32,744 [Listener at 0.0.0.0/35129] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-02 20:27:32,752 [Listener at 0.0.0.0/35129] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-02 20:27:32,760 [Listener at 0.0.0.0/35129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@48d1d7e4{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-02 20:27:32,761 [Listener at 0.0.0.0/35129] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@98ecdd4{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-02 20:27:32,761 [Listener at 0.0.0.0/35129] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-02 20:27:32,761 [Listener at 0.0.0.0/35129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@55f8ab3c{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-02 20:27:32,761 [Listener at 0.0.0.0/35129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2a85a866{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-02 20:27:32,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:32,976 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - d767bd78-5310-4536-b2f7-e45413a997a1: addNew group-4685184DB1B7:[d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER] returns group-4685184DB1B7:java.util.concurrent.CompletableFuture@1c729815[Not completed]
2023-02-02 20:27:32,977 [pool-2525-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - d767bd78-5310-4536-b2f7-e45413a997a1: new RaftServerImpl for group-4685184DB1B7:[d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:32,977 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:32,977 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:32,977 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:32,977 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:32,977 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:32,977 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:32,977 [pool-2525-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7: ConfigurationManager, init=-1: peers:[d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:32,977 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis] (custom)
2023-02-02 20:27:32,977 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:32,977 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:32,978 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:32,978 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:32,978 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:32,979 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:32,979 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:32,979 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:32,979 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:32,979 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:32,979 [pool-2525-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis/648c6b16-b370-4b37-9777-4685184db1b7 does not exist. Creating ...
2023-02-02 20:27:32,981 [pool-2525-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis/648c6b16-b370-4b37-9777-4685184db1b7/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:32,982 [pool-2525-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis/648c6b16-b370-4b37-9777-4685184db1b7 has been successfully formatted.
2023-02-02 20:27:32,982 [pool-2525-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-4685184DB1B7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:32,982 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:32,983 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 648c6b16-b370-4b37-9777-4685184db1b7, Nodes: d767bd78-5310-4536-b2f7-e45413a997a1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:d767bd78-5310-4536-b2f7-e45413a997a1, CreationTimestamp2023-02-02T20:27:29.978Z[Etc/UTC]] moved to OPEN state
2023-02-02 20:27:32,983 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:32,984 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:32,984 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:32,984 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:32,984 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:32,984 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:32,984 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:32,985 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:32,985 [pool-2525-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis/648c6b16-b370-4b37-9777-4685184db1b7
2023-02-02 20:27:32,985 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:32,985 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:32,985 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:32,985 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:32,985 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:32,985 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:32,985 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:32,985 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:32,986 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:32,987 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:32,992 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:32,992 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:32,992 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:32,992 [pool-2525-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:32,992 [pool-2525-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:32,992 [pool-2525-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7: start as a follower, conf=-1: peers:[d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:32,992 [pool-2525-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:32,992 [pool-2525-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d767bd78-5310-4536-b2f7-e45413a997a1: start d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-FollowerState
2023-02-02 20:27:32,992 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:32,993 [pool-2525-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4685184DB1B7,id=d767bd78-5310-4536-b2f7-e45413a997a1
2023-02-02 20:27:33,059 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:33,067 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:33,067 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:33,067 [pool-2525-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:32,993 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:33,068 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=648c6b16-b370-4b37-9777-4685184db1b7
2023-02-02 20:27:33,068 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=648c6b16-b370-4b37-9777-4685184db1b7.
2023-02-02 20:27:33,064 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:33,063 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:33,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:33,242 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5103445860ns, electionTimeout:5102ms
2023-02-02 20:27:33,243 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c2e5a0ee-722e-430e-828a-2d735c45daa1: shutdown c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-FollowerState
2023-02-02 20:27:33,243 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-02 20:27:33,243 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:33,243 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c2e5a0ee-722e-430e-828a-2d735c45daa1: start c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127
2023-02-02 20:27:33,245 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127 ELECTION round 0: submit vote requests at term 1 for -1: peers:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:33,245 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:33,245 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:33,246 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 4ec2caad-ead4-478e-ac51-fb863b7de4b5
2023-02-02 20:27:33,246 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854: receive requestVote(ELECTION, c2e5a0ee-722e-430e-828a-2d735c45daa1, group-82E709284854, 1, (t:0, i:0))
2023-02-02 20:27:33,246 [grpc-default-executor-18] INFO  impl.VoteContext (VoteContext.java:log(49)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-FOLLOWER: accept ELECTION from c2e5a0ee-722e-430e-828a-2d735c45daa1: our priority 0 <= candidate's priority 1
2023-02-02 20:27:33,246 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:c2e5a0ee-722e-430e-828a-2d735c45daa1
2023-02-02 20:27:33,246 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 7153b2e5-6547-4596-92e7-e397d052a5ec: shutdown 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-FollowerState
2023-02-02 20:27:33,246 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7153b2e5-6547-4596-92e7-e397d052a5ec: start 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-FollowerState
2023-02-02 20:27:33,247 [7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-FollowerState was interrupted
2023-02-02 20:27:33,247 [7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:33,247 [7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:33,248 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854 replies to ELECTION vote request: c2e5a0ee-722e-430e-828a-2d735c45daa1<-7153b2e5-6547-4596-92e7-e397d052a5ec#0:OK-t1. Peer's state: 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854:t1, leader=null, voted=c2e5a0ee-722e-430e-828a-2d735c45daa1, raftlog=Memoized:7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:33,249 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-02-02 20:27:33,249 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: c2e5a0ee-722e-430e-828a-2d735c45daa1<-7153b2e5-6547-4596-92e7-e397d052a5ec#0:OK-t1
2023-02-02 20:27:33,249 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127 ELECTION round 0: result PASSED
2023-02-02 20:27:33,249 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - c2e5a0ee-722e-430e-828a-2d735c45daa1: shutdown c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127
2023-02-02 20:27:33,249 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-02 20:27:33,249 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-82E709284854 with new leaderId: c2e5a0ee-722e-430e-828a-2d735c45daa1
2023-02-02 20:27:33,249 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854: change Leader from null to c2e5a0ee-722e-430e-828a-2d735c45daa1 at term 1 for becomeLeader, leader elected after 5125ms
2023-02-02 20:27:33,249 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-02 20:27:33,249 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:33,249 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-02 20:27:33,249 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-02 20:27:33,250 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-02 20:27:33,250 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-02 20:27:33,250 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:33,250 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-02 20:27:33,250 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-02-02 20:27:33,251 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:33,251 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-02-02 20:27:33,251 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-02-02 20:27:33,251 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-02 20:27:33,251 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:33,251 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-02 20:27:33,251 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-02-02 20:27:33,252 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-02-02 20:27:33,252 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:33,252 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-02-02 20:27:33,252 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-02-02 20:27:33,252 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-02 20:27:33,252 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:33,252 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-02 20:27:33,252 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-02-02 20:27:33,253 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - c2e5a0ee-722e-430e-828a-2d735c45daa1: start c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderStateImpl
2023-02-02 20:27:33,253 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 30f6cd70-24a3-46cb-83ea-82e709284854, Nodes: 4ec2caad-ead4-478e-ac51-fb863b7de4b5(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:c2e5a0ee-722e-430e-828a-2d735c45daa1, CreationTimestamp2023-02-02T20:27:28.524Z[Etc/UTC]] moved to OPEN state
2023-02-02 20:27:33,259 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:33,261 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854: receive requestVote(ELECTION, c2e5a0ee-722e-430e-828a-2d735c45daa1, group-82E709284854, 1, (t:0, i:0))
2023-02-02 20:27:33,263 [grpc-default-executor-18] INFO  impl.VoteContext (VoteContext.java:log(49)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-FOLLOWER: accept ELECTION from c2e5a0ee-722e-430e-828a-2d735c45daa1: our priority 0 <= candidate's priority 1
2023-02-02 20:27:33,263 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:c2e5a0ee-722e-430e-828a-2d735c45daa1
2023-02-02 20:27:33,263 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5: shutdown 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-FollowerState
2023-02-02 20:27:33,261 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71) moved to stale state. Finalizing its pipelines []
2023-02-02 20:27:33,264 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5: start 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-FollowerState
2023-02-02 20:27:33,264 [4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-FollowerState was interrupted
2023-02-02 20:27:33,264 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-3/data/ratis/30f6cd70-24a3-46cb-83ea-82e709284854/current/log_inprogress_0
2023-02-02 20:27:33,269 [4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:33,269 [4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:33,269 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854 replies to ELECTION vote request: c2e5a0ee-722e-430e-828a-2d735c45daa1<-4ec2caad-ead4-478e-ac51-fb863b7de4b5#0:OK-t1. Peer's state: 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854:t1, leader=null, voted=c2e5a0ee-722e-430e-828a-2d735c45daa1, raftlog=Memoized:4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:33,282 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderElection127] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854: set configuration 0: peers:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:33,284 [7153b2e5-6547-4596-92e7-e397d052a5ec-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-82E709284854 with new leaderId: c2e5a0ee-722e-430e-828a-2d735c45daa1
2023-02-02 20:27:33,284 [7153b2e5-6547-4596-92e7-e397d052a5ec-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854: change Leader from null to c2e5a0ee-722e-430e-828a-2d735c45daa1 at term 1 for appendEntries, leader elected after 5129ms
2023-02-02 20:27:33,291 [4ec2caad-ead4-478e-ac51-fb863b7de4b5-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-82E709284854 with new leaderId: c2e5a0ee-722e-430e-828a-2d735c45daa1
2023-02-02 20:27:33,291 [4ec2caad-ead4-478e-ac51-fb863b7de4b5-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854: change Leader from null to c2e5a0ee-722e-430e-828a-2d735c45daa1 at term 1 for appendEntries, leader elected after 5139ms
2023-02-02 20:27:33,295 [7153b2e5-6547-4596-92e7-e397d052a5ec-server-thread3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854: set configuration 0: peers:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:33,296 [7153b2e5-6547-4596-92e7-e397d052a5ec-server-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:33,297 [7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 7153b2e5-6547-4596-92e7-e397d052a5ec@group-82E709284854-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-5/data/ratis/30f6cd70-24a3-46cb-83ea-82e709284854/current/log_inprogress_0
2023-02-02 20:27:33,303 [4ec2caad-ead4-478e-ac51-fb863b7de4b5-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854: set configuration 0: peers:[c2e5a0ee-722e-430e-828a-2d735c45daa1|rpc:10.1.1.71:46481|dataStream:10.1.1.71:36873|priority:1|startupRole:FOLLOWER, 7153b2e5-6547-4596-92e7-e397d052a5ec|rpc:10.1.1.71:33067|dataStream:10.1.1.71:41865|priority:0|startupRole:FOLLOWER, 4ec2caad-ead4-478e-ac51-fb863b7de4b5|rpc:10.1.1.71:45079|dataStream:10.1.1.71:45141|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:33,303 [4ec2caad-ead4-478e-ac51-fb863b7de4b5-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:33,304 [4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 4ec2caad-ead4-478e-ac51-fb863b7de4b5@group-82E709284854-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-6/data/ratis/30f6cd70-24a3-46cb-83ea-82e709284854/current/log_inprogress_0
2023-02-02 20:27:33,356 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:33,384 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:33,384 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:33,384 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:33,422 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 235120ac-71a1-451e-bf57-c5cd114d9629: addNew group-21297C9FD6BD:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:1|startupRole:FOLLOWER] returns group-21297C9FD6BD:java.util.concurrent.CompletableFuture@279d3e87[Not completed]
2023-02-02 20:27:33,424 [pool-2555-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 235120ac-71a1-451e-bf57-c5cd114d9629: new RaftServerImpl for group-21297C9FD6BD:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:33,424 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:33,424 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:33,424 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:33,424 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:33,424 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:33,424 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:33,425 [pool-2555-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD: ConfigurationManager, init=-1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:33,425 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis] (custom)
2023-02-02 20:27:33,425 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:33,425 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:33,425 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:33,425 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:33,425 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:33,426 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:33,426 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:33,427 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:33,427 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:33,427 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:33,427 [pool-2555-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis/24040cbb-e033-4e5f-8298-21297c9fd6bd does not exist. Creating ...
2023-02-02 20:27:33,428 [pool-2555-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis/24040cbb-e033-4e5f-8298-21297c9fd6bd/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:33,429 [pool-2555-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis/24040cbb-e033-4e5f-8298-21297c9fd6bd has been successfully formatted.
2023-02-02 20:27:33,429 [pool-2555-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-21297C9FD6BD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:33,429 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:33,430 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:33,430 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:33,430 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:33,430 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:33,430 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 24040cbb-e033-4e5f-8298-21297c9fd6bd, Nodes: 235120ac-71a1-451e-bf57-c5cd114d9629(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:235120ac-71a1-451e-bf57-c5cd114d9629, CreationTimestamp2023-02-02T20:27:30.425Z[Etc/UTC]] moved to OPEN state
2023-02-02 20:27:33,430 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:33,430 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:33,431 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:33,431 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:33,431 [pool-2555-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis/24040cbb-e033-4e5f-8298-21297c9fd6bd
2023-02-02 20:27:33,431 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:33,431 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:33,431 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:33,431 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:33,431 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:33,431 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:33,431 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:33,431 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:33,432 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:33,432 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:33,438 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:33,438 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:33,438 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:33,438 [pool-2555-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:33,438 [pool-2555-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:33,438 [pool-2555-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD: start as a follower, conf=-1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:33,439 [pool-2555-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:33,439 [pool-2555-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 235120ac-71a1-451e-bf57-c5cd114d9629: start 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-FollowerState
2023-02-02 20:27:33,439 [pool-2555-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-21297C9FD6BD,id=235120ac-71a1-451e-bf57-c5cd114d9629
2023-02-02 20:27:33,439 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:33,439 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:33,439 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:33,439 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:33,439 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:33,439 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:33,440 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=24040cbb-e033-4e5f-8298-21297c9fd6bd
2023-02-02 20:27:33,440 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=24040cbb-e033-4e5f-8298-21297c9fd6bd.
2023-02-02 20:27:33,440 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 235120ac-71a1-451e-bf57-c5cd114d9629: addNew group-56A09B24DBFA:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER] returns group-56A09B24DBFA:java.util.concurrent.CompletableFuture@23a2beac[Not completed]
2023-02-02 20:27:33,441 [pool-2555-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 235120ac-71a1-451e-bf57-c5cd114d9629: new RaftServerImpl for group-56A09B24DBFA:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:33,441 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:33,441 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:33,441 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:33,441 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:33,441 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:33,441 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:33,441 [pool-2555-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA: ConfigurationManager, init=-1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:33,441 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis] (custom)
2023-02-02 20:27:33,441 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:33,441 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:33,441 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:33,441 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:33,441 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:33,443 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:33,443 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:33,443 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:33,443 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:33,443 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:33,443 [pool-2555-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis/39f90b93-57d1-4e92-9a34-56a09b24dbfa does not exist. Creating ...
2023-02-02 20:27:33,444 [pool-2555-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis/39f90b93-57d1-4e92-9a34-56a09b24dbfa/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:33,445 [pool-2555-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis/39f90b93-57d1-4e92-9a34-56a09b24dbfa has been successfully formatted.
2023-02-02 20:27:33,445 [pool-2555-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-56A09B24DBFA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:33,445 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:33,445 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:33,445 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:33,446 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:33,446 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:33,446 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:33,446 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:33,447 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:33,447 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:33,447 [pool-2555-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis/39f90b93-57d1-4e92-9a34-56a09b24dbfa
2023-02-02 20:27:33,447 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:33,447 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:33,447 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:33,447 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:33,447 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:33,447 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:33,447 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:33,447 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:33,448 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:33,448 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:33,453 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:33,453 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:33,453 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:33,454 [pool-2555-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:33,454 [pool-2555-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:33,454 [pool-2555-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA: start as a follower, conf=-1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:33,454 [pool-2555-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:33,454 [pool-2555-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 235120ac-71a1-451e-bf57-c5cd114d9629: start 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:33,454 [pool-2555-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-56A09B24DBFA,id=235120ac-71a1-451e-bf57-c5cd114d9629
2023-02-02 20:27:33,455 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:33,455 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:33,455 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:33,455 [pool-2555-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:33,455 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:33,455 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:33,456 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=39f90b93-57d1-4e92-9a34-56a09b24dbfa
2023-02-02 20:27:33,462 [grpc-default-executor-3] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: addNew group-56A09B24DBFA:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER] returns group-56A09B24DBFA:java.util.concurrent.CompletableFuture@4832af99[Not completed]
2023-02-02 20:27:33,463 [pool-2577-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: new RaftServerImpl for group-56A09B24DBFA:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:33,463 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:33,463 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:33,463 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:33,463 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:33,463 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:33,463 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:33,463 [pool-2577-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA: ConfigurationManager, init=-1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:33,463 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis] (custom)
2023-02-02 20:27:33,463 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:33,463 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:33,463 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:33,463 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:33,463 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:33,465 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:33,465 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:33,465 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:33,465 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:33,465 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:33,465 [pool-2577-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis/39f90b93-57d1-4e92-9a34-56a09b24dbfa does not exist. Creating ...
2023-02-02 20:27:33,466 [pool-2577-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis/39f90b93-57d1-4e92-9a34-56a09b24dbfa/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:33,467 [pool-2577-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis/39f90b93-57d1-4e92-9a34-56a09b24dbfa has been successfully formatted.
2023-02-02 20:27:33,469 [pool-2577-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-56A09B24DBFA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:33,469 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:33,470 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:33,470 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:33,470 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:33,470 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:33,470 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:33,471 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:33,471 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:33,471 [pool-2577-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis/39f90b93-57d1-4e92-9a34-56a09b24dbfa
2023-02-02 20:27:33,471 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:33,471 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:33,471 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:33,471 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:33,471 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:33,471 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:33,471 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:33,471 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:33,472 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:33,472 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:33,477 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:33,477 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:33,477 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:33,478 [pool-2577-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:33,478 [pool-2577-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:33,478 [pool-2577-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA: start as a follower, conf=-1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:33,478 [pool-2577-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:33,479 [pool-2577-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: start fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:33,479 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:33,479 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:33,479 [pool-2577-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-56A09B24DBFA,id=fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29
2023-02-02 20:27:33,479 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:33,479 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:33,479 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:33,479 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:33,488 [grpc-default-executor-3] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: addNew group-56A09B24DBFA:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER] returns group-56A09B24DBFA:java.util.concurrent.CompletableFuture@6cffbeaa[Not completed]
2023-02-02 20:27:33,489 [pool-2603-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: new RaftServerImpl for group-56A09B24DBFA:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:33,489 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:33,489 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:33,489 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:33,489 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:33,489 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:33,489 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:33,489 [pool-2603-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA: ConfigurationManager, init=-1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:33,489 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis] (custom)
2023-02-02 20:27:33,489 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:33,489 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:33,489 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:33,489 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:33,489 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:33,491 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:33,491 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:33,491 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:33,491 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:33,491 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:33,491 [pool-2603-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis/39f90b93-57d1-4e92-9a34-56a09b24dbfa does not exist. Creating ...
2023-02-02 20:27:33,492 [pool-2603-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis/39f90b93-57d1-4e92-9a34-56a09b24dbfa/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:33,493 [pool-2603-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis/39f90b93-57d1-4e92-9a34-56a09b24dbfa has been successfully formatted.
2023-02-02 20:27:33,494 [pool-2603-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-56A09B24DBFA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:33,494 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:33,494 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:33,495 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:33,495 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:33,495 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:33,495 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:33,496 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:33,496 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:33,496 [pool-2603-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis/39f90b93-57d1-4e92-9a34-56a09b24dbfa
2023-02-02 20:27:33,496 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:33,496 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:33,496 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:33,496 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:33,496 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:33,496 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:33,496 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:33,496 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:33,497 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:33,497 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:33,503 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:33,503 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:33,503 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:33,503 [pool-2603-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:33,503 [pool-2603-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:33,504 [pool-2603-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA: start as a follower, conf=-1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:33,504 [pool-2603-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:33,505 [pool-2603-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: start 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:33,506 [pool-2603-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-56A09B24DBFA,id=4c73a9f1-7904-4197-8af5-de7b9af59d88
2023-02-02 20:27:33,506 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:33,506 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:33,507 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:33,507 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:33,507 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:33,507 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:33,511 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=39f90b93-57d1-4e92-9a34-56a09b24dbfa.
2023-02-02 20:27:33,535 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:33,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:33,537 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-02 20:27:33,537 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:33,704 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: addNew group-947B5BDBD3E4:[fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:1|startupRole:FOLLOWER] returns group-947B5BDBD3E4:java.util.concurrent.CompletableFuture@540e40bb[Not completed]
2023-02-02 20:27:33,704 [pool-2577-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: new RaftServerImpl for group-947B5BDBD3E4:[fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:33,704 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:33,705 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:33,705 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:33,705 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:33,705 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:33,705 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:33,705 [pool-2577-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4: ConfigurationManager, init=-1: peers:[fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:33,705 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis] (custom)
2023-02-02 20:27:33,705 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:33,705 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:33,705 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:33,705 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:33,705 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:33,707 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:33,707 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:33,707 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:33,707 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:33,707 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:33,707 [pool-2577-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis/6bb9acfe-0937-42a9-8200-947b5bdbd3e4 does not exist. Creating ...
2023-02-02 20:27:33,708 [pool-2577-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis/6bb9acfe-0937-42a9-8200-947b5bdbd3e4/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:33,709 [pool-2577-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis/6bb9acfe-0937-42a9-8200-947b5bdbd3e4 has been successfully formatted.
2023-02-02 20:27:33,709 [pool-2577-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-947B5BDBD3E4: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:33,710 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:33,710 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:33,710 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:33,710 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:33,710 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 6bb9acfe-0937-42a9-8200-947b5bdbd3e4, Nodes: fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29, CreationTimestamp2023-02-02T20:27:30.737Z[Etc/UTC]] moved to OPEN state
2023-02-02 20:27:33,711 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:33,711 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:33,711 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:33,711 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:33,711 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:33,711 [pool-2577-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis/6bb9acfe-0937-42a9-8200-947b5bdbd3e4
2023-02-02 20:27:33,712 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:33,712 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:33,712 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:33,712 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:33,712 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:33,712 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:33,712 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:33,712 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:33,713 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:33,714 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:33,718 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:33,719 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:33,719 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:33,719 [pool-2577-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:33,719 [pool-2577-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:33,719 [pool-2577-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4: start as a follower, conf=-1: peers:[fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:33,719 [pool-2577-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:33,719 [pool-2577-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: start fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-FollowerState
2023-02-02 20:27:33,719 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:33,719 [pool-2577-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-947B5BDBD3E4,id=fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29
2023-02-02 20:27:33,719 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:33,720 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:33,720 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:33,720 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:33,720 [pool-2577-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:33,720 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=6bb9acfe-0937-42a9-8200-947b5bdbd3e4
2023-02-02 20:27:33,720 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=6bb9acfe-0937-42a9-8200-947b5bdbd3e4.
2023-02-02 20:27:33,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:34,003 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: addNew group-C02D4AE7FD74:[4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER] returns group-C02D4AE7FD74:java.util.concurrent.CompletableFuture@576be67d[Not completed]
2023-02-02 20:27:34,003 [pool-2603-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: new RaftServerImpl for group-C02D4AE7FD74:[4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:34,003 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:34,003 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:34,003 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:34,003 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:34,003 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:34,003 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:34,004 [pool-2603-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74: ConfigurationManager, init=-1: peers:[4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:34,004 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis] (custom)
2023-02-02 20:27:34,004 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:34,004 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:34,004 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:34,004 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:34,004 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:34,005 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:34,005 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:34,005 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:34,005 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:34,005 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:34,006 [pool-2603-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis/3664afca-a46f-42af-bb6c-c02d4ae7fd74 does not exist. Creating ...
2023-02-02 20:27:34,007 [pool-2603-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis/3664afca-a46f-42af-bb6c-c02d4ae7fd74/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:34,007 [pool-2603-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis/3664afca-a46f-42af-bb6c-c02d4ae7fd74 has been successfully formatted.
2023-02-02 20:27:34,008 [pool-2603-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-C02D4AE7FD74: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:34,008 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:34,008 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:34,008 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 3664afca-a46f-42af-bb6c-c02d4ae7fd74, Nodes: 4c73a9f1-7904-4197-8af5-de7b9af59d88(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:4c73a9f1-7904-4197-8af5-de7b9af59d88, CreationTimestamp2023-02-02T20:27:31.007Z[Etc/UTC]] moved to OPEN state
2023-02-02 20:27:34,009 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:34,009 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:34,011 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:34,011 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:34,011 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:34,011 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:34,011 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:34,012 [pool-2603-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis/3664afca-a46f-42af-bb6c-c02d4ae7fd74
2023-02-02 20:27:34,012 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:34,012 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:34,012 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:34,012 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:34,012 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:34,012 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:34,012 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:34,012 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:34,013 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:34,013 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:34,018 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:34,018 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:34,018 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:34,018 [pool-2603-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:34,018 [pool-2603-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:34,019 [pool-2603-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74: start as a follower, conf=-1: peers:[4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:34,019 [pool-2603-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:34,019 [pool-2603-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: start 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-FollowerState
2023-02-02 20:27:34,019 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:34,019 [pool-2603-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C02D4AE7FD74,id=4c73a9f1-7904-4197-8af5-de7b9af59d88
2023-02-02 20:27:34,019 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:34,019 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:34,019 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:34,019 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:34,019 [pool-2603-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:34,020 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=3664afca-a46f-42af-bb6c-c02d4ae7fd74
2023-02-02 20:27:34,020 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=3664afca-a46f-42af-bb6c-c02d4ae7fd74.
2023-02-02 20:27:34,069 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:34,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:34,069 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:34,357 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:34,379 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2: addNew group-4776704241EA:[b19954c4-943b-4bda-b8b4-ff98ab071ba2|rpc:10.1.1.71:41919|dataStream:10.1.1.71:38999|priority:1|startupRole:FOLLOWER] returns group-4776704241EA:java.util.concurrent.CompletableFuture@6bc0d433[Not completed]
2023-02-02 20:27:34,380 [pool-2629-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2: new RaftServerImpl for group-4776704241EA:[b19954c4-943b-4bda-b8b4-ff98ab071ba2|rpc:10.1.1.71:41919|dataStream:10.1.1.71:38999|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-02 20:27:34,380 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-02 20:27:34,380 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-02 20:27:34,381 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-02 20:27:34,381 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-02 20:27:34,381 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-02 20:27:34,381 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-02 20:27:34,381 [pool-2629-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA: ConfigurationManager, init=-1: peers:[b19954c4-943b-4bda-b8b4-ff98ab071ba2|rpc:10.1.1.71:41919|dataStream:10.1.1.71:38999|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-02 20:27:34,381 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data/ratis] (custom)
2023-02-02 20:27:34,381 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-02 20:27:34,381 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-02 20:27:34,381 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-02 20:27:34,381 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-02 20:27:34,381 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100μs (default)
2023-02-02 20:27:34,383 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:34,383 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-02 20:27:34,383 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-02 20:27:34,383 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-02 20:27:34,383 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-02 20:27:34,383 [pool-2629-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data/ratis/95432b81-0b2d-4aca-b61b-4776704241ea does not exist. Creating ...
2023-02-02 20:27:34,384 [pool-2629-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data/ratis/95432b81-0b2d-4aca-b61b-4776704241ea/in_use.lock acquired by nodename 63549@fv-az133-962
2023-02-02 20:27:34,384 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:34,384 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:34,384 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:34,385 [pool-2629-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data/ratis/95432b81-0b2d-4aca-b61b-4776704241ea has been successfully formatted.
2023-02-02 20:27:34,385 [pool-2629-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-4776704241EA: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-02 20:27:34,385 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-02 20:27:34,385 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-02 20:27:34,385 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:34,385 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-02 20:27:34,386 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-02 20:27:34,386 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 95432b81-0b2d-4aca-b61b-4776704241ea, Nodes: b19954c4-943b-4bda-b8b4-ff98ab071ba2(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:b19954c4-943b-4bda-b8b4-ff98ab071ba2, CreationTimestamp2023-02-02T20:27:31.384Z[Etc/UTC]] moved to OPEN state
2023-02-02 20:27:34,386 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:34,386 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:34,386 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-02 20:27:34,386 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-02 20:27:34,387 [pool-2629-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data/ratis/95432b81-0b2d-4aca-b61b-4776704241ea
2023-02-02 20:27:34,387 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-02 20:27:34,387 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-02 20:27:34,387 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-02 20:27:34,387 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-02 20:27:34,387 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-02 20:27:34,387 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-02 20:27:34,387 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-02 20:27:34,387 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-02 20:27:34,388 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-02 20:27:34,389 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:34,394 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-02 20:27:34,394 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-02 20:27:34,394 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-02 20:27:34,394 [pool-2629-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:34,394 [pool-2629-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-02 20:27:34,394 [pool-2629-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA: start as a follower, conf=-1: peers:[b19954c4-943b-4bda-b8b4-ff98ab071ba2|rpc:10.1.1.71:41919|dataStream:10.1.1.71:38999|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:34,394 [pool-2629-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-02 20:27:34,394 [pool-2629-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2: start b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-FollowerState
2023-02-02 20:27:34,395 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:34,395 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:34,395 [pool-2629-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4776704241EA,id=b19954c4-943b-4bda-b8b4-ff98ab071ba2
2023-02-02 20:27:34,395 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-02 20:27:34,395 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-02 20:27:34,395 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-02 20:27:34,395 [pool-2629-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-02 20:27:34,396 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=95432b81-0b2d-4aca-b61b-4776704241ea
2023-02-02 20:27:34,396 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=95432b81-0b2d-4aca-b61b-4776704241ea.
2023-02-02 20:27:34,535 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:34,536 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:34,537 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-02 20:27:34,537 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:34,710 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:34,741 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:34,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:34,983 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:35,008 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:35,069 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:35,069 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:35,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:35,357 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:35,385 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:35,385 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:35,385 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:35,386 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:35,445 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:35,536 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:35,537 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-02 20:27:35,537 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:35,537 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:35,710 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:35,741 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:35,785 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:36,009 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:36,069 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:36,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:36,069 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:36,264 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 71be8e41-5a57-4368-972a-d639c8cb365f(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:36,264 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/71be8e41-5a57-4368-972a-d639c8cb365f
2023-02-02 20:27:36,357 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:36,365 [Listener at 0.0.0.0/35129] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:restartStorageContainerManager(351)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneClusterImpl
2023-02-02 20:27:36,365 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1535)) - Container Balancer is not running.
2023-02-02 20:27:36,366 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1542)) - Stopping Replication Manager Service.
2023-02-02 20:27:36,366 [Listener at 0.0.0.0/35129] INFO  replication.ReplicationManager (ReplicationManager.java:stop(294)) - Stopping Replication Monitor Thread.
2023-02-02 20:27:36,366 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1549)) - Stopping the Datanode Admin Monitor.
2023-02-02 20:27:36,366 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(142)) - Over Replicated Processor interrupted. Exiting...
2023-02-02 20:27:36,366 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1556)) - Stopping datanode service RPC server
2023-02-02 20:27:36,366 [Listener at 0.0.0.0/35129] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(441)) - Stopping the RPC server for DataNodes
2023-02-02 20:27:36,366 [Listener at 0.0.0.0/35129] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 37573
2023-02-02 20:27:36,366 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(142)) - Under Replicated Processor interrupted. Exiting...
2023-02-02 20:27:36,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(671)) - Replication Monitor Thread is stopped
2023-02-02 20:27:36,393 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:36,393 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:36,393 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:36,394 [IPC Server listener on 37573] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 37573
2023-02-02 20:27:36,394 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-02 20:27:36,417 [EndpointStateMachine task thread for /0.0.0.0:37573 - 0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(242)) - Unable to communicate to SCM server at 0.0.0.0:37573 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "fv-az133-962/10.1.1.71"; destination host is: "0.0.0.0":37573; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
	at com.sun.proxy.$Proxy54.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:149)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:185)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:87)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
2023-02-02 20:27:36,464 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-02-02 20:27:36,464 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1564)) - Stopping block service RPC server
2023-02-02 20:27:36,464 [Listener at 0.0.0.0/35129] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-02-02 20:27:36,464 [Listener at 0.0.0.0/35129] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 37773
2023-02-02 20:27:36,469 [IPC Server listener on 37773] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 37773
2023-02-02 20:27:36,472 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-02 20:27:36,472 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1571)) - Stopping the StorageContainerLocationProtocol RPC server
2023-02-02 20:27:36,473 [Listener at 0.0.0.0/35129] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(179)) - Stopping the RPC server for Client Protocol
2023-02-02 20:27:36,473 [Listener at 0.0.0.0/35129] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 35129
2023-02-02 20:27:36,476 [IPC Server listener on 35129] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 35129
2023-02-02 20:27:36,478 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1578)) - Stopping Storage Container Manager HTTP server.
2023-02-02 20:27:36,479 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-02 20:27:36,479 [Listener at 0.0.0.0/35129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@5e94947e{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-02-02 20:27:36,480 [Listener at 0.0.0.0/35129] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@1892865f{HTTP/1.1, (http/1.1)}{0.0.0.0:37403}
2023-02-02 20:27:36,480 [Listener at 0.0.0.0/35129] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-02 20:27:36,480 [Listener at 0.0.0.0/35129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2fbd47b7{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-02-02 20:27:36,485 [Listener at 0.0.0.0/35129] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3df681cc{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-02 20:27:36,486 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1584)) - Stopping SCM LayoutVersionManager Service.
2023-02-02 20:27:36,486 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1592)) - Stopping Block Manager Service.
2023-02-02 20:27:36,486 [Listener at 0.0.0.0/35129] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-02 20:27:36,486 [Listener at 0.0.0.0/35129] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-02 20:27:36,486 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1614)) - Stopping SCM Event Queue.
2023-02-02 20:27:36,487 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1625)) - Stopping SCM HA services.
2023-02-02 20:27:36,488 [Listener at 0.0.0.0/35129] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-02-02 20:27:36,488 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-02-02 20:27:36,488 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-02-02 20:27:36,488 [Listener at 0.0.0.0/35129] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-02-02 20:27:36,489 [Listener at 0.0.0.0/35129] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(205)) - StorageContainerManager metrics system stopped (again)
2023-02-02 20:27:36,489 [Listener at 0.0.0.0/35129] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-02-02 20:27:36,489 [Listener at 0.0.0.0/35129] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-02-02 20:27:36,489 [Listener at 0.0.0.0/35129] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-02-02 20:27:36,489 [Listener at 0.0.0.0/35129] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-02 20:27:36,489 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-02-02 20:27:36,489 [Listener at 0.0.0.0/35129] INFO  replication.ReplicationManager (ReplicationManager.java:stop(302)) - Replication Monitor Thread is not running.
2023-02-02 20:27:36,489 [Listener at 0.0.0.0/35129] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(322)) - Cannot stop Container Balancer because it's not running or stopping
2023-02-02 20:27:36,490 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1643)) - Stopping SCM MetadataStore.
2023-02-02 20:27:36,491 [Listener at 0.0.0.0/35129] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-02 20:27:36,491 [Listener at 0.0.0.0/35129] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-02-02 20:27:36,491 [Listener at 0.0.0.0/35129] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-02-02 20:27:36,492 [Listener at 0.0.0.0/35129] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-02 20:27:36,492 [Listener at 0.0.0.0/35129] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-02 20:27:36,526 [Listener at 0.0.0.0/35129] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-02-02 20:27:36,526 [Listener at 0.0.0.0/35129] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-02-02 20:27:36,530 [Listener at 0.0.0.0/35129] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-02 20:27:36,580 [Listener at 0.0.0.0/35129] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 49 ms to scan 7 urls, producing 150 keys and 361 values 
2023-02-02 20:27:36,585 [Listener at 0.0.0.0/35129] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-02-02 20:27:36,588 [Listener at 0.0.0.0/35129] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(149)) - Entering startup safe mode.
2023-02-02 20:27:36,589 [Listener at 0.0.0.0/35129] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-02-02 20:27:36,589 [Listener at 0.0.0.0/35129] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-02-02 20:27:36,590 [Listener at 0.0.0.0/35129] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-02-02 20:27:36,590 [Listener at 0.0.0.0/35129] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-02-02 20:27:36,590 [Listener at 0.0.0.0/35129] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-02-02 20:27:36,590 [Listener at 0.0.0.0/35129] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-02-02 20:27:36,594 [Listener at 0.0.0.0/35129] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-02-02 20:27:36,596 [Listener at 0.0.0.0/35129] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-02-02 20:27:36,597 [Listener at 0.0.0.0/35129] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-02-02 20:27:36,599 [Listener at 0.0.0.0/35129] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-02-02 20:27:36,601 [Listener at 0.0.0.0/35129] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-02-02 20:27:36,602 [Listener at 0.0.0.0/35129] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-02-02 20:27:36,602 [Listener at 0.0.0.0/35129] INFO  replication.ReplicationManager (ReplicationManager.java:start(263)) - Starting Replication Monitor Thread.
2023-02-02 20:27:36,607 [Listener at 0.0.0.0/35129] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-02-02 20:27:36,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:36,607 [Listener at 0.0.0.0/35129] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 3
2023-02-02 20:27:36,608 [Listener at 0.0.0.0/35129] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 2, healthy pipeline threshold count is 1
2023-02-02 20:27:36,608 [Listener at 0.0.0.0/35129] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 2, pipeline's with at least one datanode reported threshold count is 2
2023-02-02 20:27:36,608 [Listener at 0.0.0.0/35129] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-02 20:27:36,609 [Socket Reader #1 for port 37573] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 37573
2023-02-02 20:27:36,609 [Listener at 0.0.0.0/37573] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-02 20:27:36,610 [Socket Reader #1 for port 37773] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 37773
2023-02-02 20:27:36,610 [Listener at 0.0.0.0/37773] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-02 20:27:36,611 [Socket Reader #1 for port 35129] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 35129
2023-02-02 20:27:36,613 [Listener at 0.0.0.0/35129] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-02-02 20:27:36,613 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(401)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-02-02 20:27:36,613 [Listener at 0.0.0.0/35129] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-02-02 20:27:36,613 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1440)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:35129
2023-02-02 20:27:36,615 [Listener at 0.0.0.0/35129] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2023-02-02 20:27:36,616 [Listener at 0.0.0.0/35129] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2023-02-02 20:27:36,619 [Listener at 0.0.0.0/35129] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2023-02-02 20:27:36,629 [Listener at 0.0.0.0/35129] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2023-02-02 20:27:36,629 [Listener at 0.0.0.0/35129] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2023-02-02 20:27:36,654 [Listener at 0.0.0.0/35129] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(170)) - RPC server for Client  is listening at /0.0.0.0:35129
2023-02-02 20:27:36,655 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-02 20:27:36,661 [IPC Server listener on 35129] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 35129: starting
2023-02-02 20:27:36,677 [Listener at 0.0.0.0/35129] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1454)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:37773
2023-02-02 20:27:36,677 [Listener at 0.0.0.0/35129] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:37773
2023-02-02 20:27:36,679 [IPC Server listener on 37773] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 37773: starting
2023-02-02 20:27:36,679 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-02 20:27:36,705 [Listener at 0.0.0.0/35129] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:37573
2023-02-02 20:27:36,706 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-02 20:27:36,706 [IPC Server listener on 37573] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 37573: starting
2023-02-02 20:27:36,719 [Listener at 0.0.0.0/35129] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for scm at: http://0.0.0.0:37403
2023-02-02 20:27:36,719 [Listener at 0.0.0.0/35129] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-02 20:27:36,721 [Listener at 0.0.0.0/35129] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-02 20:27:36,721 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@408980aa] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-02 20:27:36,721 [Listener at 0.0.0.0/35129] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-02 20:27:36,722 [Listener at 0.0.0.0/35129] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-02 20:27:36,723 [Listener at 0.0.0.0/35129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-02-02 20:27:36,723 [Listener at 0.0.0.0/35129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-02 20:27:36,723 [Listener at 0.0.0.0/35129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-02 20:27:36,723 [Listener at 0.0.0.0/35129] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 37403
2023-02-02 20:27:36,723 [Listener at 0.0.0.0/35129] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-02 20:27:36,725 [Listener at 0.0.0.0/35129] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-02 20:27:36,726 [Listener at 0.0.0.0/35129] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-02 20:27:36,726 [Listener at 0.0.0.0/35129] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-02-02 20:27:36,726 [Listener at 0.0.0.0/35129] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4202bfe8{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-02 20:27:36,727 [Listener at 0.0.0.0/35129] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@53c21c05{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-02-02 20:27:36,735 [Listener at 0.0.0.0/35129] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@629dfb5a{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-02-02 20:27:36,739 [Listener at 0.0.0.0/35129] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@ef59aee{HTTP/1.1, (http/1.1)}{0.0.0.0:37403}
2023-02-02 20:27:36,739 [Listener at 0.0.0.0/35129] INFO  server.Server (Server.java:doStart(415)) - Started @201249ms
2023-02-02 20:27:36,739 [Listener at 0.0.0.0/35129] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-02 20:27:36,739 [Listener at 0.0.0.0/35129] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of scm listening at http://0.0.0.0:37403
2023-02-02 20:27:36,743 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5010592612ns, electionTimeout:5010ms
2023-02-02 20:27:36,743 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: shutdown b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-FollowerState
2023-02-02 20:27:36,743 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-02 20:27:36,744 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:36,744 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: start b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128
2023-02-02 20:27:36,745 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128 ELECTION round 0: submit vote requests at term 1 for -1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:36,746 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128 ELECTION round 0: result PASSED (term=1)
2023-02-02 20:27:36,746 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: shutdown b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128
2023-02-02 20:27:36,746 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-02 20:27:36,746 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-1016D399C608 with new leaderId: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563
2023-02-02 20:27:36,746 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608: change Leader from null to b67f1ce3-fbfb-4e89-9cbc-643abd2f2563 at term 1 for becomeLeader, leader elected after 5037ms
2023-02-02 20:27:36,746 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-02 20:27:36,747 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:36,747 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:36,747 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-02 20:27:36,747 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-02 20:27:36,747 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-02 20:27:36,747 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-02 20:27:36,747 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:36,747 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-02 20:27:36,747 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: start b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderStateImpl
2023-02-02 20:27:36,748 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:36,751 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-LeaderElection128] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608: set configuration 0: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:36,751 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-1016D399C608-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis/1de3754f-9ce0-45a5-aa58-1016d399c608/current/log_inprogress_0
2023-02-02 20:27:36,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:36,942 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5193487789ns, electionTimeout:5192ms
2023-02-02 20:27:36,943 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: shutdown b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState
2023-02-02 20:27:36,943 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-02 20:27:36,943 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:36,943 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: start b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129
2023-02-02 20:27:36,945 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129 ELECTION round 0: submit vote requests at term 1 for -1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:36,945 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for d767bd78-5310-4536-b2f7-e45413a997a1
2023-02-02 20:27:36,945 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:36,945 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:36,946 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9
2023-02-02 20:27:36,946 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5136353551ns, electionTimeout:5136ms
2023-02-02 20:27:36,947 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d767bd78-5310-4536-b2f7-e45413a997a1: shutdown d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState
2023-02-02 20:27:36,947 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-02 20:27:36,947 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:36,947 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d767bd78-5310-4536-b2f7-e45413a997a1: start d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130
2023-02-02 20:27:36,956 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: receive requestVote(ELECTION, b67f1ce3-fbfb-4e89-9cbc-643abd2f2563, group-98C2244BC200, 1, (t:0, i:0))
2023-02-02 20:27:36,960 [grpc-default-executor-18] INFO  impl.VoteContext (VoteContext.java:log(49)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-CANDIDATE: reject ELECTION from b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: already has voted for d767bd78-5310-4536-b2f7-e45413a997a1 at current term 1
2023-02-02 20:27:36,960 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200 replies to ELECTION vote request: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563<-d767bd78-5310-4536-b2f7-e45413a997a1#0:FAIL-t1. Peer's state: d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200:t1, leader=null, voted=d767bd78-5310-4536-b2f7-e45413a997a1, raftlog=Memoized:d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:36,960 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130 ELECTION round 0: submit vote requests at term 1 for -1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:36,963 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: receive requestVote(ELECTION, b67f1ce3-fbfb-4e89-9cbc-643abd2f2563, group-98C2244BC200, 1, (t:0, i:0))
2023-02-02 20:27:36,961 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5186596451ns, electionTimeout:5186ms
2023-02-02 20:27:36,963 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: shutdown 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState
2023-02-02 20:27:36,963 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-02 20:27:36,961 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2023-02-02 20:27:36,963 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for b67f1ce3-fbfb-4e89-9cbc-643abd2f2563
2023-02-02 20:27:36,963 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563<-d767bd78-5310-4536-b2f7-e45413a997a1#0:FAIL-t1
2023-02-02 20:27:36,964 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129 ELECTION round 0: result REJECTED
2023-02-02 20:27:36,964 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:36,964 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:36,964 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:36,964 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2023-02-02 20:27:36,965 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: shutdown b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129
2023-02-02 20:27:36,965 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection129] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: start b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState
2023-02-02 20:27:36,965 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: start 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection131
2023-02-02 20:27:36,965 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9
2023-02-02 20:27:36,968 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:36,968 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:36,968 [grpc-default-executor-18] INFO  impl.VoteContext (VoteContext.java:log(49)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-CANDIDATE: accept ELECTION from b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: our priority 0 <= candidate's priority 0
2023-02-02 20:27:36,969 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: changes role from CANDIDATE to FOLLOWER at term 1 for candidate:b67f1ce3-fbfb-4e89-9cbc-643abd2f2563
2023-02-02 20:27:36,969 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: shutdown 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection131
2023-02-02 20:27:36,969 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: start 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState
2023-02-02 20:27:36,969 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection131] INFO  impl.LeaderElection (LeaderElection.java:run(233)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection131: skip running since this is already CLOSING
2023-02-02 20:27:36,970 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:36,970 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:36,973 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200 replies to ELECTION vote request: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563<-78962ee0-dad8-4871-bc4b-e1f0b96bf3d9#0:OK-t1. Peer's state: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200:t1, leader=null, voted=b67f1ce3-fbfb-4e89-9cbc-643abd2f2563, raftlog=Memoized:78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:36,973 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: receive requestVote(ELECTION, d767bd78-5310-4536-b2f7-e45413a997a1, group-98C2244BC200, 1, (t:0, i:0))
2023-02-02 20:27:36,973 [grpc-default-executor-18] INFO  impl.VoteContext (VoteContext.java:log(49)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FOLLOWER: reject ELECTION from d767bd78-5310-4536-b2f7-e45413a997a1: already has voted for b67f1ce3-fbfb-4e89-9cbc-643abd2f2563 at current term 1
2023-02-02 20:27:36,973 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200 replies to ELECTION vote request: d767bd78-5310-4536-b2f7-e45413a997a1<-78962ee0-dad8-4871-bc4b-e1f0b96bf3d9#0:FAIL-t1. Peer's state: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200:t1, leader=null, voted=b67f1ce3-fbfb-4e89-9cbc-643abd2f2563, raftlog=Memoized:78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:36,976 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: receive requestVote(ELECTION, d767bd78-5310-4536-b2f7-e45413a997a1, group-98C2244BC200, 1, (t:0, i:0))
2023-02-02 20:27:36,976 [grpc-default-executor-18] INFO  impl.VoteContext (VoteContext.java:log(49)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FOLLOWER: reject ELECTION from d767bd78-5310-4536-b2f7-e45413a997a1: already has voted for b67f1ce3-fbfb-4e89-9cbc-643abd2f2563 at current term 1
2023-02-02 20:27:36,976 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200 replies to ELECTION vote request: d767bd78-5310-4536-b2f7-e45413a997a1<-b67f1ce3-fbfb-4e89-9cbc-643abd2f2563#0:FAIL-t1. Peer's state: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200:t1, leader=null, voted=b67f1ce3-fbfb-4e89-9cbc-643abd2f2563, raftlog=Memoized:b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:36,980 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2023-02-02 20:27:36,980 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: d767bd78-5310-4536-b2f7-e45413a997a1<-b67f1ce3-fbfb-4e89-9cbc-643abd2f2563#0:FAIL-t1
2023-02-02 20:27:36,980 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: d767bd78-5310-4536-b2f7-e45413a997a1<-78962ee0-dad8-4871-bc4b-e1f0b96bf3d9#0:FAIL-t1
2023-02-02 20:27:36,980 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130 ELECTION round 0: result REJECTED
2023-02-02 20:27:36,980 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2023-02-02 20:27:36,980 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - d767bd78-5310-4536-b2f7-e45413a997a1: shutdown d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130
2023-02-02 20:27:36,980 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection130] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d767bd78-5310-4536-b2f7-e45413a997a1: start d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState
2023-02-02 20:27:36,985 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:36,989 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:36,989 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:37,069 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:37,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-02-02 20:27:37,070 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:37,357 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:37,393 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:37,393 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:37,393 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:37,393 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:37,425 [EndpointStateMachine task thread for /0.0.0.0:37573 - 0 ] INFO  ipc.Client (Client.java:handleConnectionFailure(1010)) - Retrying connect to server: 0.0.0.0/0.0.0.0:37573. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2023-02-02 20:27:37,439 [IPC Server handler 0 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 3f7ac4d1-ddb9-474a-8f73-3a04b1780a60(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:37,440 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(207)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:321)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.get(FutureTask.java:205)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2023-02-02 20:27:37,447 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:37,448 [IPC Server handler 1 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode ef8775a4-4a62-450d-ae4d-a3eaa392aaf8(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:37,451 [IPC Server handler 2 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 5b8e2765-a6c1-4d85-87a6-bec4168f79ce(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:37,451 [IPC Server handler 2 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 4ec2caad-ead4-478e-ac51-fb863b7de4b5(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:37,452 [IPC Server handler 4 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 3f7ac4d1-ddb9-474a-8f73-3a04b1780a60(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:37,452 [IPC Server handler 5 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 5b8e2765-a6c1-4d85-87a6-bec4168f79ce(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:37,452 [IPC Server handler 6 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:37,453 [IPC Server handler 7 on default port 37573] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71). Asking datanode to re-register.
2023-02-02 20:27:37,461 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5095911966ns, electionTimeout:5095ms
2023-02-02 20:27:37,461 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: shutdown 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-FollowerState
2023-02-02 20:27:37,461 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-02 20:27:37,461 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:37,461 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: start 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132
2023-02-02 20:27:37,464 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132 ELECTION round 0: submit vote requests at term 1 for -1: peers:[78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:37,464 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132 ELECTION round 0: result PASSED (term=1)
2023-02-02 20:27:37,465 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: shutdown 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132
2023-02-02 20:27:37,465 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-02 20:27:37,465 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-2E6A8FAA1AC2 with new leaderId: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9
2023-02-02 20:27:37,465 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2: change Leader from null to 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9 at term 1 for becomeLeader, leader elected after 5114ms
2023-02-02 20:27:37,465 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-02 20:27:37,465 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:37,465 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-02 20:27:37,466 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-02 20:27:37,466 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-02 20:27:37,466 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-02 20:27:37,466 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:37,466 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-02 20:27:37,466 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: start 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderStateImpl
2023-02-02 20:27:37,466 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:37,467 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:37,468 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis/9a11209b-2cb2-422e-bd22-2e6a8faa1ac2/current/log_inprogress_0
2023-02-02 20:27:37,472 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2-LeaderElection132] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-2E6A8FAA1AC2: set configuration 0: peers:[78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:37,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:37,731 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:37,746 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:37,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:37,985 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:38,009 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:38,070 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:38,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:38,070 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:38,076 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5084040528ns, electionTimeout:5008ms
2023-02-02 20:27:38,077 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d767bd78-5310-4536-b2f7-e45413a997a1: shutdown d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-FollowerState
2023-02-02 20:27:38,077 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-02 20:27:38,077 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:38,077 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d767bd78-5310-4536-b2f7-e45413a997a1: start d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133
2023-02-02 20:27:38,078 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133 ELECTION round 0: submit vote requests at term 1 for -1: peers:[d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:38,079 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133 ELECTION round 0: result PASSED (term=1)
2023-02-02 20:27:38,079 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - d767bd78-5310-4536-b2f7-e45413a997a1: shutdown d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133
2023-02-02 20:27:38,079 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-02 20:27:38,079 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-4685184DB1B7 with new leaderId: d767bd78-5310-4536-b2f7-e45413a997a1
2023-02-02 20:27:38,079 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7: change Leader from null to d767bd78-5310-4536-b2f7-e45413a997a1 at term 1 for becomeLeader, leader elected after 5101ms
2023-02-02 20:27:38,079 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-02 20:27:38,079 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:38,079 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-02 20:27:38,080 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-02 20:27:38,080 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-02 20:27:38,080 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-02 20:27:38,080 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:38,080 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-02 20:27:38,080 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d767bd78-5310-4536-b2f7-e45413a997a1: start d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderStateImpl
2023-02-02 20:27:38,081 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:38,082 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:38,085 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-LeaderElection133] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7: set configuration 0: peers:[d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:38,087 [d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-4685184DB1B7-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis/648c6b16-b370-4b37-9777-4685184db1b7/current/log_inprogress_0
2023-02-02 20:27:38,178 [IPC Server handler 0 on default port 37573] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/4ec2caad-ead4-478e-ac51-fb863b7de4b5
2023-02-02 20:27:38,179 [IPC Server handler 0 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 4ec2caad-ead4-478e-ac51-fb863b7de4b5{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=36373, RATIS=45079, RATIS_ADMIN=45079, RATIS_SERVER=45079, RATIS_DATASTREAM=45141, STANDALONE=42005], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:38,187 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-02-02 20:27:38,187 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-02-02 20:27:38,188 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 2
2023-02-02 20:27:38,193 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:38,195 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:38,249 [IPC Server handler 1 on default port 37573] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/c2e5a0ee-722e-430e-828a-2d735c45daa1
2023-02-02 20:27:38,250 [IPC Server handler 1 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : c2e5a0ee-722e-430e-828a-2d735c45daa1{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=42483, RATIS=46481, RATIS_ADMIN=46481, RATIS_SERVER=46481, RATIS_DATASTREAM=36873, STANDALONE=35925], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:38,250 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:38,250 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 100.0 % containers have at least one reported replica.
2023-02-02 20:27:38,250 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-02-02 20:27:38,250 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 2
2023-02-02 20:27:38,252 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-02-02 20:27:38,253 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:38,365 [IPC Server handler 2 on default port 37573] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/7153b2e5-6547-4596-92e7-e397d052a5ec
2023-02-02 20:27:38,366 [IPC Server handler 2 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 7153b2e5-6547-4596-92e7-e397d052a5ec{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=33391, RATIS=33067, RATIS_ADMIN=33067, RATIS_SERVER=33067, RATIS_DATASTREAM=41865, STANDALONE=43301], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:38,366 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:38,370 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-02-02 20:27:38,370 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:38,370 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-02-02 20:27:38,370 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 2
2023-02-02 20:27:38,373 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-02-02 20:27:38,373 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-02-02 20:27:38,373 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-02-02 20:27:38,373 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:38,373 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-02-02 20:27:38,393 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:38,394 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:38,394 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:38,418 [IPC Server handler 4 on default port 37573] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/ef8775a4-4a62-450d-ae4d-a3eaa392aaf8
2023-02-02 20:27:38,418 [IPC Server handler 4 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : ef8775a4-4a62-450d-ae4d-a3eaa392aaf8{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=45915, RATIS=33485, RATIS_ADMIN=33485, RATIS_SERVER=33485, RATIS_DATASTREAM=39369, STANDALONE=36617], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:38,423 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 2, required at least one datanode reported per pipeline count is 2
2023-02-02 20:27:38,423 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-02-02 20:27:38,423 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-02-02 20:27:38,423 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-02-02 20:27:38,423 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-02-02 20:27:38,423 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-02-02 20:27:38,423 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-02-02 20:27:38,423 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-02-02 20:27:38,423 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(937)) - Service ReplicationManager transitions to RUNNING.
2023-02-02 20:27:38,423 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-02-02 20:27:38,424 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:38,426 [IPC Server handler 5 on default port 37573] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/3f7ac4d1-ddb9-474a-8f73-3a04b1780a60
2023-02-02 20:27:38,426 [IPC Server handler 5 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 3f7ac4d1-ddb9-474a-8f73-3a04b1780a60{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=33869, RATIS=33907, RATIS_ADMIN=33907, RATIS_SERVER=33907, RATIS_DATASTREAM=40869, STANDALONE=43321], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:38,426 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:38,445 [IPC Server handler 6 on default port 37573] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/5b8e2765-a6c1-4d85-87a6-bec4168f79ce
2023-02-02 20:27:38,446 [IPC Server handler 6 on default port 37573] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 5b8e2765-a6c1-4d85-87a6-bec4168f79ce{ip: 10.1.1.71, host: fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net, ports: [REPLICATION=35361, RATIS=45251, RATIS_ADMIN=45251, RATIS_SERVER=45251, RATIS_DATASTREAM=44061, STANDALONE=42465], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-02 20:27:38,446 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-02 20:27:38,446 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-02-02 20:27:38,467 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:38,484 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5045611757ns, electionTimeout:5045ms
2023-02-02 20:27:38,484 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 235120ac-71a1-451e-bf57-c5cd114d9629: shutdown 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-FollowerState
2023-02-02 20:27:38,485 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-02 20:27:38,485 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:38,485 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 235120ac-71a1-451e-bf57-c5cd114d9629: start 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134
2023-02-02 20:27:38,487 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134 ELECTION round 0: submit vote requests at term 1 for -1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:38,487 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134 ELECTION round 0: result PASSED (term=1)
2023-02-02 20:27:38,487 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 235120ac-71a1-451e-bf57-c5cd114d9629: shutdown 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134
2023-02-02 20:27:38,487 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-02 20:27:38,487 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-21297C9FD6BD with new leaderId: 235120ac-71a1-451e-bf57-c5cd114d9629
2023-02-02 20:27:38,487 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD: change Leader from null to 235120ac-71a1-451e-bf57-c5cd114d9629 at term 1 for becomeLeader, leader elected after 5061ms
2023-02-02 20:27:38,487 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-02 20:27:38,488 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:38,488 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-02 20:27:38,488 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:38,488 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-02 20:27:38,488 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-02 20:27:38,488 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-02 20:27:38,489 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:38,489 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-02 20:27:38,489 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 235120ac-71a1-451e-bf57-c5cd114d9629: start 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderStateImpl
2023-02-02 20:27:38,489 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:38,490 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis/24040cbb-e033-4e5f-8298-21297c9fd6bd/current/log_inprogress_0
2023-02-02 20:27:38,494 [235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD-LeaderElection134] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-21297C9FD6BD: set configuration 0: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:38,536 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5081692987ns, electionTimeout:5080ms
2023-02-02 20:27:38,536 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 235120ac-71a1-451e-bf57-c5cd114d9629: shutdown 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:38,536 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-02 20:27:38,536 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:38,536 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 235120ac-71a1-451e-bf57-c5cd114d9629: start 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135
2023-02-02 20:27:38,538 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135 ELECTION round 0: submit vote requests at term 1 for -1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:38,538 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:38,538 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29
2023-02-02 20:27:38,539 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:38,539 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 4c73a9f1-7904-4197-8af5-de7b9af59d88
2023-02-02 20:27:38,548 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA: receive requestVote(ELECTION, 235120ac-71a1-451e-bf57-c5cd114d9629, group-56A09B24DBFA, 1, (t:0, i:0))
2023-02-02 20:27:38,548 [grpc-default-executor-17] INFO  impl.VoteContext (VoteContext.java:log(49)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FOLLOWER: reject ELECTION from 235120ac-71a1-451e-bf57-c5cd114d9629: our priority 1 > candidate's priority 0
2023-02-02 20:27:38,548 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:235120ac-71a1-451e-bf57-c5cd114d9629
2023-02-02 20:27:38,548 [grpc-default-executor-17] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: shutdown 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:38,548 [grpc-default-executor-17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: start 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:38,548 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState was interrupted
2023-02-02 20:27:38,549 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA: receive requestVote(ELECTION, 235120ac-71a1-451e-bf57-c5cd114d9629, group-56A09B24DBFA, 1, (t:0, i:0))
2023-02-02 20:27:38,549 [grpc-default-executor-18] INFO  impl.VoteContext (VoteContext.java:log(49)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FOLLOWER: accept ELECTION from 235120ac-71a1-451e-bf57-c5cd114d9629: our priority 0 <= candidate's priority 0
2023-02-02 20:27:38,549 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:235120ac-71a1-451e-bf57-c5cd114d9629
2023-02-02 20:27:38,549 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: shutdown fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:38,549 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: start fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:38,549 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState was interrupted
2023-02-02 20:27:38,550 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:38,550 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:38,550 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:38,550 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:38,550 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA replies to ELECTION vote request: 235120ac-71a1-451e-bf57-c5cd114d9629<-4c73a9f1-7904-4197-8af5-de7b9af59d88#0:FAIL-t1. Peer's state: 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA:t1, leader=null, voted=null, raftlog=Memoized:4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:38,552 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA replies to ELECTION vote request: 235120ac-71a1-451e-bf57-c5cd114d9629<-fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29#0:OK-t1. Peer's state: fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA:t1, leader=null, voted=235120ac-71a1-451e-bf57-c5cd114d9629, raftlog=Memoized:fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:38,552 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2023-02-02 20:27:38,552 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 235120ac-71a1-451e-bf57-c5cd114d9629<-4c73a9f1-7904-4197-8af5-de7b9af59d88#0:FAIL-t1
2023-02-02 20:27:38,552 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135 ELECTION round 0: result REJECTED
2023-02-02 20:27:38,552 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2023-02-02 20:27:38,552 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 235120ac-71a1-451e-bf57-c5cd114d9629: shutdown 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135
2023-02-02 20:27:38,552 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection135] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 235120ac-71a1-451e-bf57-c5cd114d9629: start 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:38,556 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:38,556 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:38,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:38,727 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5007515694ns, electionTimeout:5007ms
2023-02-02 20:27:38,727 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: shutdown fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-FollowerState
2023-02-02 20:27:38,727 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-02 20:27:38,727 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:38,727 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: start fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136
2023-02-02 20:27:38,729 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136 ELECTION round 0: submit vote requests at term 1 for -1: peers:[fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:38,729 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136 ELECTION round 0: result PASSED (term=1)
2023-02-02 20:27:38,729 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: shutdown fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136
2023-02-02 20:27:38,729 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-02 20:27:38,729 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-947B5BDBD3E4 with new leaderId: fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29
2023-02-02 20:27:38,729 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4: change Leader from null to fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29 at term 1 for becomeLeader, leader elected after 5024ms
2023-02-02 20:27:38,729 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-02 20:27:38,730 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:38,730 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-02 20:27:38,730 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:38,731 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-02 20:27:38,731 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-02 20:27:38,731 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-02 20:27:38,731 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:38,731 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-02 20:27:38,731 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: start fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderStateImpl
2023-02-02 20:27:38,731 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:38,736 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-LeaderElection136] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4: set configuration 0: peers:[fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:38,736 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-947B5BDBD3E4-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis/6bb9acfe-0937-42a9-8200-947b5bdbd3e4/current/log_inprogress_0
2023-02-02 20:27:38,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:39,064 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5045610757ns, electionTimeout:5045ms
2023-02-02 20:27:39,065 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: shutdown 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-FollowerState
2023-02-02 20:27:39,065 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-02 20:27:39,065 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:39,065 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: start 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137
2023-02-02 20:27:39,067 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137 ELECTION round 0: submit vote requests at term 1 for -1: peers:[4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:39,068 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137 ELECTION round 0: result PASSED (term=1)
2023-02-02 20:27:39,068 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: shutdown 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137
2023-02-02 20:27:39,068 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-02 20:27:39,068 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-C02D4AE7FD74 with new leaderId: 4c73a9f1-7904-4197-8af5-de7b9af59d88
2023-02-02 20:27:39,068 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74: change Leader from null to 4c73a9f1-7904-4197-8af5-de7b9af59d88 at term 1 for becomeLeader, leader elected after 5063ms
2023-02-02 20:27:39,068 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-02 20:27:39,068 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:39,068 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-02 20:27:39,069 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:39,069 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-02 20:27:39,069 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-02 20:27:39,069 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-02 20:27:39,069 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:39,069 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-02 20:27:39,069 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: start 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderStateImpl
2023-02-02 20:27:39,070 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:39,070 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:39,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:39,070 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:39,075 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-LeaderElection137] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74: set configuration 0: peers:[4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:39,075 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-C02D4AE7FD74-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis/3664afca-a46f-42af-bb6c-c02d4ae7fd74/current/log_inprogress_0
2023-02-02 20:27:39,393 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:39,394 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:39,394 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:39,394 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:39,468 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:39,488 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:39,562 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5167414280ns, electionTimeout:5167ms
2023-02-02 20:27:39,562 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2: shutdown b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-FollowerState
2023-02-02 20:27:39,562 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-02 20:27:39,562 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:39,562 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2: start b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138
2023-02-02 20:27:39,564 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138 ELECTION round 0: submit vote requests at term 1 for -1: peers:[b19954c4-943b-4bda-b8b4-ff98ab071ba2|rpc:10.1.1.71:41919|dataStream:10.1.1.71:38999|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:39,564 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138 ELECTION round 0: result PASSED (term=1)
2023-02-02 20:27:39,564 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2: shutdown b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138
2023-02-02 20:27:39,564 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-02 20:27:39,564 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-4776704241EA with new leaderId: b19954c4-943b-4bda-b8b4-ff98ab071ba2
2023-02-02 20:27:39,565 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA: change Leader from null to b19954c4-943b-4bda-b8b4-ff98ab071ba2 at term 1 for becomeLeader, leader elected after 5183ms
2023-02-02 20:27:39,565 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-02 20:27:39,565 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:39,566 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:39,566 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-02 20:27:39,566 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-02 20:27:39,566 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-02 20:27:39,566 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-02 20:27:39,566 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:39,567 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-02 20:27:39,567 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2: start b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderStateImpl
2023-02-02 20:27:39,567 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:39,571 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-LeaderElection138] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA: set configuration 0: peers:[b19954c4-943b-4bda-b8b4-ff98ab071ba2|rpc:10.1.1.71:41919|dataStream:10.1.1.71:38999|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:39,573 [b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - b19954c4-943b-4bda-b8b4-ff98ab071ba2@group-4776704241EA-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-6/data/ratis/95432b81-0b2d-4aca-b61b-4776704241ea/current/log_inprogress_0
2023-02-02 20:27:39,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:39,729 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:39,747 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:39,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:40,069 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:40,070 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:40,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:40,070 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:40,080 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:40,394 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:40,394 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:40,394 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:40,566 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:40,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:40,730 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:40,786 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:41,068 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:41,070 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:41,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:41,070 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:41,394 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:41,395 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:41,395 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:41,469 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:41,487 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:41,608 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:41,608 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2220)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2023-02-02 20:27:41,609 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1490)) - Sending replicateContainerCommand: containerId: 1, replicaIndex: 0, sourceNodes: [7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)], priority: NORMAL to 5b8e2765-a6c1-4d85-87a6-bec4168f79ce(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:41,609 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2220)) - Container #2 is under replicated. Expected replica count is 3, but found 2.
2023-02-02 20:27:41,609 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1490)) - Sending replicateContainerCommand: containerId: 2, replicaIndex: 0, sourceNodes: [7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)], priority: NORMAL to ef8775a4-4a62-450d-ae4d-a3eaa392aaf8(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:41,609 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2220)) - Container #3 is under replicated. Expected replica count is 3, but found 2.
2023-02-02 20:27:41,609 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1490)) - Sending replicateContainerCommand: containerId: 3, replicaIndex: 0, sourceNodes: [7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)], priority: NORMAL to ef8775a4-4a62-450d-ae4d-a3eaa392aaf8(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)
2023-02-02 20:27:41,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-02 20:27:41,616 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:41,749 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:41,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:42,070 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:42,071 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:42,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:42,081 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:42,100 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5135154949ns, electionTimeout:5132ms
2023-02-02 20:27:42,100 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: shutdown b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState
2023-02-02 20:27:42,100 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2023-02-02 20:27:42,100 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:42,100 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: start b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection139
2023-02-02 20:27:42,102 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection139] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection139 ELECTION round 0: submit vote requests at term 2 for -1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:42,102 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection139] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:42,102 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection139] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:42,103 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: receive requestVote(ELECTION, b67f1ce3-fbfb-4e89-9cbc-643abd2f2563, group-98C2244BC200, 2, (t:0, i:0))
2023-02-02 20:27:42,103 [grpc-default-executor-17] INFO  impl.VoteContext (VoteContext.java:log(49)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FOLLOWER: reject ELECTION from b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: our priority 1 > candidate's priority 0
2023-02-02 20:27:42,103 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:b67f1ce3-fbfb-4e89-9cbc-643abd2f2563
2023-02-02 20:27:42,103 [grpc-default-executor-17] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d767bd78-5310-4536-b2f7-e45413a997a1: shutdown d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState
2023-02-02 20:27:42,103 [grpc-default-executor-17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d767bd78-5310-4536-b2f7-e45413a997a1: start d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState
2023-02-02 20:27:42,103 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState was interrupted
2023-02-02 20:27:42,104 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: receive requestVote(ELECTION, b67f1ce3-fbfb-4e89-9cbc-643abd2f2563, group-98C2244BC200, 2, (t:0, i:0))
2023-02-02 20:27:42,104 [grpc-default-executor-18] INFO  impl.VoteContext (VoteContext.java:log(49)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FOLLOWER: accept ELECTION from b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: our priority 0 <= candidate's priority 0
2023-02-02 20:27:42,104 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:b67f1ce3-fbfb-4e89-9cbc-643abd2f2563
2023-02-02 20:27:42,104 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: shutdown 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState
2023-02-02 20:27:42,104 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: start 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState
2023-02-02 20:27:42,104 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState was interrupted
2023-02-02 20:27:42,104 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:42,104 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:42,105 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200 replies to ELECTION vote request: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563<-d767bd78-5310-4536-b2f7-e45413a997a1#0:FAIL-t2. Peer's state: d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200:t2, leader=null, voted=null, raftlog=Memoized:d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:42,105 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:42,105 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:42,105 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection139] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection139: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2023-02-02 20:27:42,106 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection139] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563<-d767bd78-5310-4536-b2f7-e45413a997a1#0:FAIL-t2
2023-02-02 20:27:42,106 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection139] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection139 ELECTION round 0: result REJECTED
2023-02-02 20:27:42,106 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection139] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
2023-02-02 20:27:42,106 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection139] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: shutdown b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection139
2023-02-02 20:27:42,106 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection139] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: start b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState
2023-02-02 20:27:42,106 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:42,106 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:42,106 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200 replies to ELECTION vote request: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563<-78962ee0-dad8-4871-bc4b-e1f0b96bf3d9#0:OK-t2. Peer's state: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200:t2, leader=null, voted=b67f1ce3-fbfb-4e89-9cbc-643abd2f2563, raftlog=Memoized:78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:42,395 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:42,395 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:42,395 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:42,468 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:42,566 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:42,608 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:42,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:42,616 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:42,730 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:42,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:43,069 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:43,070 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:43,071 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:43,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:43,395 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:43,395 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:43,395 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:43,418 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(71)) - Starting replication of container 2 from [7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)]
2023-02-02 20:27:43,421 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(71)) - Starting replication of container 3 from [7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)]
2023-02-02 20:27:43,424 [grpc-default-executor-17] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(61)) - Streaming container data (2) to other datanode with compression NO_COMPRESSION
2023-02-02 20:27:43,428 [grpc-default-executor-18] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(61)) - Streaming container data (3) to other datanode with compression NO_COMPRESSION
2023-02-02 20:27:43,446 [grpc-default-executor-17] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(102)) - Sent 11776 bytes for container 2
2023-02-02 20:27:43,447 [grpc-default-executor-17] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(202)) - Container 2 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-2/data-0/containers/tmp/container-copy/container-2.tar
2023-02-02 20:27:43,449 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(86)) - Container 2 is downloaded with size 11776, starting to import.
2023-02-02 20:27:43,454 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(71)) - Starting replication of container 1 from [7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)]
2023-02-02 20:27:43,466 [grpc-default-executor-17] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(61)) - Streaming container data (1) to other datanode with compression NO_COMPRESSION
2023-02-02 20:27:43,469 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:43,477 [grpc-default-executor-17] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(102)) - Sent 11776 bytes for container 1
2023-02-02 20:27:43,478 [grpc-default-executor-3] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(202)) - Container 1 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-1/data-0/containers/tmp/container-copy/container-1.tar
2023-02-02 20:27:43,479 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(86)) - Container 1 is downloaded with size 11776, starting to import.
2023-02-02 20:27:43,483 [grpc-default-executor-18] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(102)) - Sent 11776 bytes for container 3
2023-02-02 20:27:43,490 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:43,492 [grpc-default-executor-3] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(202)) - Container 3 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-2/data-0/containers/tmp/container-copy/container-3.tar
2023-02-02 20:27:43,493 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(86)) - Container 3 is downloaded with size 11776, starting to import.
2023-02-02 20:27:43,523 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(93)) - Container 3 is replicated successfully
2023-02-02 20:27:43,523 [ContainerReplicationThread-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(217)) - Successful ReplicationTask{status=DONE, cmd={replicateContainerCommand: containerId: 3, replicaIndex: 0, sourceNodes: [7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)], priority: NORMAL}, queued=2023-02-02T20:27:43.418Z}
2023-02-02 20:27:43,526 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(93)) - Container 2 is replicated successfully
2023-02-02 20:27:43,526 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(217)) - Successful ReplicationTask{status=DONE, cmd={replicateContainerCommand: containerId: 2, replicaIndex: 0, sourceNodes: [7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)], priority: NORMAL}, queued=2023-02-02T20:27:43.417Z}
2023-02-02 20:27:43,545 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(93)) - Container 1 is replicated successfully
2023-02-02 20:27:43,546 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(217)) - Successful ReplicationTask{status=DONE, cmd={replicateContainerCommand: containerId: 1, replicaIndex: 0, sourceNodes: [7153b2e5-6547-4596-92e7-e397d052a5ec(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), c2e5a0ee-722e-430e-828a-2d735c45daa1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)], priority: NORMAL}, queued=2023-02-02T20:27:43.446Z}
2023-02-02 20:27:43,608 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:43,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-02 20:27:43,616 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:43,661 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5108292029ns, electionTimeout:5104ms
2023-02-02 20:27:43,661 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 235120ac-71a1-451e-bf57-c5cd114d9629: shutdown 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:43,661 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2023-02-02 20:27:43,661 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:43,661 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 235120ac-71a1-451e-bf57-c5cd114d9629: start 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection140
2023-02-02 20:27:43,663 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection140] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection140 ELECTION round 0: submit vote requests at term 2 for -1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:43,663 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection140] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:43,663 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection140] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:43,664 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA: receive requestVote(ELECTION, 235120ac-71a1-451e-bf57-c5cd114d9629, group-56A09B24DBFA, 2, (t:0, i:0))
2023-02-02 20:27:43,664 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FOLLOWER: accept ELECTION from 235120ac-71a1-451e-bf57-c5cd114d9629: our priority 0 <= candidate's priority 0
2023-02-02 20:27:43,664 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:235120ac-71a1-451e-bf57-c5cd114d9629
2023-02-02 20:27:43,664 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: shutdown fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:43,664 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: start fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:43,664 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA: receive requestVote(ELECTION, 235120ac-71a1-451e-bf57-c5cd114d9629, group-56A09B24DBFA, 2, (t:0, i:0))
2023-02-02 20:27:43,665 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState was interrupted
2023-02-02 20:27:43,665 [grpc-default-executor-18] INFO  impl.VoteContext (VoteContext.java:log(49)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FOLLOWER: reject ELECTION from 235120ac-71a1-451e-bf57-c5cd114d9629: our priority 1 > candidate's priority 0
2023-02-02 20:27:43,665 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:235120ac-71a1-451e-bf57-c5cd114d9629
2023-02-02 20:27:43,665 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: shutdown 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:43,665 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: start 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:43,665 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:43,665 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:43,665 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState was interrupted
2023-02-02 20:27:43,666 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:43,666 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:43,666 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA replies to ELECTION vote request: 235120ac-71a1-451e-bf57-c5cd114d9629<-fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29#0:OK-t2. Peer's state: fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA:t2, leader=null, voted=235120ac-71a1-451e-bf57-c5cd114d9629, raftlog=Memoized:fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:43,666 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA replies to ELECTION vote request: 235120ac-71a1-451e-bf57-c5cd114d9629<-4c73a9f1-7904-4197-8af5-de7b9af59d88#0:FAIL-t2. Peer's state: 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA:t2, leader=null, voted=null, raftlog=Memoized:4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:43,667 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection140] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection140: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2023-02-02 20:27:43,667 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection140] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 235120ac-71a1-451e-bf57-c5cd114d9629<-fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29#0:OK-t2
2023-02-02 20:27:43,667 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection140] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 235120ac-71a1-451e-bf57-c5cd114d9629<-4c73a9f1-7904-4197-8af5-de7b9af59d88#0:FAIL-t2
2023-02-02 20:27:43,667 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection140] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection140 ELECTION round 0: result REJECTED
2023-02-02 20:27:43,667 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection140] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
2023-02-02 20:27:43,667 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection140] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 235120ac-71a1-451e-bf57-c5cd114d9629: shutdown 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection140
2023-02-02 20:27:43,667 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-LeaderElection140] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 235120ac-71a1-451e-bf57-c5cd114d9629: start 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:43,667 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:43,668 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:43,750 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:43,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:44,069 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:44,071 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:44,071 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:44,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:44,080 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:44,395 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:44,396 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:44,396 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:44,469 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:44,569 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:44,608 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:44,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:44,616 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:44,731 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:44,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:45,071 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:45,071 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:45,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:45,396 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:45,396 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:45,396 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:45,469 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:45,495 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:45,608 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:45,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:45,617 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:45,730 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:45,754 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:45,787 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:46,069 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:46,071 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:46,071 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:46,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:46,081 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:46,396 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:46,396 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:46,396 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:46,469 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:46,569 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:46,609 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:46,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-02 20:27:46,618 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:47,441 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:47,441 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:47,441 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:47,445 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5339173287ns, electionTimeout:5188ms
2023-02-02 20:27:47,445 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: shutdown 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState
2023-02-02 20:27:47,445 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2023-02-02 20:27:47,446 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:47,446 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: start 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141
2023-02-02 20:27:47,446 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5340721312ns, electionTimeout:5187ms
2023-02-02 20:27:47,446 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: shutdown b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState
2023-02-02 20:27:47,447 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2023-02-02 20:27:47,447 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:47,447 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: start b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection142
2023-02-02 20:27:47,448 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141 ELECTION round 0: submit vote requests at term 3 for -1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:47,453 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection142] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection142 ELECTION round 0: submit vote requests at term 3 for -1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:47,454 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:47,454 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:47,454 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for b67f1ce3-fbfb-4e89-9cbc-643abd2f2563
2023-02-02 20:27:47,455 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for d767bd78-5310-4536-b2f7-e45413a997a1
2023-02-02 20:27:47,456 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] WARN  impl.FollowerState (FollowerState.java:run(130)) - Unexpected long sleep: sleep 5001ms but took extra 350302585ns (> threshold = 300ms)
2023-02-02 20:27:47,456 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:47,456 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:47,456 [JvmPauseMonitor35] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-5b8e2765-a6c1-4d85-87a6-bec4168f79ce: Detected pause in JVM or host machine (eg GC): pause of approximately 383391909ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,456 [JvmPauseMonitor41] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 383524611ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,457 [JvmPauseMonitor46] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-a8bd3719-ed86-42e1-a40d-2b4ed0b09d7c: Detected pause in JVM or host machine (eg GC): pause of approximately 384065020ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,457 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:47,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:47,457 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:47,457 [JvmPauseMonitor48] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-3f3d7b74-b56c-404b-afe2-89147051cf18: Detected pause in JVM or host machine (eg GC): pause of approximately 387185671ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,457 [JvmPauseMonitor34] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-3f7ac4d1-ddb9-474a-8f73-3a04b1780a60: Detected pause in JVM or host machine (eg GC): pause of approximately 387731080ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,457 [JvmPauseMonitor55] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-235120ac-71a1-451e-bf57-c5cd114d9629: Detected pause in JVM or host machine (eg GC): pause of approximately 387946083ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,457 [JvmPauseMonitor54] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-d767bd78-5310-4536-b2f7-e45413a997a1: Detected pause in JVM or host machine (eg GC): pause of approximately 388082985ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,462 [JvmPauseMonitor43] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-c0917728-87bf-433d-b3f0-4191e0e505db: Detected pause in JVM or host machine (eg GC): pause of approximately 394175785ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,462 [JvmPauseMonitor33] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 395301103ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,462 [JvmPauseMonitor45] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-16d82cf4-1422-4a15-9631-5fbf1a57277e: Detected pause in JVM or host machine (eg GC): pause of approximately 395337203ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,462 [JvmPauseMonitor57] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-4c73a9f1-7904-4197-8af5-de7b9af59d88: Detected pause in JVM or host machine (eg GC): pause of approximately 395907413ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,468 [JvmPauseMonitor42] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-4536c619-fdf7-4443-8da6-b71e8b366fa5: Detected pause in JVM or host machine (eg GC): pause of approximately 474782799ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,469 [JvmPauseMonitor37] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-c2e5a0ee-722e-430e-828a-2d735c45daa1: Detected pause in JVM or host machine (eg GC): pause of approximately 474922102ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,469 [JvmPauseMonitor36] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-ef8775a4-4a62-450d-ae4d-a3eaa392aaf8: Detected pause in JVM or host machine (eg GC): pause of approximately 474985503ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,469 [JvmPauseMonitor39] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-7153b2e5-6547-4596-92e7-e397d052a5ec: Detected pause in JVM or host machine (eg GC): pause of approximately 479515477ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,472 [JvmPauseMonitor40] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-4ec2caad-ead4-478e-ac51-fb863b7de4b5: Detected pause in JVM or host machine (eg GC): pause of approximately 488949130ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,473 [JvmPauseMonitor58] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-b19954c4-943b-4bda-b8b4-ff98ab071ba2: Detected pause in JVM or host machine (eg GC): pause of approximately 512644717ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,480 [JvmPauseMonitor44] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-964ef1ca-08ae-4b3c-a2ce-6bf03c7bf022: Detected pause in JVM or host machine (eg GC): pause of approximately 539000247ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,480 [JvmPauseMonitor47] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-00fc006e-6b43-4634-bd06-6319b071a59a: Detected pause in JVM or host machine (eg GC): pause of approximately 539012648ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,487 [JvmPauseMonitor53] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: Detected pause in JVM or host machine (eg GC): pause of approximately 563055039ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,490 [3f7ac4d1-ddb9-474a-8f73-3a04b1780a60@group-9D5E22661B84-FollowerState] WARN  impl.FollowerState (FollowerState.java:run(130)) - Unexpected long sleep: sleep 5171ms but took extra 619803953ns (> threshold = 300ms)
2023-02-02 20:27:47,490 [5b8e2765-a6c1-4d85-87a6-bec4168f79ce@group-9D5E22661B84-FollowerState] WARN  impl.FollowerState (FollowerState.java:run(130)) - Unexpected long sleep: sleep 5189ms but took extra 627633474ns (> threshold = 300ms)
2023-02-02 20:27:47,490 [JvmPauseMonitor51] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 627814395ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,502 [JvmPauseMonitor52] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: Detected pause in JVM or host machine (eg GC): pause of approximately 734034528ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,501 [JvmPauseMonitor56] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: Detected pause in JVM or host machine (eg GC): pause of approximately 716055535ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=520ms
GC pool 'PS Scavenge' had collection(s): count=1 time=142ms
2023-02-02 20:27:47,501 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:47,516 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:47,517 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:47,523 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:47,523 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection142] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:47,529 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: receive requestVote(ELECTION, b67f1ce3-fbfb-4e89-9cbc-643abd2f2563, group-98C2244BC200, 3, (t:0, i:0))
2023-02-02 20:27:47,529 [grpc-default-executor-17] INFO  impl.VoteContext (VoteContext.java:log(49)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-CANDIDATE: reject ELECTION from b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: already has voted for 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9 at current term 3
2023-02-02 20:27:47,529 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200 replies to ELECTION vote request: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563<-78962ee0-dad8-4871-bc4b-e1f0b96bf3d9#0:FAIL-t3. Peer's state: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200:t3, leader=null, voted=78962ee0-dad8-4871-bc4b-e1f0b96bf3d9, raftlog=Memoized:78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:47,530 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: receive requestVote(ELECTION, b67f1ce3-fbfb-4e89-9cbc-643abd2f2563, group-98C2244BC200, 3, (t:0, i:0))
2023-02-02 20:27:47,530 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FOLLOWER: reject ELECTION from b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: our priority 1 > candidate's priority 0
2023-02-02 20:27:47,530 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:b67f1ce3-fbfb-4e89-9cbc-643abd2f2563
2023-02-02 20:27:47,530 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d767bd78-5310-4536-b2f7-e45413a997a1: shutdown d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState
2023-02-02 20:27:47,530 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d767bd78-5310-4536-b2f7-e45413a997a1: start d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState
2023-02-02 20:27:47,530 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState was interrupted
2023-02-02 20:27:47,532 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200 replies to ELECTION vote request: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563<-d767bd78-5310-4536-b2f7-e45413a997a1#0:FAIL-t3. Peer's state: d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200:t3, leader=null, voted=null, raftlog=Memoized:d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:47,552 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection142] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection142: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2023-02-02 20:27:47,552 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection142] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563<-d767bd78-5310-4536-b2f7-e45413a997a1#0:FAIL-t3
2023-02-02 20:27:47,552 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection142] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563<-78962ee0-dad8-4871-bc4b-e1f0b96bf3d9#0:FAIL-t3
2023-02-02 20:27:47,552 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection142] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection142 ELECTION round 0: result REJECTED
2023-02-02 20:27:47,552 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection142] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
2023-02-02 20:27:47,552 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection142] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: shutdown b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection142
2023-02-02 20:27:47,552 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-LeaderElection142] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: start b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState
2023-02-02 20:27:47,554 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:47,554 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:47,554 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:47,554 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:47,557 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: receive requestVote(ELECTION, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9, group-98C2244BC200, 3, (t:0, i:0))
2023-02-02 20:27:47,557 [grpc-default-executor-17] INFO  impl.VoteContext (VoteContext.java:log(49)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FOLLOWER: reject ELECTION from 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: our priority 1 > candidate's priority 0
2023-02-02 20:27:47,557 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:78962ee0-dad8-4871-bc4b-e1f0b96bf3d9
2023-02-02 20:27:47,557 [grpc-default-executor-17] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d767bd78-5310-4536-b2f7-e45413a997a1: shutdown d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState
2023-02-02 20:27:47,557 [grpc-default-executor-17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d767bd78-5310-4536-b2f7-e45413a997a1: start d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState
2023-02-02 20:27:47,557 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200 replies to ELECTION vote request: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9<-d767bd78-5310-4536-b2f7-e45413a997a1#0:FAIL-t3. Peer's state: d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200:t3, leader=null, voted=null, raftlog=Memoized:d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:47,557 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState was interrupted
2023-02-02 20:27:47,558 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2023-02-02 20:27:47,558 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9<-d767bd78-5310-4536-b2f7-e45413a997a1#0:FAIL-t3
2023-02-02 20:27:47,558 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141 ELECTION round 0: result REJECTED
2023-02-02 20:27:47,558 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
2023-02-02 20:27:47,558 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: shutdown 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141
2023-02-02 20:27:47,558 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection141] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: start 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState
2023-02-02 20:27:47,558 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:47,558 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:47,560 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:47,560 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:47,563 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: receive requestVote(ELECTION, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9, group-98C2244BC200, 3, (t:0, i:0))
2023-02-02 20:27:47,564 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FOLLOWER: reject ELECTION from 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: already has voted for b67f1ce3-fbfb-4e89-9cbc-643abd2f2563 at current term 3
2023-02-02 20:27:47,564 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200 replies to ELECTION vote request: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9<-b67f1ce3-fbfb-4e89-9cbc-643abd2f2563#0:FAIL-t3. Peer's state: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200:t3, leader=null, voted=b67f1ce3-fbfb-4e89-9cbc-643abd2f2563, raftlog=Memoized:b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:47,609 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:47,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:47,618 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:47,730 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:47,757 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:48,441 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:48,441 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-02 20:27:48,441 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:48,457 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:48,457 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:48,457 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:48,457 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:48,463 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:48,469 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:48,496 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:48,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:48,569 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-02 20:27:48,609 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:48,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:48,618 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:48,672 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5006944254ns, electionTimeout:5006ms
2023-02-02 20:27:48,672 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: shutdown 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:48,672 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2023-02-02 20:27:48,672 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:48,672 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: start 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143
2023-02-02 20:27:48,674 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143 ELECTION round 0: submit vote requests at term 3 for -1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:48,675 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:48,675 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:48,675 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 235120ac-71a1-451e-bf57-c5cd114d9629
2023-02-02 20:27:48,675 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29
2023-02-02 20:27:48,687 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA: receive requestVote(ELECTION, 4c73a9f1-7904-4197-8af5-de7b9af59d88, group-56A09B24DBFA, 3, (t:0, i:0))
2023-02-02 20:27:48,688 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FOLLOWER: accept ELECTION from 4c73a9f1-7904-4197-8af5-de7b9af59d88: our priority 0 <= candidate's priority 1
2023-02-02 20:27:48,688 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:4c73a9f1-7904-4197-8af5-de7b9af59d88
2023-02-02 20:27:48,688 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 235120ac-71a1-451e-bf57-c5cd114d9629: shutdown 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:48,688 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 235120ac-71a1-451e-bf57-c5cd114d9629: start 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:48,688 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState was interrupted
2023-02-02 20:27:48,688 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA: receive requestVote(ELECTION, 4c73a9f1-7904-4197-8af5-de7b9af59d88, group-56A09B24DBFA, 3, (t:0, i:0))
2023-02-02 20:27:48,688 [grpc-default-executor-17] INFO  impl.VoteContext (VoteContext.java:log(49)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FOLLOWER: accept ELECTION from 4c73a9f1-7904-4197-8af5-de7b9af59d88: our priority 0 <= candidate's priority 1
2023-02-02 20:27:48,688 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:4c73a9f1-7904-4197-8af5-de7b9af59d88
2023-02-02 20:27:48,688 [grpc-default-executor-17] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: shutdown fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:48,689 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:48,689 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:48,689 [grpc-default-executor-17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29: start fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState
2023-02-02 20:27:48,689 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState was interrupted
2023-02-02 20:27:48,690 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA replies to ELECTION vote request: 4c73a9f1-7904-4197-8af5-de7b9af59d88<-235120ac-71a1-451e-bf57-c5cd114d9629#0:OK-t3. Peer's state: 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA:t3, leader=null, voted=4c73a9f1-7904-4197-8af5-de7b9af59d88, raftlog=Memoized:235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:48,691 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-02-02 20:27:48,691 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 4c73a9f1-7904-4197-8af5-de7b9af59d88<-235120ac-71a1-451e-bf57-c5cd114d9629#0:OK-t3
2023-02-02 20:27:48,691 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:48,691 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143 ELECTION round 0: result PASSED
2023-02-02 20:27:48,691 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: shutdown 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143
2023-02-02 20:27:48,691 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
2023-02-02 20:27:48,691 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-56A09B24DBFA with new leaderId: 4c73a9f1-7904-4197-8af5-de7b9af59d88
2023-02-02 20:27:48,691 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA: change Leader from null to 4c73a9f1-7904-4197-8af5-de7b9af59d88 at term 3 for becomeLeader, leader elected after 15202ms
2023-02-02 20:27:48,692 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-02 20:27:48,692 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:48,692 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-02 20:27:48,692 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-02 20:27:48,692 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-02 20:27:48,692 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-02 20:27:48,692 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:48,692 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-02 20:27:48,691 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA replies to ELECTION vote request: 4c73a9f1-7904-4197-8af5-de7b9af59d88<-fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29#0:OK-t3. Peer's state: fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA:t3, leader=null, voted=4c73a9f1-7904-4197-8af5-de7b9af59d88, raftlog=Memoized:fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:48,695 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 39f90b93-57d1-4e92-9a34-56a09b24dbfa, Nodes: fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)235120ac-71a1-451e-bf57-c5cd114d9629(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)4c73a9f1-7904-4197-8af5-de7b9af59d88(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:4c73a9f1-7904-4197-8af5-de7b9af59d88, CreationTimestamp2023-02-02T20:27:31.007Z[Etc/UTC]] moved to OPEN state
2023-02-02 20:27:48,695 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-02-02 20:27:48,696 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-02-02 20:27:48,696 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-02-02 20:27:48,696 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-02-02 20:27:48,696 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-02-02 20:27:48,696 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-02-02 20:27:48,696 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:48,696 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-02-02 20:27:48,696 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:48,696 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-02-02 20:27:48,697 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-02-02 20:27:48,697 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-02 20:27:48,697 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:48,697 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-02 20:27:48,697 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-02-02 20:27:48,696 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-02-02 20:27:48,698 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-02-02 20:27:48,698 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(937)) - Service ReplicationManager transitions to RUNNING.
2023-02-02 20:27:48,698 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-02-02 20:27:48,700 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-02-02 20:27:48,700 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:48,700 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-02-02 20:27:48,701 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-02-02 20:27:48,701 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-02 20:27:48,701 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:48,701 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-02 20:27:48,701 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-02-02 20:27:48,701 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88: start 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderStateImpl
2023-02-02 20:27:48,702 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:48,715 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-LeaderElection143] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA: set configuration 0: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:48,716 [4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 4c73a9f1-7904-4197-8af5-de7b9af59d88@group-56A09B24DBFA-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-5/data/ratis/39f90b93-57d1-4e92-9a34-56a09b24dbfa/current/log_inprogress_0
2023-02-02 20:27:48,721 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-56A09B24DBFA with new leaderId: 4c73a9f1-7904-4197-8af5-de7b9af59d88
2023-02-02 20:27:48,721 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA: change Leader from null to 4c73a9f1-7904-4197-8af5-de7b9af59d88 at term 3 for appendEntries, leader elected after 15257ms
2023-02-02 20:27:48,722 [235120ac-71a1-451e-bf57-c5cd114d9629-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-56A09B24DBFA with new leaderId: 4c73a9f1-7904-4197-8af5-de7b9af59d88
2023-02-02 20:27:48,722 [235120ac-71a1-451e-bf57-c5cd114d9629-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA: change Leader from null to 4c73a9f1-7904-4197-8af5-de7b9af59d88 at term 3 for appendEntries, leader elected after 15280ms
2023-02-02 20:27:48,737 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA: set configuration 0: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:48,738 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:48,740 [fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29@group-56A09B24DBFA-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-4/data/ratis/39f90b93-57d1-4e92-9a34-56a09b24dbfa/current/log_inprogress_0
2023-02-02 20:27:48,744 [235120ac-71a1-451e-bf57-c5cd114d9629-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA: set configuration 0: peers:[235120ac-71a1-451e-bf57-c5cd114d9629|rpc:10.1.1.71:36259|dataStream:10.1.1.71:43003|priority:0|startupRole:FOLLOWER, fd2d6c0d-60ec-48c9-91bf-eaf2afc7eb29|rpc:10.1.1.71:46223|dataStream:10.1.1.71:40341|priority:0|startupRole:FOLLOWER, 4c73a9f1-7904-4197-8af5-de7b9af59d88|rpc:10.1.1.71:46827|dataStream:10.1.1.71:42537|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:48,744 [235120ac-71a1-451e-bf57-c5cd114d9629-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:48,747 [235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 235120ac-71a1-451e-bf57-c5cd114d9629@group-56A09B24DBFA-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-3/data/ratis/39f90b93-57d1-4e92-9a34-56a09b24dbfa/current/log_inprogress_0
2023-02-02 20:27:49,441 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-02 20:27:49,442 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Cluster exits safe mode
2023-02-02 20:27:49,442 [Listener at 127.0.0.1/43469] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-02 20:27:49,457 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:49,457 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:49,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:49,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:49,609 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:49,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:49,618 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:50,457 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:50,458 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:50,458 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:50,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:50,609 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:50,613 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:50,618 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:51,458 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:51,458 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:51,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:51,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-02 20:27:51,610 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:51,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-02 20:27:51,618 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:51,753 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:52,458 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:52,458 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:52,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:52,501 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:52,514 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:52,598 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5039833546ns, electionTimeout:5033ms
2023-02-02 20:27:52,598 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: shutdown 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState
2023-02-02 20:27:52,598 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2023-02-02 20:27:52,598 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:52,598 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: start 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection144
2023-02-02 20:27:52,600 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection144] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection144 ELECTION round 0: submit vote requests at term 4 for -1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:52,601 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:52,601 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection144] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:52,602 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: receive requestVote(ELECTION, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9, group-98C2244BC200, 4, (t:0, i:0))
2023-02-02 20:27:52,602 [grpc-default-executor-18] INFO  impl.VoteContext (VoteContext.java:log(49)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FOLLOWER: reject ELECTION from 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: our priority 1 > candidate's priority 0
2023-02-02 20:27:52,603 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:78962ee0-dad8-4871-bc4b-e1f0b96bf3d9
2023-02-02 20:27:52,603 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d767bd78-5310-4536-b2f7-e45413a997a1: shutdown d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState
2023-02-02 20:27:52,603 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d767bd78-5310-4536-b2f7-e45413a997a1: start d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState
2023-02-02 20:27:52,603 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState was interrupted
2023-02-02 20:27:52,603 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:52,604 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: receive requestVote(ELECTION, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9, group-98C2244BC200, 4, (t:0, i:0))
2023-02-02 20:27:52,604 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:52,604 [grpc-default-executor-17] INFO  impl.VoteContext (VoteContext.java:log(49)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FOLLOWER: accept ELECTION from 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: our priority 0 <= candidate's priority 0
2023-02-02 20:27:52,604 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:78962ee0-dad8-4871-bc4b-e1f0b96bf3d9
2023-02-02 20:27:52,604 [grpc-default-executor-17] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: shutdown b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState
2023-02-02 20:27:52,604 [grpc-default-executor-17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: start b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState
2023-02-02 20:27:52,604 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200 replies to ELECTION vote request: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9<-d767bd78-5310-4536-b2f7-e45413a997a1#0:FAIL-t4. Peer's state: d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200:t4, leader=null, voted=null, raftlog=Memoized:d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:52,604 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState was interrupted
2023-02-02 20:27:52,605 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:52,605 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:52,605 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection144] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection144: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2023-02-02 20:27:52,605 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection144] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9<-d767bd78-5310-4536-b2f7-e45413a997a1#0:FAIL-t4
2023-02-02 20:27:52,605 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection144] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection144 ELECTION round 0: result REJECTED
2023-02-02 20:27:52,605 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection144] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
2023-02-02 20:27:52,605 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection144] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: shutdown 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection144
2023-02-02 20:27:52,605 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-LeaderElection144] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: start 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState
2023-02-02 20:27:52,605 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200 replies to ELECTION vote request: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9<-b67f1ce3-fbfb-4e89-9cbc-643abd2f2563#0:OK-t4. Peer's state: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200:t4, leader=null, voted=78962ee0-dad8-4871-bc4b-e1f0b96bf3d9, raftlog=Memoized:b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:52,606 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:52,606 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:52,610 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:52,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:52,618 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:52,753 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:53,458 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:53,458 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:53,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:53,501 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:53,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:53,610 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:53,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:53,619 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:53,753 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:54,458 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:54,458 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:54,461 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:54,501 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:54,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:54,610 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:54,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-02 20:27:54,619 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:54,753 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:55,459 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:55,459 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:55,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:55,502 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:55,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:55,610 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:55,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:55,619 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:55,753 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:56,459 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:56,459 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:56,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:56,502 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:56,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:56,611 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:56,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:56,619 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:56,754 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:57,459 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:57,459 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:57,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:57,502 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:57,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:57,611 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:57,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-02 20:27:57,619 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:57,634 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5031386142ns, electionTimeout:5029ms
2023-02-02 20:27:57,634 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d767bd78-5310-4536-b2f7-e45413a997a1: shutdown d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState
2023-02-02 20:27:57,634 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
2023-02-02 20:27:57,634 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-02 20:27:57,634 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d767bd78-5310-4536-b2f7-e45413a997a1: start d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145
2023-02-02 20:27:57,638 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145 ELECTION round 0: submit vote requests at term 5 for -1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:57,638 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:57,638 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:57,639 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: receive requestVote(ELECTION, d767bd78-5310-4536-b2f7-e45413a997a1, group-98C2244BC200, 5, (t:0, i:0))
2023-02-02 20:27:57,640 [grpc-default-executor-18] INFO  impl.VoteContext (VoteContext.java:log(49)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FOLLOWER: accept ELECTION from d767bd78-5310-4536-b2f7-e45413a997a1: our priority 0 <= candidate's priority 1
2023-02-02 20:27:57,640 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:d767bd78-5310-4536-b2f7-e45413a997a1
2023-02-02 20:27:57,640 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: shutdown 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState
2023-02-02 20:27:57,640 [grpc-default-executor-18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9: start 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState
2023-02-02 20:27:57,640 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:57,640 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:57,641 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-FollowerState was interrupted
2023-02-02 20:27:57,641 [grpc-default-executor-18] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200 replies to ELECTION vote request: d767bd78-5310-4536-b2f7-e45413a997a1<-78962ee0-dad8-4871-bc4b-e1f0b96bf3d9#0:OK-t5. Peer's state: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200:t5, leader=null, voted=d767bd78-5310-4536-b2f7-e45413a997a1, raftlog=Memoized:78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:57,639 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: receive requestVote(ELECTION, d767bd78-5310-4536-b2f7-e45413a997a1, group-98C2244BC200, 5, (t:0, i:0))
2023-02-02 20:27:57,641 [grpc-default-executor-17] INFO  impl.VoteContext (VoteContext.java:log(49)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FOLLOWER: accept ELECTION from d767bd78-5310-4536-b2f7-e45413a997a1: our priority 0 <= candidate's priority 1
2023-02-02 20:27:57,641 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:d767bd78-5310-4536-b2f7-e45413a997a1
2023-02-02 20:27:57,642 [grpc-default-executor-17] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: shutdown b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState
2023-02-02 20:27:57,642 [grpc-default-executor-17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563: start b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState
2023-02-02 20:27:57,642 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState was interrupted
2023-02-02 20:27:57,643 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-02 20:27:57,643 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-02-02 20:27:57,643 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-02 20:27:57,643 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: d767bd78-5310-4536-b2f7-e45413a997a1<-78962ee0-dad8-4871-bc4b-e1f0b96bf3d9#0:OK-t5
2023-02-02 20:27:57,643 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145 ELECTION round 0: result PASSED
2023-02-02 20:27:57,643 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - d767bd78-5310-4536-b2f7-e45413a997a1: shutdown d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145
2023-02-02 20:27:57,643 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: changes role from CANDIDATE to LEADER at term 5 for changeToLeader
2023-02-02 20:27:57,643 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-98C2244BC200 with new leaderId: d767bd78-5310-4536-b2f7-e45413a997a1
2023-02-02 20:27:57,644 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: change Leader from null to d767bd78-5310-4536-b2f7-e45413a997a1 at term 5 for becomeLeader, leader elected after 25853ms
2023-02-02 20:27:57,644 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-02 20:27:57,644 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:57,644 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-02 20:27:57,644 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-02 20:27:57,644 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-02 20:27:57,645 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-02 20:27:57,645 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-02 20:27:57,645 [grpc-default-executor-17] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200 replies to ELECTION vote request: d767bd78-5310-4536-b2f7-e45413a997a1<-b67f1ce3-fbfb-4e89-9cbc-643abd2f2563#0:OK-t5. Peer's state: b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200:t5, leader=null, voted=d767bd78-5310-4536-b2f7-e45413a997a1, raftlog=Memoized:b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:57,645 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 32d10313-a11a-4058-8165-98c2244bc200, Nodes: 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)b67f1ce3-fbfb-4e89-9cbc-643abd2f2563(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71)d767bd78-5310-4536-b2f7-e45413a997a1(fv-az133-962.yhipumr4050edinzmvad0xeera.cx.internal.cloudapp.net/10.1.1.71), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:d767bd78-5310-4536-b2f7-e45413a997a1, CreationTimestamp2023-02-02T20:27:29.984Z[Etc/UTC]] moved to OPEN state
2023-02-02 20:27:57,645 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-02 20:27:57,647 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-02-02 20:27:57,647 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:57,647 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-02-02 20:27:57,647 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-02-02 20:27:57,647 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-02 20:27:57,647 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:57,647 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-02 20:27:57,647 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-02-02 20:27:57,648 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-02-02 20:27:57,648 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-02 20:27:57,648 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-02-02 20:27:57,648 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-02-02 20:27:57,648 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-02 20:27:57,648 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-02 20:27:57,648 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-02 20:27:57,649 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-02-02 20:27:57,649 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d767bd78-5310-4536-b2f7-e45413a997a1: start d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderStateImpl
2023-02-02 20:27:57,649 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:57,651 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-2/data/ratis/32d10313-a11a-4058-8165-98c2244bc200/current/log_inprogress_0
2023-02-02 20:27:57,663 [d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200-LeaderElection145] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - d767bd78-5310-4536-b2f7-e45413a997a1@group-98C2244BC200: set configuration 0: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:57,668 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-98C2244BC200 with new leaderId: d767bd78-5310-4536-b2f7-e45413a997a1
2023-02-02 20:27:57,668 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: change Leader from null to d767bd78-5310-4536-b2f7-e45413a997a1 at term 5 for appendEntries, leader elected after 25932ms
2023-02-02 20:27:57,672 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200: set configuration 0: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:57,672 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:57,675 [b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - b67f1ce3-fbfb-4e89-9cbc-643abd2f2563@group-98C2244BC200-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-0/data/ratis/32d10313-a11a-4058-8165-98c2244bc200/current/log_inprogress_0
2023-02-02 20:27:57,677 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-98C2244BC200 with new leaderId: d767bd78-5310-4536-b2f7-e45413a997a1
2023-02-02 20:27:57,677 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: change Leader from null to d767bd78-5310-4536-b2f7-e45413a997a1 at term 5 for appendEntries, leader elected after 25915ms
2023-02-02 20:27:57,688 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200: set configuration 0: peers:[b67f1ce3-fbfb-4e89-9cbc-643abd2f2563|rpc:10.1.1.71:40251|dataStream:10.1.1.71:45911|priority:0|startupRole:FOLLOWER, d767bd78-5310-4536-b2f7-e45413a997a1|rpc:10.1.1.71:33759|dataStream:10.1.1.71:36701|priority:1|startupRole:FOLLOWER, 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9|rpc:10.1.1.71:42621|dataStream:10.1.1.71:45109|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-02 20:27:57,689 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-02 20:27:57,690 [78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 78962ee0-dad8-4871-bc4b-e1f0b96bf3d9@group-98C2244BC200-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-c5cd579f-3d6e-4979-b5a6-975bd2cf2937/datanode-1/data/ratis/32d10313-a11a-4058-8165-98c2244bc200/current/log_inprogress_0
2023-02-02 20:27:57,754 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:58,459 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:58,459 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:58,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:58,502 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:58,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:58,611 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:58,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:58,619 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:58,754 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:59,459 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:59,460 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:59,462 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:59,502 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:59,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:27:59,611 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:59,616 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:27:59,619 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:27:59,754 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:00,460 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:00,460 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:00,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-02-02 20:28:00,503 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:00,516 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:28:00,611 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:00,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:28:00,620 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:00,754 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:01,460 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:01,460 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:01,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:28:01,503 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:01,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:28:01,612 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:01,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:28:01,620 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:01,755 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:02,460 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:02,460 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:02,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:28:02,503 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:02,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:28:02,612 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:02,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-02 20:28:02,620 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:02,755 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:03,460 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:03,460 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:03,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:28:03,503 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:03,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:28:03,612 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:03,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:28:03,620 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:03,755 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:04,461 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:04,461 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:04,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:28:04,503 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:04,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:28:04,612 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:04,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:28:04,620 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:04,755 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:05,461 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:05,461 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:05,463 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:28:05,504 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:05,517 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:28:05,613 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:05,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-02 20:28:05,620 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:05,755 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:06,461 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:06,461 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:06,464 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:28:06,504 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:06,518 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-02 20:28:06,613 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:06,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-02 20:28:06,620 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:06,756 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-02 20:28:06,995 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(450)) - Shutting down the Mini Ozone Cluster
2023-02-02 20:28:06,995 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(465)) - Stopping the Mini Ozone Cluster
2023-02-02 20:28:06,995 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(547)) - Stopping the OzoneManager
2023-02-02 20:28:06,995 [Mini-Cluster-Provider-Reap] INFO  om.OzoneManager (OzoneManager.java:stop(2097)) - om1[localhost:0]: Stopping Ozone Manager
2023-02-02 20:28:07,005 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 43711
2023-02-02 20:28:07,009 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-02 20:28:07,010 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-02 20:28:07,012 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - om1: close
2023-02-02 20:28:07,013 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - om1: shutdown server GrpcServerProtocolService now
2023-02-02 20:28:07,013 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - om1: shutdown server GrpcServerProtocolService successfully
2023-02-02 20:28:07,017 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - om1@group-C5BA1605619E: shutdown
2023-02-02 20:28:07,018 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
2023-02-02 20:28:07,018 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2023-02-02 20:28:07,018 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2023-02-02 20:28:07,048 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 88
2023-02-02 20:28:07,049 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(445)) - Current Snapshot Index (t:1, i:88)
2023-02-02 20:28:07,049 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 88
2023-02-02 20:28:07,049 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 88
2023-02-02 20:28:07,049 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-02-02 20:28:07,049 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(541)) - Stopping OMDoubleBuffer flush thread
2023-02-02 20:28:07,049 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(626)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit.
2023-02-02 20:28:07,050 [om1-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - om1@group-C5BA1605619E: closes. applyIndex: 88
2023-02-02 20:28:07,050 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-02 20:28:07,051 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2023-02-02 20:28:07,053 [JvmPauseMonitor33] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-om1: Stopped
2023-02-02 20:28:07,053 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-02-02 20:28:07,054 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(550)) - OMDoubleBuffer flush thread is not running.
2023-02-02 20:28:07,054 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service KeyDeletingService
2023-02-02 20:28:07,054 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service DirectoryDeletingService
2023-02-02 20:28:07,054 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service OpenKeyCleanupService
2023-02-02 20:28:07,054 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SstFilteringService
2023-02-02 20:28:07,055 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@211c159f{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-02-02 20:28:07,056 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@64469ce3{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-02 20:28:07,056 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-02 20:28:07,056 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4163df32{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-02-02 20:28:07,056 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@63293b0{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-02 20:28:07,061 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(524)) - Stopping the HddsDatanodes
2023-02-02 20:28:07,071 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-02 20:28:07,072 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - c2e5a0ee-722e-430e-828a-2d735c45daa1: close
2023-02-02 20:28:07,073 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-02 20:28:07,073 [c2e5a0ee-722e-430e-828a-2d735c45daa1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-503D6BB962B7: shutdown
2023-02-02 20:28:07,073 [c2e5a0ee-722e-430e-828a-2d735c45daa1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-503D6BB962B7,id=c2e5a0ee-722e-430e-828a-2d735c45daa1
2023-02-02 20:28:07,073 [c2e5a0ee-722e-430e-828a-2d735c45daa1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - c2e5a0ee-722e-430e-828a-2d735c45daa1: shutdown c2e5a0ee-722e-430e-828a-2d735c45daa1@group-503D6BB962B7-LeaderStateImpl
2023-02-02 20:28:07,073 [c2e5a0ee-722e-430e-828a-2d735c45daa1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-503D6BB962B7-PendingRequests: sendNotLeaderResponses
2023-02-02 20:28:07,076 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-503D6BB962B7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-503D6BB962B7: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-3/data/ratis/19614568-66de-478a-bf83-503d6bb962b7/sm/snapshot.1_0
2023-02-02 20:28:07,076 [c2e5a0ee-722e-430e-828a-2d735c45daa1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-503D6BB962B7-StateMachineUpdater: set stopIndex = 0
2023-02-02 20:28:07,089 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - c2e5a0ee-722e-430e-828a-2d735c45daa1: shutdown server GrpcServerProtocolService now
2023-02-02 20:28:07,090 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-503D6BB962B7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-503D6BB962B7: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-1ca5169e-081d-4c84-b198-688caf4e4cd2/datanode-3/data/ratis/19614568-66de-478a-bf83-503d6bb962b7/sm/snapshot.1_0 took: 14 ms
2023-02-02 20:28:07,090 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-503D6BB962B7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-503D6BB962B7-StateMachineUpdater: Took a snapshot at index 0
2023-02-02 20:28:07,090 [c2e5a0ee-722e-430e-828a-2d735c45daa1@group-503D6BB962B7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-503D6BB962B7-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-02 20:28:07,091 [grpc-default-executor-9] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-02 20:28:07,091 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 5b8e2765-a6c1-4d85-87a6-bec4168f79ce: close
2023-02-02 20:28:07,093 [c2e5a0ee-722e-430e-828a-2d735c45daa1-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-503D6BB962B7: closes. applyIndex: 0
2023-02-02 20:28:07,093 [c2e5a0ee-722e-430e-828a-2d735c45daa1-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854: shutdown
2023-02-02 20:28:07,093 [c2e5a0ee-722e-430e-828a-2d735c45daa1-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-82E709284854,id=c2e5a0ee-722e-430e-828a-2d735c45daa1
2023-02-02 20:28:07,096 [c2e5a0ee-722e-430e-828a-2d735c45daa1-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - c2e5a0ee-722e-430e-828a-2d735c45daa1: shutdown c2e5a0ee-722e-430e-828a-2d735c45daa1@group-82E709284854-LeaderStateImpl
2023-02-02 20:28:07,096 [5b8e2765-a6c1-4d85-87a6-bec4168f79ce-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 5b8e2765-a6c1-4d85-87a6-bec4168f79ce@group-1C1BA33CCF34: shutdown
2023-02-02 20:28:07,096 [5b8e2765-a6c1-4d85-87a6-bec4168f79ce-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1C1BA33CCF34,id=5b8e2765-a6c1-4d85-87a6-bec4168f79ce
2023-02-02 20:28:07,096 [5b8e2765-a6c1-4d85-87a6-bec4168f79ce-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 5b8e2765-a6c1-4d85-87a6-bec4168f79ce: shutdown 5b8e2765-a6c1-4d85-87a6-bec4168f79ce@group-1C1BA33CCF34-LeaderStateImpl
2023-02-02 20:28:07,096 [5b8e2765-a6c1-4d85-87a6-bec4168f79ce-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 5b8e2765-a6c1-4d85-87a6-bec4168f79ce@group-1C1BA33CCF34-PendingRequests: sendNotLeaderResponses
]]></system-out>
    <system-err><![CDATA[Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1544, target=10.1.1.71:41055} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1579, target=10.1.1.71:41763} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1641, target=10.1.1.71:43893} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1577, target=10.1.1.71:34455} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1573, target=10.1.1.71:41055} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1637, target=10.1.1.71:34455} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1575, target=10.1.1.71:34955} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1519, target=10.1.1.71:34455} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1596, target=10.1.1.71:36489} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1527, target=10.1.1.71:34955} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1607, target=10.1.1.71:41055} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1598, target=10.1.1.71:43893} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1548, target=10.1.1.71:34545} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1635, target=10.1.1.71:36489} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1639, target=10.1.1.71:41055} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1633, target=10.1.1.71:41763} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1571, target=10.1.1.71:36489} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1605, target=10.1.1.71:34955} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1525, target=10.1.1.71:41055} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1521, target=10.1.1.71:41763} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1550, target=10.1.1.71:43893} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1552, target=10.1.1.71:41763} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1546, target=10.1.1.71:36489} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1609, target=10.1.1.71:34455} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Feb 02, 2023 8:27:47 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1523, target=10.1.1.71:43893} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:124)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

]]></system-err>
  </testcase>
  <testcase name="testEnteringMaintenanceNodeCompletesAfterSCMRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="13.091"/>
  <testcase name="testDecommissioningNodesCompleteDecommissionOnSCMRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="33.935"/>
</testsuite>